--- tmp/scribe_data-2.1.1-py3-none-any.whl.zip
+++ tmp/scribe_data-2.2.2-py3-none-any.whl.zip
â”œâ”€â”€ zipinfo {}
â”‚ @@ -1,13 +1,13 @@
â”‚ -Zip file size: 102885 bytes, number of entries: 69
â”‚ +Zip file size: 103197 bytes, number of entries: 69
â”‚  -rw-r--r--  2.0 unx        0 b- defN 22-Apr-06 08:21 scribe_data/__init__.py
â”‚  -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:22 scribe_data/extract_transform/__init__.py
â”‚ --rw-r--r--  2.0 unx    13955 b- defN 22-Oct-01 21:44 scribe_data/extract_transform/extract_wiki.py
â”‚ --rw-r--r--  2.0 unx     6024 b- defN 23-Mar-04 15:35 scribe_data/extract_transform/process_unicode.py
â”‚ --rw-r--r--  2.0 unx    12782 b- defN 22-Nov-06 08:44 scribe_data/extract_transform/process_wiki.py
â”‚ +-rw-r--r--  2.0 unx    13956 b- defN 23-Apr-07 10:11 scribe_data/extract_transform/extract_wiki.py
â”‚ +-rw-r--r--  2.0 unx     6461 b- defN 23-Apr-07 11:06 scribe_data/extract_transform/process_unicode.py
â”‚ +-rw-r--r--  2.0 unx    12783 b- defN 23-Apr-07 10:12 scribe_data/extract_transform/process_wiki.py
â”‚  -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:24 scribe_data/extract_transform/French/__init__.py
â”‚  -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:41 scribe_data/extract_transform/French/nouns/__init__.py
â”‚  -rw-r--r--  2.0 unx     6162 b- defN 22-Oct-16 21:13 scribe_data/extract_transform/French/nouns/format_nouns.py
â”‚  -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:43 scribe_data/extract_transform/French/translations/__init__.py
â”‚  -rw-r--r--  2.0 unx     1297 b- defN 22-Oct-16 21:12 scribe_data/extract_transform/French/translations/format_translations.py
â”‚  -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:43 scribe_data/extract_transform/French/verbs/__init__.py
â”‚  -rw-r--r--  2.0 unx     3968 b- defN 22-Nov-04 22:50 scribe_data/extract_transform/French/verbs/format_verbs.py
â”‚ @@ -58,14 +58,14 @@
â”‚  -rw-r--r--  2.0 unx        0 b- defN 22-Apr-05 19:44 scribe_data/extract_transform/Swedish/verbs/__init__.py
â”‚  -rw-r--r--  2.0 unx     3970 b- defN 22-Oct-16 21:14 scribe_data/extract_transform/Swedish/verbs/format_verbs.py
â”‚  -rw-r--r--  2.0 unx   102823 b- defN 22-Nov-23 22:13 scribe_data/extract_transform/_resources/2021_ranked.tsv
â”‚  -rw-r--r--  2.0 unx        0 b- defN 22-Nov-23 22:13 scribe_data/extract_transform/_resources/__init__.py
â”‚  -rw-r--r--  2.0 unx        0 b- defN 22-Apr-06 08:23 scribe_data/load/__init__.py
â”‚  -rw-r--r--  2.0 unx    12972 b- defN 22-Nov-04 23:06 scribe_data/load/update_data.py
â”‚  -rw-r--r--  2.0 unx     6353 b- defN 22-Nov-21 16:40 scribe_data/load/update_utils.py
â”‚ --rw-r--r--  2.0 unx      389 b- defN 22-Nov-23 22:45 scribe_data-2.1.1.data/data/requirements.txt
â”‚ --rw-r--r--  2.0 unx    32472 b- defN 23-Mar-04 19:21 scribe_data-2.1.1.dist-info/LICENSE.txt
â”‚ --rw-r--r--  2.0 unx    12814 b- defN 23-Mar-04 19:21 scribe_data-2.1.1.dist-info/METADATA
â”‚ --rw-r--r--  2.0 unx       92 b- defN 23-Mar-04 19:21 scribe_data-2.1.1.dist-info/WHEEL
â”‚ --rw-r--r--  2.0 unx       12 b- defN 23-Mar-04 19:21 scribe_data-2.1.1.dist-info/top_level.txt
â”‚ -?rw-rw-r--  2.0 unx     7566 b- defN 23-Mar-04 19:21 scribe_data-2.1.1.dist-info/RECORD
â”‚ -69 files, 309109 bytes uncompressed, 90045 bytes compressed:  70.9%
â”‚ +-rw-r--r--  2.0 unx      389 b- defN 22-Nov-23 22:45 scribe_data-2.2.2.data/data/requirements.txt
â”‚ +-rw-r--r--  2.0 unx    32472 b- defN 23-Apr-07 11:21 scribe_data-2.2.2.dist-info/LICENSE.txt
â”‚ +-rw-r--r--  2.0 unx    13440 b- defN 23-Apr-07 11:21 scribe_data-2.2.2.dist-info/METADATA
â”‚ +-rw-r--r--  2.0 unx       92 b- defN 23-Apr-07 11:21 scribe_data-2.2.2.dist-info/WHEEL
â”‚ +-rw-r--r--  2.0 unx       12 b- defN 23-Apr-07 11:21 scribe_data-2.2.2.dist-info/top_level.txt
â”‚ +?rw-rw-r--  2.0 unx     7566 b- defN 23-Apr-07 11:21 scribe_data-2.2.2.dist-info/RECORD
â”‚ +69 files, 310174 bytes uncompressed, 90357 bytes compressed:  70.9%
â”œâ”€â”€ zipnote {}
â”‚ @@ -183,26 +183,26 @@
â”‚  
â”‚  Filename: scribe_data/load/update_data.py
â”‚  Comment: 
â”‚  
â”‚  Filename: scribe_data/load/update_utils.py
â”‚  Comment: 
â”‚  
â”‚ -Filename: scribe_data-2.1.1.data/data/requirements.txt
â”‚ +Filename: scribe_data-2.2.2.data/data/requirements.txt
â”‚  Comment: 
â”‚  
â”‚ -Filename: scribe_data-2.1.1.dist-info/LICENSE.txt
â”‚ +Filename: scribe_data-2.2.2.dist-info/LICENSE.txt
â”‚  Comment: 
â”‚  
â”‚ -Filename: scribe_data-2.1.1.dist-info/METADATA
â”‚ +Filename: scribe_data-2.2.2.dist-info/METADATA
â”‚  Comment: 
â”‚  
â”‚ -Filename: scribe_data-2.1.1.dist-info/WHEEL
â”‚ +Filename: scribe_data-2.2.2.dist-info/WHEEL
â”‚  Comment: 
â”‚  
â”‚ -Filename: scribe_data-2.1.1.dist-info/top_level.txt
â”‚ +Filename: scribe_data-2.2.2.dist-info/top_level.txt
â”‚  Comment: 
â”‚  
â”‚ -Filename: scribe_data-2.1.1.dist-info/RECORD
â”‚ +Filename: scribe_data-2.2.2.dist-info/RECORD
â”‚  Comment: 
â”‚  
â”‚  Zip file comment:
â”œâ”€â”€ scribe_data/extract_transform/extract_wiki.py
â”‚ @@ -28,17 +28,18 @@
â”‚  from multiprocessing.dummy import Pool as Threadpool
â”‚  
â”‚  import defusedxml.sax
â”‚  import mwparserfromhell
â”‚  import requests
â”‚  import tensorflow as tf
â”‚  from bs4 import BeautifulSoup
â”‚ -from scribe_data.load.update_utils import get_language_iso
â”‚  from tqdm.auto import tqdm
â”‚  
â”‚ +from scribe_data.load.update_utils import get_language_iso
â”‚ +
â”‚  
â”‚  def download_wiki(language="en", target_dir="wiki_dump", file_limit=None, dump_id=None):
â”‚      """
â”‚      Downloads the most recent stable dump of a language's Wikipedia if it is not already present.
â”‚  
â”‚      Parameters
â”‚      ----------
â”œâ”€â”€ scribe_data/extract_transform/process_unicode.py
â”‚ @@ -1,15 +1,15 @@
â”‚  """
â”‚  Process Unicode
â”‚  ------------
â”‚  
â”‚ -Module for processing Unicode based corpuses for autosuggestion generation.
â”‚ +Module for processing Unicode based corpuses for autosuggestion and autocompletion generation.
â”‚  
â”‚  Contents:
â”‚ -    gen_emoji_autosuggestions
â”‚ +    gen_emoji_keywords
â”‚  """
â”‚  
â”‚  import csv
â”‚  import json
â”‚  from importlib.resources import files
â”‚  
â”‚  import emoji
â”‚ @@ -21,61 +21,67 @@
â”‚      get_path_from_process_unicode,
â”‚      get_path_from_update_data,
â”‚  )
â”‚  
â”‚  from . import _resources
â”‚  
â”‚  
â”‚ -def gen_emoji_autosuggestions(
â”‚ +def gen_emoji_keywords(
â”‚      language="English",
â”‚      num_emojis=None,
â”‚ -    num_per_keyword=None,
â”‚ +    emojis_per_keyword=None,
â”‚      ignore_keywords=None,
â”‚ +    export_base_rank=False,
â”‚      update_scribe_apps=False,
â”‚      verbose=True,
â”‚  ):
â”‚      """
â”‚      Generates a dictionary of keywords (keys) and emoji unicode(s) associated with them (values).
â”‚  
â”‚      Parameters
â”‚      ----------
â”‚          language : string (default=en)
â”‚ -            The language autosuggestions are being generated for.
â”‚ +            The language keywords are being generated for.
â”‚  
â”‚          num_emojis : int (default=None)
â”‚ -            The limit for number of emojis that autosuggestions should be generated from.
â”‚ +            The limit for number of emojis that keywords should be generated from.
â”‚  
â”‚ -        num_per_keyword : int (default=None)
â”‚ -            The limit for number of emoji autosuggestions that should be generated per keyword.
â”‚ +        emojis_per_keyword : int (default=None)
â”‚ +            The limit for number of emoji keywords that should be generated per keyword.
â”‚  
â”‚          ignore_keywords : str or list (default=None)
â”‚              Keywords that should be ignored.
â”‚  
â”‚ +        export_base_rank : bool (default=False)
â”‚ +            Whether to export whether the emojis is a base character as well as its rank.
â”‚ +
â”‚          update_scribe_apps : bool (default=False)
â”‚              Saves the created dictionaries as JSONs in Scribe app directories.
â”‚  
â”‚          verbose : bool (default=True)
â”‚              Whether to show a tqdm progress bar for the process.
â”‚  
â”‚      Returns
â”‚      -------
â”‚ -        Autosuggestions dictionaries for emoji keywords-to-unicode are saved locally or uploaded to Scribe apps.
â”‚ +        Keywords dictionary for emoji keywords-to-unicode are saved locally or uploaded to Scribe apps.
â”‚      """
â”‚  
â”‚ -    autosuggest_dict = {}
â”‚ +    keyword_dict = {}
â”‚  
â”‚      iso = get_language_iso(language)
â”‚  
â”‚      if isinstance(ignore_keywords, str):
â”‚          keywords_to_ignore = [ignore_keywords]
â”‚      elif isinstance(ignore_keywords, list):
â”‚          keywords_to_ignore = ignore_keywords
â”‚      else:
â”‚          keywords_to_ignore = []
â”‚  
â”‚ +    keywords_to_ignore = [k.lower() for k in keywords_to_ignore]
â”‚ +
â”‚      # Pre-set up the emoji popularity data.
â”‚      popularity_dict = {}
â”‚  
â”‚      with files(_resources).joinpath("2021_ranked.tsv").open() as popularity_file:
â”‚          tsv_reader = csv.DictReader(popularity_file, delimiter="\t")
â”‚          for tsv_row in tsv_reader:
â”‚              popularity_dict[tsv_row["Emoji"]] = int(tsv_row["Rank"])
â”‚ @@ -92,28 +98,25 @@
â”‚      for cldr_file_key, cldr_file_path in cldr_file_paths.items():
â”‚          with open(cldr_file_path, "r") as file:
â”‚              cldr_data = json.load(file)
â”‚  
â”‚          cldr_dict = cldr_data[cldr_file_key]["annotations"]
â”‚  
â”‚          for cldr_char in tqdm(
â”‚ -            iterable=cldr_dict, 
â”‚ -            desc=f"Characters processed from '{cldr_file_key}' CLDR file for {language}", 
â”‚ -            unit="cldr characters", 
â”‚ +            iterable=cldr_dict,
â”‚ +            desc=f"Characters processed from '{cldr_file_key}' CLDR file for {language}",
â”‚ +            unit="cldr characters",
â”‚              disable=not verbose,
â”‚          ):
â”‚              # Filter CLDR data for emoji characters.
â”‚              if cldr_char in emoji.EMOJI_DATA:
â”‚                  emoji_rank = popularity_dict.get(cldr_char)
â”‚  
â”‚                  # If number limit specified, filter for the highest-ranked emojis.
â”‚ -                if num_emojis and (
â”‚ -                    emoji_rank is None
â”‚ -                    or emoji_rank > num_emojis
â”‚ -                ):
â”‚ +                if num_emojis and (emoji_rank is None or emoji_rank > num_emojis):
â”‚                      continue
â”‚  
â”‚                  # Process for emoji variants.
â”‚                  has_modifier_base = Char.hasBinaryProperty(
â”‚                      cldr_char, UProperty.EMOJI_MODIFIER_BASE
â”‚                  )
â”‚                  if has_modifier_base and len(cldr_char) > 1:
â”‚ @@ -124,48 +127,56 @@
â”‚                  if (
â”‚                      emoji.EMOJI_DATA[cldr_char]["status"]
â”‚                      == emoji.STATUS["fully_qualified"]
â”‚                  ):
â”‚                      emoji_annotations = cldr_dict[cldr_char]
â”‚  
â”‚                      for emoji_keyword in emoji_annotations["default"]:
â”‚ +                        emoji_keyword = emoji_keyword.lower()  # lower case the key
â”‚                          if (
â”‚                              # Use single-word annotations as keywords.
â”‚                              len(emoji_keyword.split()) == 1
â”‚                              and emoji_keyword not in keywords_to_ignore
â”‚                          ):
â”‚ -                            autosuggest_dict.setdefault(emoji_keyword, []).append(
â”‚ +                            keyword_dict.setdefault(emoji_keyword, []).append(
â”‚                                  {
â”‚                                      "emoji": cldr_char,
â”‚                                      "is_base": has_modifier_base,
â”‚                                      "rank": emoji_rank,
â”‚                                  }
â”‚                              )
â”‚  
â”‚      # Sort by rank after all emojis already found per keyword.
â”‚ -    for suggestions in autosuggest_dict.values():
â”‚ -        suggestions.sort(
â”‚ -            key=lambda suggestion: float('inf') if suggestion["rank"] is None else suggestion["rank"]
â”‚ +    for keywords in keyword_dict.values():
â”‚ +        keywords.sort(
â”‚ +            key=lambda suggestion: float("inf")
â”‚ +            if suggestion["rank"] is None
â”‚ +            else suggestion["rank"]
â”‚          )
â”‚  
â”‚          # If specified, enforce limit of emojis per keyword.
â”‚ -        if num_per_keyword and len(suggestions) > num_per_keyword:
â”‚ -            suggestions[:] = suggestions[:num_per_keyword]
â”‚ +        if emojis_per_keyword and len(keywords) > emojis_per_keyword:
â”‚ +            keywords[:] = keywords[:emojis_per_keyword]
â”‚  
â”‚      if verbose:
â”‚          print(
â”‚ -            f"Number of emoji trigger keywords found for {language}: {len(autosuggest_dict)}"
â”‚ +            f"Number of emoji trigger keywords found for {language}: {len(keyword_dict)}"
â”‚          )
â”‚  
â”‚ +    # Remove base status and rank if not needed.
â”‚ +    if not export_base_rank:
â”‚ +        keyword_dict = {
â”‚ +            k: [{"emoji": emoji_options["emoji"]} for emoji_options in v]
â”‚ +            for k, v in keyword_dict.items()
â”‚ +        }
â”‚ +
â”‚      if update_scribe_apps:
â”‚ -        output_path = f"{get_path_from_update_data()}/Scribe-iOS/Keyboards/LanguageKeyboards/{language.capitalize()}/Data/emoji_suggestions.json"
â”‚ +        output_path = f"{get_path_from_update_data()}/Scribe-iOS/Keyboards/LanguageKeyboards/{language.capitalize()}/Data/emoji_keywords.json"
â”‚      else:
â”‚ -        output_path = f"{language.lower()}_emoji_suggestions.json"
â”‚ +        output_path = f"{language.lower()}_emoji_keywords.json"
â”‚  
â”‚      with open(output_path, "w", encoding="utf-8") as file:
â”‚ -        json.dump(autosuggest_dict, file, ensure_ascii=False, indent=0)
â”‚ +        json.dump(keyword_dict, file, ensure_ascii=False, indent=0)
â”‚  
â”‚ -    print(
â”‚ -        f"Emoji autosuggestions for {language} generated and saved to '{output_path}'."
â”‚ -    )
â”‚ +    print(f"Emoji keywords for {language} generated and saved to '{output_path}'.")
â”‚  
â”‚ -    return autosuggest_dict
â”‚ +    return keyword_dict
â”œâ”€â”€ scribe_data/extract_transform/process_wiki.py
â”‚ @@ -14,24 +14,25 @@
â”‚  import warnings
â”‚  from collections import Counter
â”‚  from itertools import chain
â”‚  from urllib.error import HTTPError
â”‚  
â”‚  import numpy as np
â”‚  import regex
â”‚ +from SPARQLWrapper import JSON, POST, SPARQLWrapper
â”‚ +from tqdm.auto import tqdm
â”‚ +
â”‚  from scribe_data.load.update_utils import (  # get_android_data_path, get_desktop_data_path,
â”‚      add_num_commas,
â”‚      get_ios_data_path,
â”‚      get_language_qid,
â”‚      get_language_words_to_ignore,
â”‚      get_language_words_to_remove,
â”‚      get_path_from_process_wiki,
â”‚  )
â”‚ -from SPARQLWrapper import JSON, POST, SPARQLWrapper
â”‚ -from tqdm.auto import tqdm
â”‚  
â”‚  warnings.filterwarnings("ignore", message=r"Passing", category=FutureWarning)
â”‚  
â”‚  # Set SPARQLWrapper query conditions.
â”‚  sparql = SPARQLWrapper("https://query.wikidata.org/sparql")
â”‚  sparql.setReturnFormat(JSON)
â”‚  sparql.setMethod(POST)
â”‚   --- scribe_data-2.1.1.dist-info/LICENSE.txt
â”œâ”€â”€ +++ scribe_data-2.2.2.dist-info/LICENSE.txt
â”‚â”„ Files identical despite different names
â”‚   --- scribe_data-2.1.1.dist-info/METADATA
â”œâ”€â”€ +++ scribe_data-2.2.2.dist-info/METADATA
â”‚â”„ Files 5% similar despite different names
â”‚ @@ -1,10 +1,10 @@
â”‚  Metadata-Version: 2.1
â”‚  Name: scribe-data
â”‚ -Version: 2.1.1
â”‚ +Version: 2.2.2
â”‚  Summary: Wikidata and Wikipedia data extraction for Scribe applications
â”‚  Home-page: https://github.com/scribe-org/Scribe-Data
â”‚  Author: Andrew Tavis McAllister
â”‚  Author-email: andrew.t.mcallister@gmail.com
â”‚  Classifier: Development Status :: 5 - Production/Stable
â”‚  Classifier: Intended Audience :: Developers
â”‚  Classifier: Intended Audience :: Education
â”‚ @@ -32,26 +32,27 @@
â”‚  Requires-Dist: SPARQLWrapper (>=2.0.0)
â”‚  Requires-Dist: tabulate (>=0.8.9)
â”‚  Requires-Dist: tensorflow (>=2.5.1)
â”‚  Requires-Dist: tqdm (==4.56.1)
â”‚  Requires-Dist: transformers (>=4.12)
â”‚  
â”‚  <div align="center">
â”‚ -  <a href="https://github.com/scribe-org/Scribe-Data"><img src="https://raw.githubusercontent.com/scribe-org/Organization/main/logo/ScribeGitHubOrgBanner.png" width=1024 alt="Scribe Logo"></a>
â”‚ +  <a href="https://github.com/scribe-org/Scribe-Data"><img src="https://raw.githubusercontent.com/scribe-org/Scribe-Data/main/.github/resources/images/ScribeDataLogo.png" height=150 alt="Scribe Logo"></a>
â”‚  </div>
â”‚  
â”‚  [![platforms](https://img.shields.io/badge/Wikidata-990000.svg?logo=wikidata&logoColor=ffffff)](https://github.com/scribe-org/Scribe-Data)
â”‚  [![issues](https://img.shields.io/github/issues/scribe-org/Scribe-Data?label=%20&logo=github)](https://github.com/scribe-org/Scribe-Data/issues)
â”‚  [![language](https://img.shields.io/badge/Python%203-306998.svg?logo=python&logoColor=ffffff)](https://github.com/scribe-org/Scribe-Data/blob/main/CONTRIBUTING.md)
â”‚  [![pypi](https://img.shields.io/pypi/v/scribe-data.svg?label=%20&color=4B8BBE)](https://pypi.org/project/scribe-data/)
â”‚  [![pypistatus](https://img.shields.io/pypi/status/scribe-data.svg?label=%20)](https://pypi.org/project/scribe-data/)
â”‚  [![license](https://img.shields.io/github/license/scribe-org/Scribe-Data.svg?label=%20)](https://github.com/scribe-org/Scribe-Data/blob/main/LICENSE.txt)
â”‚  [![coc](https://img.shields.io/badge/Contributor%20Covenant-ff69b4.svg)](https://github.com/scribe-org/Scribe-Data/blob/main/.github/CODE_OF_CONDUCT.md)
â”‚  [![twitter](https://img.shields.io/badge/Twitter-1DA1F2.svg?logo=twitter&logoColor=ffffff)](https://twitter.com/scribe_org)
â”‚  [![codestyle](https://img.shields.io/badge/black-000000.svg)](https://github.com/psf/black)
â”‚ +[![matrix](https://img.shields.io/badge/Matrix-000000.svg?logo=matrix&logoColor=ffffff)](https://matrix.to/#/#scribe_community:matrix.org)
â”‚  
â”‚  ## Wikidata and Wikipedia data extraction for Scribe applications
â”‚  
â”‚  This repository contains the scripts for extracting and formatting data from [Wikidata](https://www.wikidata.org/) and [Wikipedia](https://www.wikipedia.org/) for Scribe applications. Updates to the language keyboard and interface data can be done using [scribe_data/load/update_data.py](https://github.com/scribe-org/Scribe-Data/tree/main/src/scribe_data/load/update_data.py).
â”‚  
â”‚  <a id="contents"></a>
â”‚  
â”‚ @@ -70,15 +71,19 @@
â”‚  
â”‚  The ultimate goal is that this repository will house language packs that are periodically updated with new [Wikidata](https://www.wikidata.org/) lexicographical data, with these packs then being available to download by users of Scribe applications.
â”‚  
â”‚  <a id="contributing"></a>
â”‚  
â”‚  # Contributing [`â‡§`](#contents)
â”‚  
â”‚ -Work that is in progress or could be implemented is tracked in the [issues](https://github.com/scribe-org/Scribe-Data/issues) and [projects](https://github.com/scribe-org/Scribe-Data/projects). Please see the [contribution guidelines](https://github.com/scribe-org/Scribe-Data/blob/main/CONTRIBUTING.md) if you are interested in contributing to Scribe-Data. Also check the [`-priority-`](https://github.com/scribe-org/Scribe-Data/labels/-priority-) labels in the [issues](https://github.com/scribe-org/Scribe-Data/issues) for those that are most important, as well as those marked [`good first issue`](https://github.com/scribe-org/Scribe-Data/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) that are tailored for first time contributors.
â”‚ +<a href="https://matrix.to/#/#scribe_community:matrix.org"><img src="https://raw.githubusercontent.com/scribe-org/Organization/main/resources/images/logos/MatrixLogoGrey.png" height="50" alt="Public Matrix Chat" align="right"></a>
â”‚ +
â”‚ +Scribe uses [Matrix](https://matrix.org/) for communications. You're more than welcome to [join us in our public chat rooms](https://matrix.to/#/#scribe_community:matrix.org) to share ideas, ask questions or just say hi :)
â”‚ +
â”‚ +Please see the [contribution guidelines](https://github.com/scribe-org/Scribe-Data/blob/main/CONTRIBUTING.md) if you are interested in contributing to Scribe-Data. Work that is in progress or could be implemented is tracked in the [issues](https://github.com/scribe-org/Scribe-Data/issues) and [projects](https://github.com/scribe-org/Scribe-Data/projects). Also check the [`-priority-`](https://github.com/scribe-org/Scribe-Data/labels/-priority-) labels in the [issues](https://github.com/scribe-org/Scribe-Data/issues) for those that are most important, as well as those marked [`good first issue`](https://github.com/scribe-org/Scribe-Data/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) that are tailored for first time contributors.
â”‚  
â”‚  After your first few pull requests organization members would be happy to discuss granting you further rights as a contributor, with a maintainer role then being possible after continued interest in the project. Scribe seeks to be an inclusive and supportive organization. We'd love to have you on the team!
â”‚  
â”‚  ### Ways to Help [`â‡§`](#contents)
â”‚  
â”‚  - [Reporting bugs](https://github.com/scribe-org/Scribe-Data/issues/new?assignees=&labels=bug&template=bug_report.yml) as they're found ğŸ
â”‚  - Working on [new features](https://github.com/scribe-org/Scribe-Data/issues?q=is%3Aissue+is%3Aopen+label%3Afeature) âœ¨
â”‚ @@ -134,17 +139,17 @@
â”‚  - [Presentation slides](https://docs.google.com/presentation/d/16ld_rCbwJCiAdRrfhF-Fq9Wm_ciHCbk_HCzGQs6TB1Q/edit?usp=sharing) for [Wikidata Data Reuse Days 2022](https://diff.wikimedia.org/event/wikidata-data-reuse-days-2022/)
â”‚  
â”‚  </p>
â”‚  </details>
â”‚  
â”‚  <div align="center">
â”‚    <br>
â”‚ -    <a href="https://tech-news.wikimedia.de/en/2022/03/18/lexicographical-data-for-language-learners-the-wikidata-based-app-scribe/"><img height="120"src="https://raw.githubusercontent.com/scribe-org/Organization/main/resources/images/wikimedia_deutschland_logo.png" alt="Wikimedia Deutschland Logo"></a>
â”‚ +    <a href="https://tech-news.wikimedia.de/en/2022/03/18/lexicographical-data-for-language-learners-the-wikidata-based-app-scribe/"><img height="120"src="https://raw.githubusercontent.com/scribe-org/Organization/main/resources/images/logos/WikimediaDeutschlandLogo.png" alt="Wikimedia Deutschland Logo"></a>
â”‚      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
â”‚ -    <a href="https://www.mediawiki.org/wiki/New_Developers"><img height="120" src="https://raw.githubusercontent.com/scribe-org/Organization/main/resources/images/mediawiki_logo.png" alt="MediaWiki logo"></a>
â”‚ +    <a href="https://www.mediawiki.org/wiki/New_Developers"><img height="120" src="https://raw.githubusercontent.com/scribe-org/Organization/main/resources/images/logos/MediawikiLogo.png" alt="MediaWiki logo"></a>
â”‚      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
â”‚    <br>
â”‚  </div>
â”‚  
â”‚  # Powered By
â”‚  
â”‚  ### Contributors
â”‚ @@ -167,13 +172,13 @@
â”‚  </p>
â”‚  </details>
â”‚  
â”‚  ### Wikimedia Communities
â”‚  
â”‚  <div align="center">
â”‚    <br>
â”‚ -  <a href="https://www.wikidata.org/"><img height="175" src="https://raw.githubusercontent.com/scribe-org/Organization/main/resources/images/wikidata_logo.png" alt="Wikidata logo"></a>
â”‚ +  <a href="https://www.wikidata.org/"><img height="175" src="https://raw.githubusercontent.com/scribe-org/Organization/main/resources/images/logos/WikidataLogo.png" alt="Wikidata logo"></a>
â”‚    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
â”‚ -  <a href="https://www.wikipedia.org/"><img height="190" src="https://raw.githubusercontent.com/scribe-org/Organization/main/resources/images/wikipedia_logo.png" alt="Wikipedia logo"></a>
â”‚ +  <a href="https://www.wikipedia.org/"><img height="190" src="https://raw.githubusercontent.com/scribe-org/Organization/main/resources/images/logos/WikipediaLogo.png" alt="Wikipedia logo"></a>
â”‚    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
â”‚    <br>
â”‚  </div>
â”‚ â”œâ”€â”€ html2text {}
â”‚ â”‚ @@ -1,8 +1,8 @@
â”‚ â”‚ -Metadata-Version: 2.1 Name: scribe-data Version: 2.1.1 Summary: Wikidata and
â”‚ â”‚ +Metadata-Version: 2.1 Name: scribe-data Version: 2.2.2 Summary: Wikidata and
â”‚ â”‚  Wikipedia data extraction for Scribe applications Home-page: https://
â”‚ â”‚  github.com/scribe-org/Scribe-Data Author: Andrew Tavis McAllister Author-email:
â”‚ â”‚  andrew.t.mcallister@gmail.com Classifier: Development Status :: 5 - Production/
â”‚ â”‚  Stable Classifier: Intended Audience :: Developers Classifier: Intended
â”‚ â”‚  Audience :: Education Classifier: License :: OSI Approved :: GNU General Public
â”‚ â”‚  License v3 (GPLv3) Classifier: Programming Language :: Python Classifier:
â”‚ â”‚  Programming Language :: Python :: 3 Classifier: Programming Language :: Python
â”‚ â”‚ @@ -30,15 +30,17 @@
â”‚ â”‚  (https://pypi.org/project/scribe-data/) [![license](https://img.shields.io/
â”‚ â”‚  github/license/scribe-org/Scribe-Data.svg?label=%20)](https://github.com/
â”‚ â”‚  scribe-org/Scribe-Data/blob/main/LICENSE.txt) [![coc](https://img.shields.io/
â”‚ â”‚  badge/Contributor%20Covenant-ff69b4.svg)](https://github.com/scribe-org/Scribe-
â”‚ â”‚  Data/blob/main/.github/CODE_OF_CONDUCT.md) [![twitter](https://img.shields.io/
â”‚ â”‚  badge/Twitter-1DA1F2.svg?logo=twitter&logoColor=ffffff)](https://twitter.com/
â”‚ â”‚  scribe_org) [![codestyle](https://img.shields.io/badge/black-000000.svg)]
â”‚ â”‚ -(https://github.com/psf/black) ## Wikidata and Wikipedia data extraction for
â”‚ â”‚ +(https://github.com/psf/black) [![matrix](https://img.shields.io/badge/Matrix-
â”‚ â”‚ +000000.svg?logo=matrix&logoColor=ffffff)](https://matrix.to/#/
â”‚ â”‚ +#scribe_community:matrix.org) ## Wikidata and Wikipedia data extraction for
â”‚ â”‚  Scribe applications This repository contains the scripts for extracting and
â”‚ â”‚  formatting data from [Wikidata](https://www.wikidata.org/) and [Wikipedia]
â”‚ â”‚  (https://www.wikipedia.org/) for Scribe applications. Updates to the language
â”‚ â”‚  keyboard and interface data can be done using [scribe_data/load/update_data.py]
â”‚ â”‚  (https://github.com/scribe-org/Scribe-Data/tree/main/src/scribe_data/load/
â”‚ â”‚  update_data.py).  # **Contents** - [Process](#process) - [Contributing]
â”‚ â”‚  (#contributing) - [Supported Languages](#supported-languages) - [Featured By]
â”‚ â”‚ @@ -53,32 +55,36 @@
â”‚ â”‚  effective baseline feature until natural language processing techniques are
â”‚ â”‚  employed. Functions to generate autosuggestions are ran in [scribe_data/load/
â”‚ â”‚  gen_autosuggestions.ipynb](https://github.com/scribe-org/Scribe-Data/blob/main/
â”‚ â”‚  src/scribe_data/load/gen_autosuggestions.ipynb). The ultimate goal is that this
â”‚ â”‚  repository will house language packs that are periodically updated with new
â”‚ â”‚  [Wikidata](https://www.wikidata.org/) lexicographical data, with these packs
â”‚ â”‚  then being available to download by users of Scribe applications.  #
â”‚ â”‚ -Contributing [`Ã¢Â‡Â§`](#contents) Work that is in progress or could be
â”‚ â”‚ -implemented is tracked in the [issues](https://github.com/scribe-org/Scribe-
â”‚ â”‚ -Data/issues) and [projects](https://github.com/scribe-org/Scribe-Data/
â”‚ â”‚ -projects). Please see the [contribution guidelines](https://github.com/scribe-
â”‚ â”‚ -org/Scribe-Data/blob/main/CONTRIBUTING.md) if you are interested in
â”‚ â”‚ -contributing to Scribe-Data. Also check the [`-priority-`](https://github.com/
â”‚ â”‚ -scribe-org/Scribe-Data/labels/-priority-) labels in the [issues](https://
â”‚ â”‚ -github.com/scribe-org/Scribe-Data/issues) for those that are most important, as
â”‚ â”‚ -well as those marked [`good first issue`](https://github.com/scribe-org/Scribe-
â”‚ â”‚ -Data/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) that are
â”‚ â”‚ -tailored for first time contributors. After your first few pull requests
â”‚ â”‚ -organization members would be happy to discuss granting you further rights as a
â”‚ â”‚ -contributor, with a maintainer role then being possible after continued
â”‚ â”‚ -interest in the project. Scribe seeks to be an inclusive and supportive
â”‚ â”‚ -organization. We'd love to have you on the team! ### Ways to Help [`Ã¢Â‡Â§`]
â”‚ â”‚ -(#contents) - [Reporting bugs](https://github.com/scribe-org/Scribe-Data/
â”‚ â”‚ -issues/new?assignees=&labels=bug&template=bug_report.yml) as they're found Ã°ÂŸÂÂ
â”‚ â”‚ -- Working on [new features](https://github.com/scribe-org/Scribe-Data/
â”‚ â”‚ +Contributing [`Ã¢Â‡Â§`](#contents) [Public_Matrix_Chat] Scribe uses [Matrix]
â”‚ â”‚ +(https://matrix.org/) for communications. You're more than welcome to [join us
â”‚ â”‚ +in our public chat rooms](https://matrix.to/#/#scribe_community:matrix.org) to
â”‚ â”‚ +share ideas, ask questions or just say hi :) Please see the [contribution
â”‚ â”‚ +guidelines](https://github.com/scribe-org/Scribe-Data/blob/main/
â”‚ â”‚ +CONTRIBUTING.md) if you are interested in contributing to Scribe-Data. Work
â”‚ â”‚ +that is in progress or could be implemented is tracked in the [issues](https://
â”‚ â”‚ +github.com/scribe-org/Scribe-Data/issues) and [projects](https://github.com/
â”‚ â”‚ +scribe-org/Scribe-Data/projects). Also check the [`-priority-`](https://
â”‚ â”‚ +github.com/scribe-org/Scribe-Data/labels/-priority-) labels in the [issues]
â”‚ â”‚ +(https://github.com/scribe-org/Scribe-Data/issues) for those that are most
â”‚ â”‚ +important, as well as those marked [`good first issue`](https://github.com/
â”‚ â”‚ +scribe-org/Scribe-Data/
â”‚ â”‚ +issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) that are tailored
â”‚ â”‚ +for first time contributors. After your first few pull requests organization
â”‚ â”‚ +members would be happy to discuss granting you further rights as a contributor,
â”‚ â”‚ +with a maintainer role then being possible after continued interest in the
â”‚ â”‚ +project. Scribe seeks to be an inclusive and supportive organization. We'd love
â”‚ â”‚ +to have you on the team! ### Ways to Help [`Ã¢Â‡Â§`](#contents) - [Reporting bugs]
â”‚ â”‚ +(https://github.com/scribe-org/Scribe-Data/issues/
â”‚ â”‚ +new?assignees=&labels=bug&template=bug_report.yml) as they're found Ã°ÂŸÂÂ -
â”‚ â”‚ +Working on [new features](https://github.com/scribe-org/Scribe-Data/
â”‚ â”‚  issues?q=is%3Aissue+is%3Aopen+label%3Afeature) Ã¢ÂœÂ¨ - [Documentation](https://
â”‚ â”‚  github.com/scribe-org/Scribe-Data/
â”‚ â”‚  issues?q=is%3Aissue+is%3Aopen+label%3Adocumentation) for onboarding and project
â”‚ â”‚  cohesion Ã°ÂŸÂ“Â - Adding language data to [Scribe-Data](https://github.com/
â”‚ â”‚  scribe-org/Scribe-Data/issues) via [Wikidata](https://www.wikidata.org/)!
â”‚ â”‚  Ã°ÂŸÂ—ÂƒÃ¯Â¸Â ### Road Map [`Ã¢Â‡Â§`](#contents) The Scribe road map can be followed in
â”‚ â”‚  the organization's [project board](https://github.com/orgs/scribe-org/projects/
â”‚   --- scribe_data-2.1.1.dist-info/RECORD
â”œâ”€â”€ +++ scribe_data-2.2.2.dist-info/RECORD
â”‚â”„ Files 6% similar despite different names
â”‚ @@ -1,12 +1,12 @@
â”‚  scribe_data/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚  scribe_data/extract_transform/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚ -scribe_data/extract_transform/extract_wiki.py,sha256=WoZy0yUk6CLVywfajcdtsJ7tSCcogXUOMX040w29GR0,13955
â”‚ -scribe_data/extract_transform/process_unicode.py,sha256=J8_Bbsc5AvVjWmXQr8VU7zee5pXbo7St6OyyAs9UW4g,6024
â”‚ -scribe_data/extract_transform/process_wiki.py,sha256=IeUQge4aE3g5AZTw5Eb8_1XZGMs4a9-EALlwdiW0Ag0,12782
â”‚ +scribe_data/extract_transform/extract_wiki.py,sha256=YlUAy_P2AbeVIAD1n1oiL282HdmYwEkuoXvDKjqDJ8w,13956
â”‚ +scribe_data/extract_transform/process_unicode.py,sha256=Cp32tkLV0yf_8x57jmyrC4ExvnwOQDD-hGgvlv4Ub9Y,6461
â”‚ +scribe_data/extract_transform/process_wiki.py,sha256=b5R24sRoAVIOalTIHC_c6vk_42lAQcxKmaxTp65_mn0,12783
â”‚  scribe_data/extract_transform/French/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚  scribe_data/extract_transform/French/nouns/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚  scribe_data/extract_transform/French/nouns/format_nouns.py,sha256=OOeZ6GP--vp58GFvZQFdoKDY6Gpj6yYn5FHrTeekZOg,6162
â”‚  scribe_data/extract_transform/French/translations/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚  scribe_data/extract_transform/French/translations/format_translations.py,sha256=1DUUd1ltSAgdim843aXzMrYTPQY4YsaQw6Qh4RPWDMg,1297
â”‚  scribe_data/extract_transform/French/verbs/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚  scribe_data/extract_transform/French/verbs/format_verbs.py,sha256=ZfsPKHosPnv4iwrcSO_yTlbc8zmGtMfUaCJhw4hMeuI,3968
â”‚ @@ -57,13 +57,13 @@
â”‚  scribe_data/extract_transform/Swedish/verbs/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚  scribe_data/extract_transform/Swedish/verbs/format_verbs.py,sha256=OvnLKUjYfSmV5Y3ZxtEcRf3V1lKwAeMB4pODZ8JtDVs,3970
â”‚  scribe_data/extract_transform/_resources/2021_ranked.tsv,sha256=1XXrIZetJHgCBkjmfbCLhuIbO8f4FPqBRLnQ2hH74Bc,102823
â”‚  scribe_data/extract_transform/_resources/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚  scribe_data/load/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚  scribe_data/load/update_data.py,sha256=ouQ9WOk9sYL1kFJfQDkGos0-8jz_5th2TgYB57mtmOA,12972
â”‚  scribe_data/load/update_utils.py,sha256=WXHuMsfkFVK9cMjzfCttpOhFC118UWoZkbKTjx89hlY,6353
â”‚ -scribe_data-2.1.1.data/data/requirements.txt,sha256=C13PXdDAYDT5VJjil2cnMkz4r6dMVXmI5usEZ_Khejk,389
â”‚ -scribe_data-2.1.1.dist-info/LICENSE.txt,sha256=xh8S2nza1Sa9y-1HpMCmA-YNu_2vi2aTPNCI6RMsMD8,32472
â”‚ -scribe_data-2.1.1.dist-info/METADATA,sha256=L1ceIGCsXpxjjM5Stw8o6Xh5McpqD4IkyZnhUeGVmQo,12814
â”‚ -scribe_data-2.1.1.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
â”‚ -scribe_data-2.1.1.dist-info/top_level.txt,sha256=GZ2cJsBl_mJRjLt4ZRE21TpBtIqZMjB46rmPaxur-wo,12
â”‚ -scribe_data-2.1.1.dist-info/RECORD,,
â”‚ +scribe_data-2.2.2.data/data/requirements.txt,sha256=C13PXdDAYDT5VJjil2cnMkz4r6dMVXmI5usEZ_Khejk,389
â”‚ +scribe_data-2.2.2.dist-info/LICENSE.txt,sha256=xh8S2nza1Sa9y-1HpMCmA-YNu_2vi2aTPNCI6RMsMD8,32472
â”‚ +scribe_data-2.2.2.dist-info/METADATA,sha256=B2QlEsaHBJhiPhXPHhg8iinRoSbW6sl-49BHmFo5xMc,13440
â”‚ +scribe_data-2.2.2.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
â”‚ +scribe_data-2.2.2.dist-info/top_level.txt,sha256=GZ2cJsBl_mJRjLt4ZRE21TpBtIqZMjB46rmPaxur-wo,12
â”‚ +scribe_data-2.2.2.dist-info/RECORD,,
