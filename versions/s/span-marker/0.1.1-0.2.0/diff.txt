--- tmp/span_marker-0.1.1.tar.gz
+++ tmp/span_marker-0.2.0.tar.gz
â”œâ”€â”€ filetype from file(1)
â”‚ @@ -1 +1 @@
â”‚ -gzip compressed data, was "span_marker-0.1.1.tar", last modified: Fri Mar 31 08:25:52 2023, max compression
â”‚ +gzip compressed data, was "span_marker-0.2.0.tar", last modified: Thu Apr  6 16:38:24 2023, max compression
â”‚   --- span_marker-0.1.1.tar
â”œâ”€â”€ +++ span_marker-0.2.0.tar
â”‚ â”œâ”€â”€ file list
â”‚ â”‚ @@ -1,22 +1,27 @@
â”‚ â”‚ -drwxrwxrwx   0        0        0        0 2023-03-31 08:25:52.362422 span_marker-0.1.1/
â”‚ â”‚ --rw-rw-rw-   0        0        0     1088 2023-03-28 09:30:50.000000 span_marker-0.1.1/LICENSE
â”‚ â”‚ --rw-rw-rw-   0        0        0     3805 2023-03-31 08:25:52.361422 span_marker-0.1.1/PKG-INFO
â”‚ â”‚ --rw-rw-rw-   0        0        0     3254 2023-03-31 08:10:07.000000 span_marker-0.1.1/README.md
â”‚ â”‚ --rw-rw-rw-   0        0        0     2134 2023-03-30 18:40:21.000000 span_marker-0.1.1/pyproject.toml
â”‚ â”‚ --rw-rw-rw-   0        0        0       42 2023-03-31 08:25:52.362422 span_marker-0.1.1/setup.cfg
â”‚ â”‚ --rw-rw-rw-   0        0        0       41 2023-03-28 09:28:01.000000 span_marker-0.1.1/setup.py
â”‚ â”‚ -drwxrwxrwx   0        0        0        0 2023-03-31 08:25:52.350423 span_marker-0.1.1/span_marker/
â”‚ â”‚ --rw-rw-rw-   0        0        0      352 2023-03-31 08:24:53.000000 span_marker-0.1.1/span_marker/__init__.py
â”‚ â”‚ --rw-rw-rw-   0        0        0     4722 2023-03-30 12:05:00.000000 span_marker-0.1.1/span_marker/configuration.py
â”‚ â”‚ --rw-rw-rw-   0        0        0     3727 2023-03-29 13:01:07.000000 span_marker-0.1.1/span_marker/data_collator.py
â”‚ â”‚ --rw-rw-rw-   0        0        0     4504 2023-03-31 08:23:37.000000 span_marker-0.1.1/span_marker/evaluation.py
â”‚ â”‚ --rw-rw-rw-   0        0        0     4812 2023-03-30 07:38:30.000000 span_marker-0.1.1/span_marker/label_normalizer.py
â”‚ â”‚ --rw-rw-rw-   0        0        0    11365 2023-03-30 14:53:23.000000 span_marker-0.1.1/span_marker/modeling.py
â”‚ â”‚ --rw-rw-rw-   0        0        0     7027 2023-03-30 14:34:34.000000 span_marker-0.1.1/span_marker/tokenizer.py
â”‚ â”‚ --rw-rw-rw-   0        0        0     9591 2023-03-31 07:34:36.000000 span_marker-0.1.1/span_marker/trainer.py
â”‚ â”‚ -drwxrwxrwx   0        0        0        0 2023-03-31 08:25:52.361422 span_marker-0.1.1/span_marker.egg-info/
â”‚ â”‚ --rw-rw-rw-   0        0        0     3805 2023-03-31 08:25:52.000000 span_marker-0.1.1/span_marker.egg-info/PKG-INFO
â”‚ â”‚ --rw-rw-rw-   0        0        0      427 2023-03-31 08:25:52.000000 span_marker-0.1.1/span_marker.egg-info/SOURCES.txt
â”‚ â”‚ --rw-rw-rw-   0        0        0        1 2023-03-31 08:25:52.000000 span_marker-0.1.1/span_marker.egg-info/dependency_links.txt
â”‚ â”‚ --rw-rw-rw-   0        0        0       89 2023-03-31 08:25:52.000000 span_marker-0.1.1/span_marker.egg-info/requires.txt
â”‚ â”‚ --rw-rw-rw-   0        0        0       12 2023-03-31 08:25:52.000000 span_marker-0.1.1/span_marker.egg-info/top_level.txt
â”‚ â”‚ +drwxrwxrwx   0        0        0        0 2023-04-06 16:38:24.208481 span_marker-0.2.0/
â”‚ â”‚ +-rw-rw-rw-   0        0        0     1088 2023-03-28 09:30:50.000000 span_marker-0.2.0/LICENSE
â”‚ â”‚ +-rw-rw-rw-   0        0        0     4282 2023-04-06 16:38:24.207477 span_marker-0.2.0/PKG-INFO
â”‚ â”‚ +-rw-rw-rw-   0        0        0     3705 2023-04-06 15:23:05.000000 span_marker-0.2.0/README.md
â”‚ â”‚ +-rw-rw-rw-   0        0        0     2305 2023-04-06 15:01:25.000000 span_marker-0.2.0/pyproject.toml
â”‚ â”‚ +-rw-rw-rw-   0        0        0       42 2023-04-06 16:38:24.208481 span_marker-0.2.0/setup.cfg
â”‚ â”‚ +-rw-rw-rw-   0        0        0       41 2023-03-28 09:28:01.000000 span_marker-0.2.0/setup.py
â”‚ â”‚ +drwxrwxrwx   0        0        0        0 2023-04-06 16:38:24.194916 span_marker-0.2.0/span_marker/
â”‚ â”‚ +-rw-rw-rw-   0        0        0      352 2023-04-06 16:37:29.000000 span_marker-0.2.0/span_marker/__init__.py
â”‚ â”‚ +-rw-rw-rw-   0        0        0     4825 2023-04-06 07:35:29.000000 span_marker-0.2.0/span_marker/configuration.py
â”‚ â”‚ +-rw-rw-rw-   0        0        0     5389 2023-04-06 13:34:33.000000 span_marker-0.2.0/span_marker/data_collator.py
â”‚ â”‚ +-rw-rw-rw-   0        0        0     4295 2023-04-06 07:35:29.000000 span_marker-0.2.0/span_marker/evaluation.py
â”‚ â”‚ +-rw-rw-rw-   0        0        0     4831 2023-04-06 07:35:29.000000 span_marker-0.2.0/span_marker/label_normalizer.py
â”‚ â”‚ +-rw-rw-rw-   0        0        0    18246 2023-04-06 14:00:45.000000 span_marker-0.2.0/span_marker/modeling.py
â”‚ â”‚ +-rw-rw-rw-   0        0        0     1686 2023-04-06 14:00:45.000000 span_marker-0.2.0/span_marker/output.py
â”‚ â”‚ +-rw-rw-rw-   0        0        0     6313 2023-04-06 09:12:18.000000 span_marker-0.2.0/span_marker/tokenizer.py
â”‚ â”‚ +-rw-rw-rw-   0        0        0    11036 2023-04-06 14:00:45.000000 span_marker-0.2.0/span_marker/trainer.py
â”‚ â”‚ +drwxrwxrwx   0        0        0        0 2023-04-06 16:38:24.205424 span_marker-0.2.0/span_marker.egg-info/
â”‚ â”‚ +-rw-rw-rw-   0        0        0     4282 2023-04-06 16:38:24.000000 span_marker-0.2.0/span_marker.egg-info/PKG-INFO
â”‚ â”‚ +-rw-rw-rw-   0        0        0      522 2023-04-06 16:38:24.000000 span_marker-0.2.0/span_marker.egg-info/SOURCES.txt
â”‚ â”‚ +-rw-rw-rw-   0        0        0        1 2023-04-06 16:38:24.000000 span_marker-0.2.0/span_marker.egg-info/dependency_links.txt
â”‚ â”‚ +-rw-rw-rw-   0        0        0      182 2023-04-06 16:38:24.000000 span_marker-0.2.0/span_marker.egg-info/requires.txt
â”‚ â”‚ +-rw-rw-rw-   0        0        0       12 2023-04-06 16:38:24.000000 span_marker-0.2.0/span_marker.egg-info/top_level.txt
â”‚ â”‚ +drwxrwxrwx   0        0        0        0 2023-04-06 16:38:24.207477 span_marker-0.2.0/tests/
â”‚ â”‚ +-rw-rw-rw-   0        0        0      961 2023-04-06 07:35:29.000000 span_marker-0.2.0/tests/test_configuration.py
â”‚ â”‚ +-rw-rw-rw-   0        0        0     3534 2023-04-06 07:35:29.000000 span_marker-0.2.0/tests/test_modeling.py
â”‚ â”‚ +-rw-rw-rw-   0        0        0     3992 2023-04-06 07:35:29.000000 span_marker-0.2.0/tests/test_trainer.py
â”‚ â”‚   --- span_marker-0.1.1/LICENSE
â”‚ â”œâ”€â”€ +++ span_marker-0.2.0/LICENSE
â”‚ â”‚â”„ Files identical despite different names
â”‚ â”‚   --- span_marker-0.1.1/PKG-INFO
â”‚ â”œâ”€â”€ +++ span_marker-0.2.0/README.md
â”‚ â”‚â”„ Files 21% similar despite different names
â”‚ â”‚ @@ -1,38 +1,34 @@
â”‚ â”‚ -Metadata-Version: 2.1
â”‚ â”‚ -Name: span_marker
â”‚ â”‚ -Version: 0.1.1
â”‚ â”‚ -Summary: Few-Shot Named Entity Recognition using Span Markers
â”‚ â”‚ -Author: Tom Aarsen
â”‚ â”‚ -Maintainer: Tom Aarsen
â”‚ â”‚ -Project-URL: Homepage, https://github.com/tomaarsen/SpanMarkerNER
â”‚ â”‚ -Project-URL: Repository, https://github.com/tomaarsen/SpanMarkerNER
â”‚ â”‚ -Keywords: data-science,natural-language-processing,artificial-intelligence,mlops,nlp,machine-learning,transformers
â”‚ â”‚ -Requires-Python: >=3.7
â”‚ â”‚ -Description-Content-Type: text/markdown
â”‚ â”‚ -Provides-Extra: dev
â”‚ â”‚ -Provides-Extra: wandb
â”‚ â”‚ -License-File: LICENSE
â”‚ â”‚ -
â”‚ â”‚ -# SpanMarker for Named Entity Recognition
â”‚ â”‚ +<h1 align="center">
â”‚ â”‚ +SpanMarker for Named Entity Recognition
â”‚ â”‚ +</h1>
â”‚ â”‚ +<div align="center">
â”‚ â”‚ +
â”‚ â”‚ +[ğŸ¤— Models](https://huggingface.co/models?other=span-marker) |
â”‚ â”‚ +[ğŸ› ï¸ Getting Started In Google Colab](https://colab.research.google.com/github/tomaarsen/SpanMarkerNER/blob/main/notebooks/getting_started.ipynb) |
â”‚ â”‚ +[ğŸ“„ Documentation](https://tomaarsen.github.io/SpanMarkerNER)
â”‚ â”‚ +</div>
â”‚ â”‚  
â”‚ â”‚  SpanMarker is a framework for training powerful Named Entity Recognition models using familiar encoders such as BERT, RoBERTa and DeBERTa.
â”‚ â”‚  Tightly implemented on top of the [ğŸ¤— Transformers](https://github.com/huggingface/transformers/) library, SpanMarker can take advantage of its valuable functionality.
â”‚ â”‚  <!-- like performance dashboard integration, automatic mixed precision, 8-bit inference-->
â”‚ â”‚  
â”‚ â”‚  Based on the [PL-Marker](https://arxiv.org/pdf/2109.06067.pdf) paper, SpanMarker breaks the mold through its accessibility and ease of use. Crucially, SpanMarker works out of the box with many common encoders such as `bert-base-cased` and `roberta-large`, and automatically works with datasets using the `IOB`, `IOB2`, `BIOES`, `BILOU` or no label annotation scheme.
â”‚ â”‚  
â”‚ â”‚ +## Documentation
â”‚ â”‚ +Feel free to have a look at the [documentation](https://tomaarsen.github.io/SpanMarkerNER).
â”‚ â”‚ +
â”‚ â”‚  ## Installation
â”‚ â”‚ -You may install the `span_marker` Python module via `pip` like so:
â”‚ â”‚ +You may install the [`span_marker`](https://pypi.org/project/span-marker) Python module via `pip` like so:
â”‚ â”‚  ```
â”‚ â”‚  pip install span_marker
â”‚ â”‚  ```
â”‚ â”‚  
â”‚ â”‚  ## Quick Start
â”‚ â”‚ -Please have a look at our [Getting Started](examples/getting_started.ipynb) jupyter notebook for details on how SpanMarker is commonly used. That notebook explains the following snippet in more detail.
â”‚ â”‚ +Please have a look at our [Getting Started](notebooks/getting_started.ipynb) notebook for details on how SpanMarker is commonly used. It explains the following snippet in more detail.
â”‚ â”‚  
â”‚ â”‚  ```python
â”‚ â”‚  from datasets import load_dataset
â”‚ â”‚  from span_marker import SpanMarkerModel, Trainer
â”‚ â”‚  from transformers import TrainingArguments
â”‚ â”‚  
â”‚ â”‚  dataset = load_dataset("DFKI-SLT/few-nerd", "supervised")
â”‚ â”‚ @@ -65,14 +61,16 @@
â”‚ â”‚  trainer.train()
â”‚ â”‚  trainer.save_model("my_span_marker_model/checkpoint-final")
â”‚ â”‚  
â”‚ â”‚  metrics = trainer.evaluate()
â”‚ â”‚  print(metrics)
â”‚ â”‚  ```
â”‚ â”‚  
â”‚ â”‚ -For this work is based on [PL-Marker](https://arxiv.org/pdf/2109.06067v5.pdf), you may expect similar results to its [Papers with Code Leaderboard](https://paperswithcode.com/paper/pack-together-entity-and-relation-extraction). Tests, documentation and further information on expected performance will come soon.
â”‚ â”‚ +Because this work is based on [PL-Marker](https://arxiv.org/pdf/2109.06067v5.pdf), you may expect similar results to its [Papers with Code Leaderboard](https://paperswithcode.com/paper/pack-together-entity-and-relation-extraction) results. Tests, documentation and further information on expected performance will come soon.
â”‚ â”‚  
â”‚ â”‚  ## Pretrained Models
â”‚ â”‚  
â”‚ â”‚ -* [`tomaarsen/span-marker-bert-base-fewnerd-fine-super`](https://huggingface.co/tomaarsen/span-marker-bert-base-fewnerd-fine-super) is a model that I have trained in just 4 hours on the finegrained, supervised [Few-NERD dataset](https://huggingface.co/datasets/DFKI-SLT/few-nerd). It reached a 0.7020 Test F1, competitive in the all-time [Few-NERD leaderboard](https://paperswithcode.com/sota/named-entity-recognition-on-few-nerd-sup).
â”‚ â”‚ -See this [Weights and Biases report](https://api.wandb.ai/links/tomaarsen/dm21vbbm) for details. You can observe the model inferences in this [Argilla dataset](https://argilla-span-marker.hf.space/datasets/team/span-marker-bert-base-fewnerd-fine-super) (username: `argilla`, password: `1234`).
â”‚ â”‚ +* [`tomaarsen/span-marker-bert-base-fewnerd-fine-super`](https://huggingface.co/tomaarsen/span-marker-bert-base-fewnerd-fine-super) is a model that I have trained in just 4 hours on the finegrained, supervised [Few-NERD dataset](https://huggingface.co/datasets/DFKI-SLT/few-nerd). It reached a 0.7020 Test F1, competitive in the all-time [Few-NERD leaderboard](https://paperswithcode.com/sota/named-entity-recognition-on-few-nerd-sup). My training script resembles the one that you can see above.
â”‚ â”‚ +  * See this [Weights and Biases report](https://api.wandb.ai/links/tomaarsen/dm21vbbm) for training details.
â”‚ â”‚  
â”‚ â”‚ +## Changelog
â”‚ â”‚ +See [CHANGELOG.md](CHANGELOG.md) for news on all SpanMarker versions.
â”‚ â”‚   --- span_marker-0.1.1/README.md
â”‚ â”œâ”€â”€ +++ span_marker-0.2.0/PKG-INFO
â”‚ â”‚â”„ Files 21% similar despite different names
â”‚ â”‚ @@ -1,23 +1,50 @@
â”‚ â”‚ -# SpanMarker for Named Entity Recognition
â”‚ â”‚ +Metadata-Version: 2.1
â”‚ â”‚ +Name: span_marker
â”‚ â”‚ +Version: 0.2.0
â”‚ â”‚ +Summary: Few-Shot Named Entity Recognition using Span Markers
â”‚ â”‚ +Author: Tom Aarsen
â”‚ â”‚ +Maintainer: Tom Aarsen
â”‚ â”‚ +Project-URL: Documentation, https://tomaarsen.github.io/SpanMarkerNER
â”‚ â”‚ +Project-URL: Repository, https://github.com/tomaarsen/SpanMarkerNER
â”‚ â”‚ +Keywords: data-science,natural-language-processing,artificial-intelligence,mlops,nlp,machine-learning,transformers
â”‚ â”‚ +Requires-Python: >=3.7
â”‚ â”‚ +Description-Content-Type: text/markdown
â”‚ â”‚ +Provides-Extra: dev
â”‚ â”‚ +Provides-Extra: docs
â”‚ â”‚ +Provides-Extra: wandb
â”‚ â”‚ +License-File: LICENSE
â”‚ â”‚ +
â”‚ â”‚ +<h1 align="center">
â”‚ â”‚ +SpanMarker for Named Entity Recognition
â”‚ â”‚ +</h1>
â”‚ â”‚ +<div align="center">
â”‚ â”‚ +
â”‚ â”‚ +[ğŸ¤— Models](https://huggingface.co/models?other=span-marker) |
â”‚ â”‚ +[ğŸ› ï¸ Getting Started In Google Colab](https://colab.research.google.com/github/tomaarsen/SpanMarkerNER/blob/main/notebooks/getting_started.ipynb) |
â”‚ â”‚ +[ğŸ“„ Documentation](https://tomaarsen.github.io/SpanMarkerNER)
â”‚ â”‚ +</div>
â”‚ â”‚  
â”‚ â”‚  SpanMarker is a framework for training powerful Named Entity Recognition models using familiar encoders such as BERT, RoBERTa and DeBERTa.
â”‚ â”‚  Tightly implemented on top of the [ğŸ¤— Transformers](https://github.com/huggingface/transformers/) library, SpanMarker can take advantage of its valuable functionality.
â”‚ â”‚  <!-- like performance dashboard integration, automatic mixed precision, 8-bit inference-->
â”‚ â”‚  
â”‚ â”‚  Based on the [PL-Marker](https://arxiv.org/pdf/2109.06067.pdf) paper, SpanMarker breaks the mold through its accessibility and ease of use. Crucially, SpanMarker works out of the box with many common encoders such as `bert-base-cased` and `roberta-large`, and automatically works with datasets using the `IOB`, `IOB2`, `BIOES`, `BILOU` or no label annotation scheme.
â”‚ â”‚  
â”‚ â”‚ +## Documentation
â”‚ â”‚ +Feel free to have a look at the [documentation](https://tomaarsen.github.io/SpanMarkerNER).
â”‚ â”‚ +
â”‚ â”‚  ## Installation
â”‚ â”‚ -You may install the `span_marker` Python module via `pip` like so:
â”‚ â”‚ +You may install the [`span_marker`](https://pypi.org/project/span-marker) Python module via `pip` like so:
â”‚ â”‚  ```
â”‚ â”‚  pip install span_marker
â”‚ â”‚  ```
â”‚ â”‚  
â”‚ â”‚  ## Quick Start
â”‚ â”‚ -Please have a look at our [Getting Started](examples/getting_started.ipynb) jupyter notebook for details on how SpanMarker is commonly used. That notebook explains the following snippet in more detail.
â”‚ â”‚ +Please have a look at our [Getting Started](notebooks/getting_started.ipynb) notebook for details on how SpanMarker is commonly used. It explains the following snippet in more detail.
â”‚ â”‚  
â”‚ â”‚  ```python
â”‚ â”‚  from datasets import load_dataset
â”‚ â”‚  from span_marker import SpanMarkerModel, Trainer
â”‚ â”‚  from transformers import TrainingArguments
â”‚ â”‚  
â”‚ â”‚  dataset = load_dataset("DFKI-SLT/few-nerd", "supervised")
â”‚ â”‚ @@ -50,14 +77,16 @@
â”‚ â”‚  trainer.train()
â”‚ â”‚  trainer.save_model("my_span_marker_model/checkpoint-final")
â”‚ â”‚  
â”‚ â”‚  metrics = trainer.evaluate()
â”‚ â”‚  print(metrics)
â”‚ â”‚  ```
â”‚ â”‚  
â”‚ â”‚ -For this work is based on [PL-Marker](https://arxiv.org/pdf/2109.06067v5.pdf), you may expect similar results to its [Papers with Code Leaderboard](https://paperswithcode.com/paper/pack-together-entity-and-relation-extraction). Tests, documentation and further information on expected performance will come soon.
â”‚ â”‚ +Because this work is based on [PL-Marker](https://arxiv.org/pdf/2109.06067v5.pdf), you may expect similar results to its [Papers with Code Leaderboard](https://paperswithcode.com/paper/pack-together-entity-and-relation-extraction) results. Tests, documentation and further information on expected performance will come soon.
â”‚ â”‚  
â”‚ â”‚  ## Pretrained Models
â”‚ â”‚  
â”‚ â”‚ -* [`tomaarsen/span-marker-bert-base-fewnerd-fine-super`](https://huggingface.co/tomaarsen/span-marker-bert-base-fewnerd-fine-super) is a model that I have trained in just 4 hours on the finegrained, supervised [Few-NERD dataset](https://huggingface.co/datasets/DFKI-SLT/few-nerd). It reached a 0.7020 Test F1, competitive in the all-time [Few-NERD leaderboard](https://paperswithcode.com/sota/named-entity-recognition-on-few-nerd-sup).
â”‚ â”‚ -See this [Weights and Biases report](https://api.wandb.ai/links/tomaarsen/dm21vbbm) for details. You can observe the model inferences in this [Argilla dataset](https://argilla-span-marker.hf.space/datasets/team/span-marker-bert-base-fewnerd-fine-super) (username: `argilla`, password: `1234`).
â”‚ â”‚ +* [`tomaarsen/span-marker-bert-base-fewnerd-fine-super`](https://huggingface.co/tomaarsen/span-marker-bert-base-fewnerd-fine-super) is a model that I have trained in just 4 hours on the finegrained, supervised [Few-NERD dataset](https://huggingface.co/datasets/DFKI-SLT/few-nerd). It reached a 0.7020 Test F1, competitive in the all-time [Few-NERD leaderboard](https://paperswithcode.com/sota/named-entity-recognition-on-few-nerd-sup). My training script resembles the one that you can see above.
â”‚ â”‚ +  * See this [Weights and Biases report](https://api.wandb.ai/links/tomaarsen/dm21vbbm) for training details.
â”‚ â”‚  
â”‚ â”‚ +## Changelog
â”‚ â”‚ +See [CHANGELOG.md](CHANGELOG.md) for news on all SpanMarker versions.
â”‚ â”‚   --- span_marker-0.1.1/pyproject.toml
â”‚ â”œâ”€â”€ +++ span_marker-0.2.0/pyproject.toml
â”‚ â”‚â”„ Files 26% similar despite different names
â”‚ â”‚ @@ -32,37 +32,49 @@
â”‚ â”‚  ]
â”‚ â”‚  dynamic = ["version"]
â”‚ â”‚  
â”‚ â”‚  [project.optional-dependencies]
â”‚ â”‚  dev = [
â”‚ â”‚      "pre-commit",
â”‚ â”‚      "ruff",
â”‚ â”‚ -    "black"
â”‚ â”‚ +    "black",
â”‚ â”‚ +    "pytest",
â”‚ â”‚ +    "pytest-cov"
â”‚ â”‚ +]
â”‚ â”‚ +docs = [
â”‚ â”‚ +    "nltk_theme",
â”‚ â”‚ +    "sphinx",
â”‚ â”‚ +    "m2r2",
â”‚ â”‚ +    "better-apidoc",
â”‚ â”‚ +    "nbsphinx",
â”‚ â”‚ +    "nbconvert<7",
â”‚ â”‚ +    "pandoc<3"
â”‚ â”‚  ]
â”‚ â”‚  wandb = [
â”‚ â”‚      "wandb"
â”‚ â”‚  ]
â”‚ â”‚  
â”‚ â”‚  [project.urls]
â”‚ â”‚ -Homepage = "https://github.com/tomaarsen/SpanMarkerNER"
â”‚ â”‚ +Documentation = "https://tomaarsen.github.io/SpanMarkerNER"
â”‚ â”‚  Repository = "https://github.com/tomaarsen/SpanMarkerNER"
â”‚ â”‚  
â”‚ â”‚  [tool.setuptools.packages.find]
â”‚ â”‚  include = ["span_marker"]
â”‚ â”‚  
â”‚ â”‚  [tool.setuptools.dynamic]
â”‚ â”‚  version = {attr = "span_marker.__version__"}
â”‚ â”‚  
â”‚ â”‚  [tool.pytest.ini_options]
â”‚ â”‚ -log_format = "%(asctime)s %(name)s %(levelname)s %(message)s"
â”‚ â”‚ -log_date_format = "%Y-%m-%d %H:%M:%S"
â”‚ â”‚ -log_cli = "True"
â”‚ â”‚  testpaths = [
â”‚ â”‚      "tests"
â”‚ â”‚  ]
â”‚ â”‚ +filterwarnings = [
â”‚ â”‚ +    "ignore::DeprecationWarning:tensorboard.*:"
â”‚ â”‚ +]
â”‚ â”‚ +addopts = "--cov=span_marker --durations=10"
â”‚ â”‚  
â”‚ â”‚  [tool.coverage.report]
â”‚ â”‚  exclude_lines = [
â”‚ â”‚      "pragma: no cover",
â”‚ â”‚      "def __repr__",
â”‚ â”‚      "def __str__",
â”‚ â”‚      "raise AssertionError",
â”‚ â”‚   --- span_marker-0.1.1/span_marker/configuration.py
â”‚ â”œâ”€â”€ +++ span_marker-0.2.0/span_marker/configuration.py
â”‚ â”‚â”„ Files 21% similar despite different names
â”‚ â”‚ @@ -2,14 +2,15 @@
â”‚ â”‚  from typing import Any, Dict, Iterable, Optional, Set, Union
â”‚ â”‚  
â”‚ â”‚  from transformers import PretrainedConfig
â”‚ â”‚  
â”‚ â”‚  
â”‚ â”‚  class SpanMarkerConfig(PretrainedConfig):
â”‚ â”‚      model_type: str = "span-marker"
â”‚ â”‚ +    is_composition = True
â”‚ â”‚  
â”‚ â”‚      def __init__(
â”‚ â”‚          self,
â”‚ â”‚          encoder_config: Optional[Dict[str, Any]] = None,
â”‚ â”‚          model_max_length: Optional[int] = None,
â”‚ â”‚          marker_max_length: int = 256,
â”‚ â”‚          entity_max_length: int = 16,
â”‚ â”‚ @@ -17,62 +18,57 @@
â”‚ â”‚      ) -> None:
â”‚ â”‚          self.encoder = encoder_config
â”‚ â”‚          self.model_max_length = model_max_length
â”‚ â”‚          self.model_max_length_default = 512
â”‚ â”‚          self.marker_max_length = marker_max_length
â”‚ â”‚          self.entity_max_length = entity_max_length
â”‚ â”‚          super().__init__(**kwargs)
â”‚ â”‚ -        # These are automatically set by super().__init__, but we want to rely on
â”‚ â”‚ -        # the encoder configs instead if we can, so we delete them.
â”‚ â”‚ -        del self.id2label
â”‚ â”‚ -        del self.label2id
â”‚ â”‚  
â”‚ â”‚ -        if encoder_config is None:
â”‚ â”‚ -            return
â”‚ â”‚ -
â”‚ â”‚ -        # If the id2label of the encoder is not overridden
â”‚ â”‚ -        if self.id2label == {0: "LABEL_0", 1: "LABEL_1"}:
â”‚ â”‚ -            raise ValueError(
â”‚ â”‚ -                "Please provide a `labels` list to `SpanMarkerModel.from_pretrained()`, e.g.\n"
â”‚ â”‚ -                ">>> SpanMarkerModel.from_pretrained(\n"
â”‚ â”‚ -                '...     "roberta-large",\n'
â”‚ â”‚ -                '...     labels=["O", "B-PER", "I-PER", "B-ORG", "I-ORG", ...]\n'
â”‚ â”‚ -                "... )\n"
â”‚ â”‚ -                "or\n"
â”‚ â”‚ -                ">>> SpanMarkerModel.from_pretrained(\n"
â”‚ â”‚ -                '...     "roberta-large",\n'
â”‚ â”‚ -                '...     labels=["O", "PER", "ORG", "LOC", "MISC"]\n'
â”‚ â”‚ -                "... )"
â”‚ â”‚ -            )
â”‚ â”‚ -
â”‚ â”‚ -        if self.id2label and "O" not in self.label2id:
â”‚ â”‚ -            raise Exception("There must be an 'O' label.")
â”‚ â”‚ -
â”‚ â”‚ -        # TODO: Consider converting this into several properties
â”‚ â”‚ -        if self.are_labels_schemed():
â”‚ â”‚ +        # label2id and id2label are automatically set by super().__init__, but we want to rely on
â”‚ â”‚ +        # the encoder configs instead if we can, so we delete them under two conditions
â”‚ â”‚ +        # 1. if they're the default ({0: "LABEL_0", 1: "LABEL_1"})
â”‚ â”‚ +        # 2. if they're identical to the encoder label2id
â”‚ â”‚ +        span_marker_label2id = super().__getattribute__("label2id")
â”‚ â”‚ +        if span_marker_label2id == {"LABEL_0": 0, "LABEL_1": 1} or span_marker_label2id == self.encoder.get("label2id"):
â”‚ â”‚ +            del self.id2label
â”‚ â”‚ +            del self.label2id
â”‚ â”‚ +
â”‚ â”‚ +        # We need the "O" label for label normalization, etc.
â”‚ â”‚ +        if self.label2id and "O" not in self.label2id:
â”‚ â”‚ +            raise ValueError("There must be an 'O' label in the list of `labels`.")
â”‚ â”‚ +
â”‚ â”‚ +        # Keys are always strings in JSON so convert ids to int here.
â”‚ â”‚ +        self.encoder["id2label"] = {int(label_id): label for label_id, label in self.encoder["id2label"].items()}
â”‚ â”‚ +        if hasattr(self, "id2reduced_id"):
â”‚ â”‚ +            self.id2reduced_id = {int(label_id): reduced_id for label_id, reduced_id in self.id2reduced_id.items()}
â”‚ â”‚ +        elif self.are_labels_schemed():
â”‚ â”‚              reduced_labels = {label[2:] for label in self.label2id.keys() if label != "O"}
â”‚ â”‚              reduced_labels = ["O"] + sorted(reduced_labels)
â”‚ â”‚              self.id2reduced_id = {
â”‚ â”‚                  _id: reduced_labels.index(label[2:] if label != "O" else label) for label, _id in self.label2id.items()
â”‚ â”‚              }
â”‚ â”‚              self.id2label = dict(enumerate(reduced_labels))
â”‚ â”‚              self.label2id = {v: k for k, v in self.id2label.items()}
â”‚ â”‚ -            self.outside_id = 0
â”‚ â”‚ -        else:
â”‚ â”‚ -            self.outside_id = self.label2id["O"]
â”‚ â”‚ +
â”‚ â”‚ +    @property
â”‚ â”‚ +    def outside_id(self) -> None:
â”‚ â”‚ +        return self.label2id["O"]
â”‚ â”‚  
â”‚ â”‚      def __setattr__(self, name, value) -> None:
â”‚ â”‚          """Whenever the vocab_size is updated, update it for both the SpanMarkerConfig and the
â”‚ â”‚          underlying encoder config.
â”‚ â”‚          """
â”‚ â”‚          if name == "vocab_size":
â”‚ â”‚              self.encoder[name] = value
â”‚ â”‚ +        # `outside_id` is now a property instead.
â”‚ â”‚ +        if name == "outside_id":
â”‚ â”‚ +            return
â”‚ â”‚          return super().__setattr__(name, value)
â”‚ â”‚  
â”‚ â”‚ -    def __getattribute__(self, key: str):
â”‚ â”‚ +    def __getattribute__(self, key: str) -> Any:
â”‚ â”‚          try:
â”‚ â”‚              return super().__getattribute__(key)
â”‚ â”‚          except AttributeError as e:
â”‚ â”‚              try:
â”‚ â”‚                  return super().__getattribute__("encoder")[key]
â”‚ â”‚              except KeyError:
â”‚ â”‚                  raise e
â”‚ â”‚   --- span_marker-0.1.1/span_marker/evaluation.py
â”‚ â”œâ”€â”€ +++ span_marker-0.2.0/span_marker/evaluation.py
â”‚ â”‚â”„ Files 4% similar despite different names
â”‚ â”‚ @@ -49,17 +49,15 @@
â”‚ â”‚              }
â”‚ â”‚          else:
â”‚ â”‚              sample_dict[token_hash]["gold_labels"] += gold_labels[sample_idx].tolist()
â”‚ â”‚              sample_dict[token_hash]["pred_labels"] += pred_labels[sample_idx].tolist()
â”‚ â”‚              sample_dict[token_hash]["scores"] += scores[sample_idx].tolist()
â”‚ â”‚  
â”‚ â”‚      outside_id = tokenizer.config.outside_id
â”‚ â”‚ -    id2label = {int(label_id): label for label_id, label in tokenizer.config.id2label.items()}
â”‚ â”‚ -    if tokenizer.config.are_labels_schemed():
â”‚ â”‚ -        id2label = {label_id: id2label[tokenizer.config.id2reduced_id[label_id]] for label_id in id2label}
â”‚ â”‚ +    id2label = tokenizer.config.id2label
â”‚ â”‚      # seqeval works wonders for NER evaluation
â”‚ â”‚      seqeval = evaluate.load("seqeval")
â”‚ â”‚      for sample in sample_dict.values():
â”‚ â”‚          spans = sample["spans"]
â”‚ â”‚          scores = sample["scores"]
â”‚ â”‚          num_words = sample["num_words"]
â”‚ â”‚          gold_labels = sample["gold_labels"]
â”‚ â”‚   --- span_marker-0.1.1/span_marker/label_normalizer.py
â”‚ â”œâ”€â”€ +++ span_marker-0.2.0/span_marker/label_normalizer.py
â”‚ â”‚â”„ Files 1% similar despite different names
â”‚ â”‚ @@ -14,15 +14,15 @@
â”‚ â”‚  
â”‚ â”‚      def __init__(self, config: SpanMarkerConfig) -> None:
â”‚ â”‚          super().__init__()
â”‚ â”‚          self.config = config
â”‚ â”‚  
â”‚ â”‚      @abstractmethod
â”‚ â”‚      def __call__(self, ner_tags: List[int]) -> Dict[str, List[Any]]:
â”‚ â”‚ -        return
â”‚ â”‚ +        raise NotImplementedError
â”‚ â”‚  
â”‚ â”‚  
â”‚ â”‚  class LabelNormalizerScheme(LabelNormalizer):
â”‚ â”‚      def __init__(self, config: SpanMarkerConfig) -> None:
â”‚ â”‚          super().__init__(config)
â”‚ â”‚          self.label_ids_by_tag = self.config.group_label_ids_by_tag()
â”‚ â”‚          self.start_ids = set()
â”‚ â”‚   --- span_marker-0.1.1/span_marker/tokenizer.py
â”‚ â”œâ”€â”€ +++ span_marker-0.2.0/span_marker/tokenizer.py
â”‚ â”‚â”„ Files 7% similar despite different names
â”‚ â”‚ @@ -1,59 +1,51 @@
â”‚ â”‚  import itertools
â”‚ â”‚  import os
â”‚ â”‚  import warnings
â”‚ â”‚ -from typing import Dict, Iterator, List, Tuple, Union
â”‚ â”‚ +from typing import Any, Dict, Iterator, List, Tuple, Union
â”‚ â”‚  
â”‚ â”‚  from transformers import AutoTokenizer, PreTrainedTokenizer
â”‚ â”‚  
â”‚ â”‚  from span_marker.configuration import SpanMarkerConfig
â”‚ â”‚  
â”‚ â”‚  
â”‚ â”‚  class SpanMarkerTokenizer:
â”‚ â”‚ -    # def __init__(self, model: SpanMarkerModel, tokenizer: PreTrainedTokenizer, **kwargs):
â”‚ â”‚      def __init__(self, tokenizer: PreTrainedTokenizer, config: SpanMarkerConfig, **kwargs) -> None:
â”‚ â”‚ -        # super().__init__(**kwargs)
â”‚ â”‚ -        # self.model = model
â”‚ â”‚          self.tokenizer = tokenizer
â”‚ â”‚          self.config = config
â”‚ â”‚  
â”‚ â”‚          tokenizer.add_tokens(["<start>", "<end>"], special_tokens=True)
â”‚ â”‚ -        # tokenizer.add_special_tokens({"additional_special_tokens": ["<start>", "<end>"]})
â”‚ â”‚          self.start_marker_id, self.end_marker_id = self.tokenizer.convert_tokens_to_ids(["<start>", "<end>"])
â”‚ â”‚ -        # self.start_marker_id, self.end_marker_id = self.tokenizer.convert_tokens_to_ids(['madeupword0000', 'madeupword0001'])
â”‚ â”‚ -
â”‚ â”‚ -        # TODO: This could be done more cleverly. Perhaps I can just subclass PreTrainedTokenizerFast?
â”‚ â”‚ -        # I'm concerned about .from_pretrained not initializing a SpanMarkerTokenizer though.
â”‚ â”‚  
â”‚ â”‚          if self.tokenizer.model_max_length > 1e29 and self.config.model_max_length is None:
â”‚ â”‚              warnings.warn(
â”‚ â”‚ -                f"Base {self.tokenizer.__class__.__name__} nor {self.config.__class__.__name__} specify"
â”‚ â”‚ -                f" `model_max_length`: defaulting to {self.model_max_length_default} tokens."
â”‚ â”‚ +                f"The underlying {self.tokenizer.__class__.__name__!r} tokenizer nor {self.config.__class__.__name__!r}"
â”‚ â”‚ +                f" specify `model_max_length`: defaulting to {self.config.model_max_length_default} tokens."
â”‚ â”‚              )
â”‚ â”‚          self.model_max_length = min(
â”‚ â”‚              self.tokenizer.model_max_length, self.config.model_max_length or self.config.model_max_length_default
â”‚ â”‚          )
â”‚ â”‚ -        self.pad = tokenizer.pad
â”‚ â”‚ -        self.save_pretrained = tokenizer.save_pretrained
â”‚ â”‚ -        self.push_to_hub = tokenizer.push_to_hub
â”‚ â”‚ -        self.decode = tokenizer.decode
â”‚ â”‚ -        self.pad_token_id = self.tokenizer.pad_token_id
â”‚ â”‚ -        self.eos_token_id = self.tokenizer.eos_token_id
â”‚ â”‚  
â”‚ â”‚      def get_all_valid_spans(self, num_words: int, entity_max_length: int) -> Iterator[Tuple[int, int]]:
â”‚ â”‚          for start_idx in range(num_words):
â”‚ â”‚              for end_idx in range(start_idx + 1, min(num_words + 1, start_idx + 1 + entity_max_length)):
â”‚ â”‚                  yield (start_idx, end_idx)
â”‚ â”‚  
â”‚ â”‚      def get_all_valid_spans_and_labels(
â”‚ â”‚          self, num_words: int, span_to_label: Dict[Tuple[int, int], int], entity_max_length: int, outside_id: int
â”‚ â”‚      ) -> Iterator[Tuple[Tuple[int, int], int]]:
â”‚ â”‚          for span in self.get_all_valid_spans(num_words, entity_max_length):
â”‚ â”‚              yield span, span_to_label.get(span, outside_id)
â”‚ â”‚  
â”‚ â”‚ +    def __getattribute__(self, key: str) -> Any:
â”‚ â”‚ +        try:
â”‚ â”‚ +            return super().__getattribute__(key)
â”‚ â”‚ +        except AttributeError:
â”‚ â”‚ +            return super().__getattribute__("tokenizer").__getattribute__(key)
â”‚ â”‚ +
â”‚ â”‚      def __call__(
â”‚ â”‚          self, inputs, labels=None, return_num_words: bool = False, return_batch_encoding=False, **kwargs
â”‚ â”‚      ) -> Dict[str, List]:
â”‚ â”‚          # TODO: Increase robustness of this
â”‚ â”‚          is_split_into_words = True
â”‚ â”‚          if isinstance(inputs, str) or (inputs and " " in inputs[0]):
â”‚ â”‚              is_split_into_words = False
â”‚ â”‚ @@ -135,12 +127,11 @@
â”‚ â”‚          return output
â”‚ â”‚  
â”‚ â”‚      def __len__(self) -> int:
â”‚ â”‚          return len(self.tokenizer)
â”‚ â”‚  
â”‚ â”‚      @classmethod
â”‚ â”‚      def from_pretrained(cls, pretrained_model_name_or_path: Union[str, os.PathLike], *inputs, config=None, **kwargs):
â”‚ â”‚ -        # TODO: Consider subclassing an AutoTokenizer directly instead of loading one like this:
â”‚ â”‚          tokenizer = AutoTokenizer.from_pretrained(
â”‚ â”‚              pretrained_model_name_or_path, *inputs, **kwargs, add_prefix_space=True
â”‚ â”‚          )
â”‚ â”‚          return cls(tokenizer, config=config, **kwargs)
â”‚ â”‚   --- span_marker-0.1.1/span_marker/trainer.py
â”‚ â”œâ”€â”€ +++ span_marker-0.2.0/span_marker/trainer.py
â”‚ â”‚â”„ Files 19% similar despite different names
â”‚ â”‚ @@ -1,60 +1,61 @@
â”‚ â”‚ +import warnings
â”‚ â”‚  from typing import Callable, Dict, List, Optional, Tuple
â”‚ â”‚  
â”‚ â”‚  import torch
â”‚ â”‚  from datasets import Dataset
â”‚ â”‚ +from torch.utils.data import DataLoader
â”‚ â”‚  from transformers import (
â”‚ â”‚      EvalPrediction,
â”‚ â”‚      TrainerCallback,
â”‚ â”‚      TrainingArguments,
â”‚ â”‚  )
â”‚ â”‚ -from transformers import (
â”‚ â”‚ -    Trainer as TransformersTrainer,
â”‚ â”‚ -)
â”‚ â”‚ +from transformers import Trainer as TransformersTrainer
â”‚ â”‚ +from transformers.trainer_utils import PredictionOutput
â”‚ â”‚  
â”‚ â”‚  from span_marker.evaluation import compute_f1_via_seqeval
â”‚ â”‚  from span_marker.label_normalizer import AutoLabelNormalizer, LabelNormalizer
â”‚ â”‚  from span_marker.modeling import SpanMarkerModel
â”‚ â”‚  from span_marker.tokenizer import SpanMarkerTokenizer
â”‚ â”‚  
â”‚ â”‚  
â”‚ â”‚  class Trainer(TransformersTrainer):
â”‚ â”‚      """
â”‚ â”‚      Trainer is a simple but feature-complete training and eval loop for SpanMarker,
â”‚ â”‚ -    built tightly on top of the ğŸ¤— Transformers Trainer.
â”‚ â”‚ +    built tightly on top of the ğŸ¤— Transformers `Trainer <https://huggingface.co/docs/transformers/main_classes/trainer>`_.
â”‚ â”‚  
â”‚ â”‚      Args:
â”‚ â”‚ -        model (`SpanMarkerModel`, *optional*):
â”‚ â”‚ +        model (Optional[SpanMarkerModel]):
â”‚ â”‚              The model to train, evaluate or use for predictions. If not provided, a `model_init` must be passed.
â”‚ â”‚ -        args (`TrainingArguments`, *optional*):
â”‚ â”‚ +        args (Optional[TrainingArguments]):
â”‚ â”‚              The arguments to tweak for training. Will default to a basic instance of [`TrainingArguments`] with the
â”‚ â”‚              `output_dir` set to a directory named *tmp_trainer* in the current directory if not provided.
â”‚ â”‚ -        train_dataset (`datasets.Dataset`, *optional*):
â”‚ â”‚ +        train_dataset (Optional[datasets.Dataset]):
â”‚ â”‚              The dataset to use for training.
â”‚ â”‚ -        eval_dataset (`datasets.Dataset`, *optional*):
â”‚ â”‚ +        eval_dataset (Optional[datasets.Dataset]):
â”‚ â”‚               The dataset to use for evaluation.
â”‚ â”‚ -        model_init (`Callable[[], SpanMarkerModel]`, *optional*):
â”‚ â”‚ +        model_init (Optional[Callable[[], SpanMarkerModel]]):
â”‚ â”‚              A function that instantiates the model to be used. If provided, each call to `Trainer.train` will start
â”‚ â”‚              from a new instance of the model as given by this function.
â”‚ â”‚  
â”‚ â”‚              The function may have zero argument, or a single one containing the optuna/Ray Tune/SigOpt trial object, to
â”‚ â”‚              be able to choose different architectures according to hyper parameters (such as layer count, sizes of
â”‚ â”‚              inner layers, dropout probabilities etc).
â”‚ â”‚ -        compute_metrics (`Callable[[EvalPrediction], Dict]`, *optional*):
â”‚ â”‚ +        compute_metrics (Optional[Callable[[EvalPrediction], Dict]]):
â”‚ â”‚              The function that will be used to compute metrics at evaluation. Must take a [`EvalPrediction`] and return
â”‚ â”‚              a dictionary string to metric values.
â”‚ â”‚ -        callbacks (List of [`TrainerCallback`], *optional*):
â”‚ â”‚ +        callbacks (Optional[List[TrainerCallback]]):
â”‚ â”‚              A list of callbacks to customize the training loop. Will add those to the list of default callbacks
â”‚ â”‚              detailed in [here](https://huggingface.co/docs/transformers/main/en/main_classes/callback).
â”‚ â”‚  
â”‚ â”‚              If you want to remove one of the default callbacks used, use the [`Trainer.remove_callback`] method.
â”‚ â”‚ -        optimizers (`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`, *optional*): A tuple
â”‚ â”‚ +        optimizers (Tuple[Optional[torch.optim.Optimizer], Optional[torch.optim.lr_scheduler.LambdaLR]]): A tuple
â”‚ â”‚              containing the optimizer and the scheduler to use. Will default to an instance of `AdamW` on your model
â”‚ â”‚              and a scheduler given by `get_linear_schedule_with_warmup` controlled by `args`.
â”‚ â”‚ -        preprocess_logits_for_metrics (`Callable[[torch.Tensor, torch.Tensor], torch.Tensor]`, *optional*):
â”‚ â”‚ +        preprocess_logits_for_metrics (Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]]):
â”‚ â”‚              A function that preprocess the logits right before caching them at each evaluation step. Must take two
â”‚ â”‚              tensors, the logits and the labels, and return the logits once processed as desired. The modifications made
â”‚ â”‚              by this function will be reflected in the predictions received by `compute_metrics`.
â”‚ â”‚  
â”‚ â”‚              Note that the labels (second parameter) will be `None` if the dataset does not have them.
â”‚ â”‚  
â”‚ â”‚      Important attributes:
â”‚ â”‚ @@ -71,63 +72,56 @@
â”‚ â”‚            `TrainingArguments.place_model_on_device` is overridden to return `False` .
â”‚ â”‚          - **is_in_train** -- Whether or not a model is currently running `train` (e.g. when `evaluate` is called while
â”‚ â”‚            in `train`)
â”‚ â”‚      """
â”‚ â”‚  
â”‚ â”‚      def __init__(
â”‚ â”‚          self,
â”‚ â”‚ -        model: SpanMarkerModel = None,
â”‚ â”‚ -        args: TrainingArguments = None,
â”‚ â”‚ +        model: Optional[SpanMarkerModel] = None,
â”‚ â”‚ +        args: Optional[TrainingArguments] = None,
â”‚ â”‚          train_dataset: Optional[Dataset] = None,
â”‚ â”‚          eval_dataset: Optional[Dataset] = None,
â”‚ â”‚          model_init: Callable[[], SpanMarkerModel] = None,
â”‚ â”‚          compute_metrics: Optional[Callable[[EvalPrediction], Dict]] = None,
â”‚ â”‚          callbacks: Optional[List[TrainerCallback]] = None,
â”‚ â”‚ -        optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None),
â”‚ â”‚ -        preprocess_logits_for_metrics: Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = None,
â”‚ â”‚ +        optimizers: Tuple[Optional[torch.optim.Optimizer], Optional[torch.optim.lr_scheduler.LambdaLR]] = (None, None),
â”‚ â”‚ +        preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,
â”‚ â”‚      ) -> None:
â”‚ â”‚          # Extract the model from an initializer function
â”‚ â”‚          if model_init:
â”‚ â”‚              self.model_init = model_init
â”‚ â”‚              model = self.call_model_init()
â”‚ â”‚  
â”‚ â”‚          # To convert dataset labels to a common format (list of label-start-end tuples)
â”‚ â”‚ -        label_normalizer = AutoLabelNormalizer.from_config(model.config)
â”‚ â”‚ -        # Normalize labels & tokenize the provided datasets
â”‚ â”‚ -        if train_dataset:
â”‚ â”‚ -            train_dataset = self.preprocess_dataset(train_dataset, label_normalizer, model.tokenizer)
â”‚ â”‚ -        if eval_dataset:
â”‚ â”‚ -            eval_dataset = self.preprocess_dataset(
â”‚ â”‚ -                eval_dataset, label_normalizer, model.tokenizer, dataset_name="eval", is_evaluate=True
â”‚ â”‚ -            )
â”‚ â”‚ +        self.label_normalizer = AutoLabelNormalizer.from_config(model.config)
â”‚ â”‚  
â”‚ â”‚          # Set some Training arguments that must be set for SpanMarker
â”‚ â”‚          if args is None:
â”‚ â”‚              args = TrainingArguments(output_dir="models/my_span_marker_model")
â”‚ â”‚          args.include_inputs_for_metrics = True
â”‚ â”‚          args.remove_unused_columns = False
â”‚ â”‚  
â”‚ â”‚          # Always compute `compute_f1_via_seqeval` - optionally compute user-provided metrics
â”‚ â”‚          if compute_metrics is not None:
â”‚ â”‚ -            compute_metrics = lambda eval_prediction: {
â”‚ â”‚ +            compute_metrics_func = lambda eval_prediction: {
â”‚ â”‚                  **compute_f1_via_seqeval(model.tokenizer, eval_prediction),
â”‚ â”‚                  **compute_metrics(eval_prediction),
â”‚ â”‚              }
â”‚ â”‚          else:
â”‚ â”‚ -            compute_metrics = lambda eval_prediction: compute_f1_via_seqeval(model.tokenizer, eval_prediction)
â”‚ â”‚ +            compute_metrics_func = lambda eval_prediction: compute_f1_via_seqeval(model.tokenizer, eval_prediction)
â”‚ â”‚  
â”‚ â”‚          super().__init__(
â”‚ â”‚              model=model,
â”‚ â”‚              args=args,
â”‚ â”‚              data_collator=model.data_collator,
â”‚ â”‚              train_dataset=train_dataset,
â”‚ â”‚              eval_dataset=eval_dataset,
â”‚ â”‚              tokenizer=model.tokenizer,
â”‚ â”‚              model_init=None,
â”‚ â”‚ -            compute_metrics=compute_metrics,
â”‚ â”‚ +            compute_metrics=compute_metrics_func,
â”‚ â”‚              callbacks=callbacks,
â”‚ â”‚              optimizers=optimizers,
â”‚ â”‚              preprocess_logits_for_metrics=preprocess_logits_for_metrics,
â”‚ â”‚          )
â”‚ â”‚          # We have to provide the __init__ with None for model_init and then override it here again
â”‚ â”‚          # We do this because we need `model` to already be defined in this SpanMarker Trainer class
â”‚ â”‚          # and the Transformers Trainer would complain if we provide both a model and a model_init
â”‚ â”‚ @@ -174,7 +168,39 @@
â”‚ â”‚          dataset = dataset.map(
â”‚ â”‚              lambda batch: tokenizer(batch["tokens"], labels=batch["ner_tags"], return_num_words=is_evaluate),
â”‚ â”‚              batched=True,
â”‚ â”‚              remove_columns=dataset.column_names,
â”‚ â”‚              desc=f"Tokenizing the {dataset_name} dataset",
â”‚ â”‚          )
â”‚ â”‚          return dataset
â”‚ â”‚ +
â”‚ â”‚ +    def get_train_dataloader(self) -> DataLoader:
â”‚ â”‚ +        """Return the preprocessed training DataLoader."""
â”‚ â”‚ +        self.train_dataset = self.preprocess_dataset(self.train_dataset, self.label_normalizer, self.tokenizer)
â”‚ â”‚ +        return super().get_train_dataloader()
â”‚ â”‚ +
â”‚ â”‚ +    def get_eval_dataloader(self, eval_dataset: Optional[Dataset] = None) -> DataLoader:
â”‚ â”‚ +        """Return the preprocessed evaluation DataLoader."""
â”‚ â”‚ +        eval_dataset = eval_dataset or self.eval_dataset
â”‚ â”‚ +        if eval_dataset is not None:
â”‚ â”‚ +            eval_dataset = self.preprocess_dataset(
â”‚ â”‚ +                eval_dataset, self.label_normalizer, self.tokenizer, dataset_name="evaluation", is_evaluate=True
â”‚ â”‚ +            )
â”‚ â”‚ +        return super().get_eval_dataloader(eval_dataset)
â”‚ â”‚ +
â”‚ â”‚ +    def get_test_dataloader(self, test_dataset: Dataset) -> DataLoader:
â”‚ â”‚ +        """Return the preprocessed evaluation DataLoader."""
â”‚ â”‚ +        test_dataset = self.preprocess_dataset(
â”‚ â”‚ +            test_dataset, self.label_normalizer, self.tokenizer, dataset_name="test", is_evaluate=True
â”‚ â”‚ +        )
â”‚ â”‚ +        return super().get_test_dataloader(test_dataset)
â”‚ â”‚ +
â”‚ â”‚ +    def predict(
â”‚ â”‚ +        self, test_dataset: Dataset, ignore_keys: Optional[List[str]] = None, metric_key_prefix: str = "test"
â”‚ â”‚ +    ) -> PredictionOutput:
â”‚ â”‚ +        warnings.warn(
â”‚ â”‚ +            f"`Trainer.predict` is not recommended for a {self.model.__class__.__name__}. "
â”‚ â”‚ +            f"Consider using `{self.model.__class__.__name__}.predict` instead.",
â”‚ â”‚ +            UserWarning,
â”‚ â”‚ +            stacklevel=2,
â”‚ â”‚ +        )
â”‚ â”‚ +        return super().predict(test_dataset, ignore_keys, metric_key_prefix)
â”‚ â”‚   --- span_marker-0.1.1/span_marker.egg-info/PKG-INFO
â”‚ â”œâ”€â”€ +++ span_marker-0.2.0/span_marker.egg-info/PKG-INFO
â”‚ â”‚â”„ Files 23% similar despite different names
â”‚ â”‚ @@ -1,38 +1,50 @@
â”‚ â”‚  Metadata-Version: 2.1
â”‚ â”‚  Name: span-marker
â”‚ â”‚ -Version: 0.1.1
â”‚ â”‚ +Version: 0.2.0
â”‚ â”‚  Summary: Few-Shot Named Entity Recognition using Span Markers
â”‚ â”‚  Author: Tom Aarsen
â”‚ â”‚  Maintainer: Tom Aarsen
â”‚ â”‚ -Project-URL: Homepage, https://github.com/tomaarsen/SpanMarkerNER
â”‚ â”‚ +Project-URL: Documentation, https://tomaarsen.github.io/SpanMarkerNER
â”‚ â”‚  Project-URL: Repository, https://github.com/tomaarsen/SpanMarkerNER
â”‚ â”‚  Keywords: data-science,natural-language-processing,artificial-intelligence,mlops,nlp,machine-learning,transformers
â”‚ â”‚  Requires-Python: >=3.7
â”‚ â”‚  Description-Content-Type: text/markdown
â”‚ â”‚  Provides-Extra: dev
â”‚ â”‚ +Provides-Extra: docs
â”‚ â”‚  Provides-Extra: wandb
â”‚ â”‚  License-File: LICENSE
â”‚ â”‚  
â”‚ â”‚ -# SpanMarker for Named Entity Recognition
â”‚ â”‚ +<h1 align="center">
â”‚ â”‚ +SpanMarker for Named Entity Recognition
â”‚ â”‚ +</h1>
â”‚ â”‚ +<div align="center">
â”‚ â”‚ +
â”‚ â”‚ +[ğŸ¤— Models](https://huggingface.co/models?other=span-marker) |
â”‚ â”‚ +[ğŸ› ï¸ Getting Started In Google Colab](https://colab.research.google.com/github/tomaarsen/SpanMarkerNER/blob/main/notebooks/getting_started.ipynb) |
â”‚ â”‚ +[ğŸ“„ Documentation](https://tomaarsen.github.io/SpanMarkerNER)
â”‚ â”‚ +</div>
â”‚ â”‚  
â”‚ â”‚  SpanMarker is a framework for training powerful Named Entity Recognition models using familiar encoders such as BERT, RoBERTa and DeBERTa.
â”‚ â”‚  Tightly implemented on top of the [ğŸ¤— Transformers](https://github.com/huggingface/transformers/) library, SpanMarker can take advantage of its valuable functionality.
â”‚ â”‚  <!-- like performance dashboard integration, automatic mixed precision, 8-bit inference-->
â”‚ â”‚  
â”‚ â”‚  Based on the [PL-Marker](https://arxiv.org/pdf/2109.06067.pdf) paper, SpanMarker breaks the mold through its accessibility and ease of use. Crucially, SpanMarker works out of the box with many common encoders such as `bert-base-cased` and `roberta-large`, and automatically works with datasets using the `IOB`, `IOB2`, `BIOES`, `BILOU` or no label annotation scheme.
â”‚ â”‚  
â”‚ â”‚ +## Documentation
â”‚ â”‚ +Feel free to have a look at the [documentation](https://tomaarsen.github.io/SpanMarkerNER).
â”‚ â”‚ +
â”‚ â”‚  ## Installation
â”‚ â”‚ -You may install the `span_marker` Python module via `pip` like so:
â”‚ â”‚ +You may install the [`span_marker`](https://pypi.org/project/span-marker) Python module via `pip` like so:
â”‚ â”‚  ```
â”‚ â”‚  pip install span_marker
â”‚ â”‚  ```
â”‚ â”‚  
â”‚ â”‚  ## Quick Start
â”‚ â”‚ -Please have a look at our [Getting Started](examples/getting_started.ipynb) jupyter notebook for details on how SpanMarker is commonly used. That notebook explains the following snippet in more detail.
â”‚ â”‚ +Please have a look at our [Getting Started](notebooks/getting_started.ipynb) notebook for details on how SpanMarker is commonly used. It explains the following snippet in more detail.
â”‚ â”‚  
â”‚ â”‚  ```python
â”‚ â”‚  from datasets import load_dataset
â”‚ â”‚  from span_marker import SpanMarkerModel, Trainer
â”‚ â”‚  from transformers import TrainingArguments
â”‚ â”‚  
â”‚ â”‚  dataset = load_dataset("DFKI-SLT/few-nerd", "supervised")
â”‚ â”‚ @@ -65,14 +77,16 @@
â”‚ â”‚  trainer.train()
â”‚ â”‚  trainer.save_model("my_span_marker_model/checkpoint-final")
â”‚ â”‚  
â”‚ â”‚  metrics = trainer.evaluate()
â”‚ â”‚  print(metrics)
â”‚ â”‚  ```
â”‚ â”‚  
â”‚ â”‚ -For this work is based on [PL-Marker](https://arxiv.org/pdf/2109.06067v5.pdf), you may expect similar results to its [Papers with Code Leaderboard](https://paperswithcode.com/paper/pack-together-entity-and-relation-extraction). Tests, documentation and further information on expected performance will come soon.
â”‚ â”‚ +Because this work is based on [PL-Marker](https://arxiv.org/pdf/2109.06067v5.pdf), you may expect similar results to its [Papers with Code Leaderboard](https://paperswithcode.com/paper/pack-together-entity-and-relation-extraction) results. Tests, documentation and further information on expected performance will come soon.
â”‚ â”‚  
â”‚ â”‚  ## Pretrained Models
â”‚ â”‚  
â”‚ â”‚ -* [`tomaarsen/span-marker-bert-base-fewnerd-fine-super`](https://huggingface.co/tomaarsen/span-marker-bert-base-fewnerd-fine-super) is a model that I have trained in just 4 hours on the finegrained, supervised [Few-NERD dataset](https://huggingface.co/datasets/DFKI-SLT/few-nerd). It reached a 0.7020 Test F1, competitive in the all-time [Few-NERD leaderboard](https://paperswithcode.com/sota/named-entity-recognition-on-few-nerd-sup).
â”‚ â”‚ -See this [Weights and Biases report](https://api.wandb.ai/links/tomaarsen/dm21vbbm) for details. You can observe the model inferences in this [Argilla dataset](https://argilla-span-marker.hf.space/datasets/team/span-marker-bert-base-fewnerd-fine-super) (username: `argilla`, password: `1234`).
â”‚ â”‚ +* [`tomaarsen/span-marker-bert-base-fewnerd-fine-super`](https://huggingface.co/tomaarsen/span-marker-bert-base-fewnerd-fine-super) is a model that I have trained in just 4 hours on the finegrained, supervised [Few-NERD dataset](https://huggingface.co/datasets/DFKI-SLT/few-nerd). It reached a 0.7020 Test F1, competitive in the all-time [Few-NERD leaderboard](https://paperswithcode.com/sota/named-entity-recognition-on-few-nerd-sup). My training script resembles the one that you can see above.
â”‚ â”‚ +  * See this [Weights and Biases report](https://api.wandb.ai/links/tomaarsen/dm21vbbm) for training details.
â”‚ â”‚  
â”‚ â”‚ +## Changelog
â”‚ â”‚ +See [CHANGELOG.md](CHANGELOG.md) for news on all SpanMarker versions.
