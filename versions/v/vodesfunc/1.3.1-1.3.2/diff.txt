--- tmp/vodesfunc-1.3.1.tar.gz
+++ tmp/vodesfunc-1.3.2.tar.gz
├── filetype from file(1)
│ @@ -1 +1 @@
│ -gzip compressed data, was "vodesfunc-1.3.1.tar", last modified: Fri Mar 31 19:52:13 2023, max compression
│ +gzip compressed data, was "vodesfunc-1.3.2.tar", last modified: Thu Apr  6 21:21:01 2023, max compression
│   --- vodesfunc-1.3.1.tar
├── +++ vodesfunc-1.3.2.tar
│ ├── file list
│ │ @@ -1,46 +1,33 @@
│ │ -drwxr-xr-x   0 alex      (1000) alex      (1000)        0 2023-03-31 19:52:13.784377 vodesfunc-1.3.1/
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)       58 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/.gitignore
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     1062 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/LICENSE
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)       56 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/MANIFEST.in
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     1161 2023-03-31 19:52:13.784377 vodesfunc-1.3.1/PKG-INFO
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)      362 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/README.md
│ │ -drwxr-xr-x   0 alex      (1000) alex      (1000)        0 2023-03-31 19:52:13.781044 vodesfunc-1.3.1/docs/
│ │ -drwxr-xr-x   0 alex      (1000) alex      (1000)        0 2023-03-31 19:52:13.781044 vodesfunc-1.3.1/docs/changelogs/
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)      305 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/docs/changelogs/changelogs.rst
│ │ -drwxr-xr-x   0 alex      (1000) alex      (1000)        0 2023-03-31 19:52:13.781044 vodesfunc-1.3.1/docs/submodules/
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)      717 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/docs/submodules/automation.rst
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)      160 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/docs/submodules/misc.rst
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)      166 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/docs/submodules/scale.rst
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)      154 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/docs/submodules/util.rst
│ │ -drwxr-xr-x   0 alex      (1000) alex      (1000)        0 2023-03-31 19:52:13.781044 vodesfunc-1.3.1/examples/
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     1728 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/examples/01 - Basic Encode.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     1840 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/examples/02 - Batch Muxing.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)      237 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/examples/config.ini
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)      324 2023-03-25 00:35:55.000000 vodesfunc-1.3.1/requirements.txt
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)       38 2023-03-31 19:52:13.784377 vodesfunc-1.3.1/setup.cfg
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     1702 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/setup.py
│ │ -drwxr-xr-x   0 alex      (1000) alex      (1000)        0 2023-03-31 19:52:13.784377 vodesfunc-1.3.1/vodesfunc/
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)      312 2023-03-25 00:20:24.000000 vodesfunc-1.3.1/vodesfunc/__init__.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)      350 2023-03-31 19:51:51.000000 vodesfunc-1.3.1/vodesfunc/_metadata.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     1736 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/vodesfunc/aa.py
│ │ -drwxr-xr-x   0 alex      (1000) alex      (1000)        0 2023-03-31 19:52:13.784377 vodesfunc-1.3.1/vodesfunc/auto/
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     3777 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/vodesfunc/auto/convert.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     2777 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/vodesfunc/auto/download.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)    17809 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/vodesfunc/auto/fonts.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)    16192 2023-03-18 19:49:49.000000 vodesfunc-1.3.1/vodesfunc/auto/muxing.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     4664 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/vodesfunc/auto/parsing.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     1793 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/vodesfunc/auto/webhook.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)    31552 2023-03-31 19:50:25.000000 vodesfunc-1.3.1/vodesfunc/automation.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     4528 2023-03-31 19:51:30.000000 vodesfunc-1.3.1/vodesfunc/denoise.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)    12219 2023-03-19 23:51:47.000000 vodesfunc-1.3.1/vodesfunc/descale.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     3520 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/vodesfunc/misc.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     7176 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/vodesfunc/noise.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)    10896 2023-03-24 17:50:09.000000 vodesfunc-1.3.1/vodesfunc/scale.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)      623 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/vodesfunc/types.py
│ │ --rw-r--r--   0 alex      (1000) alex      (1000)     7341 2023-03-18 11:28:05.000000 vodesfunc-1.3.1/vodesfunc/util.py
│ │ -drwxr-xr-x   0 alex      (1000) alex      (1000)        0 2023-03-31 19:52:13.784377 vodesfunc-1.3.1/vodesfunc.egg-info/
│ │ --rwxr-xr-x   0 alex      (1000) alex      (1000)     1161 2023-03-31 19:52:13.000000 vodesfunc-1.3.1/vodesfunc.egg-info/PKG-INFO
│ │ --rwxr-xr-x   0 alex      (1000) alex      (1000)      822 2023-03-31 19:52:13.000000 vodesfunc-1.3.1/vodesfunc.egg-info/SOURCES.txt
│ │ --rwxr-xr-x   0 alex      (1000) alex      (1000)        1 2023-03-31 19:52:13.000000 vodesfunc-1.3.1/vodesfunc.egg-info/dependency_links.txt
│ │ --rwxr-xr-x   0 alex      (1000) alex      (1000)      169 2023-03-31 19:52:13.000000 vodesfunc-1.3.1/vodesfunc.egg-info/requires.txt
│ │ --rwxr-xr-x   0 alex      (1000) alex      (1000)       10 2023-03-31 19:52:13.000000 vodesfunc-1.3.1/vodesfunc.egg-info/top_level.txt
│ │ +drwxrwxrwx   0        0        0        0 2023-04-06 21:21:01.935778 vodesfunc-1.3.2/
│ │ +-rw-rw-rw-   0        0        0     1083 2022-09-09 23:13:19.000000 vodesfunc-1.3.2/LICENSE
│ │ +-rw-rw-rw-   0        0        0       60 2022-12-04 22:36:49.000000 vodesfunc-1.3.2/MANIFEST.in
│ │ +-rw-rw-rw-   0        0        0     1196 2023-04-06 21:21:01.934778 vodesfunc-1.3.2/PKG-INFO
│ │ +-rw-rw-rw-   0        0        0      374 2022-12-04 22:36:49.000000 vodesfunc-1.3.2/README.md
│ │ +-rw-rw-rw-   0        0        0      340 2022-12-11 22:06:28.000000 vodesfunc-1.3.2/requirements.txt
│ │ +-rw-rw-rw-   0        0        0       42 2023-04-06 21:21:01.935778 vodesfunc-1.3.2/setup.cfg
│ │ +-rw-rw-rw-   0        0        0     1760 2022-12-04 22:36:49.000000 vodesfunc-1.3.2/setup.py
│ │ +drwxrwxrwx   0        0        0        0 2023-04-06 21:21:01.911215 vodesfunc-1.3.2/vodesfunc/
│ │ +-rw-rw-rw-   0        0        0      328 2023-03-25 20:17:58.000000 vodesfunc-1.3.2/vodesfunc/__init__.py
│ │ +-rw-rw-rw-   0        0        0      362 2023-04-06 21:20:30.000000 vodesfunc-1.3.2/vodesfunc/_metadata.py
│ │ +-rw-rw-rw-   0        0        0     1777 2023-01-06 15:15:08.000000 vodesfunc-1.3.2/vodesfunc/aa.py
│ │ +drwxrwxrwx   0        0        0        0 2023-04-06 21:21:01.933778 vodesfunc-1.3.2/vodesfunc/auto/
│ │ +-rw-rw-rw-   0        0        0     3883 2022-11-14 21:15:19.000000 vodesfunc-1.3.2/vodesfunc/auto/convert.py
│ │ +-rw-rw-rw-   0        0        0     2859 2023-01-02 21:02:04.000000 vodesfunc-1.3.2/vodesfunc/auto/download.py
│ │ +-rw-rw-rw-   0        0        0    18298 2023-02-11 15:17:49.000000 vodesfunc-1.3.2/vodesfunc/auto/fonts.py
│ │ +-rw-rw-rw-   0        0        0    16967 2023-04-02 20:43:50.000000 vodesfunc-1.3.2/vodesfunc/auto/muxing.py
│ │ +-rw-rw-rw-   0        0        0     4772 2022-12-25 22:08:09.000000 vodesfunc-1.3.2/vodesfunc/auto/parsing.py
│ │ +-rw-rw-rw-   0        0        0     1850 2022-09-09 23:21:11.000000 vodesfunc-1.3.2/vodesfunc/auto/webhook.py
│ │ +-rw-rw-rw-   0        0        0    32242 2023-04-06 21:19:38.000000 vodesfunc-1.3.2/vodesfunc/automation.py
│ │ +-rw-rw-rw-   0        0        0     4743 2023-04-02 16:40:34.000000 vodesfunc-1.3.2/vodesfunc/denoise.py
│ │ +-rw-rw-rw-   0        0        0    12477 2023-03-25 20:17:58.000000 vodesfunc-1.3.2/vodesfunc/descale.py
│ │ +-rw-rw-rw-   0        0        0     3604 2022-11-26 23:27:32.000000 vodesfunc-1.3.2/vodesfunc/misc.py
│ │ +-rw-rw-rw-   0        0        0     7305 2023-03-13 21:24:06.000000 vodesfunc-1.3.2/vodesfunc/noise.py
│ │ +-rw-rw-rw-   0        0        0    11134 2023-04-06 21:20:11.000000 vodesfunc-1.3.2/vodesfunc/scale.py
│ │ +-rw-rw-rw-   0        0        0      650 2022-12-26 01:30:13.000000 vodesfunc-1.3.2/vodesfunc/types.py
│ │ +-rw-rw-rw-   0        0        0     7542 2023-02-25 18:27:53.000000 vodesfunc-1.3.2/vodesfunc/util.py
│ │ +drwxrwxrwx   0        0        0        0 2023-04-06 21:21:01.928221 vodesfunc-1.3.2/vodesfunc.egg-info/
│ │ +-rw-rw-rw-   0        0        0     1196 2023-04-06 21:21:01.000000 vodesfunc-1.3.2/vodesfunc.egg-info/PKG-INFO
│ │ +-rw-rw-rw-   0        0        0      593 2023-04-06 21:21:01.000000 vodesfunc-1.3.2/vodesfunc.egg-info/SOURCES.txt
│ │ +-rw-rw-rw-   0        0        0        1 2023-04-06 21:21:01.000000 vodesfunc-1.3.2/vodesfunc.egg-info/dependency_links.txt
│ │ +-rw-rw-rw-   0        0        0      169 2023-04-06 21:21:01.000000 vodesfunc-1.3.2/vodesfunc.egg-info/requires.txt
│ │ +-rw-rw-rw-   0        0        0       10 2023-04-06 21:21:01.000000 vodesfunc-1.3.2/vodesfunc.egg-info/top_level.txt
│ │   --- vodesfunc-1.3.1/LICENSE
│ ├── +++ vodesfunc-1.3.2/LICENSE
│ │┄ Ordering differences only
│ │┄ Files 27% similar despite different names
│ │ @@ -1,21 +1,21 @@
│ │ -MIT License
│ │ -
│ │ -Copyright (c) 2022 Vodes
│ │ -
│ │ -Permission is hereby granted, free of charge, to any person obtaining a copy
│ │ -of this software and associated documentation files (the "Software"), to deal
│ │ -in the Software without restriction, including without limitation the rights
│ │ -to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
│ │ -copies of the Software, and to permit persons to whom the Software is
│ │ -furnished to do so, subject to the following conditions:
│ │ -
│ │ -The above copyright notice and this permission notice shall be included in all
│ │ -copies or substantial portions of the Software.
│ │ -
│ │ -THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
│ │ -IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
│ │ -FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
│ │ -AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
│ │ -LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
│ │ -OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
│ │ -SOFTWARE.
│ │ +MIT License
│ │ +
│ │ +Copyright (c) 2022 Vodes
│ │ +
│ │ +Permission is hereby granted, free of charge, to any person obtaining a copy
│ │ +of this software and associated documentation files (the "Software"), to deal
│ │ +in the Software without restriction, including without limitation the rights
│ │ +to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
│ │ +copies of the Software, and to permit persons to whom the Software is
│ │ +furnished to do so, subject to the following conditions:
│ │ +
│ │ +The above copyright notice and this permission notice shall be included in all
│ │ +copies or substantial portions of the Software.
│ │ +
│ │ +THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
│ │ +IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
│ │ +FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
│ │ +AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
│ │ +LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
│ │ +OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
│ │ +SOFTWARE.
│ │   --- vodesfunc-1.3.1/PKG-INFO
│ ├── +++ vodesfunc-1.3.2/PKG-INFO
│ │┄ Files 18% similar despite different names
│ │ @@ -1,35 +1,35 @@
│ │ -Metadata-Version: 2.1
│ │ -Name: vodesfunc
│ │ -Version: 1.3.1
│ │ -Summary: Vodes's Vapoursynth Functions.
│ │ -Author: Vodes
│ │ -Author-email: vodes.imp@gmail.com
│ │ -Maintainer: Vodes
│ │ -Maintainer-email: vodes.imp@gmail.com
│ │ -Project-URL: Source Code, https://github.com/Vodes/vodesfunc
│ │ -Project-URL: Contact, https://discord.gg/Kf94Nv6WVN
│ │ -Classifier: Natural Language :: English
│ │ -Classifier: Intended Audience :: Developers
│ │ -Classifier: Intended Audience :: Other Audience
│ │ -Classifier: Programming Language :: Python :: 3.10
│ │ -Classifier: License :: OSI Approved :: MIT License
│ │ -Classifier: Operating System :: OS Independent
│ │ -Classifier: Typing :: Typed
│ │ -Classifier: Topic :: Multimedia :: Video
│ │ -Classifier: Topic :: Multimedia :: Video :: Display
│ │ -Requires-Python: >=3.10
│ │ -Description-Content-Type: text/markdown
│ │ -License-File: LICENSE
│ │ -
│ │ -# vodesfunc
│ │ -
│ │ -Contains various functions for automation and other stuff I use in my scripts
│ │ -
│ │ -### This is by no means me trying to be professional and as such, the code will not be treated like it.
│ │ -<br>
│ │ -
│ │ -## Installation
│ │ -
│ │ -`pip install vodesfunc` <br>for ~~mostly~~ stable versions
│ │ -
│ │ -`pip install git+https://github.com/Vodes/vodesfunc.git` <br>for absolutely latest
│ │ +Metadata-Version: 2.1
│ │ +Name: vodesfunc
│ │ +Version: 1.3.2
│ │ +Summary: Vodes's Vapoursynth Functions.
│ │ +Author: Vodes
│ │ +Author-email: vodes.imp@gmail.com
│ │ +Maintainer: Vodes
│ │ +Maintainer-email: vodes.imp@gmail.com
│ │ +Project-URL: Source Code, https://github.com/Vodes/vodesfunc
│ │ +Project-URL: Contact, https://discord.gg/Kf94Nv6WVN
│ │ +Classifier: Natural Language :: English
│ │ +Classifier: Intended Audience :: Developers
│ │ +Classifier: Intended Audience :: Other Audience
│ │ +Classifier: Programming Language :: Python :: 3.10
│ │ +Classifier: License :: OSI Approved :: MIT License
│ │ +Classifier: Operating System :: OS Independent
│ │ +Classifier: Typing :: Typed
│ │ +Classifier: Topic :: Multimedia :: Video
│ │ +Classifier: Topic :: Multimedia :: Video :: Display
│ │ +Requires-Python: >=3.10
│ │ +Description-Content-Type: text/markdown
│ │ +License-File: LICENSE
│ │ +
│ │ +# vodesfunc
│ │ +
│ │ +Contains various functions for automation and other stuff I use in my scripts
│ │ +
│ │ +### This is by no means me trying to be professional and as such, the code will not be treated like it.
│ │ +<br>
│ │ +
│ │ +## Installation
│ │ +
│ │ +`pip install vodesfunc` <br>for ~~mostly~~ stable versions
│ │ +
│ │ +`pip install git+https://github.com/Vodes/vodesfunc.git` <br>for absolutely latest
│ │   --- vodesfunc-1.3.1/setup.py
│ ├── +++ vodesfunc-1.3.2/setup.py
│ │┄ Ordering differences only
│ │┄ Files 24% similar despite different names
│ │ @@ -1,58 +1,58 @@
│ │ -#!/usr/bin/env python3
│ │ -
│ │ -import setuptools
│ │ -from pathlib import Path
│ │ -
│ │ -long_description = Path("README.md").read_text()
│ │ -install_requires = Path("requirements.txt").read_text()
│ │ -
│ │ -package_name = "vodesfunc"
│ │ -
│ │ -exec(Path(f'{package_name}/_metadata.py').read_text(), meta := dict[str, str]())
│ │ -
│ │ -setuptools.setup(
│ │ -    name=package_name,
│ │ -    version=meta['__version__'],
│ │ -    author=meta['__author_name__'],
│ │ -    author_email=meta['__author_email__'],
│ │ -    maintainer=meta['__maintainer_name__'],
│ │ -    maintainer_email=meta['__maintainer_email__'],
│ │ -    description=meta['__doc__'],
│ │ -    long_description=long_description,
│ │ -    long_description_content_type="text/markdown",
│ │ -    packages=[
│ │ -        package_name,
│ │ -        f'{package_name}.auto',
│ │ -    ],
│ │ -    package_data={
│ │ -        package_name: ['py.typed'],
│ │ -    },
│ │ -    install_requires=install_requires,
│ │ -    project_urls={
│ │ -        "Source Code": 'https://github.com/Vodes/vodesfunc',
│ │ -        "Contact": 'https://discord.gg/Kf94Nv6WVN',
│ │ -    },
│ │ -    classifiers=[
│ │ -        "Natural Language :: English",
│ │ -
│ │ -        "Intended Audience :: Developers",
│ │ -        "Intended Audience :: Other Audience",
│ │ -
│ │ -        "Programming Language :: Python :: 3.10",
│ │ -        "License :: OSI Approved :: MIT License",
│ │ -        "Operating System :: OS Independent",
│ │ -        "Typing :: Typed",
│ │ -
│ │ -        "Topic :: Multimedia :: Video",
│ │ -        "Topic :: Multimedia :: Video :: Display",
│ │ -    ],
│ │ -    python_requires='>=3.10',
│ │ -    command_options={
│ │ -        "build_sphinx": {
│ │ -            "project": ("setup.py", package_name),
│ │ -            "version": ("setup.py", meta['__version__']),
│ │ -            "release": ("setup.py", meta['__version__']),
│ │ -            "source_dir": ("setup.py", "docs")
│ │ -        }
│ │ -    }
│ │ -)
│ │ +#!/usr/bin/env python3
│ │ +
│ │ +import setuptools
│ │ +from pathlib import Path
│ │ +
│ │ +long_description = Path("README.md").read_text()
│ │ +install_requires = Path("requirements.txt").read_text()
│ │ +
│ │ +package_name = "vodesfunc"
│ │ +
│ │ +exec(Path(f'{package_name}/_metadata.py').read_text(), meta := dict[str, str]())
│ │ +
│ │ +setuptools.setup(
│ │ +    name=package_name,
│ │ +    version=meta['__version__'],
│ │ +    author=meta['__author_name__'],
│ │ +    author_email=meta['__author_email__'],
│ │ +    maintainer=meta['__maintainer_name__'],
│ │ +    maintainer_email=meta['__maintainer_email__'],
│ │ +    description=meta['__doc__'],
│ │ +    long_description=long_description,
│ │ +    long_description_content_type="text/markdown",
│ │ +    packages=[
│ │ +        package_name,
│ │ +        f'{package_name}.auto',
│ │ +    ],
│ │ +    package_data={
│ │ +        package_name: ['py.typed'],
│ │ +    },
│ │ +    install_requires=install_requires,
│ │ +    project_urls={
│ │ +        "Source Code": 'https://github.com/Vodes/vodesfunc',
│ │ +        "Contact": 'https://discord.gg/Kf94Nv6WVN',
│ │ +    },
│ │ +    classifiers=[
│ │ +        "Natural Language :: English",
│ │ +
│ │ +        "Intended Audience :: Developers",
│ │ +        "Intended Audience :: Other Audience",
│ │ +
│ │ +        "Programming Language :: Python :: 3.10",
│ │ +        "License :: OSI Approved :: MIT License",
│ │ +        "Operating System :: OS Independent",
│ │ +        "Typing :: Typed",
│ │ +
│ │ +        "Topic :: Multimedia :: Video",
│ │ +        "Topic :: Multimedia :: Video :: Display",
│ │ +    ],
│ │ +    python_requires='>=3.10',
│ │ +    command_options={
│ │ +        "build_sphinx": {
│ │ +            "project": ("setup.py", package_name),
│ │ +            "version": ("setup.py", meta['__version__']),
│ │ +            "release": ("setup.py", meta['__version__']),
│ │ +            "source_dir": ("setup.py", "docs")
│ │ +        }
│ │ +    }
│ │ +)
│ │   --- vodesfunc-1.3.1/vodesfunc/aa.py
│ ├── +++ vodesfunc-1.3.2/vodesfunc/aa.py
│ │┄ Ordering differences only
│ │┄ Files 15% similar despite different names
│ │ @@ -1,42 +1,42 @@
│ │ -import vapoursynth as vs
│ │ -core = vs.core
│ │ -
│ │ -from .scale import mod_padding
│ │ -
│ │ -from vsrgtools import unsharp_masked
│ │ -from vstools import depth, get_y, join, plane
│ │ -
│ │ -def pre_aa(clip: vs.VideoNode, radius: int = 1, strength: float = 100, opencl: bool = True, **nnedi3_args):
│ │ -    """
│ │ -        A prefilter to use in conjunction with an AA function.
│ │ -        The idea is to fix the luminance uniformity on lineart and make AAing more effective.
│ │ -
│ │ -        :param radius:      Radius used for the unsharp function
│ │ -        :param strength:    Strength used for the unsharp function
│ │ -        :param opencl:      Use nnedi3cl instead of znedi3
│ │ -        :param nnedi3_args: Additional args passed to the respective nnedi function
│ │ -
│ │ -        :return:            Processed clip
│ │ -    """
│ │ -    args = {"qual": 2, "nsize": 0, "nns": 4, "pscrn": 1}
│ │ -    args.update(**nnedi3_args)
│ │ -    clip_y = plane(clip, 0)
│ │ -    
│ │ -    if opencl:
│ │ -        (left, right, top, bottom) = mod_padding(clip_y, 2, 2)
│ │ -        width = clip.width + left + right
│ │ -        height = clip.height + top + bottom
│ │ -        clip_y = clip_y.resize.Point(width, height, src_left=-left, src_top=-top, src_width=width, src_height=height)
│ │ -
│ │ -    for i in range(2):
│ │ -        bob = clip_y.nnedi3cl.NNEDI3CL(field=3, **nnedi3_args) if opencl else \
│ │ -            clip_y.znedi3.nnedi3(field=3, **nnedi3_args)
│ │ -        sharp = unsharp_masked(clip_y, radius, strength)
│ │ -        limit = core.std.Expr([sharp, clip_y, bob[::2], bob[1::2]], "x y z a max max min y z a min min max")
│ │ -        clip_y = limit.std.Transpose()
│ │ -    
│ │ -    if opencl:
│ │ -        clip_y = clip_y.std.Crop(left, right, top, bottom)
│ │ -        clip_y = clip_y.std.CopyFrameProps(clip)
│ │ -
│ │ +import vapoursynth as vs
│ │ +core = vs.core
│ │ +
│ │ +from .scale import mod_padding
│ │ +
│ │ +from vsrgtools import unsharp_masked
│ │ +from vstools import depth, get_y, join, plane
│ │ +
│ │ +def pre_aa(clip: vs.VideoNode, radius: int = 1, strength: float = 100, opencl: bool = True, **nnedi3_args):
│ │ +    """
│ │ +        A prefilter to use in conjunction with an AA function.
│ │ +        The idea is to fix the luminance uniformity on lineart and make AAing more effective.
│ │ +
│ │ +        :param radius:      Radius used for the unsharp function
│ │ +        :param strength:    Strength used for the unsharp function
│ │ +        :param opencl:      Use nnedi3cl instead of znedi3
│ │ +        :param nnedi3_args: Additional args passed to the respective nnedi function
│ │ +
│ │ +        :return:            Processed clip
│ │ +    """
│ │ +    args = {"qual": 2, "nsize": 0, "nns": 4, "pscrn": 1}
│ │ +    args.update(**nnedi3_args)
│ │ +    clip_y = plane(clip, 0)
│ │ +    
│ │ +    if opencl:
│ │ +        (left, right, top, bottom) = mod_padding(clip_y, 2, 2)
│ │ +        width = clip.width + left + right
│ │ +        height = clip.height + top + bottom
│ │ +        clip_y = clip_y.resize.Point(width, height, src_left=-left, src_top=-top, src_width=width, src_height=height)
│ │ +
│ │ +    for i in range(2):
│ │ +        bob = clip_y.nnedi3cl.NNEDI3CL(field=3, **nnedi3_args) if opencl else \
│ │ +            clip_y.znedi3.nnedi3(field=3, **nnedi3_args)
│ │ +        sharp = unsharp_masked(clip_y, radius, strength)
│ │ +        limit = core.std.Expr([sharp, clip_y, bob[::2], bob[1::2]], "x y z a max max min y z a min min max")
│ │ +        clip_y = limit.std.Transpose()
│ │ +    
│ │ +    if opencl:
│ │ +        clip_y = clip_y.std.Crop(left, right, top, bottom)
│ │ +        clip_y = clip_y.std.CopyFrameProps(clip)
│ │ +
│ │      return clip_y if clip.format.color_family == vs.GRAY else join(clip_y, clip)
│ │   --- vodesfunc-1.3.1/vodesfunc/auto/convert.py
│ ├── +++ vodesfunc-1.3.2/vodesfunc/auto/convert.py
│ │┄ Ordering differences only
│ │┄ Files 12% similar despite different names
│ │ @@ -1,107 +1,107 @@
│ │ -from math import trunc
│ │ -from decimal import ROUND_HALF_DOWN, Decimal
│ │ -from fractions import Fraction
│ │ -from datetime import timedelta
│ │ -import vapoursynth as vs
│ │ -
│ │ -__all__: list[str] = [
│ │ -    'mpls_timestamp_to_timedelta',
│ │ -    'timedelta_to_frame',
│ │ -    'frame_to_timedelta',
│ │ -    'format_timedelta',
│ │ -    'timedelta_from_formatted',
│ │ -    'frames_to_samples'
│ │ -]
│ │ -
│ │ -def _fraction_to_decimal(f: Fraction) -> Decimal:
│ │ -    return Decimal(f.numerator) / Decimal(f.denominator)
│ │ -
│ │ -def mpls_timestamp_to_timedelta(timestamp: int) -> timedelta:
│ │ -    """
│ │ -        Converts a mpls timestamp (from BDMV Playlist files) to a timedelta.
│ │ -
│ │ -        :param timestamp:       The mpls timestamp
│ │ -
│ │ -        :return:                The resulting timedelta
│ │ -    """
│ │ -    seconds = Decimal(timestamp) / Decimal(45000)
│ │ -    return timedelta(seconds = float(seconds))
│ │ -
│ │ -def timedelta_to_frame(time: timedelta, fps: Fraction = Fraction(24000, 1001)) -> int:
│ │ -    """
│ │ -        Converts a timedelta to a frame number.
│ │ -
│ │ -        :param time:    The timedelta
│ │ -        :param fps:     A Fraction containing fps_num and fps_den
│ │ -
│ │ -        :return:        The resulting frame number
│ │ -    """
│ │ -
│ │ -    s = Decimal(time.total_seconds())
│ │ -    fps_dec = _fraction_to_decimal(fps)
│ │ -    return round((s * fps_dec))
│ │ -
│ │ -def frame_to_timedelta(f: int, fps: Fraction = Fraction(24000, 1001)) -> timedelta:
│ │ -    """
│ │ -        Converts a frame number to a timedelta.
│ │ -        Mostly used in the conversion for manually defined chapters.
│ │ -
│ │ -        :param f:       The frame number
│ │ -        :param fps:     A Fraction containing fps_num and fps_den
│ │ -
│ │ -        :return:        The resulting timedelta
│ │ -    """
│ │ -    fps_dec = _fraction_to_decimal(fps)
│ │ -    seconds = Decimal(f) / fps_dec
│ │ -    return timedelta(seconds = float(seconds))
│ │ -
│ │ -def format_timedelta(time: timedelta, precision: int = 3) -> str:
│ │ -    """
│ │ -        Formats a timedelta to hh:mm:ss.s[*precision] and pads with 0 if there aren't more numbers to work with.
│ │ -        Mostly to be used for ogm/xml files.
│ │ -
│ │ -        :param time:        The timedelta
│ │ -        :param precision:   3 = milliseconds, 6 = microseconds, 9 = nanoseconds
│ │ -
│ │ -        :return:            The formatted string
│ │ -    """
│ │ -    dec = Decimal(time.total_seconds())
│ │ -    pattern = "." + ''.join(["0"] * (precision - 1)) + "1"
│ │ -    rounded = float(dec.quantize(Decimal(pattern), rounding=ROUND_HALF_DOWN))
│ │ -    s = trunc(rounded)
│ │ -    m = s // 60
│ │ -    s %= 60
│ │ -    h = m // 60
│ │ -    m %= 60
│ │ -    return f'{h:02d}:{m:02d}:{s:02d}.{str(rounded).split(".")[1].ljust(precision, "0")}'
│ │ -
│ │ -def timedelta_from_formatted(formatted: str) -> timedelta:
│ │ -    """
│ │ -        Parses a string with the format of hh:mm:ss.sss
│ │ -        Mostly to be used for ogm/xml files.
│ │ -
│ │ -        :param formatted:       The timestamp string
│ │ -        
│ │ -        :return:                The parsed timedelta
│ │ -    """
│ │ -    # 00:05:25.534...
│ │ -    seconds: float = 0.0
│ │ -    split = formatted.split(':')
│ │ -    seconds += float(split[0]) * 3600
│ │ -    seconds += float(split[1]) * 60
│ │ -    seconds += float(split[2])
│ │ -    return timedelta(seconds=seconds)
│ │ -
│ │ -def frames_to_samples(frame: int, sample_rate: vs.AudioNode | int = 48000, fps: vs.VideoNode | Fraction = Fraction(24000, 1001)) -> int:
│ │ -    """
│ │ -        Converts a frame number to a sample number
│ │ -
│ │ -        :param frame:           The frame number
│ │ -        :param sample_rate:     Can be a flat number like 48000 (=48 kHz) or an AudioNode to get the sample rate from
│ │ -        :param fps:             Can be a Fraction or a VideoNode to get the fps from
│ │ -
│ │ -        :return:                The sample number
│ │ -    """
│ │ -    sample_rate = sample_rate.sample_rate if isinstance(sample_rate, vs.AudioNode) else sample_rate
│ │ -    fps = Fraction(fps.fps_num, fps.fps_den) if isinstance(fps, vs.VideoNode) else fps
│ │ +from math import trunc
│ │ +from decimal import ROUND_HALF_DOWN, Decimal
│ │ +from fractions import Fraction
│ │ +from datetime import timedelta
│ │ +import vapoursynth as vs
│ │ +
│ │ +__all__: list[str] = [
│ │ +    'mpls_timestamp_to_timedelta',
│ │ +    'timedelta_to_frame',
│ │ +    'frame_to_timedelta',
│ │ +    'format_timedelta',
│ │ +    'timedelta_from_formatted',
│ │ +    'frames_to_samples'
│ │ +]
│ │ +
│ │ +def _fraction_to_decimal(f: Fraction) -> Decimal:
│ │ +    return Decimal(f.numerator) / Decimal(f.denominator)
│ │ +
│ │ +def mpls_timestamp_to_timedelta(timestamp: int) -> timedelta:
│ │ +    """
│ │ +        Converts a mpls timestamp (from BDMV Playlist files) to a timedelta.
│ │ +
│ │ +        :param timestamp:       The mpls timestamp
│ │ +
│ │ +        :return:                The resulting timedelta
│ │ +    """
│ │ +    seconds = Decimal(timestamp) / Decimal(45000)
│ │ +    return timedelta(seconds = float(seconds))
│ │ +
│ │ +def timedelta_to_frame(time: timedelta, fps: Fraction = Fraction(24000, 1001)) -> int:
│ │ +    """
│ │ +        Converts a timedelta to a frame number.
│ │ +
│ │ +        :param time:    The timedelta
│ │ +        :param fps:     A Fraction containing fps_num and fps_den
│ │ +
│ │ +        :return:        The resulting frame number
│ │ +    """
│ │ +
│ │ +    s = Decimal(time.total_seconds())
│ │ +    fps_dec = _fraction_to_decimal(fps)
│ │ +    return round((s * fps_dec))
│ │ +
│ │ +def frame_to_timedelta(f: int, fps: Fraction = Fraction(24000, 1001)) -> timedelta:
│ │ +    """
│ │ +        Converts a frame number to a timedelta.
│ │ +        Mostly used in the conversion for manually defined chapters.
│ │ +
│ │ +        :param f:       The frame number
│ │ +        :param fps:     A Fraction containing fps_num and fps_den
│ │ +
│ │ +        :return:        The resulting timedelta
│ │ +    """
│ │ +    fps_dec = _fraction_to_decimal(fps)
│ │ +    seconds = Decimal(f) / fps_dec
│ │ +    return timedelta(seconds = float(seconds))
│ │ +
│ │ +def format_timedelta(time: timedelta, precision: int = 3) -> str:
│ │ +    """
│ │ +        Formats a timedelta to hh:mm:ss.s[*precision] and pads with 0 if there aren't more numbers to work with.
│ │ +        Mostly to be used for ogm/xml files.
│ │ +
│ │ +        :param time:        The timedelta
│ │ +        :param precision:   3 = milliseconds, 6 = microseconds, 9 = nanoseconds
│ │ +
│ │ +        :return:            The formatted string
│ │ +    """
│ │ +    dec = Decimal(time.total_seconds())
│ │ +    pattern = "." + ''.join(["0"] * (precision - 1)) + "1"
│ │ +    rounded = float(dec.quantize(Decimal(pattern), rounding=ROUND_HALF_DOWN))
│ │ +    s = trunc(rounded)
│ │ +    m = s // 60
│ │ +    s %= 60
│ │ +    h = m // 60
│ │ +    m %= 60
│ │ +    return f'{h:02d}:{m:02d}:{s:02d}.{str(rounded).split(".")[1].ljust(precision, "0")}'
│ │ +
│ │ +def timedelta_from_formatted(formatted: str) -> timedelta:
│ │ +    """
│ │ +        Parses a string with the format of hh:mm:ss.sss
│ │ +        Mostly to be used for ogm/xml files.
│ │ +
│ │ +        :param formatted:       The timestamp string
│ │ +        
│ │ +        :return:                The parsed timedelta
│ │ +    """
│ │ +    # 00:05:25.534...
│ │ +    seconds: float = 0.0
│ │ +    split = formatted.split(':')
│ │ +    seconds += float(split[0]) * 3600
│ │ +    seconds += float(split[1]) * 60
│ │ +    seconds += float(split[2])
│ │ +    return timedelta(seconds=seconds)
│ │ +
│ │ +def frames_to_samples(frame: int, sample_rate: vs.AudioNode | int = 48000, fps: vs.VideoNode | Fraction = Fraction(24000, 1001)) -> int:
│ │ +    """
│ │ +        Converts a frame number to a sample number
│ │ +
│ │ +        :param frame:           The frame number
│ │ +        :param sample_rate:     Can be a flat number like 48000 (=48 kHz) or an AudioNode to get the sample rate from
│ │ +        :param fps:             Can be a Fraction or a VideoNode to get the fps from
│ │ +
│ │ +        :return:                The sample number
│ │ +    """
│ │ +    sample_rate = sample_rate.sample_rate if isinstance(sample_rate, vs.AudioNode) else sample_rate
│ │ +    fps = Fraction(fps.fps_num, fps.fps_den) if isinstance(fps, vs.VideoNode) else fps
│ │      return int(sample_rate * (fps.denominator / fps.numerator) * frame)
│ │   --- vodesfunc-1.3.1/vodesfunc/auto/fonts.py
│ ├── +++ vodesfunc-1.3.2/vodesfunc/auto/fonts.py
│ │┄ Ordering differences only
│ │┄ Files 23% similar despite different names
│ │ @@ -1,489 +1,489 @@
│ │ -import logging
│ │ -import os
│ │ -import re
│ │ -import shutil
│ │ -import sys
│ │ -from collections import defaultdict, namedtuple
│ │ -from io import BytesIO
│ │ -from itertools import groupby
│ │ -from pathlib import Path
│ │ -
│ │ -import ass
│ │ -import ebmlite
│ │ -import fontTools
│ │ -from fontTools.misc import encodingTools
│ │ -from fontTools.ttLib import ttFont
│ │ -
│ │ -__all__: list[str] = [
│ │ -    '_HOME',
│ │ -    'disable_logging',
│ │ -    'FONT_MIMETYPES',
│ │ -    'Font', 'FontCollection',
│ │ -    'get_dicts',
│ │ -    'get_element', 'get_elements',
│ │ -    'get_fonts',
│ │ -    'getFontDirs',
│ │ -    'INT_PATTERN',
│ │ -    'is_mkv',
│ │ -    'LINE_PATTERN',
│ │ -    'LinuxFontDirs', 'OSxFontDirs', 'WinFontDirs',
│ │ -    'parse_int', 'parse_line', 'parse_tags', 'parse_text',
│ │ -    'State',
│ │ -    'strip_fontname',
│ │ -    'TAG_PATTERN',
│ │ -    'TEXT_WHITESPACE_PATTERN',
│ │ -    'validate_and_save_fonts', 'validate_fonts',
│ │ -]
│ │ -
│ │ -TAG_PATTERN = re.compile(r"\\\s*([^(\\]+)(?<!\s)\s*(?:\(\s*([^)]+)(?<!\s)\s*)?")
│ │ -INT_PATTERN = re.compile(r"^[+-]?\d+")
│ │ -LINE_PATTERN = re.compile(r"(?:\{(?P<tags>[^}]*)\}?)?(?P<text>[^{]*)")
│ │ -TEXT_WHITESPACE_PATTERN = re.compile(r"\\[nNh]")
│ │ -
│ │ -State = namedtuple("State", ["font", "italic", "weight", "drawing"])
│ │ -
│ │ -
│ │ -def parse_int(s):
│ │ -    if match := INT_PATTERN.match(s):
│ │ -        return int(match.group(0))
│ │ -    else:
│ │ -        return 0
│ │ -
│ │ -
│ │ -def strip_fontname(s):
│ │ -    if s.startswith('@'):
│ │ -        return s[1:]
│ │ -    else:
│ │ -        return s
│ │ -
│ │ -
│ │ -def parse_tags(s, state, line_style, styles):
│ │ -    for match in TAG_PATTERN.finditer(s):
│ │ -        value, paren = match.groups()
│ │ -
│ │ -        def get_tag(name, *exclude):
│ │ -            if value.startswith(name) and not any(value.startswith(ex) for ex in exclude):
│ │ -                args = []
│ │ -                if paren is not None:
│ │ -                    args.append(paren)
│ │ -                if len(stripped := value[len(name):].lstrip()) > 0:
│ │ -                    args.append(stripped)
│ │ -                return args
│ │ -            else:
│ │ -                return None
│ │ -
│ │ -        if (args := get_tag("fn")) is not None:
│ │ -            if len(args) == 0:
│ │ -                font = line_style.font
│ │ -            else:
│ │ -                font = strip_fontname(args[0])
│ │ -            state = state._replace(font=font)
│ │ -        elif (args := get_tag("b", "blur", "be", "bord")) is not None:
│ │ -            weight = None if len(args) == 0 else parse_int(args[0])
│ │ -            if weight is None:
│ │ -                transformed = None
│ │ -            elif weight == 0:
│ │ -                transformed = 400
│ │ -            elif weight in (1, -1):
│ │ -                transformed = 700
│ │ -            elif 100 <= weight <= 900:
│ │ -                transformed = weight
│ │ -            else:
│ │ -                transformed = None
│ │ -
│ │ -            state = state._replace(weight=transformed or line_style.weight)
│ │ -        elif (args := get_tag("i", "iclip")) is not None:
│ │ -            slant = None if len(args) == 0 else parse_int(args[0])
│ │ -            state = state._replace(italic=slant == 1 if slant in (0, 1) else line_style.italic)
│ │ -        elif (args := get_tag("p", "pos", "pbo")) is not None:
│ │ -            scale = 0 if len(args) == 0 else parse_int(args[0])
│ │ -            state = state._replace(drawing=scale != 0)
│ │ -        elif (args := get_tag("r")) is not None:
│ │ -            if len(args) == 0:
│ │ -                style = line_style
│ │ -            else:
│ │ -                if (style := styles.get(args[0])) is None:
│ │ -                    print(rf"Warning: \r argument {args[0]} does not exist; defaulting to line style")
│ │ -                    style = line_style
│ │ -            state = state._replace(font=style.font, italic=style.italic, weight=style.weight)
│ │ -        elif (args := get_tag("t")) is not None:
│ │ -            if len(args) > 0:
│ │ -                state = parse_tags(args[0], state, line_style, styles)
│ │ -
│ │ -    return state
│ │ -
│ │ -
│ │ -def parse_text(text):
│ │ -    return TEXT_WHITESPACE_PATTERN.sub(' ', text)
│ │ -
│ │ -
│ │ -def parse_line(line, line_style, styles):
│ │ -    state = line_style
│ │ -    for tags, text in LINE_PATTERN.findall(line):
│ │ -        if len(tags) > 0:
│ │ -            state = parse_tags(tags, state, line_style, styles)
│ │ -        if len(text) > 0:
│ │ -            yield state, parse_text(text)
│ │ -
│ │ -
│ │ -class Font:
│ │ -    def __init__(self, fontfile, font_number=0, debug=False):
│ │ -        self.fontfile = fontfile
│ │ -        self.font = ttFont.TTFont(fontfile, fontNumber=font_number)
│ │ -        self.num_fonts = getattr(self.font.reader, "numFonts", 1)
│ │ -        self.postscript = self.font.has_key("CFF ")
│ │ -        self.glyphs = self.font.getGlyphSet()
│ │ -
│ │ -        os2 = self.font["OS/2"]
│ │ -        self.weight = os2.usWeightClass
│ │ -        self.italic = os2.fsSelection & 0b1 > 0
│ │ -        self.slant = self.italic * 110
│ │ -        self.width = 100
│ │ -
│ │ -        self.names = [name for name in self.font["name"].names
│ │ -                      if name.platformID == 3 and name.platEncID in (0, 1)]
│ │ -        self.family_names = [name.string.decode('utf_16_be')
│ │ -                             for name in self.names if name.nameID == 1]
│ │ -        self.full_names = [name.string.decode('utf_16_be')
│ │ -                           for name in self.names if name.nameID == 4]
│ │ -        self.postscript_name = ''
│ │ -
│ │ -        for name in self.font["name"].names:
│ │ -            if name.nameID == 6 and (encoding := encodingTools.getEncoding(
│ │ -                    name.platformID, name.platEncID, name.langID)) is not None:
│ │ -                self.postscript_name = name.string.decode(encoding).strip()
│ │ -
│ │ -                # these are the two recommended formats, prioritize them
│ │ -                if (name.platformID, name.platEncID, name.langID) in \
│ │ -                        [(1, 0, 0), (3, 1, 0x409)]:
│ │ -                    break
│ │ -
│ │ -        exact_names = [self.postscript_name] if (self.postscript and self.postscript_name) else self.full_names
│ │ -        self.exact_names = [name for name in exact_names
│ │ -                            if all(name.lower() != family.lower() for family in self.family_names)]
│ │ -
│ │ -        mac_italic = self.font["head"].macStyle & 0b10 > 0
│ │ -        if mac_italic != self.italic and debug:
│ │ -            print(f"warning: different italic values in macStyle and fsSelection for font {self.postscript_name}")
│ │ -
│ │ -        # fail early if glyph tables can't be accessed
│ │ -        self.missing_glyphs('', debug)
│ │ -
│ │ -    def missing_glyphs(self, text, debug=False):
│ │ -        if (uniTable := self.font.getBestCmap()):
│ │ -            return [c for c in text
│ │ -                    if ord(c) not in uniTable]
│ │ -        elif (symbolTable := self.font["cmap"].getcmap(3, 0)):
│ │ -            macTable = self.font["cmap"].getcmap(1, 0)
│ │ -            encoding = encodingTools.getEncoding(1, 0, macTable.language) if macTable else 'mac_roman'
│ │ -            missing = []
│ │ -            for c in text:
│ │ -                try:
│ │ -                    if (c.encode(encoding)[0] + 0xf000) not in symbolTable.cmap:
│ │ -                        missing.append(c)
│ │ -                except UnicodeEncodeError:
│ │ -                    missing.append(c)
│ │ -            return missing
│ │ -        else:
│ │ -            if debug:
│ │ -                print(f"warning: could not read glyphs for font {self}")
│ │ -
│ │ -    def __repr__(self):
│ │ -        return f"{self.postscript_name}(italic={self.italic}, weight={self.weight})"
│ │ -
│ │ -
│ │ -class FontCollection:
│ │ -    def __init__(self, fontfiles, debug: bool = False):
│ │ -        self.fonts = []
│ │ -        for name, f in fontfiles:
│ │ -            try:
│ │ -                font = Font(f, debug=debug)
│ │ -                self.fonts.append(font)
│ │ -
│ │ -                if font.num_fonts > 1:
│ │ -                    for i in range(1, font.num_fonts):
│ │ -                        self.fonts.append(Font(f, font_number=i))
│ │ -            except Exception as e:
│ │ -                print(f"Error reading {name}: {e}")
│ │ -
│ │ -        self.cache = {}
│ │ -        self.by_full = {name.lower(): font
│ │ -                        for font in self.fonts
│ │ -                        for name in font.exact_names}
│ │ -        self.by_postscriptName = {name.lower(): font
│ │ -                                  for font in self.fonts
│ │ -                                  for name in [font.postscript_name]}
│ │ -        self.by_family = {name.lower(): [font for (_, font) in fonts]
│ │ -                          for name, fonts in groupby(
│ │ -                              sorted([(family, font)
│ │ -                                      for font in self.fonts
│ │ -                                      for family in font.family_names],
│ │ -                                     key=lambda x: x[0]),
│ │ -                              key=lambda x: x[0])}
│ │ -
│ │ -    def similarity(self, state, font):
│ │ -        return abs(state.weight - font.weight) + abs(state.italic * 100 - font.slant)
│ │ -
│ │ -    def _match(self, state):
│ │ -        # if not os.path.exists('Test.txt'):
│ │ -        #   with(open('Text.txt', 'w', encoding = 'utf-8') as t):
│ │ -        #      t.write(str(self.by_postscriptName))
│ │ -        if (exact := self.by_full.get(state.font)):
│ │ -            return exact, True
│ │ -        elif (family := self.by_family.get(state.font)):
│ │ -            # print('Test')
│ │ -            return min(family, key=lambda font: self.similarity(state, font)), False
│ │ -        else:
│ │ -            # print('None')
│ │ -            return None, False
│ │ -
│ │ -    def match(self, state):
│ │ -        s = state._replace(font=state.font.lower(), drawing=False)
│ │ -        try:
│ │ -            return self.cache[s]
│ │ -        except KeyError:
│ │ -            font = self._match(s)
│ │ -            self.cache[s] = font
│ │ -            return font
│ │ -
│ │ -
│ │ -def validate_fonts(doc, fonts, ignore_drawings=False, warn_on_exact=False, debug=False):
│ │ -    report = {
│ │ -        "should_copy": defaultdict(set),
│ │ -        "missing_font": defaultdict(set),
│ │ -        "missing_glyphs": defaultdict(set),
│ │ -        "missing_glyphs_lines": defaultdict(set),
│ │ -        "faux_bold": defaultdict(set),
│ │ -        "faux_italic": defaultdict(set),
│ │ -        "mismatch_bold": defaultdict(set),
│ │ -        "mismatch_italic": defaultdict(set)
│ │ -    }
│ │ -
│ │ -    styles = {style.name: State(strip_fontname(style.fontname), style.italic, 700 if style.bold else 400, False)
│ │ -              for style in doc.styles}
│ │ -    for i, line in enumerate(doc.events):
│ │ -        if isinstance(line, ass.Comment):
│ │ -            continue
│ │ -        nline = i + 1
│ │ -
│ │ -        try:
│ │ -            style = styles[line.style]
│ │ -        except KeyError:
│ │ -            print(f"Warning: Unknown style {line.style} on line {nline}; assuming default style")
│ │ -            style = State("Arial", False, 400, False)
│ │ -
│ │ -        for state, text in parse_line(line.text, style, styles):
│ │ -            font, exact_match = fonts.match(state)
│ │ -
│ │ -            if ignore_drawings and state.drawing:
│ │ -                continue
│ │ -
│ │ -            if font is None:
│ │ -                report["missing_font"][state.font].add(nline)
│ │ -                continue
│ │ -            else:
│ │ -                report["should_copy"][font].add(nline)
│ │ -
│ │ -            if state.weight >= font.weight + 150:
│ │ -                report["faux_bold"][state.font, state.weight, font.weight].add(nline)
│ │ -
│ │ -            if state.weight <= font.weight - 150 and (not exact_match or warn_on_exact):
│ │ -                report["mismatch_bold"][state.font, state.weight, font.weight].add(nline)
│ │ -
│ │ -            if state.italic and not font.italic:
│ │ -                report["faux_italic"][state.font].add(nline)
│ │ -
│ │ -            if not state.italic and font.italic and (not exact_match or warn_on_exact):
│ │ -                report["mismatch_italic"][state.font].add(nline)
│ │ -
│ │ -            if not state.drawing:
│ │ -                missing = font.missing_glyphs(text, debug)
│ │ -                report["missing_glyphs"][state.font].update(missing)
│ │ -                if len(missing) > 0:
│ │ -                    report["missing_glyphs_lines"][state.font].add(nline)
│ │ -
│ │ -    issues = 0
│ │ -
│ │ -    def format_lines(lines, limit=3):
│ │ -        sorted_lines = sorted(lines)
│ │ -        if len(sorted_lines) > limit:
│ │ -            sorted_lines = sorted_lines[:limit]
│ │ -            sorted_lines.append("[...]")
│ │ -        return ' '.join(map(str, sorted_lines))
│ │ -
│ │ -    if len(report["missing_font"].items()) > 0:
│ │ -        print("-------------- Missing --------------\n")
│ │ -
│ │ -    for font, lines in sorted(report["missing_font"].items(), key=lambda x: x[0]):
│ │ -        issues += 1
│ │ -        print(f"- {font}\non line(s): {format_lines(lines)}\n")
│ │ -
│ │ -    if len(report["missing_font"].items()) > 0:
│ │ -        print("-------------------------------------\n")
│ │ -
│ │ -    for (font, reqweight, realweight), lines in sorted(report["faux_bold"].items(), key=lambda x: x[0]):
│ │ -        issues += 1
│ │ -        print(f"- Faux bold used for font {font} (requested weight {reqweight}, got {realweight}) "
│ │ -              f"on line(s): {format_lines(lines)}")
│ │ -
│ │ -    for font, lines in sorted(report["faux_italic"].items(), key=lambda x: x[0]):
│ │ -        issues += 1
│ │ -        print(f"- Faux italic used for font {font} on line(s): {format_lines(lines)}")
│ │ -
│ │ -    for (font, reqweight, realweight), lines in sorted(report["mismatch_bold"].items(), key=lambda x: x[0]):
│ │ -        issues += 1
│ │ -        print(f"- Requested weight {reqweight} but got {realweight} for font {font} "
│ │ -              f"on line(s): {format_lines(lines)}")
│ │ -
│ │ -    for font, lines in sorted(report["mismatch_italic"].items(), key=lambda x: x[0]):
│ │ -        issues += 1
│ │ -        print(f"- Requested non-italic but got italic for font {font} on line(s): "
│ │ -              + format_lines(lines))
│ │ -
│ │ -    for font, lines in sorted(report["missing_glyphs_lines"].items(), key=lambda x: x[0]):
│ │ -        issues += 1
│ │ -        missing = ' '.join(f'{g}(U+{ord(g):04X})' for g in sorted(report['missing_glyphs'][font]))
│ │ -        print(f"- Font {font} is missing glyphs {missing} "
│ │ -              f"on line(s): {format_lines(lines)}")
│ │ -
│ │ -    print(f"{issues} issue(s) found")
│ │ -    return issues > 0, report
│ │ -
│ │ -
│ │ -def get_element(parent, element, id=False):
│ │ -    return next(get_elements(parent, element, id=id))
│ │ -
│ │ -
│ │ -def get_elements(parent, *element, id=False):
│ │ -    if id:
│ │ -        return filter(lambda x: x.id in element, parent)
│ │ -    else:
│ │ -        return filter(lambda x: x.name in element, parent)
│ │ -
│ │ -
│ │ -def get_dicts(parent, element, id=False):
│ │ -    return ({x.name: x for x in elem} for elem in get_elements(parent, element, id=id))
│ │ -
│ │ -
│ │ -# from mpv
│ │ -FONT_MIMETYPES = {
│ │ -    b"application/x-truetype-font",
│ │ -    b"application/vnd.ms-opentype",
│ │ -    b"application/x-font-ttf",
│ │ -    b"application/x-font",
│ │ -    b"application/font-sfnt",
│ │ -    b"font/collection",
│ │ -    b"font/otf",
│ │ -    b"font/sfnt",
│ │ -    b"font/ttf"
│ │ -}
│ │ -
│ │ -
│ │ -def get_fonts(mkv):
│ │ -    fonts = []
│ │ -
│ │ -    for segment in get_elements(mkv, "Segment"):
│ │ -        for attachments in get_elements(segment, "Attachments"):
│ │ -            for attachment in get_dicts(attachments, "AttachedFile"):
│ │ -                if Path(attachment['FileName'].value.lower()).suffix not in ('.otf', '.ttf'):
│ │ -                    print(f"Ignoring non-font attachment {attachment['FileName'].value}")
│ │ -                    continue
│ │ -
│ │ -                fonts.append((attachment["FileName"].value,
│ │ -                              BytesIO(attachment["FileData"].value)))
│ │ -
│ │ -    return fonts
│ │ -
│ │ -
│ │ -def is_mkv(filename):
│ │ -    with open(filename, 'rb') as f:
│ │ -        return f.read(4) == b'\x1a\x45\xdf\xa3'
│ │ -
│ │ -
│ │ -try:
│ │ -    _HOME = Path.home()
│ │ -except Exception:
│ │ -    _HOME = Path(os.devnull)
│ │ -
│ │ -def getFontDirs() -> list[str]:
│ │ -    if sys.platform == 'win32':
│ │ -        fontpaths = [
│ │ -            # System
│ │ -            os.path.join(os.environ['WINDIR'], "Fonts"),
│ │ -            # User
│ │ -            os.path.join(os.getenv("LOCALAPPDATA"), "Microsoft", "Windows", "Fonts")
│ │ -        ]
│ │ -    else:
│ │ -        LinuxFontDirs = [
│ │ -            # old x11 dirs
│ │ -            "/usr/X11R6/lib/X11/fonts/TTF/",
│ │ -            "/usr/X11/lib/X11/fonts",
│ │ -            # New standard loc apparently?
│ │ -            "/usr/share/fonts/",
│ │ -            # Kinda user
│ │ -            "/usr/local/share/fonts/",
│ │ -            # User
│ │ -            os.path.join(os.environ.get('XDG_DATA_HOME') or os.path.join(_HOME, ".local", "share"), "fonts"),
│ │ -            os.path.join(_HOME, ".fonts"),
│ │ -        ]
│ │ -
│ │ -        if sys.platform == 'darwin':
│ │ -            OSxFontDirs = [
│ │ -                # System
│ │ -                "/Library/Fonts/",
│ │ -                "/Network/Library/Fonts/",
│ │ -                "/System/Library/Fonts/",
│ │ -                "/opt/local/share/fonts",
│ │ -                # User
│ │ -                os.path.join(_HOME, "Library", "Fonts"),
│ │ -            ]
│ │ -            fontpaths = [*LinuxFontDirs, *OSxFontDirs]
│ │ -        else:
│ │ -            fontpaths = LinuxFontDirs
│ │ -    return fontpaths
│ │ -
│ │ -
│ │ -def disable_logging():
│ │ -    logging.getLogger(fontTools.__name__).setLevel(logging.CRITICAL)
│ │ -
│ │ -
│ │ -def validate_and_save_fonts(ass_doc: tuple[str, ass.Document], out_dir: str | Path,
│ │ -                            font_sources: list[str | Path] | tuple[str | Path] = None,
│ │ -                            debug: bool = False):
│ │ -    if not debug:
│ │ -        disable_logging()
│ │ -    out_dir = out_dir if isinstance(out_dir, Path) else Path(out_dir)
│ │ -    fontlist = []
│ │ -    fontdirs = [os.getcwd()]
│ │ -    if font_sources:
│ │ -        for source in font_sources:
│ │ -            fontdirs.append(str(source.resolve()) if isinstance(source, Path) else source)
│ │ -    fontdirs.extend(getFontDirs())
│ │ -    print(f'Parsing all available fonts...')
│ │ -
│ │ -    for additional_fonts in fontdirs:
│ │ -        path = Path(additional_fonts)
│ │ -        if not path.exists():
│ │ -            continue
│ │ -        if path.is_dir():
│ │ -            fontlist.extend((p.name, str(p)) for p in path.rglob(
│ │ -                '*') if p.is_file() and p.suffix.lower() in ('.otf', '.ttf'))
│ │ -        elif is_mkv(additional_fonts):
│ │ -            schema = ebmlite.loadSchema("matroska.xml")
│ │ -            fontmkv = schema.load(additional_fonts)
│ │ -            fontlist.extend(get_fonts(fontmkv))
│ │ -        else:
│ │ -            fontlist.append((path.name, additional_fonts))
│ │ -
│ │ -    fonts = FontCollection(fontlist, debug)
│ │ -    print(f'Checking {ass_doc[0]} ...')
│ │ -    validate = validate_fonts(ass_doc[1], fonts, False, False, debug)
│ │ -    print('')
│ │ -
│ │ -    for font, _ in validate[1]["should_copy"].items():
│ │ -        current = Path(font.fontfile)
│ │ -        future_name = font.postscript_name.strip() + current.suffix
│ │ -        dest = os.path.join(out_dir, future_name)
│ │ -        if not os.path.exists(dest):
│ │ -            shutil.copyfile(current, dest)
│ │ -            print(f'Copied font "{future_name}"')
│ │ +import logging
│ │ +import os
│ │ +import re
│ │ +import shutil
│ │ +import sys
│ │ +from collections import defaultdict, namedtuple
│ │ +from io import BytesIO
│ │ +from itertools import groupby
│ │ +from pathlib import Path
│ │ +
│ │ +import ass
│ │ +import ebmlite
│ │ +import fontTools
│ │ +from fontTools.misc import encodingTools
│ │ +from fontTools.ttLib import ttFont
│ │ +
│ │ +__all__: list[str] = [
│ │ +    '_HOME',
│ │ +    'disable_logging',
│ │ +    'FONT_MIMETYPES',
│ │ +    'Font', 'FontCollection',
│ │ +    'get_dicts',
│ │ +    'get_element', 'get_elements',
│ │ +    'get_fonts',
│ │ +    'getFontDirs',
│ │ +    'INT_PATTERN',
│ │ +    'is_mkv',
│ │ +    'LINE_PATTERN',
│ │ +    'LinuxFontDirs', 'OSxFontDirs', 'WinFontDirs',
│ │ +    'parse_int', 'parse_line', 'parse_tags', 'parse_text',
│ │ +    'State',
│ │ +    'strip_fontname',
│ │ +    'TAG_PATTERN',
│ │ +    'TEXT_WHITESPACE_PATTERN',
│ │ +    'validate_and_save_fonts', 'validate_fonts',
│ │ +]
│ │ +
│ │ +TAG_PATTERN = re.compile(r"\\\s*([^(\\]+)(?<!\s)\s*(?:\(\s*([^)]+)(?<!\s)\s*)?")
│ │ +INT_PATTERN = re.compile(r"^[+-]?\d+")
│ │ +LINE_PATTERN = re.compile(r"(?:\{(?P<tags>[^}]*)\}?)?(?P<text>[^{]*)")
│ │ +TEXT_WHITESPACE_PATTERN = re.compile(r"\\[nNh]")
│ │ +
│ │ +State = namedtuple("State", ["font", "italic", "weight", "drawing"])
│ │ +
│ │ +
│ │ +def parse_int(s):
│ │ +    if match := INT_PATTERN.match(s):
│ │ +        return int(match.group(0))
│ │ +    else:
│ │ +        return 0
│ │ +
│ │ +
│ │ +def strip_fontname(s):
│ │ +    if s.startswith('@'):
│ │ +        return s[1:]
│ │ +    else:
│ │ +        return s
│ │ +
│ │ +
│ │ +def parse_tags(s, state, line_style, styles):
│ │ +    for match in TAG_PATTERN.finditer(s):
│ │ +        value, paren = match.groups()
│ │ +
│ │ +        def get_tag(name, *exclude):
│ │ +            if value.startswith(name) and not any(value.startswith(ex) for ex in exclude):
│ │ +                args = []
│ │ +                if paren is not None:
│ │ +                    args.append(paren)
│ │ +                if len(stripped := value[len(name):].lstrip()) > 0:
│ │ +                    args.append(stripped)
│ │ +                return args
│ │ +            else:
│ │ +                return None
│ │ +
│ │ +        if (args := get_tag("fn")) is not None:
│ │ +            if len(args) == 0:
│ │ +                font = line_style.font
│ │ +            else:
│ │ +                font = strip_fontname(args[0])
│ │ +            state = state._replace(font=font)
│ │ +        elif (args := get_tag("b", "blur", "be", "bord")) is not None:
│ │ +            weight = None if len(args) == 0 else parse_int(args[0])
│ │ +            if weight is None:
│ │ +                transformed = None
│ │ +            elif weight == 0:
│ │ +                transformed = 400
│ │ +            elif weight in (1, -1):
│ │ +                transformed = 700
│ │ +            elif 100 <= weight <= 900:
│ │ +                transformed = weight
│ │ +            else:
│ │ +                transformed = None
│ │ +
│ │ +            state = state._replace(weight=transformed or line_style.weight)
│ │ +        elif (args := get_tag("i", "iclip")) is not None:
│ │ +            slant = None if len(args) == 0 else parse_int(args[0])
│ │ +            state = state._replace(italic=slant == 1 if slant in (0, 1) else line_style.italic)
│ │ +        elif (args := get_tag("p", "pos", "pbo")) is not None:
│ │ +            scale = 0 if len(args) == 0 else parse_int(args[0])
│ │ +            state = state._replace(drawing=scale != 0)
│ │ +        elif (args := get_tag("r")) is not None:
│ │ +            if len(args) == 0:
│ │ +                style = line_style
│ │ +            else:
│ │ +                if (style := styles.get(args[0])) is None:
│ │ +                    print(rf"Warning: \r argument {args[0]} does not exist; defaulting to line style")
│ │ +                    style = line_style
│ │ +            state = state._replace(font=style.font, italic=style.italic, weight=style.weight)
│ │ +        elif (args := get_tag("t")) is not None:
│ │ +            if len(args) > 0:
│ │ +                state = parse_tags(args[0], state, line_style, styles)
│ │ +
│ │ +    return state
│ │ +
│ │ +
│ │ +def parse_text(text):
│ │ +    return TEXT_WHITESPACE_PATTERN.sub(' ', text)
│ │ +
│ │ +
│ │ +def parse_line(line, line_style, styles):
│ │ +    state = line_style
│ │ +    for tags, text in LINE_PATTERN.findall(line):
│ │ +        if len(tags) > 0:
│ │ +            state = parse_tags(tags, state, line_style, styles)
│ │ +        if len(text) > 0:
│ │ +            yield state, parse_text(text)
│ │ +
│ │ +
│ │ +class Font:
│ │ +    def __init__(self, fontfile, font_number=0, debug=False):
│ │ +        self.fontfile = fontfile
│ │ +        self.font = ttFont.TTFont(fontfile, fontNumber=font_number)
│ │ +        self.num_fonts = getattr(self.font.reader, "numFonts", 1)
│ │ +        self.postscript = self.font.has_key("CFF ")
│ │ +        self.glyphs = self.font.getGlyphSet()
│ │ +
│ │ +        os2 = self.font["OS/2"]
│ │ +        self.weight = os2.usWeightClass
│ │ +        self.italic = os2.fsSelection & 0b1 > 0
│ │ +        self.slant = self.italic * 110
│ │ +        self.width = 100
│ │ +
│ │ +        self.names = [name for name in self.font["name"].names
│ │ +                      if name.platformID == 3 and name.platEncID in (0, 1)]
│ │ +        self.family_names = [name.string.decode('utf_16_be')
│ │ +                             for name in self.names if name.nameID == 1]
│ │ +        self.full_names = [name.string.decode('utf_16_be')
│ │ +                           for name in self.names if name.nameID == 4]
│ │ +        self.postscript_name = ''
│ │ +
│ │ +        for name in self.font["name"].names:
│ │ +            if name.nameID == 6 and (encoding := encodingTools.getEncoding(
│ │ +                    name.platformID, name.platEncID, name.langID)) is not None:
│ │ +                self.postscript_name = name.string.decode(encoding).strip()
│ │ +
│ │ +                # these are the two recommended formats, prioritize them
│ │ +                if (name.platformID, name.platEncID, name.langID) in \
│ │ +                        [(1, 0, 0), (3, 1, 0x409)]:
│ │ +                    break
│ │ +
│ │ +        exact_names = [self.postscript_name] if (self.postscript and self.postscript_name) else self.full_names
│ │ +        self.exact_names = [name for name in exact_names
│ │ +                            if all(name.lower() != family.lower() for family in self.family_names)]
│ │ +
│ │ +        mac_italic = self.font["head"].macStyle & 0b10 > 0
│ │ +        if mac_italic != self.italic and debug:
│ │ +            print(f"warning: different italic values in macStyle and fsSelection for font {self.postscript_name}")
│ │ +
│ │ +        # fail early if glyph tables can't be accessed
│ │ +        self.missing_glyphs('', debug)
│ │ +
│ │ +    def missing_glyphs(self, text, debug=False):
│ │ +        if (uniTable := self.font.getBestCmap()):
│ │ +            return [c for c in text
│ │ +                    if ord(c) not in uniTable]
│ │ +        elif (symbolTable := self.font["cmap"].getcmap(3, 0)):
│ │ +            macTable = self.font["cmap"].getcmap(1, 0)
│ │ +            encoding = encodingTools.getEncoding(1, 0, macTable.language) if macTable else 'mac_roman'
│ │ +            missing = []
│ │ +            for c in text:
│ │ +                try:
│ │ +                    if (c.encode(encoding)[0] + 0xf000) not in symbolTable.cmap:
│ │ +                        missing.append(c)
│ │ +                except UnicodeEncodeError:
│ │ +                    missing.append(c)
│ │ +            return missing
│ │ +        else:
│ │ +            if debug:
│ │ +                print(f"warning: could not read glyphs for font {self}")
│ │ +
│ │ +    def __repr__(self):
│ │ +        return f"{self.postscript_name}(italic={self.italic}, weight={self.weight})"
│ │ +
│ │ +
│ │ +class FontCollection:
│ │ +    def __init__(self, fontfiles, debug: bool = False):
│ │ +        self.fonts = []
│ │ +        for name, f in fontfiles:
│ │ +            try:
│ │ +                font = Font(f, debug=debug)
│ │ +                self.fonts.append(font)
│ │ +
│ │ +                if font.num_fonts > 1:
│ │ +                    for i in range(1, font.num_fonts):
│ │ +                        self.fonts.append(Font(f, font_number=i))
│ │ +            except Exception as e:
│ │ +                print(f"Error reading {name}: {e}")
│ │ +
│ │ +        self.cache = {}
│ │ +        self.by_full = {name.lower(): font
│ │ +                        for font in self.fonts
│ │ +                        for name in font.exact_names}
│ │ +        self.by_postscriptName = {name.lower(): font
│ │ +                                  for font in self.fonts
│ │ +                                  for name in [font.postscript_name]}
│ │ +        self.by_family = {name.lower(): [font for (_, font) in fonts]
│ │ +                          for name, fonts in groupby(
│ │ +                              sorted([(family, font)
│ │ +                                      for font in self.fonts
│ │ +                                      for family in font.family_names],
│ │ +                                     key=lambda x: x[0]),
│ │ +                              key=lambda x: x[0])}
│ │ +
│ │ +    def similarity(self, state, font):
│ │ +        return abs(state.weight - font.weight) + abs(state.italic * 100 - font.slant)
│ │ +
│ │ +    def _match(self, state):
│ │ +        # if not os.path.exists('Test.txt'):
│ │ +        #   with(open('Text.txt', 'w', encoding = 'utf-8') as t):
│ │ +        #      t.write(str(self.by_postscriptName))
│ │ +        if (exact := self.by_full.get(state.font)):
│ │ +            return exact, True
│ │ +        elif (family := self.by_family.get(state.font)):
│ │ +            # print('Test')
│ │ +            return min(family, key=lambda font: self.similarity(state, font)), False
│ │ +        else:
│ │ +            # print('None')
│ │ +            return None, False
│ │ +
│ │ +    def match(self, state):
│ │ +        s = state._replace(font=state.font.lower(), drawing=False)
│ │ +        try:
│ │ +            return self.cache[s]
│ │ +        except KeyError:
│ │ +            font = self._match(s)
│ │ +            self.cache[s] = font
│ │ +            return font
│ │ +
│ │ +
│ │ +def validate_fonts(doc, fonts, ignore_drawings=False, warn_on_exact=False, debug=False):
│ │ +    report = {
│ │ +        "should_copy": defaultdict(set),
│ │ +        "missing_font": defaultdict(set),
│ │ +        "missing_glyphs": defaultdict(set),
│ │ +        "missing_glyphs_lines": defaultdict(set),
│ │ +        "faux_bold": defaultdict(set),
│ │ +        "faux_italic": defaultdict(set),
│ │ +        "mismatch_bold": defaultdict(set),
│ │ +        "mismatch_italic": defaultdict(set)
│ │ +    }
│ │ +
│ │ +    styles = {style.name: State(strip_fontname(style.fontname), style.italic, 700 if style.bold else 400, False)
│ │ +              for style in doc.styles}
│ │ +    for i, line in enumerate(doc.events):
│ │ +        if isinstance(line, ass.Comment):
│ │ +            continue
│ │ +        nline = i + 1
│ │ +
│ │ +        try:
│ │ +            style = styles[line.style]
│ │ +        except KeyError:
│ │ +            print(f"Warning: Unknown style {line.style} on line {nline}; assuming default style")
│ │ +            style = State("Arial", False, 400, False)
│ │ +
│ │ +        for state, text in parse_line(line.text, style, styles):
│ │ +            font, exact_match = fonts.match(state)
│ │ +
│ │ +            if ignore_drawings and state.drawing:
│ │ +                continue
│ │ +
│ │ +            if font is None:
│ │ +                report["missing_font"][state.font].add(nline)
│ │ +                continue
│ │ +            else:
│ │ +                report["should_copy"][font].add(nline)
│ │ +
│ │ +            if state.weight >= font.weight + 150:
│ │ +                report["faux_bold"][state.font, state.weight, font.weight].add(nline)
│ │ +
│ │ +            if state.weight <= font.weight - 150 and (not exact_match or warn_on_exact):
│ │ +                report["mismatch_bold"][state.font, state.weight, font.weight].add(nline)
│ │ +
│ │ +            if state.italic and not font.italic:
│ │ +                report["faux_italic"][state.font].add(nline)
│ │ +
│ │ +            if not state.italic and font.italic and (not exact_match or warn_on_exact):
│ │ +                report["mismatch_italic"][state.font].add(nline)
│ │ +
│ │ +            if not state.drawing:
│ │ +                missing = font.missing_glyphs(text, debug)
│ │ +                report["missing_glyphs"][state.font].update(missing)
│ │ +                if len(missing) > 0:
│ │ +                    report["missing_glyphs_lines"][state.font].add(nline)
│ │ +
│ │ +    issues = 0
│ │ +
│ │ +    def format_lines(lines, limit=3):
│ │ +        sorted_lines = sorted(lines)
│ │ +        if len(sorted_lines) > limit:
│ │ +            sorted_lines = sorted_lines[:limit]
│ │ +            sorted_lines.append("[...]")
│ │ +        return ' '.join(map(str, sorted_lines))
│ │ +
│ │ +    if len(report["missing_font"].items()) > 0:
│ │ +        print("-------------- Missing --------------\n")
│ │ +
│ │ +    for font, lines in sorted(report["missing_font"].items(), key=lambda x: x[0]):
│ │ +        issues += 1
│ │ +        print(f"- {font}\non line(s): {format_lines(lines)}\n")
│ │ +
│ │ +    if len(report["missing_font"].items()) > 0:
│ │ +        print("-------------------------------------\n")
│ │ +
│ │ +    for (font, reqweight, realweight), lines in sorted(report["faux_bold"].items(), key=lambda x: x[0]):
│ │ +        issues += 1
│ │ +        print(f"- Faux bold used for font {font} (requested weight {reqweight}, got {realweight}) "
│ │ +              f"on line(s): {format_lines(lines)}")
│ │ +
│ │ +    for font, lines in sorted(report["faux_italic"].items(), key=lambda x: x[0]):
│ │ +        issues += 1
│ │ +        print(f"- Faux italic used for font {font} on line(s): {format_lines(lines)}")
│ │ +
│ │ +    for (font, reqweight, realweight), lines in sorted(report["mismatch_bold"].items(), key=lambda x: x[0]):
│ │ +        issues += 1
│ │ +        print(f"- Requested weight {reqweight} but got {realweight} for font {font} "
│ │ +              f"on line(s): {format_lines(lines)}")
│ │ +
│ │ +    for font, lines in sorted(report["mismatch_italic"].items(), key=lambda x: x[0]):
│ │ +        issues += 1
│ │ +        print(f"- Requested non-italic but got italic for font {font} on line(s): "
│ │ +              + format_lines(lines))
│ │ +
│ │ +    for font, lines in sorted(report["missing_glyphs_lines"].items(), key=lambda x: x[0]):
│ │ +        issues += 1
│ │ +        missing = ' '.join(f'{g}(U+{ord(g):04X})' for g in sorted(report['missing_glyphs'][font]))
│ │ +        print(f"- Font {font} is missing glyphs {missing} "
│ │ +              f"on line(s): {format_lines(lines)}")
│ │ +
│ │ +    print(f"{issues} issue(s) found")
│ │ +    return issues > 0, report
│ │ +
│ │ +
│ │ +def get_element(parent, element, id=False):
│ │ +    return next(get_elements(parent, element, id=id))
│ │ +
│ │ +
│ │ +def get_elements(parent, *element, id=False):
│ │ +    if id:
│ │ +        return filter(lambda x: x.id in element, parent)
│ │ +    else:
│ │ +        return filter(lambda x: x.name in element, parent)
│ │ +
│ │ +
│ │ +def get_dicts(parent, element, id=False):
│ │ +    return ({x.name: x for x in elem} for elem in get_elements(parent, element, id=id))
│ │ +
│ │ +
│ │ +# from mpv
│ │ +FONT_MIMETYPES = {
│ │ +    b"application/x-truetype-font",
│ │ +    b"application/vnd.ms-opentype",
│ │ +    b"application/x-font-ttf",
│ │ +    b"application/x-font",
│ │ +    b"application/font-sfnt",
│ │ +    b"font/collection",
│ │ +    b"font/otf",
│ │ +    b"font/sfnt",
│ │ +    b"font/ttf"
│ │ +}
│ │ +
│ │ +
│ │ +def get_fonts(mkv):
│ │ +    fonts = []
│ │ +
│ │ +    for segment in get_elements(mkv, "Segment"):
│ │ +        for attachments in get_elements(segment, "Attachments"):
│ │ +            for attachment in get_dicts(attachments, "AttachedFile"):
│ │ +                if Path(attachment['FileName'].value.lower()).suffix not in ('.otf', '.ttf'):
│ │ +                    print(f"Ignoring non-font attachment {attachment['FileName'].value}")
│ │ +                    continue
│ │ +
│ │ +                fonts.append((attachment["FileName"].value,
│ │ +                              BytesIO(attachment["FileData"].value)))
│ │ +
│ │ +    return fonts
│ │ +
│ │ +
│ │ +def is_mkv(filename):
│ │ +    with open(filename, 'rb') as f:
│ │ +        return f.read(4) == b'\x1a\x45\xdf\xa3'
│ │ +
│ │ +
│ │ +try:
│ │ +    _HOME = Path.home()
│ │ +except Exception:
│ │ +    _HOME = Path(os.devnull)
│ │ +
│ │ +def getFontDirs() -> list[str]:
│ │ +    if sys.platform == 'win32':
│ │ +        fontpaths = [
│ │ +            # System
│ │ +            os.path.join(os.environ['WINDIR'], "Fonts"),
│ │ +            # User
│ │ +            os.path.join(os.getenv("LOCALAPPDATA"), "Microsoft", "Windows", "Fonts")
│ │ +        ]
│ │ +    else:
│ │ +        LinuxFontDirs = [
│ │ +            # old x11 dirs
│ │ +            "/usr/X11R6/lib/X11/fonts/TTF/",
│ │ +            "/usr/X11/lib/X11/fonts",
│ │ +            # New standard loc apparently?
│ │ +            "/usr/share/fonts/",
│ │ +            # Kinda user
│ │ +            "/usr/local/share/fonts/",
│ │ +            # User
│ │ +            os.path.join(os.environ.get('XDG_DATA_HOME') or os.path.join(_HOME, ".local", "share"), "fonts"),
│ │ +            os.path.join(_HOME, ".fonts"),
│ │ +        ]
│ │ +
│ │ +        if sys.platform == 'darwin':
│ │ +            OSxFontDirs = [
│ │ +                # System
│ │ +                "/Library/Fonts/",
│ │ +                "/Network/Library/Fonts/",
│ │ +                "/System/Library/Fonts/",
│ │ +                "/opt/local/share/fonts",
│ │ +                # User
│ │ +                os.path.join(_HOME, "Library", "Fonts"),
│ │ +            ]
│ │ +            fontpaths = [*LinuxFontDirs, *OSxFontDirs]
│ │ +        else:
│ │ +            fontpaths = LinuxFontDirs
│ │ +    return fontpaths
│ │ +
│ │ +
│ │ +def disable_logging():
│ │ +    logging.getLogger(fontTools.__name__).setLevel(logging.CRITICAL)
│ │ +
│ │ +
│ │ +def validate_and_save_fonts(ass_doc: tuple[str, ass.Document], out_dir: str | Path,
│ │ +                            font_sources: list[str | Path] | tuple[str | Path] = None,
│ │ +                            debug: bool = False):
│ │ +    if not debug:
│ │ +        disable_logging()
│ │ +    out_dir = out_dir if isinstance(out_dir, Path) else Path(out_dir)
│ │ +    fontlist = []
│ │ +    fontdirs = [os.getcwd()]
│ │ +    if font_sources:
│ │ +        for source in font_sources:
│ │ +            fontdirs.append(str(source.resolve()) if isinstance(source, Path) else source)
│ │ +    fontdirs.extend(getFontDirs())
│ │ +    print(f'Parsing all available fonts...')
│ │ +
│ │ +    for additional_fonts in fontdirs:
│ │ +        path = Path(additional_fonts)
│ │ +        if not path.exists():
│ │ +            continue
│ │ +        if path.is_dir():
│ │ +            fontlist.extend((p.name, str(p)) for p in path.rglob(
│ │ +                '*') if p.is_file() and p.suffix.lower() in ('.otf', '.ttf'))
│ │ +        elif is_mkv(additional_fonts):
│ │ +            schema = ebmlite.loadSchema("matroska.xml")
│ │ +            fontmkv = schema.load(additional_fonts)
│ │ +            fontlist.extend(get_fonts(fontmkv))
│ │ +        else:
│ │ +            fontlist.append((path.name, additional_fonts))
│ │ +
│ │ +    fonts = FontCollection(fontlist, debug)
│ │ +    print(f'Checking {ass_doc[0]} ...')
│ │ +    validate = validate_fonts(ass_doc[1], fonts, False, False, debug)
│ │ +    print('')
│ │ +
│ │ +    for font, _ in validate[1]["should_copy"].items():
│ │ +        current = Path(font.fontfile)
│ │ +        future_name = font.postscript_name.strip() + current.suffix
│ │ +        dest = os.path.join(out_dir, future_name)
│ │ +        if not os.path.exists(dest):
│ │ +            shutil.copyfile(current, dest)
│ │ +            print(f'Copied font "{future_name}"')
│ │   --- vodesfunc-1.3.1/vodesfunc/auto/muxing.py
│ ├── +++ vodesfunc-1.3.2/vodesfunc/auto/muxing.py
│ │┄ Files 19% similar despite different names
│ │ @@ -1,370 +1,381 @@
│ │ -from enum import IntEnum
│ │ -from pathlib import Path
│ │ -from datetime import timedelta
│ │ -import os
│ │ -from fractions import Fraction
│ │ -
│ │ -import ass
│ │ -from .fonts import validate_and_save_fonts
│ │ -from ..types import PathLike, Chapter, TrackType
│ │ -from ..util import uniquify_path
│ │ -from ..automation import get_workdir
│ │ -from .convert import timedelta_to_frame, frame_to_timedelta
│ │ -
│ │ -__all__: list[str] = [
│ │ -    '_track',
│ │ -    'Attachment',
│ │ -    'AudioTrack', 'AT',
│ │ -    'Chapter',
│ │ -    'GlobSearch',
│ │ -    'MkvTrack',
│ │ -    'SubTrack', 'ST',
│ │ -    'TrackType',
│ │ -    'VideoTrack', 'VT',
│ │ -]
│ │ -
│ │ -
│ │ -class GlobSearch():
│ │ -
│ │ -    paths: Path | list[Path] = None
│ │ -
│ │ -    def __init__(self, pattern: str, allow_multiple: bool = False, dir: PathLike = None, recursive: bool = True) -> None:
│ │ -        """
│ │ -            Glob Pattern based search for files
│ │ -
│ │ -            :param pattern:         Glob pattern
│ │ -            :param allow_multiple:  Will return all file matches if True and only the first if False
│ │ -            :param dir:             Directory to run the search in. Defaults to current working dir.
│ │ -            :param recursive:       Search recursively
│ │ -        """
│ │ -
│ │ -        dir = Path(dir) if isinstance(dir, str) else dir
│ │ -        if dir is None:
│ │ -            dir = Path(os.getcwd()).resolve()
│ │ -
│ │ -        search = dir.rglob(pattern) if recursive else dir.glob(pattern)
│ │ -        # print(search)
│ │ -        for f in search:
│ │ -            if allow_multiple:
│ │ -                if self.paths:
│ │ -                    self.paths.append(f)
│ │ -                else:
│ │ -                    init: list[Path] = [f, ]
│ │ -                    self.paths = init
│ │ -            else:
│ │ -                self.paths = f
│ │ -                break
│ │ -
│ │ -
│ │ -class _track():
│ │ -
│ │ -    file: Path
│ │ -    type: TrackType
│ │ -    default: bool
│ │ -    forced: bool
│ │ -    name: str
│ │ -    lang: str
│ │ -    delay: int
│ │ -
│ │ -    def __init__(self, file: PathLike, type: str | int | TrackType, name: str = '', lang: str = '', default: bool = True, forced: bool = False, delay: int = 0) -> None:
│ │ -        """
│ │ -            :param file:        Filepath as string or Path object
│ │ -            :param type:        TrackType enum, or int or string (1 = 'video', 2 = 'audio', 3 = 'sub')
│ │ -            :param name:        The track name in the resulting mkv file
│ │ -            :param lang:        The language tag for the track
│ │ -            :param default:     Default flag
│ │ -            :param forced:      Forced flag
│ │ -            :param delay:       Container delay of track in ms
│ │ -        """
│ │ -        self.file = file if isinstance(file, Path) else Path(file)
│ │ -        self.default = default
│ │ -        self.forced = forced
│ │ -        self.name = name
│ │ -        self.delay = delay
│ │ -        # Maybe use https://pypi.org/project/pycountry/ to automatically convert iso-2 to iso-3
│ │ -        # as ffmpeg expects 3 letter codes; I am not sure what mkvmerge wants or can work with
│ │ -        self.lang = lang
│ │ -        self.type = type if isinstance(type, TrackType) \
│ │ -            else (TrackType(type) if isinstance(type, int) else TrackType[type.upper()])
│ │ -
│ │ -    def mkvmerge_args(self) -> str:
│ │ -        self.file = self.file if isinstance(self.file, Path) else Path(self.file)
│ │ -        if self.type == TrackType.ATTACHMENT:
│ │ -            is_font = self.file.suffix.lower() in ['.ttf', '.otf']
│ │ -            if not is_font and not self.lang:
│ │ -                raise ValueError(f'Please specify a mimetype for the attachments if they\'re not fonts!')
│ │ -            if not is_font:
│ │ -                return f' --attachment-mime-type {self.lang} --attach-file "{self.file.resolve()}"'
│ │ -            else:
│ │ -                return f' --attachment-mime-type {"font/ttf" if self.file.suffix.lower() == ".ttf" else "font/otf"} --attach-file "{self.file.resolve()}"'
│ │ -        elif self.type == TrackType.MKV:
│ │ -            return f' {self.name.strip()} "{self.file.resolve()}"'
│ │ -        elif self.type == TrackType.CHAPTERS:
│ │ -            return f' --chapters "{self.file.resolve()}"'
│ │ -        name_args = f' --track-name 0:"{self.name}"' if self.name else ''
│ │ -        lang_args = f' --language 0:{self.lang}' if self.lang else ''
│ │ -        delay_args = f' --sync 0:{self.delay}' if self.delay != 0 else ''
│ │ -        default_args = f' --default-track-flag 0:{"yes" if self.default else "no"}'
│ │ -        forced_args = f' --forced-display-flag 0:{"yes" if self.forced else "no"}'
│ │ -        timecode_args = ''
│ │ -        if isinstance(self, VideoTrack) and self.timecode_file is not None:
│ │ -            timecode_args = f' --timestamps 0:"{self.timecode_file.resolve()}"'
│ │ -        return f'{timecode_args}{name_args}{lang_args}{default_args}{forced_args}{delay_args} "{self.file.resolve()}"'
│ │ -
│ │ -
│ │ -class VideoTrack(_track):
│ │ -    """
│ │ -        _track object with VIDEO type preselected and japanese language default
│ │ -    """
│ │ -
│ │ -    timecode_file: PathLike | None = None
│ │ -
│ │ -    def __init__(self, file: PathLike | GlobSearch, name: str = '', lang: str = 'ja', default: bool = True, forced: bool = False, delay: int = 0, timecode_file: PathLike | GlobSearch = None) -> None:
│ │ -        if isinstance(file, GlobSearch):
│ │ -            file = file.paths[0] if isinstance(file.paths, list) else file.paths
│ │ -        if timecode_file is not None:
│ │ -            if isinstance(timecode_file, GlobSearch):
│ │ -                timecode_file = timecode_file.paths[0] if isinstance(timecode_file.paths, list) else timecode_file.paths
│ │ -            self.timecode_file = timecode_file if isinstance(timecode_file, Path) else Path(timecode_file)
│ │ -        super().__init__(file, TrackType.VIDEO, name, lang, default, forced, delay)
│ │ -
│ │ -
│ │ -class AudioTrack(_track):
│ │ -    """
│ │ -        _track object with AUDIO type preselected and japanese language default
│ │ -    """
│ │ -
│ │ -    def __init__(self, file: PathLike | GlobSearch, name: str = '', lang: str = 'ja', default: bool = True, forced: bool = False, delay: int = 0) -> None:
│ │ -        if isinstance(file, GlobSearch):
│ │ -            file = file.paths[0] if isinstance(file.paths, list) else file.paths
│ │ -        super().__init__(file, TrackType.AUDIO, name, lang, default, forced, delay)
│ │ -
│ │ -
│ │ -class Attachment(_track):
│ │ -    """
│ │ -        pseudo _track object for attachments
│ │ -    """
│ │ -
│ │ -    def __init__(self, file: str | Path, mimetype: str = '') -> None:
│ │ -        super().__init__(file, TrackType.ATTACHMENT, '', mimetype, False, False, 0)
│ │ -
│ │ -
│ │ -class SubTrack(_track):
│ │ -    """
│ │ -        _track object with SUB type preselected and english language default
│ │ -
│ │ -        Supports merging multiple files by passing a List of Path objects or filepath strings
│ │ -        and of course also a GlobSearch
│ │ -    """
│ │ -
│ │ -    def __init__(self, file: PathLike | list[PathLike] | GlobSearch, name: str = '', lang: str = 'en',
│ │ -                 default: bool = True, forced: bool = False, delay: int = 0) -> None:
│ │ -        if isinstance(file, GlobSearch):
│ │ -            file = file.paths
│ │ -
│ │ -        # Merge if multiple sub files
│ │ -        if isinstance(file, list):
│ │ -            ffs_python = f'for track "{name}"'
│ │ -            print(f'Merging subtitle files {ffs_python if name else ""}...')
│ │ -            ass_documents: list[ass.Document] = []
│ │ -            for ass_file in file:
│ │ -                ass_file = ass_file if isinstance(ass_file, Path) else Path(ass_file)
│ │ -                with open(ass_file, 'r', encoding='utf_8_sig') as read:
│ │ -                    ass_documents.append(ass.parse(read))
│ │ -
│ │ -            merged = ass_documents[0]
│ │ -            existing_styles = [style.name for style in (merged.styles)]
│ │ -            ass_documents.remove(merged)
│ │ -            for doc in ass_documents:
│ │ -                # Merges all the lines
│ │ -                merged.events.extend(doc.events)
│ │ -                # Check for dupe styles
│ │ -                for style in doc.styles:
│ │ -                    if style.name in existing_styles:
│ │ -                        print(f'WARN: Ignoring style "{style.name}" due to preexisting style of the same name!')
│ │ -                        continue
│ │ -                    merged.styles.append(style)
│ │ -                
│ │ -            out_file = uniquify_path(Path(os.path.join(get_workdir(), f'{Path(file[0]).stem}-merged.ass')))
│ │ -            with open(out_file, 'w', encoding='utf_8_sig') as merge_write:
│ │ -                merged.dump_file(merge_write)
│ │ -
│ │ -            file = Path(out_file)
│ │ -            print('Done.\n')
│ │ -
│ │ -        super().__init__(file, TrackType.SUB, name, lang, default, forced, delay)
│ │ -
│ │ -    def collect_fonts(self, work_dir: Path = get_workdir(), font_sources: list[str | Path] = None,
│ │ -                      debug_output: bool = False) -> list[Attachment]:
│ │ -        """
│ │ -            Validates and copies the fonts needed for this track into the specified `work_dir`.
│ │ -            `font_sources` can be mkv files or directories.
│ │ -
│ │ -            Returns a list of Attachment tracks you can feed into Mux()
│ │ -        """
│ │ -        out: list[Attachment] = []
│ │ -        doc: ass.Document = None
│ │ -        with open(self.file, 'r', encoding='utf_8_sig') as read:
│ │ -            doc = ass.parse(read)
│ │ -        validate_and_save_fonts([f'track "{self.name}"' if self.name else self.file.stem,
│ │ -                                doc], work_dir, font_sources, debug_output)
│ │ -        for f in os.listdir(work_dir):
│ │ -            filepath = Path(os.path.join(work_dir, f))
│ │ -            if filepath.suffix.lower() in ['.ttf', '.otf']:
│ │ -                out.append(Attachment(filepath.resolve()))
│ │ -
│ │ -        return out
│ │ -
│ │ -    def autoswapper(self, allowed_styles: list[str] | None = ['Default', 'Main', 'Alt', 'Overlap', 'Flashback', 'Top', 'Italics'], print_swaps: bool = False) -> "SubTrack":
│ │ -        """
│ │ -            autoswapper does the swapping.
│ │ -            Too lazy to explain
│ │ -
│ │ -            :param allowed_styles:      List of allowed styles to do the swapping on
│ │ -                                        Will run on every line if passed `None`
│ │ -            :param print_swaps:         Prints the swaps
│ │ -            
│ │ -            :return:                    This SubTrack
│ │ -        """
│ │ -        import re
│ │ -        with open(self.file, 'r', encoding='utf_8_sig') as f:
│ │ -            doc = ass.parse(f)
│ │ -        
│ │ -        events = []
│ │ -
│ │ -        for i, line in enumerate(doc.events):
│ │ -            if not allowed_styles or line.style.lower() in (style.lower() for style in allowed_styles):
│ │ -                to_swap: dict = {}
│ │ -                # {*}This will be replaced{*With this}
│ │ -                for match in re.finditer(re.compile(r'\{\*\}([^{]*)\{\*([^}*]+)\}'), line.text):
│ │ -                    to_swap.update({
│ │ -                        f"{match.group(0)}":
│ │ -                        f"{{*}}{match.group(2)}{{*{match.group(1)}}}"
│ │ -                    })
│ │ -                
│ │ -                # This sentence is no longer{** incomplete}
│ │ -                for match in re.finditer(re.compile(r'\{\*\*([^}]+)\}'), line.text):
│ │ -                    to_swap.update({
│ │ -                        f"{match.group(0)}":
│ │ -                        f"{{*}}{match.group(1)}{{*}}"
│ │ -                    })
│ │ -                
│ │ -                # This sentence is no longer{*} incomplete{*} 
│ │ -                for match in re.finditer(re.compile(r'\{\*\}([^{]*)\{\* *\}'), line.text):
│ │ -                    to_swap.update({
│ │ -                        f"{match.group(0)}":
│ │ -                        f"{{**{match.group(1)}}}"
│ │ -                    })
│ │ -                #print(to_swap)
│ │ -                for key, val in to_swap.items():
│ │ -                    if print_swaps:
│ │ -                        print(f'autoswapper: Swapped "{key}" for "{val}" on line {i}')
│ │ -                    line.text = line.text.replace(key, val)
│ │ -            
│ │ -            if line.effect.strip() == "***" or line.name.strip() == "***":
│ │ -                if isinstance(line, ass.Comment):
│ │ -                    line.TYPE = 'Dialogue'
│ │ -                elif isinstance(line, ass.Dialogue):
│ │ -                    line.TYPE = 'Comment'
│ │ -
│ │ -            events.append(line)
│ │ -        
│ │ -        doc.events = events
│ │ -        out_file = Path(os.path.join(get_workdir(), Path(self.file).stem + "-swapped.ass"))
│ │ -        with open(out_file, 'w', encoding='utf_8_sig') as f:
│ │ -            doc.dump_file(f)
│ │ -        
│ │ -        self.file = out_file
│ │ -        return self
│ │ -
│ │ -    def syncpoint_merge(self, syncpoint: str, mergefile: PathLike | GlobSearch, use_actor_field: bool = False, 
│ │ -        use_frames: bool = False, fps: Fraction = Fraction(24000, 1001), override_p1: int | timedelta = None) -> "SubTrack":
│ │ -        """
│ │ -            Merge other sub files (Opening/Ending kfx for example) with offsetting by syncpoints
│ │ -
│ │ -            :param syncpoint:           The syncpoint to be used
│ │ -            :param mergefile:           The file to be merged
│ │ -            :param use_actor_field:     Search the actor field instead of the effect field for the syncpoint
│ │ -            :param use_frames:          Uses frames to shift lines instead of direct timestamps
│ │ -            :param fps:                 The fps to go off of for the conversion
│ │ -            :param override_p1:         A manual override of the initial syncpoint
│ │ -                                        Obviously either a frame number or timedelta
│ │ -
│ │ -            :return:                    This SubTrack
│ │ -        """
│ │ -        if isinstance(mergefile, GlobSearch):
│ │ -            mergefile = mergefile.paths[0] if isinstance(mergefile.paths, list) else mergefile.paths
│ │ -        mergefile = mergefile if isinstance(mergefile, Path) else Path(mergefile)
│ │ -        was_merged = False
│ │ -
│ │ -        with open(self.file, 'r', encoding='utf_8_sig') as f:
│ │ -            doc = ass.parse(f)
│ │ -        with open(mergefile, 'r', encoding='utf_8_sig') as f:
│ │ -            mergedoc = ass.parse(f)
│ │ -
│ │ -        events = []
│ │ -        tomerge = []
│ │ -        existing_styles = [style.name for style in (doc.styles)]
│ │ -
│ │ -        for line in doc.events:
│ │ -            events.append(line)
│ │ -            if was_merged:
│ │ -                continue
│ │ -            field = line.name if use_actor_field else line.effect
│ │ -            if field.lower().strip() == syncpoint.lower().strip() or line.text.lower().strip() == syncpoint.lower().strip() or override_p1 is not None:
│ │ -                was_merged = True
│ │ -                start = line.start if override_p1 is None else override_p1
│ │ -                offset: timedelta | int = None
│ │ -                for l in mergedoc.events:
│ │ -                    lfield = l.name if use_actor_field else l.effect
│ │ -                    if lfield.lower().strip() == syncpoint.lower().strip() or l.text.lower().strip() == syncpoint.lower().strip():
│ │ -                        mergedoc.events.remove(l)
│ │ -                        if use_frames:
│ │ -                            offset = timedelta_to_frame(start - l.start, fps)
│ │ -                        else:
│ │ -                            offset = start - l.start
│ │ -                        break
│ │ -
│ │ -                for l in sorted(mergedoc.events, key = lambda event: event.start):
│ │ -                    if offset is None:
│ │ -                        if use_frames:
│ │ -                            offset = timedelta_to_frame(start - l.start, fps)
│ │ -                        else:
│ │ -                            offset = start - l.start
│ │ -                        l.start = start
│ │ -                        l.end = (l.end + (frame_to_timedelta(offset, fps) if use_frames else offset))
│ │ -                    else:
│ │ -                        l.start = (l.start + (frame_to_timedelta(offset, fps) if use_frames else offset))
│ │ -                        l.end = (l.end + (frame_to_timedelta(offset, fps) if use_frames else offset))
│ │ -                    tomerge.append(l)
│ │ -
│ │ -        if was_merged:
│ │ -            events.extend(tomerge)
│ │ -            # Merge the styles in aswell
│ │ -            for style in mergedoc.styles:
│ │ -                if style.name in existing_styles:
│ │ -                    continue
│ │ -                doc.styles.append(style)
│ │ -
│ │ -            doc.events = events
│ │ -            out_file = uniquify_path(Path(os.path.join(get_workdir(), Path(self.file).stem + "-merge.ass")))
│ │ -            with open(out_file, 'w', encoding='utf_8_sig') as f:
│ │ -                doc.dump_file(f)
│ │ -
│ │ -            self.file = Path(out_file)
│ │ -        else:
│ │ -            print(f'Syncpoint "{syncpoint}" was not found!')
│ │ -
│ │ -        return self
│ │ -
│ │ -
│ │ -class MkvTrack(_track):
│ │ -
│ │ -    def __init__(self, file: PathLike | GlobSearch, mkvmerge_args: str = '') -> None:
│ │ -        if isinstance(file, GlobSearch):
│ │ -            file = file.paths[0] if isinstance(file.paths, list) else file.paths
│ │ -        super().__init__(file, TrackType.MKV, mkvmerge_args, '', False, False, 0)
│ │ -
│ │ -VT = VideoTrack
│ │ -AT = AudioTrack
│ │ -ST = SubTrack
│ │ +from enum import IntEnum
│ │ +from pathlib import Path
│ │ +from datetime import timedelta
│ │ +import os
│ │ +from fractions import Fraction
│ │ +
│ │ +import ass
│ │ +from .fonts import validate_and_save_fonts
│ │ +from ..types import PathLike, Chapter, TrackType
│ │ +from ..util import uniquify_path
│ │ +from ..automation import get_workdir
│ │ +from .convert import timedelta_to_frame, frame_to_timedelta
│ │ +
│ │ +__all__: list[str] = [
│ │ +    '_track',
│ │ +    'Attachment',
│ │ +    'AudioTrack', 'AT',
│ │ +    'Chapter',
│ │ +    'GlobSearch',
│ │ +    'MkvTrack',
│ │ +    'SubTrack', 'ST',
│ │ +    'TrackType',
│ │ +    'VideoTrack', 'VT',
│ │ +]
│ │ +
│ │ +
│ │ +class GlobSearch():
│ │ +
│ │ +    paths: Path | list[Path] = None
│ │ +
│ │ +    def __init__(self, pattern: str, allow_multiple: bool = False, dir: PathLike = None, recursive: bool = True) -> None:
│ │ +        """
│ │ +            Glob Pattern based search for files
│ │ +
│ │ +            :param pattern:         Glob pattern
│ │ +            :param allow_multiple:  Will return all file matches if True and only the first if False
│ │ +            :param dir:             Directory to run the search in. Defaults to current working dir.
│ │ +            :param recursive:       Search recursively
│ │ +        """
│ │ +
│ │ +        dir = Path(dir) if isinstance(dir, str) else dir
│ │ +        if dir is None:
│ │ +            dir = Path(os.getcwd()).resolve()
│ │ +
│ │ +        search = dir.rglob(pattern) if recursive else dir.glob(pattern)
│ │ +        # print(search)
│ │ +        for f in search:
│ │ +            if allow_multiple:
│ │ +                if self.paths:
│ │ +                    self.paths.append(f)
│ │ +                else:
│ │ +                    init: list[Path] = [f, ]
│ │ +                    self.paths = init
│ │ +            else:
│ │ +                self.paths = f
│ │ +                break
│ │ +
│ │ +
│ │ +class _track():
│ │ +
│ │ +    file: Path
│ │ +    type: TrackType
│ │ +    default: bool
│ │ +    forced: bool
│ │ +    name: str
│ │ +    lang: str
│ │ +    delay: int
│ │ +
│ │ +    def __init__(self, file: PathLike, type: str | int | TrackType, name: str = '', lang: str = '', default: bool = True, forced: bool = False, delay: int = 0) -> None:
│ │ +        """
│ │ +            :param file:        Filepath as string or Path object
│ │ +            :param type:        TrackType enum, or int or string (1 = 'video', 2 = 'audio', 3 = 'sub')
│ │ +            :param name:        The track name in the resulting mkv file
│ │ +            :param lang:        The language tag for the track
│ │ +            :param default:     Default flag
│ │ +            :param forced:      Forced flag
│ │ +            :param delay:       Container delay of track in ms
│ │ +        """
│ │ +        self.file = file if isinstance(file, Path) else Path(file)
│ │ +        self.default = default
│ │ +        self.forced = forced
│ │ +        self.name = name
│ │ +        self.delay = delay
│ │ +        # Maybe use https://pypi.org/project/pycountry/ to automatically convert iso-2 to iso-3
│ │ +        # as ffmpeg expects 3 letter codes; I am not sure what mkvmerge wants or can work with
│ │ +        self.lang = lang
│ │ +        self.type = type if isinstance(type, TrackType) \
│ │ +            else (TrackType(type) if isinstance(type, int) else TrackType[type.upper()])
│ │ +
│ │ +    def mkvmerge_args(self) -> str:
│ │ +        self.file = self.file if isinstance(self.file, Path) else Path(self.file)
│ │ +        if self.type == TrackType.ATTACHMENT:
│ │ +            is_font = self.file.suffix.lower() in ['.ttf', '.otf']
│ │ +            if not is_font and not self.lang:
│ │ +                raise ValueError(f'Please specify a mimetype for the attachments if they\'re not fonts!')
│ │ +            if not is_font:
│ │ +                return f' --attachment-mime-type {self.lang} --attach-file "{self.file.resolve()}"'
│ │ +            else:
│ │ +                return f' --attachment-mime-type {"font/ttf" if self.file.suffix.lower() == ".ttf" else "font/otf"} --attach-file "{self.file.resolve()}"'
│ │ +        elif self.type == TrackType.MKV:
│ │ +            return f' {self.name.strip()} "{self.file.resolve()}"'
│ │ +        elif self.type == TrackType.CHAPTERS:
│ │ +            return f' --chapters "{self.file.resolve()}"'
│ │ +        name_args = f' --track-name 0:"{self.name}"' if self.name else ''
│ │ +        lang_args = f' --language 0:{self.lang}' if self.lang else ''
│ │ +        delay_args = f' --sync 0:{self.delay}' if self.delay != 0 else ''
│ │ +        default_args = f' --default-track-flag 0:{"yes" if self.default else "no"}'
│ │ +        forced_args = f' --forced-display-flag 0:{"yes" if self.forced else "no"}'
│ │ +        timecode_args = ''
│ │ +        if isinstance(self, VideoTrack) and self.timecode_file is not None:
│ │ +            timecode_args = f' --timestamps 0:"{self.timecode_file.resolve()}"'
│ │ +        return f'{timecode_args}{name_args}{lang_args}{default_args}{forced_args}{delay_args} "{self.file.resolve()}"'
│ │ +
│ │ +
│ │ +class VideoTrack(_track):
│ │ +    """
│ │ +        _track object with VIDEO type preselected and japanese language default
│ │ +    """
│ │ +
│ │ +    timecode_file: PathLike | None = None
│ │ +
│ │ +    def __init__(self, file: PathLike | GlobSearch, name: str = '', lang: str = 'ja', default: bool = True, forced: bool = False, delay: int = 0, timecode_file: PathLike | GlobSearch = None) -> None:
│ │ +        if isinstance(file, GlobSearch):
│ │ +            file = file.paths[0] if isinstance(file.paths, list) else file.paths
│ │ +        if timecode_file is not None:
│ │ +            if isinstance(timecode_file, GlobSearch):
│ │ +                timecode_file = timecode_file.paths[0] if isinstance(timecode_file.paths, list) else timecode_file.paths
│ │ +            self.timecode_file = timecode_file if isinstance(timecode_file, Path) else Path(timecode_file)
│ │ +        super().__init__(file, TrackType.VIDEO, name, lang, default, forced, delay)
│ │ +
│ │ +
│ │ +class AudioTrack(_track):
│ │ +    """
│ │ +        _track object with AUDIO type preselected and japanese language default
│ │ +    """
│ │ +
│ │ +    def __init__(self, file: PathLike | GlobSearch, name: str = '', lang: str = 'ja', default: bool = True, forced: bool = False, delay: int = 0) -> None:
│ │ +        if isinstance(file, GlobSearch):
│ │ +            file = file.paths[0] if isinstance(file.paths, list) else file.paths
│ │ +        super().__init__(file, TrackType.AUDIO, name, lang, default, forced, delay)
│ │ +
│ │ +
│ │ +class Attachment(_track):
│ │ +    """
│ │ +        pseudo _track object for attachments
│ │ +    """
│ │ +
│ │ +    def __init__(self, file: str | Path, mimetype: str = '') -> None:
│ │ +        super().__init__(file, TrackType.ATTACHMENT, '', mimetype, False, False, 0)
│ │ +
│ │ +
│ │ +class SubTrack(_track):
│ │ +    """
│ │ +        _track object with SUB type preselected and english language default
│ │ +
│ │ +        Supports merging multiple files by passing a List of Path objects or filepath strings
│ │ +        and of course also a GlobSearch
│ │ +    """
│ │ +
│ │ +    def __init__(self, file: PathLike | list[PathLike] | GlobSearch, name: str = '', lang: str = 'en',
│ │ +                 default: bool = True, forced: bool = False, delay: int = 0) -> None:
│ │ +        if isinstance(file, GlobSearch):
│ │ +            file = file.paths
│ │ +
│ │ +        # Merge if multiple sub files
│ │ +        if isinstance(file, list):
│ │ +            ffs_python = f'for track "{name}"'
│ │ +            print(f'Merging subtitle files {ffs_python if name else ""}...')
│ │ +            ass_documents: list[ass.Document] = []
│ │ +            for ass_file in file:
│ │ +                ass_file = ass_file if isinstance(ass_file, Path) else Path(ass_file)
│ │ +                with open(ass_file, 'r', encoding='utf_8_sig') as read:
│ │ +                    ass_documents.append(ass.parse(read))
│ │ +
│ │ +            merged = ass_documents[0]
│ │ +            existing_styles = [style.name for style in (merged.styles)]
│ │ +            ass_documents.remove(merged)
│ │ +            for doc in ass_documents:
│ │ +                # Merges all the lines
│ │ +                merged.events.extend(doc.events)
│ │ +                # Check for dupe styles
│ │ +                for style in doc.styles:
│ │ +                    if style.name in existing_styles:
│ │ +                        print(f'WARN: Ignoring style "{style.name}" due to preexisting style of the same name!')
│ │ +                        continue
│ │ +                    merged.styles.append(style)
│ │ +                
│ │ +            out_file = uniquify_path(Path(os.path.join(get_workdir(), f'{Path(file[0]).stem}-merged.ass')))
│ │ +            with open(out_file, 'w', encoding='utf_8_sig') as merge_write:
│ │ +                merged.dump_file(merge_write)
│ │ +
│ │ +            file = Path(out_file)
│ │ +            print('Done.\n')
│ │ +
│ │ +        super().__init__(file, TrackType.SUB, name, lang, default, forced, delay)
│ │ +
│ │ +    def collect_fonts(self, work_dir: Path = get_workdir(), font_sources: list[str | Path] = None,
│ │ +                      debug_output: bool = False) -> list[Attachment]:
│ │ +        """
│ │ +            Validates and copies the fonts needed for this track into the specified `work_dir`.
│ │ +            `font_sources` can be mkv files or directories.
│ │ +
│ │ +            Returns a list of Attachment tracks you can feed into Mux()
│ │ +        """
│ │ +        out: list[Attachment] = []
│ │ +        doc: ass.Document = None
│ │ +        with open(self.file, 'r', encoding='utf_8_sig') as read:
│ │ +            doc = ass.parse(read)
│ │ +        validate_and_save_fonts([f'track "{self.name}"' if self.name else self.file.stem,
│ │ +                                doc], work_dir, font_sources, debug_output)
│ │ +        for f in os.listdir(work_dir):
│ │ +            filepath = Path(os.path.join(work_dir, f))
│ │ +            if filepath.suffix.lower() in ['.ttf', '.otf']:
│ │ +                out.append(Attachment(filepath.resolve()))
│ │ +
│ │ +        return out
│ │ +
│ │ +    def autoswapper(self, allowed_styles: list[str] | None = ['Default', 'Main', 'Alt', 'Overlap', 'Flashback', 'Top', 'Italics'], print_swaps: bool = False) -> "SubTrack":
│ │ +        """
│ │ +            autoswapper does the swapping.
│ │ +            Too lazy to explain
│ │ +
│ │ +            :param allowed_styles:      List of allowed styles to do the swapping on
│ │ +                                        Will run on every line if passed `None`
│ │ +            :param print_swaps:         Prints the swaps
│ │ +            
│ │ +            :return:                    This SubTrack
│ │ +        """
│ │ +        import re
│ │ +        with open(self.file, 'r', encoding='utf_8_sig') as f:
│ │ +            doc = ass.parse(f)
│ │ +        
│ │ +        events = []
│ │ +
│ │ +        for i, line in enumerate(doc.events):
│ │ +            if not allowed_styles or line.style.lower() in (style.lower() for style in allowed_styles):
│ │ +                to_swap: dict = {}
│ │ +                # {*}This will be replaced{*With this}
│ │ +                for match in re.finditer(re.compile(r'\{\*\}([^{]*)\{\*([^}*]+)\}'), line.text):
│ │ +                    to_swap.update({
│ │ +                        f"{match.group(0)}":
│ │ +                        f"{{*}}{match.group(2)}{{*{match.group(1)}}}"
│ │ +                    })
│ │ +                
│ │ +                # This sentence is no longer{** incomplete}
│ │ +                for match in re.finditer(re.compile(r'\{\*\*([^}]+)\}'), line.text):
│ │ +                    to_swap.update({
│ │ +                        f"{match.group(0)}":
│ │ +                        f"{{*}}{match.group(1)}{{*}}"
│ │ +                    })
│ │ +                
│ │ +                # This sentence is no longer{*} incomplete{*} 
│ │ +                for match in re.finditer(re.compile(r'\{\*\}([^{]*)\{\* *\}'), line.text):
│ │ +                    to_swap.update({
│ │ +                        f"{match.group(0)}":
│ │ +                        f"{{**{match.group(1)}}}"
│ │ +                    })
│ │ +                #print(to_swap)
│ │ +                for key, val in to_swap.items():
│ │ +                    if print_swaps:
│ │ +                        print(f'autoswapper: Swapped "{key}" for "{val}" on line {i}')
│ │ +                    line.text = line.text.replace(key, val)
│ │ +            
│ │ +            if line.effect.strip() == "***" or line.name.strip() == "***":
│ │ +                if isinstance(line, ass.Comment):
│ │ +                    line.TYPE = 'Dialogue'
│ │ +                elif isinstance(line, ass.Dialogue):
│ │ +                    line.TYPE = 'Comment'
│ │ +
│ │ +            events.append(line)
│ │ +        
│ │ +        doc.events = events
│ │ +        out_file = Path(os.path.join(get_workdir(), Path(self.file).stem + "-swapped.ass"))
│ │ +        with open(out_file, 'w', encoding='utf_8_sig') as f:
│ │ +            doc.dump_file(f)
│ │ +        
│ │ +        self.file = out_file
│ │ +        return self
│ │ +
│ │ +    def syncpoint_merge(self, syncpoint: str, mergefile: PathLike | GlobSearch, use_actor_field: bool = False, 
│ │ +        use_frames: bool = False, fps: Fraction = Fraction(24000, 1001), override_p1: int | timedelta = None, 
│ │ +        add_offset: int | timedelta = None, debug: bool = False) -> "SubTrack":
│ │ +        """
│ │ +            Merge other sub files (Opening/Ending kfx for example) with offsetting by syncpoints
│ │ +
│ │ +            :param syncpoint:           The syncpoint to be used
│ │ +            :param mergefile:           The file to be merged
│ │ +            :param use_actor_field:     Search the actor field instead of the effect field for the syncpoint
│ │ +            :param use_frames:          Uses frames to shift lines instead of direct timestamps
│ │ +            :param fps:                 The fps to go off of for the conversion
│ │ +            :param override_p1:         A manual override of the initial syncpoint
│ │ +                                        Obviously either a frame number or timedelta
│ │ +
│ │ +            :return:                    This SubTrack
│ │ +        """
│ │ +        if isinstance(mergefile, GlobSearch):
│ │ +            mergefile = mergefile.paths[0] if isinstance(mergefile.paths, list) else mergefile.paths
│ │ +        mergefile = mergefile if isinstance(mergefile, Path) else Path(mergefile)
│ │ +        was_merged = False
│ │ +
│ │ +        with open(self.file, 'r', encoding='utf_8_sig') as f:
│ │ +            doc = ass.parse(f)
│ │ +        with open(mergefile, 'r', encoding='utf_8_sig') as f:
│ │ +            mergedoc = ass.parse(f)
│ │ +
│ │ +        events = []
│ │ +        tomerge = []
│ │ +        existing_styles = [style.name for style in (doc.styles)]
│ │ +
│ │ +        if isinstance(add_offset, int) and not use_frames:
│ │ +            add_offset = frame_to_timedelta(add_offset, fps)
│ │ +
│ │ +        for line in doc.events:
│ │ +            events.append(line)
│ │ +            if was_merged:
│ │ +                continue
│ │ +            field = line.name if use_actor_field else line.effect
│ │ +            if field.lower().strip() == syncpoint.lower().strip() or line.text.lower().strip() == syncpoint.lower().strip() or override_p1 is not None:
│ │ +                was_merged = True
│ │ +                start = line.start if override_p1 is None else override_p1
│ │ +                offset: timedelta | int = None
│ │ +                for l in mergedoc.events:
│ │ +                    lfield = l.name if use_actor_field else l.effect
│ │ +                    if lfield.lower().strip() == syncpoint.lower().strip() or l.text.lower().strip() == syncpoint.lower().strip():
│ │ +                        mergedoc.events.remove(l)
│ │ +                        if use_frames:
│ │ +                            offset = timedelta_to_frame(start - l.start, fps)
│ │ +                        else:
│ │ +                            offset = start - l.start
│ │ +
│ │ +                        if add_offset:
│ │ +                            offset += add_offset
│ │ +                        break
│ │ +
│ │ +                for l in sorted(mergedoc.events, key = lambda event: event.start):
│ │ +                    if offset is None:
│ │ +                        if use_frames:
│ │ +                            offset = timedelta_to_frame(start - l.start, fps)
│ │ +                        else:
│ │ +                            offset = start - l.start
│ │ +
│ │ +                        if add_offset:
│ │ +                            offset += add_offset
│ │ +                            
│ │ +                        l.start = start
│ │ +                        l.end = (l.end + (frame_to_timedelta(offset, fps) if use_frames else offset))
│ │ +                    else:
│ │ +                        l.start = (l.start + (frame_to_timedelta(offset, fps) if use_frames else offset))
│ │ +                        l.end = (l.end + (frame_to_timedelta(offset, fps) if use_frames else offset))
│ │ +                    tomerge.append(l)
│ │ +
│ │ +        if was_merged:
│ │ +            events.extend(tomerge)
│ │ +            # Merge the styles in aswell
│ │ +            for style in mergedoc.styles:
│ │ +                if style.name in existing_styles:
│ │ +                    continue
│ │ +                doc.styles.append(style)
│ │ +
│ │ +            doc.events = events
│ │ +            out_file = uniquify_path(Path(os.path.join(get_workdir(), Path(self.file).stem + "-merge.ass")))
│ │ +            with open(out_file, 'w', encoding='utf_8_sig') as f:
│ │ +                doc.dump_file(f)
│ │ +
│ │ +            self.file = Path(out_file)
│ │ +        else:
│ │ +            print(f'Syncpoint "{syncpoint}" was not found!')
│ │ +
│ │ +        return self
│ │ +
│ │ +
│ │ +class MkvTrack(_track):
│ │ +
│ │ +    def __init__(self, file: PathLike | GlobSearch, mkvmerge_args: str = '') -> None:
│ │ +        if isinstance(file, GlobSearch):
│ │ +            file = file.paths[0] if isinstance(file.paths, list) else file.paths
│ │ +        super().__init__(file, TrackType.MKV, mkvmerge_args, '', False, False, 0)
│ │ +
│ │ +VT = VideoTrack
│ │ +AT = AudioTrack
│ │ +ST = SubTrack
│ │   --- vodesfunc-1.3.1/vodesfunc/auto/parsing.py
│ ├── +++ vodesfunc-1.3.2/vodesfunc/auto/parsing.py
│ │┄ Ordering differences only
│ │┄ Files 11% similar despite different names
│ │ @@ -1,109 +1,109 @@
│ │ -import re
│ │ -import os
│ │ -from pathlib import Path
│ │ -from fractions import Fraction
│ │ -from pyparsebluray import mpls
│ │ -from ..types import Chapter
│ │ -from .convert import timedelta_from_formatted, timedelta_to_frame, \
│ │ -        frame_to_timedelta, mpls_timestamp_to_timedelta, format_timedelta
│ │ -
│ │ -
│ │ -__all__: list[str] = [
│ │ -    'parse_ogm',
│ │ -    'parse_xml',
│ │ -    'parse_src_file',
│ │ -    'parse_m2ts_path'
│ │ -]
│ │ -
│ │ -OGM_REGEX = r'(^CHAPTER(?P<num>\d+)=(?P<time>.*)\nCHAPTER\d\dNAME=(?P<name>.*))'
│ │ -XML_REGEX = r'(\<ChapterAtom\>.*?\<ChapterTimeStart\>(?P<time>[^\<]*).*?\<ChapterString\>(?P<name>[^\<]*)\<\/ChapterString\>.*?\<\/ChapterAtom\>)'
│ │ -
│ │ -def parse_ogm(file: Path) -> list[Chapter]:
│ │ -    return _parse_chapters(file, OGM_REGEX, re.I | re.M) 
│ │ -
│ │ -def parse_xml(file: Path) -> list[Chapter]:
│ │ -    return _parse_chapters(file, XML_REGEX, re.I | re.M | re.S)
│ │ -
│ │ -def _parse_chapters(file: Path, reg: str, flags: int = 0) -> list[Chapter]:
│ │ -    chapters: list[Chapter] = []
│ │ -    with file.open('r', encoding='utf-8') as f:
│ │ -        for match in re.finditer(re.compile(reg, flags), f.read()):
│ │ -            chapters.append(
│ │ -                (timedelta_from_formatted(match.group('time')),
│ │ -                match.group('name'))
│ │ -            )
│ │ -
│ │ -    return chapters
│ │ -
│ │ -def parse_m2ts_path(dgiFile: Path) -> Path:
│ │ -    with open(dgiFile, 'r') as fp:
│ │ -        for i, line in enumerate(fp):
│ │ -            for match in re.finditer(re.compile(r"^(.*\.m2ts) \d+$", re.IGNORECASE), line):
│ │ -                m2tsFile = Path(match.group(1))
│ │ -                if m2tsFile.exists():
│ │ -                    return m2tsFile
│ │ -    print("Warning!\nCould not resolve origin file path from the dgindex input!")
│ │ -    return dgiFile
│ │ -
│ │ -from ..util import src_file
│ │ -
│ │ -def parse_src_file(src: src_file, _print: bool = False) -> list[Chapter]:
│ │ -    stream_dir = src.file.resolve().parent
│ │ -    if stream_dir.name.lower() != 'stream':
│ │ -        print(f'Your source file is not in a default bdmv structure!\nWill skip chapters.')
│ │ -        return None
│ │ -    playlist_dir = Path(os.path.join(stream_dir.parent, "PLAYLIST"))
│ │ -    if not playlist_dir.exists():
│ │ -        print(f'PLAYLIST folder couldn\'t have been found!\nWill skip chapters.')
│ │ -        return None
│ │ -
│ │ -    chapters: list[Chapter] = []
│ │ -    for f in playlist_dir.rglob("*"):
│ │ -        if not os.path.isfile(f) or f.suffix.lower() != '.mpls':
│ │ -            continue
│ │ -        with f.open('rb') as file:
│ │ -            header = mpls.load_movie_playlist(file)
│ │ -            file.seek(header.playlist_start_address, os.SEEK_SET)
│ │ -            playlist = mpls.load_playlist(file)
│ │ -            if not playlist.play_items:
│ │ -                continue
│ │ -
│ │ -            file.seek(header.playlist_mark_start_address, os.SEEK_SET)
│ │ -            playlist_mark = mpls.load_playlist_mark(file)
│ │ -            if (plsmarks := playlist_mark.playlist_marks) is not None:
│ │ -                marks = plsmarks
│ │ -            else:
│ │ -                raise 'There is no playlist marks in this file!'
│ │ -
│ │ -        for i, playitem in enumerate(playlist.play_items):
│ │ -            if playitem.clip_information_filename == src.file.stem and \
│ │ -                    playitem.clip_codec_identifier.lower() == src.file.suffix.lower().split('.')[1]:
│ │ -                if _print:
│ │ -                    print(f'Found chapters for "{src.file.name}" in "{f.name}":')
│ │ -                linked_marks = [mark for mark in marks if mark.ref_to_play_item_id == i]
│ │ -                try:
│ │ -                    assert playitem.intime
│ │ -                    offset = min(playitem.intime, linked_marks[0].mark_timestamp)
│ │ -                except IndexError:
│ │ -                    continue
│ │ -                if playitem.stn_table and playitem.stn_table.length != 0 and playitem.stn_table.prim_video_stream_entries \
│ │ -                        and (fps_n := playitem.stn_table.prim_video_stream_entries[0][1].framerate):
│ │ -                    try:
│ │ -                        fps = mpls.FRAMERATE[fps_n]
│ │ -                    except:
│ │ -                        print('Couldn\'t parse fps from playlist! Will take fps from source clip.')
│ │ -                        fps = Fraction(src.src_cut.fps_num, src.src_cut.fps_den)
│ │ -
│ │ -                    for i, lmark in enumerate(linked_marks, start=1):
│ │ -                        time = mpls_timestamp_to_timedelta(lmark.mark_timestamp - offset)
│ │ -                        if time > frame_to_timedelta(src.src.num_frames - 1, fps):
│ │ -                            continue
│ │ -                        chapters.append((time, f'Chapter {i:02.0f}'))
│ │ -                    if chapters and _print:
│ │ -                        for (time, name) in chapters:
│ │ -                            print(f'{name}: {format_timedelta(time)} | {timedelta_to_frame(time, fps)}')
│ │ -
│ │ -        if chapters:
│ │ -            break
│ │ -
│ │ +import re
│ │ +import os
│ │ +from pathlib import Path
│ │ +from fractions import Fraction
│ │ +from pyparsebluray import mpls
│ │ +from ..types import Chapter
│ │ +from .convert import timedelta_from_formatted, timedelta_to_frame, \
│ │ +        frame_to_timedelta, mpls_timestamp_to_timedelta, format_timedelta
│ │ +
│ │ +
│ │ +__all__: list[str] = [
│ │ +    'parse_ogm',
│ │ +    'parse_xml',
│ │ +    'parse_src_file',
│ │ +    'parse_m2ts_path'
│ │ +]
│ │ +
│ │ +OGM_REGEX = r'(^CHAPTER(?P<num>\d+)=(?P<time>.*)\nCHAPTER\d\dNAME=(?P<name>.*))'
│ │ +XML_REGEX = r'(\<ChapterAtom\>.*?\<ChapterTimeStart\>(?P<time>[^\<]*).*?\<ChapterString\>(?P<name>[^\<]*)\<\/ChapterString\>.*?\<\/ChapterAtom\>)'
│ │ +
│ │ +def parse_ogm(file: Path) -> list[Chapter]:
│ │ +    return _parse_chapters(file, OGM_REGEX, re.I | re.M) 
│ │ +
│ │ +def parse_xml(file: Path) -> list[Chapter]:
│ │ +    return _parse_chapters(file, XML_REGEX, re.I | re.M | re.S)
│ │ +
│ │ +def _parse_chapters(file: Path, reg: str, flags: int = 0) -> list[Chapter]:
│ │ +    chapters: list[Chapter] = []
│ │ +    with file.open('r', encoding='utf-8') as f:
│ │ +        for match in re.finditer(re.compile(reg, flags), f.read()):
│ │ +            chapters.append(
│ │ +                (timedelta_from_formatted(match.group('time')),
│ │ +                match.group('name'))
│ │ +            )
│ │ +
│ │ +    return chapters
│ │ +
│ │ +def parse_m2ts_path(dgiFile: Path) -> Path:
│ │ +    with open(dgiFile, 'r') as fp:
│ │ +        for i, line in enumerate(fp):
│ │ +            for match in re.finditer(re.compile(r"^(.*\.m2ts) \d+$", re.IGNORECASE), line):
│ │ +                m2tsFile = Path(match.group(1))
│ │ +                if m2tsFile.exists():
│ │ +                    return m2tsFile
│ │ +    print("Warning!\nCould not resolve origin file path from the dgindex input!")
│ │ +    return dgiFile
│ │ +
│ │ +from ..util import src_file
│ │ +
│ │ +def parse_src_file(src: src_file, _print: bool = False) -> list[Chapter]:
│ │ +    stream_dir = src.file.resolve().parent
│ │ +    if stream_dir.name.lower() != 'stream':
│ │ +        print(f'Your source file is not in a default bdmv structure!\nWill skip chapters.')
│ │ +        return None
│ │ +    playlist_dir = Path(os.path.join(stream_dir.parent, "PLAYLIST"))
│ │ +    if not playlist_dir.exists():
│ │ +        print(f'PLAYLIST folder couldn\'t have been found!\nWill skip chapters.')
│ │ +        return None
│ │ +
│ │ +    chapters: list[Chapter] = []
│ │ +    for f in playlist_dir.rglob("*"):
│ │ +        if not os.path.isfile(f) or f.suffix.lower() != '.mpls':
│ │ +            continue
│ │ +        with f.open('rb') as file:
│ │ +            header = mpls.load_movie_playlist(file)
│ │ +            file.seek(header.playlist_start_address, os.SEEK_SET)
│ │ +            playlist = mpls.load_playlist(file)
│ │ +            if not playlist.play_items:
│ │ +                continue
│ │ +
│ │ +            file.seek(header.playlist_mark_start_address, os.SEEK_SET)
│ │ +            playlist_mark = mpls.load_playlist_mark(file)
│ │ +            if (plsmarks := playlist_mark.playlist_marks) is not None:
│ │ +                marks = plsmarks
│ │ +            else:
│ │ +                raise 'There is no playlist marks in this file!'
│ │ +
│ │ +        for i, playitem in enumerate(playlist.play_items):
│ │ +            if playitem.clip_information_filename == src.file.stem and \
│ │ +                    playitem.clip_codec_identifier.lower() == src.file.suffix.lower().split('.')[1]:
│ │ +                if _print:
│ │ +                    print(f'Found chapters for "{src.file.name}" in "{f.name}":')
│ │ +                linked_marks = [mark for mark in marks if mark.ref_to_play_item_id == i]
│ │ +                try:
│ │ +                    assert playitem.intime
│ │ +                    offset = min(playitem.intime, linked_marks[0].mark_timestamp)
│ │ +                except IndexError:
│ │ +                    continue
│ │ +                if playitem.stn_table and playitem.stn_table.length != 0 and playitem.stn_table.prim_video_stream_entries \
│ │ +                        and (fps_n := playitem.stn_table.prim_video_stream_entries[0][1].framerate):
│ │ +                    try:
│ │ +                        fps = mpls.FRAMERATE[fps_n]
│ │ +                    except:
│ │ +                        print('Couldn\'t parse fps from playlist! Will take fps from source clip.')
│ │ +                        fps = Fraction(src.src_cut.fps_num, src.src_cut.fps_den)
│ │ +
│ │ +                    for i, lmark in enumerate(linked_marks, start=1):
│ │ +                        time = mpls_timestamp_to_timedelta(lmark.mark_timestamp - offset)
│ │ +                        if time > frame_to_timedelta(src.src.num_frames - 1, fps):
│ │ +                            continue
│ │ +                        chapters.append((time, f'Chapter {i:02.0f}'))
│ │ +                    if chapters and _print:
│ │ +                        for (time, name) in chapters:
│ │ +                            print(f'{name}: {format_timedelta(time)} | {timedelta_to_frame(time, fps)}')
│ │ +
│ │ +        if chapters:
│ │ +            break
│ │ +
│ │      return chapters
│ │   --- vodesfunc-1.3.1/vodesfunc/auto/webhook.py
│ ├── +++ vodesfunc-1.3.2/vodesfunc/auto/webhook.py
│ │┄ Ordering differences only
│ │┄ Files 26% similar despite different names
│ │ @@ -1,57 +1,57 @@
│ │ -"""
│ │ -    WIP, kinda demotivated to do this shit
│ │ -"""
│ │ -
│ │ -from datetime import datetime
│ │ -from time import sleep
│ │ -
│ │ -from discord_webhook import DiscordEmbed, DiscordWebhook
│ │ -from StringProgressBar import progressBar
│ │ -
│ │ -
│ │ -__all__: list[str] = [
│ │ -    'Webhook',
│ │ -]
│ │ -
│ │ -
│ │ -class Webhook:
│ │ -
│ │ -    sent = None
│ │ -    url: str
│ │ -    show_name: str
│ │ -    episode: str
│ │ -    last_updated: datetime
│ │ -    prev_progress: int = 0
│ │ -    discord_webhook: DiscordWebhook
│ │ -
│ │ -    def __init__(self, url: str, show_name: str, episode: str) -> None:
│ │ -        self.url = url
│ │ -        self.show_name = show_name
│ │ -        self.episode = episode
│ │ -        discord_webhook = DiscordWebhook(self.url, content="Initializing...")
│ │ -        sleep(10)
│ │ -        self.sent = discord_webhook.execute()
│ │ -
│ │ -    def update_message(self, process: str = 'Encode', details: str = "", fields: dict = {}, progress: int = 0, total: int = 0) -> bool | None:
│ │ -        now = datetime.now()
│ │ -        if ((self.last_updated.second + 5) < now.second) or self.sent is None:
│ │ -            return None
│ │ -
│ │ -        bar = progressBar().filledBar(total=total, current=progress, size=80)
│ │ -
│ │ -        self.discord_webhook.content = ""
│ │ -
│ │ -        self.discord_webhook.remove_embeds()
│ │ -        embed = DiscordEmbed(self.show_name + " - " + self.episode)
│ │ -        embed.set_author(process + " running...")
│ │ -        newline = "\n"
│ │ -        padded_details = "\n" + details
│ │ -        embed.set_description(f'Progress:```{newline}{bar[0]} {bar[1]}```{padded_details if details else ""}')
│ │ -        for key, val in fields:
│ │ -            embed.add_embed_field(str(key), str(val), True)
│ │ -        self.discord_webhook.add_embed(embed)
│ │ -
│ │ -        self.sent = self.discord_webhook.edit(self.sent)
│ │ -        self.prev_progress = progress
│ │ -        #requests.patch(self.url + "/messages/" + self.message_id)
│ │ -        self.last_updated = now
│ │ +"""
│ │ +    WIP, kinda demotivated to do this shit
│ │ +"""
│ │ +
│ │ +from datetime import datetime
│ │ +from time import sleep
│ │ +
│ │ +from discord_webhook import DiscordEmbed, DiscordWebhook
│ │ +from StringProgressBar import progressBar
│ │ +
│ │ +
│ │ +__all__: list[str] = [
│ │ +    'Webhook',
│ │ +]
│ │ +
│ │ +
│ │ +class Webhook:
│ │ +
│ │ +    sent = None
│ │ +    url: str
│ │ +    show_name: str
│ │ +    episode: str
│ │ +    last_updated: datetime
│ │ +    prev_progress: int = 0
│ │ +    discord_webhook: DiscordWebhook
│ │ +
│ │ +    def __init__(self, url: str, show_name: str, episode: str) -> None:
│ │ +        self.url = url
│ │ +        self.show_name = show_name
│ │ +        self.episode = episode
│ │ +        discord_webhook = DiscordWebhook(self.url, content="Initializing...")
│ │ +        sleep(10)
│ │ +        self.sent = discord_webhook.execute()
│ │ +
│ │ +    def update_message(self, process: str = 'Encode', details: str = "", fields: dict = {}, progress: int = 0, total: int = 0) -> bool | None:
│ │ +        now = datetime.now()
│ │ +        if ((self.last_updated.second + 5) < now.second) or self.sent is None:
│ │ +            return None
│ │ +
│ │ +        bar = progressBar().filledBar(total=total, current=progress, size=80)
│ │ +
│ │ +        self.discord_webhook.content = ""
│ │ +
│ │ +        self.discord_webhook.remove_embeds()
│ │ +        embed = DiscordEmbed(self.show_name + " - " + self.episode)
│ │ +        embed.set_author(process + " running...")
│ │ +        newline = "\n"
│ │ +        padded_details = "\n" + details
│ │ +        embed.set_description(f'Progress:```{newline}{bar[0]} {bar[1]}```{padded_details if details else ""}')
│ │ +        for key, val in fields:
│ │ +            embed.add_embed_field(str(key), str(val), True)
│ │ +        self.discord_webhook.add_embed(embed)
│ │ +
│ │ +        self.sent = self.discord_webhook.edit(self.sent)
│ │ +        self.prev_progress = progress
│ │ +        #requests.patch(self.url + "/messages/" + self.message_id)
│ │ +        self.last_updated = now
│ │   --- vodesfunc-1.3.1/vodesfunc/automation.py
│ ├── +++ vodesfunc-1.3.2/vodesfunc/automation.py
│ │┄ Ordering differences only
│ │┄ Files 23% similar despite different names
│ │ @@ -1,690 +1,690 @@
│ │ -import os
│ │ -import re
│ │ -import shutil as sh
│ │ -import subprocess
│ │ -from configparser import ConfigParser
│ │ -from fractions import Fraction
│ │ -from pathlib import Path
│ │ -from typing import Callable
│ │ -from datetime import timedelta
│ │ -
│ │ -import vapoursynth as vs
│ │ -from vstools import Matrix, Primaries, Transfer, ColorRange, ChromaLocation
│ │ -
│ │ -from .auto.download import get_executable
│ │ -from .auto.convert import timedelta_to_frame, frame_to_timedelta, format_timedelta
│ │ -from .auto.parsing import parse_ogm, parse_xml, parse_src_file
│ │ -from .types import PathLike, Trim, Zone, Chapter, TrackType
│ │ -from .util import src_file, uniquify_path, get_crc32, is_x264_zone
│ │ -
│ │ -global setup
│ │ -setup = None
│ │ -
│ │ -__all__: list[str] = [
│ │ -    'Chapters',
│ │ -    'light_sucks',
│ │ -    'Mux',
│ │ -    'settings_builder_x265', 'sb', 'sb264', 'sb265',
│ │ -    'Setup',
│ │ -    'VT', 'AT', 'ST',
│ │ -    'VideoTrack', 'AudioTrack', 'SubTrack',
│ │ -    'Attachment', 'GlobSearch'
│ │ -]
│ │ -
│ │ -class Setup:
│ │ -    """
│ │ -        When you initiate this for the first time in a directory
│ │ -        it will create a new config.ini. Set that up and have fun with all the other functions :)
│ │ -    """
│ │ -
│ │ -    bdmv_dir = "BDMV"
│ │ -    show_name = "Nice Series"
│ │ -    allow_binary_download = True
│ │ -    clean_work_dirs = False
│ │ -    out_dir = "premux"
│ │ -    out_name = "$show$ - $ep$ (premux)"
│ │ -    mkv_title_naming = r"$show$ - $ep$"
│ │ -
│ │ -    episode: str = "01"
│ │ -    work_dir: Path = None
│ │ -    webhook_url: str = None
│ │ -
│ │ -    def __init__(self, episode: str = "01", config_file: str = "config.ini"):
│ │ -        """
│ │ -            :param episode:         Episode identifier(?)
│ │ -            :param config_file:     Path to config file (defaults to 'config.ini' in current working dir)
│ │ -        """
│ │ -
│ │ -        if config_file:
│ │ -            config = ConfigParser()
│ │ -            config_name = config_file
│ │ -
│ │ -            if not os.path.exists(config_name):
│ │ -                config['SETUP'] = {
│ │ -                    'bdmv_dir': self.bdmv_dir,
│ │ -                    'show_name': self.show_name,
│ │ -                    'allow_binary_download': self.allow_binary_download,
│ │ -                    'clean_work_dirs': self.clean_work_dirs,
│ │ -                    'out_dir': self.out_dir,
│ │ -                    'out_name': self.out_name,
│ │ -                    'mkv_title_naming': self.mkv_title_naming,
│ │ -                    # 'webhook_url': self.webhook_url
│ │ -                }
│ │ -
│ │ -                with open(config_name, 'w') as config_file:
│ │ -                    config.write(config_file)
│ │ -
│ │ -                raise SystemExit(f"Template config created at {Path(config_name).resolve()}.\nPlease set it up!")
│ │ -
│ │ -            config.read(config_name)
│ │ -            settings = config['SETUP']
│ │ -
│ │ -            for key in settings:
│ │ -                setattr(self, key, settings[key])
│ │ -
│ │ -            if isinstance(self.allow_binary_download, str):
│ │ -                self.allow_binary_download = True if self.allow_binary_download.strip().lower() in ['true', 'yes'] else False
│ │ -                
│ │ -            if isinstance(self.clean_work_dirs, str):
│ │ -                self.clean_work_dirs = True if self.clean_work_dirs.strip().lower() in ['true', 'yes'] else False
│ │ -
│ │ -        self.episode = episode
│ │ -        self.work_dir = Path(os.path.join(os.getcwd(), "_workdir", episode))
│ │ -        self.work_dir.mkdir(parents=True, exist_ok=True)
│ │ -
│ │ -        global setup
│ │ -        setup = self
│ │ -        return None
│ │ -
│ │ -    def encode_video(self, clip: vs.VideoNode, settings: str = '', zones: Zone | list[Zone] = None, codec: str = 'x265',
│ │ -                     save_csv_log: bool = True, generate_qpfile: bool = True, src: vs.VideoNode | src_file = None,
│ │ -                     specify_props: bool = True, print_command: bool = False) -> str:
│ │ -        """
│ │ -            Encodes the clip you pass into it with your desired encoder
│ │ -
│ │ -            :param clip:            Clip to be encoded
│ │ -            :param settings:        Settings passed to the encoder. I recommend using the settings_builder function
│ │ -            :param zones:           Zone(s) like these (start, end, bitrate_multiplier)
│ │ -            :param codec:           x265, x264 and ffv1 are supported
│ │ -            :param save_csv_log:    Saves the csv log file from x265
│ │ -            :param generate_qpfile: Automatically generates a qpfile from your source clip (would not recommend running on the filtered clip)
│ │ -            :param src:             Source Clip or `src_file` for the qpfile generation
│ │ -            :param specify_props:   Specify color related props to the encoder if using x265 or x264
│ │ -            :param print_command:   Prints the final encoder command before running it
│ │ -            :return:                Absolute filepath for resulting video file
│ │ -        """
│ │ -        if codec.lower() not in ['x265', 'x264', 'ffv1']:
│ │ -            raise ValueError('encode_video: codec has to be either x265, x264 or ffv1')
│ │ -        encoder_exe = get_executable('ffmpeg' if codec.lower() == 'ffv1' else codec, self.allow_binary_download)
│ │ -        args = settings
│ │ -
│ │ -        if codec.lower() in ['x265', 'x264']:
│ │ -            if zones:
│ │ -                zones_settings: str = ''
│ │ -                for i, zone in enumerate(zones):
│ │ -                    if is_x264_zone(zone):
│ │ -                        if codec.lower() == 'x265' and zone[2].lower() != 'q':
│ │ -                            raise ValueError(f"Zone '{zone}' is invalid for x265. Please only use b or q.")
│ │ -                        zones_settings += f'{zone[0]},{zone[1]},{zone[2]}={zone[3]}'
│ │ -                    else:
│ │ -                        zones_settings += f'{zone[0]},{zone[1]},b={zone[2]}'
│ │ -                    if i != len(zones) - 1:
│ │ -                        zones_settings += '/'
│ │ -                args += f' --zones {zones_settings}'
│ │ -
│ │ -            if save_csv_log and codec.lower() == 'x265':
│ │ -                args += f' --csv "{Path(self.show_name + "_log_x265.csv").resolve()}"'
│ │ -            if generate_qpfile:
│ │ -                if isinstance(src, vs.VideoNode) or isinstance(src, src_file):
│ │ -                    src = src if isinstance(src, vs.VideoNode) else src.src_cut
│ │ -                    qpfile = self.generate_qp_file(src)
│ │ -                    if qpfile:
│ │ -                        args += f' --qpfile "{qpfile}"'
│ │ -                else:
│ │ -                    print("encode_video: No 'src' parameter passed, Skipping qpfile creation!")
│ │ -
│ │ -            if specify_props:
│ │ -                bits = clip.format.bits_per_sample
│ │ -                c_range = ColorRange.from_video(clip).string if codec.lower() == 'x265' else \
│ │ -                    ('tv' if ColorRange.from_video(clip) == ColorRange.LIMITED else 'pc')
│ │ -                args += f' --input-depth {bits} --output-depth {bits} --colorprim {Primaries.from_video(clip).string}'
│ │ -                args += f' --transfer {Transfer.from_video(clip).string} --colormatrix {Matrix.from_video(clip).string}'
│ │ -                args += f' --chromaloc {int(ChromaLocation.from_video(clip))} --range {c_range}'
│ │ -
│ │ -            outpath = self.work_dir.joinpath(self.episode + "." + codec.strip('x')).resolve()
│ │ -            if codec.lower() == 'x265':
│ │ -                encoder_command = f'"{encoder_exe}" -o "{outpath}" - --y4m ' + args.strip()
│ │ -            else:
│ │ -                encoder_command = f'"{encoder_exe}" -o "{outpath}" --demuxer y4m - ' + args.strip()
│ │ -        else:
│ │ -            if not args:
│ │ -                args = f'-coder 1 -context 0 -g 1 -level 3 -threads 0 -slices 24 -slicecrc 1'
│ │ -            outpath = self.work_dir.joinpath(self.episode + ".mkv").resolve()
│ │ -            encoder_command = f'"{encoder_exe}" -f yuv4mpegpipe -i - -c:v ffv1 {args.strip()} "{outpath}"'
│ │ -        if print_command:
│ │ -            print(f'\nxEncoder Command:\n{encoder_command}\n')
│ │ -
│ │ -        print(f"Encoding episode {self.episode} to {codec}...")
│ │ -        if os.name != 'nt':
│ │ -            process = subprocess.Popen(encoder_command, stdin=subprocess.PIPE, shell=True)
│ │ -        else:
│ │ -            process = subprocess.Popen(encoder_command, stdin=subprocess.PIPE, shell=False)
│ │ -        clip.output(process.stdin, y4m=True, progress_update=lambda x, y: self._update_progress(x, y))
│ │ -        process.communicate()
│ │ -
│ │ -        print("\nDone encoding video.")
│ │ -        return str(outpath.resolve())
│ │ -
│ │ -    def encode_audio(self, file: PathLike | src_file, track: int = 0, codec: str = 'opus', q: int = 200,
│ │ -                     encoder_settings: str = '', trim: Trim = None, clip: vs.VideoNode | src_file = None,# use_bs_trimming: bool = False,
│ │ -                     dither_flac: bool = True, always_dither: bool = False, quiet: bool = True) -> str:
│ │ -        """
│ │ -            Encodes the audio
│ │ -
│ │ -            :param file:                Either a string based filepath, a Path object or a `src_file`
│ │ -            :param track:               Audio Track Number of your input file. 0-based
│ │ -            :param codec:               Either flac, opus or aac. Uses ffmpeg, opusenc or qaac respectively.
│ │ -                                        'pass' and 'passthrough' also exist and do what they say
│ │ -            :param q:                   Quality. Basically just the bitrate when using opus and the tVBR/-V value for qaac
│ │ -            :param encoder_settings:    Arguments directly passed to opusenc or qaac
│ │ -            :param trim:                Tuple of frame numbers; Can be left empty if you passed a `src_file` with trims
│ │ -            :param clip:                Vapoursynth VideoNode needed when trimming; Can be left empty if you passed a `src_file`
│ │ -            :param dither_flac:         Will dither your FLAC output to 16bit and 48 kHz
│ │ -            :param always_dither:       Dithers regardless of your final output
│ │ -            :param quiet:               Will print the subprocess outputs if False
│ │ -            :return:                    Absolute filepath for resulting audio file
│ │ -        """
│ │ -        encoder_settings = ' ' + encoder_settings.strip()
│ │ -        
│ │ -        if trim is not None:
│ │ -            if isinstance(file, src_file):
│ │ -                print("Warning: trims in src_file types will overwrite other trims passed!")
│ │ -            else:
│ │ -                if not isinstance(clip, vs.VideoNode) and not isinstance(clip, src_file):
│ │ -                    raise "encode_audio: Trimming audio requires a clip input!"
│ │ -                elif isinstance(clip, src_file):
│ │ -                    clip = clip.src
│ │ -                    fps = Fraction(clip.fps_num, clip.fps_den)
│ │ -                else:
│ │ -                    fps = Fraction(clip.fps_num, clip.fps_den)
│ │ -
│ │ -        if isinstance(file, src_file):
│ │ -            trim = file.trim
│ │ -            clip = file.src
│ │ -            fps = Fraction(clip.fps_num, clip.fps_den)
│ │ -
│ │ -        file = file.file if isinstance(file, src_file) else file
│ │ -        file = file if isinstance(file, Path) else Path(file)
│ │ -
│ │ -        base_path = os.path.join(self.work_dir.resolve(), file.stem + "_" + str(track))
│ │ -
│ │ -        def ffmpeg_header() -> str:
│ │ -            ffmpeg_exe = get_executable('ffmpeg', self.allow_binary_download)
│ │ -            return f'"{ffmpeg_exe}" -hide_banner{" -loglevel warning" if quiet else ""}'
│ │ -
│ │ -        def ffmpeg_seekargs() -> str:
│ │ -            args = ''
│ │ -            if trim:
│ │ -                if trim[0] is not None and trim[0] > 0:
│ │ -                    args += f' -ss {format_timedelta(frame_to_timedelta(trim[0], fps))}'
│ │ -                if trim[1] is not None and trim[1] != 0:
│ │ -                    if trim[1] > 0:
│ │ -                        args += f' -to {format_timedelta(frame_to_timedelta(trim[1], fps))}'
│ │ -                    else:
│ │ -                        end_frame = clip.num_frames - abs(trim[1])
│ │ -                        args += f' -to {format_timedelta(frame_to_timedelta(end_frame, fps))}'
│ │ -                if not quiet:
│ │ -                    print(args)
│ │ -            return args
│ │ -
│ │ -        def toflac() -> str:
│ │ -            is_intermediary = codec.lower() != 'flac'
│ │ -            compression_level = "10" if not is_intermediary else "0"
│ │ -            commandline = f'{ffmpeg_header()} -i "{file.resolve()}" -map_metadata -1 -map_chapters -1 -map 0:a:{track} {ffmpeg_seekargs()} -f flac -compression_level {compression_level}'
│ │ -            if (dither_flac and codec.lower() == 'flac') or always_dither:
│ │ -                commandline += ' -sample_fmt s16 -ar 48000 -resampler soxr -precision 28 -dither_method shibata'
│ │ -            if codec.lower() != 'opus':
│ │ -                _flac = base_path + ".flac"
│ │ -                if not should_create_again(_flac):
│ │ -                    return _flac
│ │ -                commandline += f' "{_flac}"'
│ │ -                print(f'Creating FLAC intermediary audio track {track} for EP{self.episode}...'
│ │ -                    if is_intermediary else f'Encoding audio track {track} for EP{self.episode} to FLAC...')
│ │ -                run_commandline(commandline, quiet, False)
│ │ -                if not is_intermediary:
│ │ -                    print('Done\n')
│ │ -                return _flac
│ │ -            else:
│ │ -                # We can just use a cool pipe with opusenc
│ │ -                return commandline + " - | "
│ │ -            
│ │ -        if codec.lower() == 'flac':
│ │ -            return toflac()
│ │ -
│ │ -        if codec.lower() in ['pass', 'passthrough']:
│ │ -            out_file = base_path + ".mka"
│ │ -            if not should_create_again(out_file):
│ │ -                return out_file
│ │ -            print(f'Trimming audio track {track} for EP{self.episode}...'
│ │ -                if trim else f'Extracting audio track {track} for EP{self.episode}')
│ │ -            commandline = f'{ffmpeg_header()} -i "{file.resolve()}" -map_metadata -1 -map_chapters -1 -map 0:a:{track} {ffmpeg_seekargs()} -c:a copy "{out_file}"'
│ │ -            run_commandline(commandline, quiet, False)
│ │ -            print('Done.\n')
│ │ -            return out_file
│ │ -
│ │ -        if codec.lower() == 'aac':
│ │ -            if q > 127 or q < 0:
│ │ -                raise ValueError(f'encode_audio: QAAC tvbr must be in the range of 0 - 127')
│ │ -            flac = toflac()
│ │ -            qaac =  get_executable('qaac', self.allow_binary_download)
│ │ -            out_file = base_path + ".m4a"
│ │ -            if not should_create_again(out_file):
│ │ -                return out_file
│ │ -            commandline = f'"{qaac}" -V {q} {encoder_settings} -o "{out_file}" "{flac}"'
│ │ -            print(f'Encoding audio track {track} for EP{self.episode} to AAC...')
│ │ -            run_commandline(commandline, quiet, False)
│ │ -            print('Done.\n')
│ │ -            Path(flac).unlink(missing_ok = True)
│ │ -            return out_file
│ │ -        
│ │ -        if codec.lower() == 'opus':
│ │ -            if q > 512 or q < 8:
│ │ -                raise ValueError(f'encode_audio: Opus bitrate must be in the range of 8 - 512 (kbit/s)')
│ │ -            commandline = toflac()
│ │ -            opusenc = get_executable('opusenc', self.allow_binary_download)
│ │ -            out_file = base_path + ".ogg"
│ │ -            if not should_create_again(out_file):
│ │ -                return out_file
│ │ -            commandline += f'"{opusenc}" --bitrate {q} {encoder_settings} - "{out_file}"'
│ │ -            print(f'Encoding audio track {track} for EP{self.episode} to Opus...')
│ │ -            run_commandline(commandline, quiet, True)
│ │ -            print('Done.\n')
│ │ -            return out_file
│ │ -
│ │ -    def generate_qp_file(self, clip: vs.VideoNode) -> str:
│ │ -        filepath = os.path.join(self.work_dir, 'qpfile.txt')
│ │ -        if not should_create_again(filepath, 100):
│ │ -            print('Reusing existing QP File.')
│ │ -            return str(Path(filepath).resolve())
│ │ -        print('Generating QP File...')
│ │ -        clip = clip.resize.Bicubic(640, 360, format=vs.YUV410P8)
│ │ -        clip = clip.wwxd.WWXD()
│ │ -        out = ""
│ │ -        for i in range(1, clip.num_frames):
│ │ -            if clip.get_frame(i).props.Scenechange == 1:
│ │ -                out += f"{i} I -1\n"
│ │ -
│ │ -        with open(filepath, 'w') as file:
│ │ -            file.write(out)
│ │ -
│ │ -        return str(Path(filepath).resolve()) if os.path.exists(filepath) else ""
│ │ -
│ │ -    def from_mkv(self, mkv: PathLike, type: TrackType, track: int = -1) -> str:
│ │ -        """
│ │ -            Get various tracks from an existing mkv file
│ │ -
│ │ -            :param mkv:         Path to file
│ │ -            :param type:        TrackType to get
│ │ -            :param track:       The *absolute* track number. No idea why they do this
│ │ -                                but a specific video/audio/sub track is not a thing
│ │ -                                so you're gonna have to pass the absolute number
│ │ -            :return:            Path to resulting mkv or txt (if chapters)
│ │ -        """
│ │ -        mkv = mkv if isinstance(mkv, Path) else Path(mkv)
│ │ -        mkvmerge_exe = get_executable('mkvmerge', self.allow_binary_download)
│ │ -        mkvextract_exe = get_executable('mkvextract', self.allow_binary_download)
│ │ -        out_file = f"{mkv.stem}_{TrackType(type).name}_{str(track)}.{'txt' if type == TrackType.CHAPTERS else 'mkv'}"
│ │ -        out_path = os.path.join(self.work_dir.resolve(), out_file)
│ │ -
│ │ -        if type == TrackType.CHAPTERS:
│ │ -            commandline = f'"{mkvextract_exe}" "{mkv.resolve()}" chapters --simple "{out_path}"'
│ │ -        else:
│ │ -            commandline = f'"{mkvmerge_exe}" -o "{out_path} '
│ │ -            if type != TrackType.ATTACHMENT and track < 0:
│ │ -                raise ValueError(f'from_mkv: Please specify a track for anything but \'Attachment\'')
│ │ -            match type:
│ │ -                case TrackType.VIDEO:
│ │ -                    commandline += f' -A -d {track} -S -B -T -M --no-chapters --no-global-tags'
│ │ -                case TrackType.AUDIO:
│ │ -                    commandline += f' -a {track} -D -S -B -T -M --no-chapters --no-global-tags'
│ │ -                case TrackType.SUB:
│ │ -                    commandline += f' -A -D -s {track} -B -T -M --no-chapters --no-global-tags'
│ │ -                case TrackType.ATTACHMENT:
│ │ -                    commandline += f' -A -D -S -B -T --no-chapters --no-global-tags'
│ │ -            commandline += f' "{mkv.resolve()}"'
│ │ -
│ │ -        p = subprocess.Popen(commandline, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
│ │ -        output, error = p.communicate()
│ │ -        if p.returncode != 0:
│ │ -            s = f"from_mkv: {str(output)} \n{str(error)}"
│ │ -            if p.returncode == 1:
│ │ -                print(f"WARN: {s}")
│ │ -            else:
│ │ -                raise ChildProcessError(s)
│ │ -
│ │ -        return out_path
│ │ -
│ │ -    def _update_progress(self, current_frame, total_frames):
│ │ -        print(f"\rVapoursynth: {current_frame} / {total_frames} "
│ │ -              f"({100 * current_frame // total_frames}%) || Encoder: ", end="")
│ │ -
│ │ -    video = encode_video
│ │ -    audio = encode_audio
│ │ -
│ │ -def get_setup() -> Setup:
│ │ -    global setup
│ │ -    return setup
│ │ -
│ │ -def get_workdir() -> Path:
│ │ -    if get_setup() is None:
│ │ -        return os.getcwd()
│ │ -    return get_setup().work_dir
│ │ -
│ │ -setup: Setup | None = None
│ │ -
│ │ -from .auto import muxing
│ │ -from .auto.muxing import VT, AT, ST, VideoTrack, AudioTrack, SubTrack, Attachment, GlobSearch, _track
│ │ -
│ │ -class Chapters():
│ │ -
│ │ -    chapters: list[Chapter] = []
│ │ -    fps: Fraction
│ │ -
│ │ -    def __init__(self, chapter_source: PathLike | GlobSearch | Chapter | list[Chapter] | src_file,
│ │ -                 fps: Fraction = Fraction(24000, 1001), _print: bool = True) -> None:
│ │ -        """
│ │ -            Convenience class for chapters
│ │ -
│ │ -            :param chapter_source:      Input either `vodesfunc.src_file` or (a list of) self defined chapters
│ │ -            :param fps:                 Needed for timestamp convertion (Will be taken from your source clip
│ │ -                                        if passed a `src_file`). Assumes 24000/1001 by default
│ │ -            :param _print:              Prints chapters after parsing and after trimming
│ │ -        """
│ │ -        self.fps = fps
│ │ -        if isinstance(chapter_source, tuple):
│ │ -            self.chapters = [chapter_source]
│ │ -        elif isinstance(chapter_source, list):
│ │ -            self.chapters = chapter_source
│ │ -        elif isinstance(chapter_source, src_file):
│ │ -            self.chapters = parse_src_file(chapter_source, _print)
│ │ -            self.fps = Fraction(chapter_source.src.fps_num, chapter_source.src.fps_den)
│ │ -            if chapter_source.trim:
│ │ -                self.trim(chapter_source.trim[0], chapter_source.trim[1], chapter_source)
│ │ -                if _print:
│ │ -                    print('After trim:')
│ │ -                    self.print()
│ │ -        else:
│ │ -            # Handle both OGM .txt files and xml files
│ │ -            if isinstance(chapter_source, GlobSearch):
│ │ -                chapter_source = chapter_source.paths[0] if isinstance(chapter_source.paths, list) else chapter_source.paths
│ │ -            chapter_source = chapter_source if isinstance(chapter_source, Path) else Path(chapter_source)
│ │ -
│ │ -            self.chapters = parse_xml(chapter_source) if chapter_source.suffix.lower() == '.xml' else parse_ogm(chapter_source)
│ │ -            if _print:
│ │ -                self.print()
│ │ -        
│ │ -        # Convert all framenumbers to timedeltas
│ │ -        chapters = []
│ │ -        for ch in self.chapters:
│ │ -            if isinstance(ch[0], int):
│ │ -                current = list(ch)
│ │ -                current[0] = frame_to_timedelta(current[0], self.fps)
│ │ -                chapters.append(tuple(current))
│ │ -            else:
│ │ -                chapters.append(ch)
│ │ -        self.chapters = chapters
│ │ -
│ │ -    def trim(self, trim_start: int = 0, trim_end: int = 0, src: src_file = None):
│ │ -        if trim_start > 0:
│ │ -            chapters: list[Chapter] = []
│ │ -            for chapter in self.chapters:
│ │ -                if timedelta_to_frame(chapter[0]) == 0:
│ │ -                    chapters.append(chapter)
│ │ -                    continue
│ │ -                if timedelta_to_frame(chapter[0]) - trim_start < 0:
│ │ -                    continue
│ │ -                current = list(chapter)
│ │ -                current[0] = current[0] - frame_to_timedelta(trim_start, self.fps)
│ │ -                if src:
│ │ -                    if current[0] > frame_to_timedelta(src.src_cut.num_frames - 1, self.fps):
│ │ -                        continue
│ │ -                chapters.append(tuple(current))
│ │ -
│ │ -            self.chapters = chapters
│ │ -        if trim_end != 0:
│ │ -            if trim_end > 0:
│ │ -                chapters: list[Chapter] = []
│ │ -                for chapter in self.chapters:
│ │ -                    if timedelta_to_frame(chapter[0], self.fps) < trim_end:
│ │ -                        chapters.append(chapter)
│ │ -                self.chapters = chapters
│ │ -
│ │ -        return self
│ │ -
│ │ -    def set_names(self, names: list[str | None]) -> "Chapters":
│ │ -        """
│ │ -            Renames the chapters
│ │ -
│ │ -            :param names:   List of names
│ │ -        """
│ │ -        old: list[str] = [chapter[1] for chapter in self.chapters]
│ │ -        if len(names) > len(old):
│ │ -            raise ValueError(f'Chapters: too many names!')
│ │ -        if len(names) < len(old):
│ │ -            names += [None] * (len(old) - len(names))
│ │ -
│ │ -        chapters: list[Chapter] = []
│ │ -        for i, name in enumerate(names):
│ │ -            current = list(self.chapters[i])
│ │ -            current[1] = name
│ │ -            chapters.append(tuple(current))
│ │ -
│ │ -        self.chapters = chapters
│ │ -        return self
│ │ -
│ │ -    def add(self, chapters: Chapter | list[Chapter], index: int = 0) -> "Chapters":
│ │ -        if isinstance(chapters, tuple):
│ │ -            chapters = [chapters]
│ │ -        else:
│ │ -            chapters = chapters
│ │ -        
│ │ -        converted = []
│ │ -        for ch in chapters:
│ │ -            if isinstance(ch[0], int):
│ │ -                current = list(ch)
│ │ -                current[0] = frame_to_timedelta(current[0], self.fps)
│ │ -                converted.append(tuple(current))
│ │ -            else:
│ │ -                converted.append(ch)
│ │ -
│ │ -        for ch in converted:
│ │ -            self.chapters.insert(index, ch)
│ │ -            index += 1
│ │ -        return self
│ │ -
│ │ -    def shift_chapter(self, chapter: int = 0, shift_amount: int = 0) -> "Chapters":
│ │ -        """
│ │ -            Used to shift a single chapter by x frames
│ │ -
│ │ -            :param chapter:         Chapter number (starting at 0)
│ │ -            :param shift_amount:    Frames to shift by
│ │ -        """
│ │ -        ch = list(self.chapters[chapter])
│ │ -        shifted_frame = ch[0] + frame_to_timedelta(shift_amount, self.fps)
│ │ -        if shifted_frame.total_seconds() > 0:
│ │ -            ch[0] = shifted_frame
│ │ -        else:
│ │ -            ch[0] = timedelta(seconds=0)
│ │ -        self.chapters[chapter] = tuple(ch)
│ │ -        return self
│ │ -
│ │ -    def print(self) -> "Chapters":
│ │ -        """
│ │ -            Prettier print for these because default timedelta formatting sucks
│ │ -        """
│ │ -        for (time, name) in self.chapters:
│ │ -            print(f'{name}: {format_timedelta(time)} | {timedelta_to_frame(time, self.fps)}')
│ │ -        print("", end='\n')
│ │ -        return self
│ │ -
│ │ -    def to_file(self, out: PathLike = Path(get_workdir())) -> str:
│ │ -        """
│ │ -            Outputs the chapters to an OGM file
│ │ -
│ │ -            :param out:     Can be either a directory or a full file path
│ │ -        """
│ │ -        out = out.resolve() if isinstance(out, Path) else Path(out).resolve()
│ │ -        if out.is_dir():
│ │ -            out_file = os.path.join(out, 'chapters.txt')
│ │ -        else:
│ │ -            out_file = out
│ │ -        with open(out_file, 'w', encoding='UTF-8') as f:
│ │ -            f.writelines([f'CHAPTER{i:02d}={format_timedelta(chapter[0])}\nCHAPTER{i:02d}NAME='
│ │ -                          f'{chapter[1] if chapter[1] else ""}\n' for i, chapter in enumerate(self.chapters)])
│ │ -        return out_file
│ │ -
│ │ -
│ │ -class Mux():
│ │ -
│ │ -    outfile: str | Path
│ │ -    commandline: str
│ │ -    setup: Setup
│ │ -
│ │ -    def __init__(self, setup: Setup, *tracks) -> None:
│ │ -        """
│ │ -            Initialize the commandline for muxing your track objects
│ │ -            Call `this.run()` to actually start the process
│ │ -
│ │ -            :param tracks:      However many track objects you want
│ │ -        """
│ │ -        filename = re.sub(r'\$show\$', setup.show_name, setup.out_name)
│ │ -        filename = re.sub(r'\$ep\$', setup.episode, filename)
│ │ -        filename = re.sub(r'\$crc32\$', "#crc32#", filename)
│ │ -
│ │ -        mkvtitle = re.sub(r'\$show\$', setup.show_name, setup.mkv_title_naming)
│ │ -        mkvtitle = re.sub(r'\$ep\$', setup.episode, mkvtitle)
│ │ -
│ │ -        self.setup = setup
│ │ -        mkvmerge = get_executable('mkvmerge', self.setup.allow_binary_download)
│ │ -
│ │ -        self.outfile = Path(os.path.join(Path(setup.out_dir), filename + ".mkv"))
│ │ -        self.commandline = f'"{mkvmerge}" -o "{self.outfile.resolve()}" --title "{mkvtitle}"'
│ │ -
│ │ -        for track in tracks:
│ │ -            if isinstance(track, _track):
│ │ -                self.commandline += track.mkvmerge_args()
│ │ -                continue
│ │ -            elif isinstance(track, Chapters):
│ │ -                chapterfile = track.to_file(setup.work_dir)
│ │ -                self.commandline += f' --chapters "{chapterfile}"'
│ │ -                continue
│ │ -            elif isinstance(track, PathLike) or isinstance(track, GlobSearch):
│ │ -                # Failsave for if someone passes Chapters().to_file() or a txt/xml file
│ │ -                if isinstance(track, GlobSearch):
│ │ -                    track = track.paths[0] if isinstance(track.paths, list) else track.paths
│ │ -                track = track if isinstance(track, Path) else Path(track)
│ │ -                if track.suffix.lower() in ['.txt', '.xml']:
│ │ -                    self.commandline += f' --chapters "{track.resolve()}"'
│ │ -                continue
│ │ -
│ │ -            raise f'Mux: Only _track or Chapters types are supported as muxing input!'
│ │ -
│ │ -    def run(self, print_command: bool = False) -> str:
│ │ -        """
│ │ -            Starts the muxing process
│ │ -
│ │ -            :param print_command:   Prints final command if True
│ │ -            :return:                Absolute path of resulting mux
│ │ -        """
│ │ -        print("Muxing episode...")
│ │ -        if print_command:
│ │ -            print(f'\n\n{self.commandline}\n\n')
│ │ -        code = run_commandline(self.commandline, False)
│ │ -        if self.setup.clean_work_dirs == True and code == 0:
│ │ -            sh.rmtree(self.setup.work_dir)
│ │ -        print("Done.")
│ │ -        absolute = str(self.outfile.resolve())
│ │ -        if r'#crc32#' in absolute:
│ │ -            print("Generating CRC32 for muxed file...")
│ │ -            self.outfile = self.outfile.rename(re.sub(r'#crc32#', get_crc32(self.outfile), absolute))
│ │ -            print("Done.")
│ │ -        return str(self.outfile.resolve())
│ │ -
│ │ -
│ │ -def settings_builder_x265(
│ │ -        preset: str | int = 'slow', crf: float = 14.5, qcomp: float = 0.75,
│ │ -        psy_rd: float = 2.0, psy_rdoq: float = 2.0, aq_strength: float = 0.75, aq_mode: int = 3, rd: int = 4,
│ │ -        rect: bool = True, amp: bool = False, chroma_qpoffsets: int = -2, tu_intra_depth: int = 2,
│ │ -        tu_inter_depth: int = 2, rskip: bool | int = 0, tskip: bool = False, ref: int = 4, bframes: int = 16,
│ │ -        cutree: bool = False, rc_lookahead: int = 60, subme: int = 5, me: int = 3, b_intra: bool = True,
│ │ -        weightb: bool = True, deblock: list[int] | str = [-2, -2], sar: int | str = 1, append: str = "") -> str:
│ │ -
│ │ -    # Simple insert values
│ │ -    settings = f" --preset {preset} --crf {crf} --bframes {bframes} --ref {ref} --rc-lookahead {rc_lookahead} --subme {subme} --me {me}"
│ │ -    settings += f" --aq-mode {aq_mode} --aq-strength {aq_strength} --qcomp {qcomp} --cbqpoffs {chroma_qpoffsets} --crqpoffs {chroma_qpoffsets}"
│ │ -    settings += f" --rd {rd} --psy-rd {psy_rd} --psy-rdoq {psy_rdoq} --tu-intra-depth {tu_intra_depth} --tu-inter-depth {tu_inter_depth} --sar {sar}"
│ │ -
│ │ -    # Less simple
│ │ -    settings += f" --{'rect' if rect else 'no-rect'} --{'amp' if amp else 'no-amp'} --{'tskip' if tskip else 'no-tskip'}"
│ │ -    settings += f" --{'b-intra' if b_intra else 'no-b-intra'} --{'weightb' if weightb else 'no-weightb'} --{'cutree' if cutree else 'no-cutree'}"
│ │ -    settings += f" --rskip {int(rskip) if isinstance(rskip, bool) else rskip}"
│ │ -
│ │ -    if isinstance(deblock, list):
│ │ -        deblock = f"{str(deblock[0])}:{str(deblock[1])}"
│ │ -    settings += f" --deblock={deblock}"
│ │ -
│ │ -    # Don't need to change these lol
│ │ -    settings += " --no-sao --no-sao-non-deblock --no-strong-intra-smoothing --no-open-gop"
│ │ -
│ │ -    settings += (" " + append.strip()) if append.strip() else ""
│ │ -    return settings
│ │ -
│ │ -def settings_builder_x264(
│ │ -        preset: str = 'placebo', crf: float = 13, qcomp: float = 0.7, psy_rd: float = 1.0, psy_trellis: float = 0.0, trellis: int = 0,
│ │ -        aq_strength: float = 0.8, aq_mode: int = 3, ref: int = 16, bframes: int = 16, mbtree: bool = False, rc_lookahead: int = 250, me: str = "umh",
│ │ -        subme: int = 11, threads: int = 6,
│ │ -        merange: int = 32, deblock: list[int] | str = [-1, -1], dct_decimate: bool = False, sar: str = "1:1", append: str = "") -> str:
│ │ -
│ │ -    # Simple insert values
│ │ -    settings = f" --preset {preset} --crf {crf} --bframes {bframes} --ref {ref} --rc-lookahead {rc_lookahead} --me {me} --merange {merange}"
│ │ -    settings += f" --aq-mode {aq_mode} --aq-strength {aq_strength} --qcomp {qcomp}"
│ │ -    settings += f" --psy-rd {psy_rd}:{psy_trellis} --trellis {trellis} --subme {subme} --threads {threads} --sar {sar}"
│ │ -
│ │ -    # Less simple
│ │ -    settings += f" {'--no-mbtree' if not mbtree else ''} {'--no-dct-decimate' if not dct_decimate else ''}"
│ │ -
│ │ -    if isinstance(deblock, list):
│ │ -        deblock = f"{str(deblock[0])}:{str(deblock[1])}"
│ │ -    settings += f" --deblock={deblock}"
│ │ -
│ │ -    settings += (" " + append.strip()) if append.strip() else ""
│ │ -    return settings
│ │ -
│ │ -
│ │ -def light_sucks(**kwargs) -> str:
│ │ -    return " --".join(f'{setting} {value}' for setting, value in kwargs.items()).strip()
│ │ -
│ │ -
│ │ -def should_create_again(file: str | Path, min_bytes: int = 10000) -> bool:
│ │ -    file = file if isinstance(file, Path) else Path(file)
│ │ -    if file.exists() and file.stat().st_size < min_bytes:
│ │ -        os.remove(file)
│ │ -        return True
│ │ -    elif not file.exists():
│ │ -        return True
│ │ -    else:
│ │ -        return False
│ │ -
│ │ -def run_commandline(command: str, quiet: bool = True, shell: bool = False) -> int:
│ │ -    if os.name != 'nt':
│ │ -        shell = True
│ │ -    if quiet:
│ │ -        p = subprocess.Popen(command, stdin=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=shell)
│ │ -    else:
│ │ -        p = subprocess.Popen(command, shell=shell)
│ │ -    
│ │ -    return p.wait()
│ │ -
│ │ -sb = settings_builder_x265
│ │ -sb265 = sb
│ │ -sb264 = settings_builder_x264
│ │ +import os
│ │ +import re
│ │ +import shutil as sh
│ │ +import subprocess
│ │ +from configparser import ConfigParser
│ │ +from fractions import Fraction
│ │ +from pathlib import Path
│ │ +from typing import Callable
│ │ +from datetime import timedelta
│ │ +
│ │ +import vapoursynth as vs
│ │ +from vstools import Matrix, Primaries, Transfer, ColorRange, ChromaLocation
│ │ +
│ │ +from .auto.download import get_executable
│ │ +from .auto.convert import timedelta_to_frame, frame_to_timedelta, format_timedelta
│ │ +from .auto.parsing import parse_ogm, parse_xml, parse_src_file
│ │ +from .types import PathLike, Trim, Zone, Chapter, TrackType
│ │ +from .util import src_file, uniquify_path, get_crc32, is_x264_zone
│ │ +
│ │ +global setup
│ │ +setup = None
│ │ +
│ │ +__all__: list[str] = [
│ │ +    'Chapters',
│ │ +    'light_sucks',
│ │ +    'Mux',
│ │ +    'settings_builder_x265', 'sb', 'sb264', 'sb265',
│ │ +    'Setup',
│ │ +    'VT', 'AT', 'ST',
│ │ +    'VideoTrack', 'AudioTrack', 'SubTrack',
│ │ +    'Attachment', 'GlobSearch'
│ │ +]
│ │ +
│ │ +class Setup:
│ │ +    """
│ │ +        When you initiate this for the first time in a directory
│ │ +        it will create a new config.ini. Set that up and have fun with all the other functions :)
│ │ +    """
│ │ +
│ │ +    bdmv_dir = "BDMV"
│ │ +    show_name = "Nice Series"
│ │ +    allow_binary_download = True
│ │ +    clean_work_dirs = False
│ │ +    out_dir = "premux"
│ │ +    out_name = "$show$ - $ep$ (premux)"
│ │ +    mkv_title_naming = r"$show$ - $ep$"
│ │ +
│ │ +    episode: str = "01"
│ │ +    work_dir: Path = None
│ │ +    webhook_url: str = None
│ │ +
│ │ +    def __init__(self, episode: str = "01", config_file: str = "config.ini"):
│ │ +        """
│ │ +            :param episode:         Episode identifier(?)
│ │ +            :param config_file:     Path to config file (defaults to 'config.ini' in current working dir)
│ │ +        """
│ │ +
│ │ +        if config_file:
│ │ +            config = ConfigParser()
│ │ +            config_name = config_file
│ │ +
│ │ +            if not os.path.exists(config_name):
│ │ +                config['SETUP'] = {
│ │ +                    'bdmv_dir': self.bdmv_dir,
│ │ +                    'show_name': self.show_name,
│ │ +                    'allow_binary_download': self.allow_binary_download,
│ │ +                    'clean_work_dirs': self.clean_work_dirs,
│ │ +                    'out_dir': self.out_dir,
│ │ +                    'out_name': self.out_name,
│ │ +                    'mkv_title_naming': self.mkv_title_naming,
│ │ +                    # 'webhook_url': self.webhook_url
│ │ +                }
│ │ +
│ │ +                with open(config_name, 'w') as config_file:
│ │ +                    config.write(config_file)
│ │ +
│ │ +                raise SystemExit(f"Template config created at {Path(config_name).resolve()}.\nPlease set it up!")
│ │ +
│ │ +            config.read(config_name)
│ │ +            settings = config['SETUP']
│ │ +
│ │ +            for key in settings:
│ │ +                setattr(self, key, settings[key])
│ │ +
│ │ +            if isinstance(self.allow_binary_download, str):
│ │ +                self.allow_binary_download = True if self.allow_binary_download.strip().lower() in ['true', 'yes'] else False
│ │ +                
│ │ +            if isinstance(self.clean_work_dirs, str):
│ │ +                self.clean_work_dirs = True if self.clean_work_dirs.strip().lower() in ['true', 'yes'] else False
│ │ +
│ │ +        self.episode = episode
│ │ +        self.work_dir = Path(os.path.join(os.getcwd(), "_workdir", episode))
│ │ +        self.work_dir.mkdir(parents=True, exist_ok=True)
│ │ +
│ │ +        global setup
│ │ +        setup = self
│ │ +        return None
│ │ +
│ │ +    def encode_video(self, clip: vs.VideoNode, settings: str = '', zones: Zone | list[Zone] = None, codec: str = 'x265',
│ │ +                     save_csv_log: bool = True, generate_qpfile: bool = True, src: vs.VideoNode | src_file = None,
│ │ +                     specify_props: bool = True, print_command: bool = False) -> str:
│ │ +        """
│ │ +            Encodes the clip you pass into it with your desired encoder
│ │ +
│ │ +            :param clip:            Clip to be encoded
│ │ +            :param settings:        Settings passed to the encoder. I recommend using the settings_builder function
│ │ +            :param zones:           Zone(s) like these (start, end, bitrate_multiplier)
│ │ +            :param codec:           x265, x264 and ffv1 are supported
│ │ +            :param save_csv_log:    Saves the csv log file from x265
│ │ +            :param generate_qpfile: Automatically generates a qpfile from your source clip (would not recommend running on the filtered clip)
│ │ +            :param src:             Source Clip or `src_file` for the qpfile generation
│ │ +            :param specify_props:   Specify color related props to the encoder if using x265 or x264
│ │ +            :param print_command:   Prints the final encoder command before running it
│ │ +            :return:                Absolute filepath for resulting video file
│ │ +        """
│ │ +        if codec.lower() not in ['x265', 'x264', 'ffv1']:
│ │ +            raise ValueError('encode_video: codec has to be either x265, x264 or ffv1')
│ │ +        encoder_exe = get_executable('ffmpeg' if codec.lower() == 'ffv1' else codec, self.allow_binary_download)
│ │ +        args = settings
│ │ +
│ │ +        if codec.lower() in ['x265', 'x264']:
│ │ +            if zones:
│ │ +                zones_settings: str = ''
│ │ +                for i, zone in enumerate(zones):
│ │ +                    if is_x264_zone(zone):
│ │ +                        if codec.lower() == 'x265' and zone[2].lower() != 'q':
│ │ +                            raise ValueError(f"Zone '{zone}' is invalid for x265. Please only use b or q.")
│ │ +                        zones_settings += f'{zone[0]},{zone[1]},{zone[2]}={zone[3]}'
│ │ +                    else:
│ │ +                        zones_settings += f'{zone[0]},{zone[1]},b={zone[2]}'
│ │ +                    if i != len(zones) - 1:
│ │ +                        zones_settings += '/'
│ │ +                args += f' --zones {zones_settings}'
│ │ +
│ │ +            if save_csv_log and codec.lower() == 'x265':
│ │ +                args += f' --csv "{Path(self.show_name + "_log_x265.csv").resolve()}"'
│ │ +            if generate_qpfile:
│ │ +                if isinstance(src, vs.VideoNode) or isinstance(src, src_file):
│ │ +                    src = src if isinstance(src, vs.VideoNode) else src.src_cut
│ │ +                    qpfile = self.generate_qp_file(src)
│ │ +                    if qpfile:
│ │ +                        args += f' --qpfile "{qpfile}"'
│ │ +                else:
│ │ +                    print("encode_video: No 'src' parameter passed, Skipping qpfile creation!")
│ │ +
│ │ +            if specify_props:
│ │ +                bits = clip.format.bits_per_sample
│ │ +                c_range = ColorRange.from_video(clip).string if codec.lower() == 'x265' else \
│ │ +                    ('tv' if ColorRange.from_video(clip) == ColorRange.LIMITED else 'pc')
│ │ +                args += f' --input-depth {bits} --output-depth {bits} --colorprim {Primaries.from_video(clip).string}'
│ │ +                args += f' --transfer {Transfer.from_video(clip).string} --colormatrix {Matrix.from_video(clip).string}'
│ │ +                args += f' --chromaloc {int(ChromaLocation.from_video(clip))} --range {c_range}'
│ │ +
│ │ +            outpath = self.work_dir.joinpath(self.episode + "." + codec.strip('x')).resolve()
│ │ +            if codec.lower() == 'x265':
│ │ +                encoder_command = f'"{encoder_exe}" -o "{outpath}" - --y4m ' + args.strip()
│ │ +            else:
│ │ +                encoder_command = f'"{encoder_exe}" -o "{outpath}" --demuxer y4m - ' + args.strip()
│ │ +        else:
│ │ +            if not args:
│ │ +                args = f'-coder 1 -context 0 -g 1 -level 3 -threads 0 -slices 24 -slicecrc 1'
│ │ +            outpath = self.work_dir.joinpath(self.episode + ".mkv").resolve()
│ │ +            encoder_command = f'"{encoder_exe}" -f yuv4mpegpipe -i - -c:v ffv1 {args.strip()} "{outpath}"'
│ │ +        if print_command:
│ │ +            print(f'\nxEncoder Command:\n{encoder_command}\n')
│ │ +
│ │ +        print(f"Encoding episode {self.episode} to {codec}...")
│ │ +        if os.name != 'nt':
│ │ +            process = subprocess.Popen(encoder_command, stdin=subprocess.PIPE, shell=True)
│ │ +        else:
│ │ +            process = subprocess.Popen(encoder_command, stdin=subprocess.PIPE, shell=False)
│ │ +        clip.output(process.stdin, y4m=True, progress_update=lambda x, y: self._update_progress(x, y))
│ │ +        process.communicate()
│ │ +
│ │ +        print("\nDone encoding video.")
│ │ +        return str(outpath.resolve())
│ │ +
│ │ +    def encode_audio(self, file: PathLike | src_file, track: int = 0, codec: str = 'opus', q: int = 200,
│ │ +                     encoder_settings: str = '', trim: Trim = None, clip: vs.VideoNode | src_file = None,# use_bs_trimming: bool = False,
│ │ +                     dither_flac: bool = True, always_dither: bool = False, quiet: bool = True) -> str:
│ │ +        """
│ │ +            Encodes the audio
│ │ +
│ │ +            :param file:                Either a string based filepath, a Path object or a `src_file`
│ │ +            :param track:               Audio Track Number of your input file. 0-based
│ │ +            :param codec:               Either flac, opus or aac. Uses ffmpeg, opusenc or qaac respectively.
│ │ +                                        'pass' and 'passthrough' also exist and do what they say
│ │ +            :param q:                   Quality. Basically just the bitrate when using opus and the tVBR/-V value for qaac
│ │ +            :param encoder_settings:    Arguments directly passed to opusenc or qaac
│ │ +            :param trim:                Tuple of frame numbers; Can be left empty if you passed a `src_file` with trims
│ │ +            :param clip:                Vapoursynth VideoNode needed when trimming; Can be left empty if you passed a `src_file`
│ │ +            :param dither_flac:         Will dither your FLAC output to 16bit and 48 kHz
│ │ +            :param always_dither:       Dithers regardless of your final output
│ │ +            :param quiet:               Will print the subprocess outputs if False
│ │ +            :return:                    Absolute filepath for resulting audio file
│ │ +        """
│ │ +        encoder_settings = ' ' + encoder_settings.strip()
│ │ +        
│ │ +        if trim is not None:
│ │ +            if isinstance(file, src_file):
│ │ +                print("Warning: trims in src_file types will overwrite other trims passed!")
│ │ +            else:
│ │ +                if not isinstance(clip, vs.VideoNode) and not isinstance(clip, src_file):
│ │ +                    raise "encode_audio: Trimming audio requires a clip input!"
│ │ +                elif isinstance(clip, src_file):
│ │ +                    clip = clip.src
│ │ +                    fps = Fraction(clip.fps_num, clip.fps_den)
│ │ +                else:
│ │ +                    fps = Fraction(clip.fps_num, clip.fps_den)
│ │ +
│ │ +        if isinstance(file, src_file):
│ │ +            trim = file.trim
│ │ +            clip = file.src
│ │ +            fps = Fraction(clip.fps_num, clip.fps_den)
│ │ +
│ │ +        file = file.file if isinstance(file, src_file) else file
│ │ +        file = file if isinstance(file, Path) else Path(file)
│ │ +
│ │ +        base_path = os.path.join(self.work_dir.resolve(), file.stem + "_" + str(track))
│ │ +
│ │ +        def ffmpeg_header() -> str:
│ │ +            ffmpeg_exe = get_executable('ffmpeg', self.allow_binary_download)
│ │ +            return f'"{ffmpeg_exe}" -hide_banner{" -loglevel warning" if quiet else ""}'
│ │ +
│ │ +        def ffmpeg_seekargs() -> str:
│ │ +            args = ''
│ │ +            if trim:
│ │ +                if trim[0] is not None and trim[0] > 0:
│ │ +                    args += f' -ss {format_timedelta(frame_to_timedelta(trim[0], fps))}'
│ │ +                if trim[1] is not None and trim[1] != 0:
│ │ +                    if trim[1] > 0:
│ │ +                        args += f' -to {format_timedelta(frame_to_timedelta(trim[1], fps))}'
│ │ +                    else:
│ │ +                        end_frame = clip.num_frames - abs(trim[1])
│ │ +                        args += f' -to {format_timedelta(frame_to_timedelta(end_frame, fps))}'
│ │ +                if not quiet:
│ │ +                    print(args)
│ │ +            return args
│ │ +
│ │ +        def toflac() -> str:
│ │ +            is_intermediary = codec.lower() != 'flac'
│ │ +            compression_level = "10" if not is_intermediary else "0"
│ │ +            commandline = f'{ffmpeg_header()} -i "{file.resolve()}" -map_metadata -1 -map_chapters -1 -map 0:a:{track} {ffmpeg_seekargs()} -f flac -compression_level {compression_level}'
│ │ +            if (dither_flac and codec.lower() == 'flac') or always_dither:
│ │ +                commandline += ' -sample_fmt s16 -ar 48000 -resampler soxr -precision 28 -dither_method shibata'
│ │ +            if codec.lower() != 'opus':
│ │ +                _flac = base_path + ".flac"
│ │ +                if not should_create_again(_flac):
│ │ +                    return _flac
│ │ +                commandline += f' "{_flac}"'
│ │ +                print(f'Creating FLAC intermediary audio track {track} for EP{self.episode}...'
│ │ +                    if is_intermediary else f'Encoding audio track {track} for EP{self.episode} to FLAC...')
│ │ +                run_commandline(commandline, quiet, False)
│ │ +                if not is_intermediary:
│ │ +                    print('Done\n')
│ │ +                return _flac
│ │ +            else:
│ │ +                # We can just use a cool pipe with opusenc
│ │ +                return commandline + " - | "
│ │ +            
│ │ +        if codec.lower() == 'flac':
│ │ +            return toflac()
│ │ +
│ │ +        if codec.lower() in ['pass', 'passthrough']:
│ │ +            out_file = base_path + ".mka"
│ │ +            if not should_create_again(out_file):
│ │ +                return out_file
│ │ +            print(f'Trimming audio track {track} for EP{self.episode}...'
│ │ +                if trim else f'Extracting audio track {track} for EP{self.episode}')
│ │ +            commandline = f'{ffmpeg_header()} -i "{file.resolve()}" -map_metadata -1 -map_chapters -1 -map 0:a:{track} {ffmpeg_seekargs()} -c:a copy "{out_file}"'
│ │ +            run_commandline(commandline, quiet, False)
│ │ +            print('Done.\n')
│ │ +            return out_file
│ │ +
│ │ +        if codec.lower() == 'aac':
│ │ +            if q > 127 or q < 0:
│ │ +                raise ValueError(f'encode_audio: QAAC tvbr must be in the range of 0 - 127')
│ │ +            flac = toflac()
│ │ +            qaac =  get_executable('qaac', self.allow_binary_download)
│ │ +            out_file = base_path + ".m4a"
│ │ +            if not should_create_again(out_file):
│ │ +                return out_file
│ │ +            commandline = f'"{qaac}" -V {q} {encoder_settings} -o "{out_file}" "{flac}"'
│ │ +            print(f'Encoding audio track {track} for EP{self.episode} to AAC...')
│ │ +            run_commandline(commandline, quiet, False)
│ │ +            print('Done.\n')
│ │ +            Path(flac).unlink(missing_ok = True)
│ │ +            return out_file
│ │ +        
│ │ +        if codec.lower() == 'opus':
│ │ +            if q > 512 or q < 8:
│ │ +                raise ValueError(f'encode_audio: Opus bitrate must be in the range of 8 - 512 (kbit/s)')
│ │ +            commandline = toflac()
│ │ +            opusenc = get_executable('opusenc', self.allow_binary_download)
│ │ +            out_file = base_path + ".ogg"
│ │ +            if not should_create_again(out_file):
│ │ +                return out_file
│ │ +            commandline += f'"{opusenc}" --bitrate {q} {encoder_settings} - "{out_file}"'
│ │ +            print(f'Encoding audio track {track} for EP{self.episode} to Opus...')
│ │ +            run_commandline(commandline, quiet, True)
│ │ +            print('Done.\n')
│ │ +            return out_file
│ │ +
│ │ +    def generate_qp_file(self, clip: vs.VideoNode) -> str:
│ │ +        filepath = os.path.join(self.work_dir, 'qpfile.txt')
│ │ +        if not should_create_again(filepath, 100):
│ │ +            print('Reusing existing QP File.')
│ │ +            return str(Path(filepath).resolve())
│ │ +        print('Generating QP File...')
│ │ +        clip = clip.resize.Bicubic(640, 360, format=vs.YUV410P8)
│ │ +        clip = clip.wwxd.WWXD()
│ │ +        out = ""
│ │ +        for i in range(1, clip.num_frames):
│ │ +            if clip.get_frame(i).props.Scenechange == 1:
│ │ +                out += f"{i} I -1\n"
│ │ +
│ │ +        with open(filepath, 'w') as file:
│ │ +            file.write(out)
│ │ +
│ │ +        return str(Path(filepath).resolve()) if os.path.exists(filepath) else ""
│ │ +
│ │ +    def from_mkv(self, mkv: PathLike, type: TrackType, track: int = -1) -> str:
│ │ +        """
│ │ +            Get various tracks from an existing mkv file
│ │ +
│ │ +            :param mkv:         Path to file
│ │ +            :param type:        TrackType to get
│ │ +            :param track:       The *absolute* track number. No idea why they do this
│ │ +                                but a specific video/audio/sub track is not a thing
│ │ +                                so you're gonna have to pass the absolute number
│ │ +            :return:            Path to resulting mkv or txt (if chapters)
│ │ +        """
│ │ +        mkv = mkv if isinstance(mkv, Path) else Path(mkv)
│ │ +        mkvmerge_exe = get_executable('mkvmerge', self.allow_binary_download)
│ │ +        mkvextract_exe = get_executable('mkvextract', self.allow_binary_download)
│ │ +        out_file = f"{mkv.stem}_{TrackType(type).name}_{str(track)}.{'txt' if type == TrackType.CHAPTERS else 'mkv'}"
│ │ +        out_path = os.path.join(self.work_dir.resolve(), out_file)
│ │ +
│ │ +        if type == TrackType.CHAPTERS:
│ │ +            commandline = f'"{mkvextract_exe}" "{mkv.resolve()}" chapters --simple "{out_path}"'
│ │ +        else:
│ │ +            commandline = f'"{mkvmerge_exe}" -o "{out_path} '
│ │ +            if type != TrackType.ATTACHMENT and track < 0:
│ │ +                raise ValueError(f'from_mkv: Please specify a track for anything but \'Attachment\'')
│ │ +            match type:
│ │ +                case TrackType.VIDEO:
│ │ +                    commandline += f' -A -d {track} -S -B -T -M --no-chapters --no-global-tags'
│ │ +                case TrackType.AUDIO:
│ │ +                    commandline += f' -a {track} -D -S -B -T -M --no-chapters --no-global-tags'
│ │ +                case TrackType.SUB:
│ │ +                    commandline += f' -A -D -s {track} -B -T -M --no-chapters --no-global-tags'
│ │ +                case TrackType.ATTACHMENT:
│ │ +                    commandline += f' -A -D -S -B -T --no-chapters --no-global-tags'
│ │ +            commandline += f' "{mkv.resolve()}"'
│ │ +
│ │ +        p = subprocess.Popen(commandline, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
│ │ +        output, error = p.communicate()
│ │ +        if p.returncode != 0:
│ │ +            s = f"from_mkv: {str(output)} \n{str(error)}"
│ │ +            if p.returncode == 1:
│ │ +                print(f"WARN: {s}")
│ │ +            else:
│ │ +                raise ChildProcessError(s)
│ │ +
│ │ +        return out_path
│ │ +
│ │ +    def _update_progress(self, current_frame, total_frames):
│ │ +        print(f"\rVapoursynth: {current_frame} / {total_frames} "
│ │ +              f"({100 * current_frame // total_frames}%) || Encoder: ", end="")
│ │ +
│ │ +    video = encode_video
│ │ +    audio = encode_audio
│ │ +
│ │ +def get_setup() -> Setup:
│ │ +    global setup
│ │ +    return setup
│ │ +
│ │ +def get_workdir() -> Path:
│ │ +    if get_setup() is None:
│ │ +        return os.getcwd()
│ │ +    return get_setup().work_dir
│ │ +
│ │ +setup: Setup | None = None
│ │ +
│ │ +from .auto import muxing
│ │ +from .auto.muxing import VT, AT, ST, VideoTrack, AudioTrack, SubTrack, Attachment, GlobSearch, _track
│ │ +
│ │ +class Chapters():
│ │ +
│ │ +    chapters: list[Chapter] = []
│ │ +    fps: Fraction
│ │ +
│ │ +    def __init__(self, chapter_source: PathLike | GlobSearch | Chapter | list[Chapter] | src_file,
│ │ +                 fps: Fraction = Fraction(24000, 1001), _print: bool = True) -> None:
│ │ +        """
│ │ +            Convenience class for chapters
│ │ +
│ │ +            :param chapter_source:      Input either `vodesfunc.src_file` or (a list of) self defined chapters
│ │ +            :param fps:                 Needed for timestamp convertion (Will be taken from your source clip
│ │ +                                        if passed a `src_file`). Assumes 24000/1001 by default
│ │ +            :param _print:              Prints chapters after parsing and after trimming
│ │ +        """
│ │ +        self.fps = fps
│ │ +        if isinstance(chapter_source, tuple):
│ │ +            self.chapters = [chapter_source]
│ │ +        elif isinstance(chapter_source, list):
│ │ +            self.chapters = chapter_source
│ │ +        elif isinstance(chapter_source, src_file):
│ │ +            self.chapters = parse_src_file(chapter_source, _print)
│ │ +            self.fps = Fraction(chapter_source.src.fps_num, chapter_source.src.fps_den)
│ │ +            if chapter_source.trim:
│ │ +                self.trim(chapter_source.trim[0], chapter_source.trim[1], chapter_source)
│ │ +                if _print:
│ │ +                    print('After trim:')
│ │ +                    self.print()
│ │ +        else:
│ │ +            # Handle both OGM .txt files and xml files
│ │ +            if isinstance(chapter_source, GlobSearch):
│ │ +                chapter_source = chapter_source.paths[0] if isinstance(chapter_source.paths, list) else chapter_source.paths
│ │ +            chapter_source = chapter_source if isinstance(chapter_source, Path) else Path(chapter_source)
│ │ +
│ │ +            self.chapters = parse_xml(chapter_source) if chapter_source.suffix.lower() == '.xml' else parse_ogm(chapter_source)
│ │ +            if _print:
│ │ +                self.print()
│ │ +        
│ │ +        # Convert all framenumbers to timedeltas
│ │ +        chapters = []
│ │ +        for ch in self.chapters:
│ │ +            if isinstance(ch[0], int):
│ │ +                current = list(ch)
│ │ +                current[0] = frame_to_timedelta(current[0], self.fps)
│ │ +                chapters.append(tuple(current))
│ │ +            else:
│ │ +                chapters.append(ch)
│ │ +        self.chapters = chapters
│ │ +
│ │ +    def trim(self, trim_start: int = 0, trim_end: int = 0, src: src_file = None):
│ │ +        if trim_start > 0:
│ │ +            chapters: list[Chapter] = []
│ │ +            for chapter in self.chapters:
│ │ +                if timedelta_to_frame(chapter[0]) == 0:
│ │ +                    chapters.append(chapter)
│ │ +                    continue
│ │ +                if timedelta_to_frame(chapter[0]) - trim_start < 0:
│ │ +                    continue
│ │ +                current = list(chapter)
│ │ +                current[0] = current[0] - frame_to_timedelta(trim_start, self.fps)
│ │ +                if src:
│ │ +                    if current[0] > frame_to_timedelta(src.src_cut.num_frames - 1, self.fps):
│ │ +                        continue
│ │ +                chapters.append(tuple(current))
│ │ +
│ │ +            self.chapters = chapters
│ │ +        if trim_end != 0:
│ │ +            if trim_end > 0:
│ │ +                chapters: list[Chapter] = []
│ │ +                for chapter in self.chapters:
│ │ +                    if timedelta_to_frame(chapter[0], self.fps) < trim_end:
│ │ +                        chapters.append(chapter)
│ │ +                self.chapters = chapters
│ │ +
│ │ +        return self
│ │ +
│ │ +    def set_names(self, names: list[str | None]) -> "Chapters":
│ │ +        """
│ │ +            Renames the chapters
│ │ +
│ │ +            :param names:   List of names
│ │ +        """
│ │ +        old: list[str] = [chapter[1] for chapter in self.chapters]
│ │ +        if len(names) > len(old):
│ │ +            raise ValueError(f'Chapters: too many names!')
│ │ +        if len(names) < len(old):
│ │ +            names += [None] * (len(old) - len(names))
│ │ +
│ │ +        chapters: list[Chapter] = []
│ │ +        for i, name in enumerate(names):
│ │ +            current = list(self.chapters[i])
│ │ +            current[1] = name
│ │ +            chapters.append(tuple(current))
│ │ +
│ │ +        self.chapters = chapters
│ │ +        return self
│ │ +
│ │ +    def add(self, chapters: Chapter | list[Chapter], index: int = 0) -> "Chapters":
│ │ +        if isinstance(chapters, tuple):
│ │ +            chapters = [chapters]
│ │ +        else:
│ │ +            chapters = chapters
│ │ +        
│ │ +        converted = []
│ │ +        for ch in chapters:
│ │ +            if isinstance(ch[0], int):
│ │ +                current = list(ch)
│ │ +                current[0] = frame_to_timedelta(current[0], self.fps)
│ │ +                converted.append(tuple(current))
│ │ +            else:
│ │ +                converted.append(ch)
│ │ +
│ │ +        for ch in converted:
│ │ +            self.chapters.insert(index, ch)
│ │ +            index += 1
│ │ +        return self
│ │ +
│ │ +    def shift_chapter(self, chapter: int = 0, shift_amount: int = 0) -> "Chapters":
│ │ +        """
│ │ +            Used to shift a single chapter by x frames
│ │ +
│ │ +            :param chapter:         Chapter number (starting at 0)
│ │ +            :param shift_amount:    Frames to shift by
│ │ +        """
│ │ +        ch = list(self.chapters[chapter])
│ │ +        shifted_frame = ch[0] + frame_to_timedelta(shift_amount, self.fps)
│ │ +        if shifted_frame.total_seconds() > 0:
│ │ +            ch[0] = shifted_frame
│ │ +        else:
│ │ +            ch[0] = timedelta(seconds=0)
│ │ +        self.chapters[chapter] = tuple(ch)
│ │ +        return self
│ │ +
│ │ +    def print(self) -> "Chapters":
│ │ +        """
│ │ +            Prettier print for these because default timedelta formatting sucks
│ │ +        """
│ │ +        for (time, name) in self.chapters:
│ │ +            print(f'{name}: {format_timedelta(time)} | {timedelta_to_frame(time, self.fps)}')
│ │ +        print("", end='\n')
│ │ +        return self
│ │ +
│ │ +    def to_file(self, out: PathLike = Path(get_workdir())) -> str:
│ │ +        """
│ │ +            Outputs the chapters to an OGM file
│ │ +
│ │ +            :param out:     Can be either a directory or a full file path
│ │ +        """
│ │ +        out = out.resolve() if isinstance(out, Path) else Path(out).resolve()
│ │ +        if out.is_dir():
│ │ +            out_file = os.path.join(out, 'chapters.txt')
│ │ +        else:
│ │ +            out_file = out
│ │ +        with open(out_file, 'w', encoding='UTF-8') as f:
│ │ +            f.writelines([f'CHAPTER{i:02d}={format_timedelta(chapter[0])}\nCHAPTER{i:02d}NAME='
│ │ +                          f'{chapter[1] if chapter[1] else ""}\n' for i, chapter in enumerate(self.chapters)])
│ │ +        return out_file
│ │ +
│ │ +
│ │ +class Mux():
│ │ +
│ │ +    outfile: str | Path
│ │ +    commandline: str
│ │ +    setup: Setup
│ │ +
│ │ +    def __init__(self, setup: Setup, *tracks) -> None:
│ │ +        """
│ │ +            Initialize the commandline for muxing your track objects
│ │ +            Call `this.run()` to actually start the process
│ │ +
│ │ +            :param tracks:      However many track objects you want
│ │ +        """
│ │ +        filename = re.sub(r'\$show\$', setup.show_name, setup.out_name)
│ │ +        filename = re.sub(r'\$ep\$', setup.episode, filename)
│ │ +        filename = re.sub(r'\$crc32\$', "#crc32#", filename)
│ │ +
│ │ +        mkvtitle = re.sub(r'\$show\$', setup.show_name, setup.mkv_title_naming)
│ │ +        mkvtitle = re.sub(r'\$ep\$', setup.episode, mkvtitle)
│ │ +
│ │ +        self.setup = setup
│ │ +        mkvmerge = get_executable('mkvmerge', self.setup.allow_binary_download)
│ │ +
│ │ +        self.outfile = Path(os.path.join(Path(setup.out_dir), filename + ".mkv"))
│ │ +        self.commandline = f'"{mkvmerge}" -o "{self.outfile.resolve()}" --title "{mkvtitle}"'
│ │ +
│ │ +        for track in tracks:
│ │ +            if isinstance(track, _track):
│ │ +                self.commandline += track.mkvmerge_args()
│ │ +                continue
│ │ +            elif isinstance(track, Chapters):
│ │ +                chapterfile = track.to_file(setup.work_dir)
│ │ +                self.commandline += f' --chapters "{chapterfile}"'
│ │ +                continue
│ │ +            elif isinstance(track, PathLike) or isinstance(track, GlobSearch):
│ │ +                # Failsave for if someone passes Chapters().to_file() or a txt/xml file
│ │ +                if isinstance(track, GlobSearch):
│ │ +                    track = track.paths[0] if isinstance(track.paths, list) else track.paths
│ │ +                track = track if isinstance(track, Path) else Path(track)
│ │ +                if track.suffix.lower() in ['.txt', '.xml']:
│ │ +                    self.commandline += f' --chapters "{track.resolve()}"'
│ │ +                continue
│ │ +
│ │ +            raise f'Mux: Only _track or Chapters types are supported as muxing input!'
│ │ +
│ │ +    def run(self, print_command: bool = False) -> str:
│ │ +        """
│ │ +            Starts the muxing process
│ │ +
│ │ +            :param print_command:   Prints final command if True
│ │ +            :return:                Absolute path of resulting mux
│ │ +        """
│ │ +        print("Muxing episode...")
│ │ +        if print_command:
│ │ +            print(f'\n\n{self.commandline}\n\n')
│ │ +        code = run_commandline(self.commandline, False)
│ │ +        if self.setup.clean_work_dirs == True and code == 0:
│ │ +            sh.rmtree(self.setup.work_dir)
│ │ +        print("Done.")
│ │ +        absolute = str(self.outfile.resolve())
│ │ +        if r'#crc32#' in absolute:
│ │ +            print("Generating CRC32 for muxed file...")
│ │ +            self.outfile = self.outfile.rename(re.sub(r'#crc32#', get_crc32(self.outfile), absolute))
│ │ +            print("Done.")
│ │ +        return str(self.outfile.resolve())
│ │ +
│ │ +
│ │ +def settings_builder_x265(
│ │ +        preset: str | int = 'slow', crf: float = 14.5, qcomp: float = 0.75,
│ │ +        psy_rd: float = 2.0, psy_rdoq: float = 2.0, aq_strength: float = 0.75, aq_mode: int = 3, rd: int = 4,
│ │ +        rect: bool = True, amp: bool = False, chroma_qpoffsets: int = -2, tu_intra_depth: int = 2,
│ │ +        tu_inter_depth: int = 2, rskip: bool | int = 0, tskip: bool = False, ref: int = 4, bframes: int = 16,
│ │ +        cutree: bool = False, rc_lookahead: int = 60, subme: int = 5, me: int = 3, b_intra: bool = True,
│ │ +        weightb: bool = True, deblock: list[int] | str = [-2, -2], sar: int | str = 1, append: str = "") -> str:
│ │ +
│ │ +    # Simple insert values
│ │ +    settings = f" --preset {preset} --crf {crf} --bframes {bframes} --ref {ref} --rc-lookahead {rc_lookahead} --subme {subme} --me {me}"
│ │ +    settings += f" --aq-mode {aq_mode} --aq-strength {aq_strength} --qcomp {qcomp} --cbqpoffs {chroma_qpoffsets} --crqpoffs {chroma_qpoffsets}"
│ │ +    settings += f" --rd {rd} --psy-rd {psy_rd} --psy-rdoq {psy_rdoq} --tu-intra-depth {tu_intra_depth} --tu-inter-depth {tu_inter_depth} --sar {sar}"
│ │ +
│ │ +    # Less simple
│ │ +    settings += f" --{'rect' if rect else 'no-rect'} --{'amp' if amp else 'no-amp'} --{'tskip' if tskip else 'no-tskip'}"
│ │ +    settings += f" --{'b-intra' if b_intra else 'no-b-intra'} --{'weightb' if weightb else 'no-weightb'} --{'cutree' if cutree else 'no-cutree'}"
│ │ +    settings += f" --rskip {int(rskip) if isinstance(rskip, bool) else rskip}"
│ │ +
│ │ +    if isinstance(deblock, list):
│ │ +        deblock = f"{str(deblock[0])}:{str(deblock[1])}"
│ │ +    settings += f" --deblock={deblock}"
│ │ +
│ │ +    # Don't need to change these lol
│ │ +    settings += " --no-sao --no-sao-non-deblock --no-strong-intra-smoothing --no-open-gop"
│ │ +
│ │ +    settings += (" " + append.strip()) if append.strip() else ""
│ │ +    return settings
│ │ +
│ │ +def settings_builder_x264(
│ │ +        preset: str = 'placebo', crf: float = 13, qcomp: float = 0.7, psy_rd: float = 1.0, psy_trellis: float = 0.0, trellis: int = 0,
│ │ +        aq_strength: float = 0.8, aq_mode: int = 3, ref: int = 16, bframes: int = 16, mbtree: bool = False, rc_lookahead: int = 250, me: str = "umh",
│ │ +        subme: int = 11, threads: int = 6,
│ │ +        merange: int = 32, deblock: list[int] | str = [-1, -1], dct_decimate: bool = False, sar: str = "1:1", append: str = "") -> str:
│ │ +
│ │ +    # Simple insert values
│ │ +    settings = f" --preset {preset} --crf {crf} --bframes {bframes} --ref {ref} --rc-lookahead {rc_lookahead} --me {me} --merange {merange}"
│ │ +    settings += f" --aq-mode {aq_mode} --aq-strength {aq_strength} --qcomp {qcomp}"
│ │ +    settings += f" --psy-rd {psy_rd}:{psy_trellis} --trellis {trellis} --subme {subme} --threads {threads} --sar {sar}"
│ │ +
│ │ +    # Less simple
│ │ +    settings += f" {'--no-mbtree' if not mbtree else ''} {'--no-dct-decimate' if not dct_decimate else ''}"
│ │ +
│ │ +    if isinstance(deblock, list):
│ │ +        deblock = f"{str(deblock[0])}:{str(deblock[1])}"
│ │ +    settings += f" --deblock={deblock}"
│ │ +
│ │ +    settings += (" " + append.strip()) if append.strip() else ""
│ │ +    return settings
│ │ +
│ │ +
│ │ +def light_sucks(**kwargs) -> str:
│ │ +    return " --".join(f'{setting} {value}' for setting, value in kwargs.items()).strip()
│ │ +
│ │ +
│ │ +def should_create_again(file: str | Path, min_bytes: int = 10000) -> bool:
│ │ +    file = file if isinstance(file, Path) else Path(file)
│ │ +    if file.exists() and file.stat().st_size < min_bytes:
│ │ +        os.remove(file)
│ │ +        return True
│ │ +    elif not file.exists():
│ │ +        return True
│ │ +    else:
│ │ +        return False
│ │ +
│ │ +def run_commandline(command: str, quiet: bool = True, shell: bool = False) -> int:
│ │ +    if os.name != 'nt':
│ │ +        shell = True
│ │ +    if quiet:
│ │ +        p = subprocess.Popen(command, stdin=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=shell)
│ │ +    else:
│ │ +        p = subprocess.Popen(command, shell=shell)
│ │ +    
│ │ +    return p.wait()
│ │ +
│ │ +sb = settings_builder_x265
│ │ +sb265 = sb
│ │ +sb264 = settings_builder_x264
│ │   --- vodesfunc-1.3.1/vodesfunc/descale.py
│ ├── +++ vodesfunc-1.3.2/vodesfunc/descale.py
│ │┄ Ordering differences only
│ │┄ Files 15% similar despite different names
│ │ @@ -1,258 +1,258 @@
│ │ -from vstools import vs, core, get_w, get_y, depth, iterate, ColorRange, join, get_depth
│ │ -from vskernels import Scaler, ScalerT, Kernel, KernelT, Catrom
│ │ -from typing import Callable
│ │ -from math import floor
│ │ -from dataclasses import dataclass
│ │ -
│ │ -from .scale import Doubler, NNEDI_Doubler
│ │ -
│ │ -__all__ = ['DescaleTarget', 'MixedRescale', 'DT']
│ │ -
│ │ -def get_args(clip: vs.VideoNode, base_height: int, height: float, base_width: float = None):
│ │ -    base_height = float(base_height)
│ │ -    src_width = height * clip.width / clip.height
│ │ -    if not base_width:
│ │ -        base_width = clip.width
│ │ -    cropped_width = base_width - 2 * floor((base_width - src_width) / 2)
│ │ -    cropped_height = base_height - 2 * floor((base_height - height) / 2)
│ │ -    fractional_args = dict(height = cropped_height, width = cropped_width, 
│ │ -        src_width = src_width, src_height = height, src_left = (cropped_width - src_width) / 2,
│ │ -        src_top = (cropped_height - height) / 2)
│ │ -    return fractional_args
│ │ -
│ │ -class TargetVals():
│ │ -    input_clip: vs.VideoNode | None = None
│ │ -    descale: vs.VideoNode | None = None
│ │ -    rescale: vs.VideoNode | None = None
│ │ -    doubled: vs.VideoNode | None = None
│ │ -    upscale: vs.VideoNode | None = None
│ │ -
│ │ -    index: int = 0
│ │ -
│ │ -@dataclass
│ │ -class DescaleTarget(TargetVals):
│ │ -    """
│ │ -        Basically an entirely self contained rescaling utility class that can do pretty much everything.
│ │ -
│ │ -        :param height:          Height to be descaled to.
│ │ -        :param kernel:          The kernel used for descaling.
│ │ -        :param upscaler:        Either a vodesfunc doubler or any scaler from vsscale used to upscale/double the descaled clip.
│ │ -        :param downscaler:      Any kernel or scaler used for downscaling the upscaled/doubled clip back to input res.
│ │ -        :param base_height:     Needed for fractional descales.
│ │ -        :param width:           Width to be descaled to. (will be calculated if None)
│ │ -        :param base_width:      Needed for fractional descales. (will be calculated if None)
│ │ -        :param do_post_double:  A function that's called on the doubled clip. Can be used to do sensitive processing on a bigger clip. (e. g. Dehaloing)
│ │ -        :param credit_mask:     Can be used to pass a mask that'll be used or False to disable error masking.
│ │ -        :param credit_mask_thr: The error threshold of the automatically generated credit mask.
│ │ -        :param credit_mask_bh:  Generates an error mask based on a descale using the baseheight. For some reason had better results with this on some shows.
│ │ -        :param line_mask:       Can be used to pass a mask that'll be used or False to disable line masking.
│ │ -        :param bbmod_masks:     Specify rows to be bbmod'ed for a clip to generate the masks on. Will probably be useful for the new border param in descale.
│ │ -    """
│ │ -    height: float
│ │ -    kernel: KernelT = Catrom
│ │ -    upscaler: Doubler | ScalerT = NNEDI_Doubler()
│ │ -    downscaler: ScalerT = Catrom
│ │ -    base_height: int | None = None
│ │ -    width: float | None = None
│ │ -    base_width: int | None = None
│ │ -    do_post_double: Callable[[vs.VideoNode], vs.VideoNode] | None = None
│ │ -    credit_mask: vs.VideoNode | bool | None = None
│ │ -    credit_mask_thr: float = 0.04
│ │ -    credit_mask_bh: bool = False
│ │ -    line_mask: vs.VideoNode | bool | None = None
│ │ -    bbmod_masks: int | list[int] = 0 # Not actually implemented yet lol
│ │ -
│ │ -    def generate_clips(self, clip: vs.VideoNode) -> 'DescaleTarget':
│ │ -        """
│ │ -            Generates descaled and rescaled clips of the given input clip
│ │ -
│ │ -            :param clip:    Clip to descale and rescale
│ │ -        """
│ │ -        self.kernel = Kernel.ensure_obj(self.kernel)
│ │ -        self.input_clip = clip.std.SetFrameProp('Target', self.index + 1)
│ │ -        clip = depth(get_y(clip), 16)
│ │ -        self.height = float(self.height)
│ │ -        if self.height.is_integer():
│ │ -            if not self.width:
│ │ -                self.width = self.height * clip.width / clip.height
│ │ -            self.descale = self.kernel.descale(clip, self.width, self.height)
│ │ -            self.rescale = self.kernel.scale(self.descale, clip.width, clip.height)
│ │ -            ref_y = self.rescale
│ │ -        else:
│ │ -            if self.base_height is None:
│ │ -                raise ValueError("DescaleTarget: height cannot be fractional if you don't pass a base_height.")
│ │ -            if not float(self.base_height).is_integer():
│ │ -                raise ValueError("DescaleTarget: Your base_height has to be an integer.")
│ │ -            if self.base_height < self.height:
│ │ -                raise ValueError("DescaleTarget: Your base_height has to be bigger than your height.")
│ │ -            self.frac_args = get_args(clip, self.base_height, self.height, self.base_width)
│ │ -            self.descale = self.kernel.descale(clip, **self.frac_args)  \
│ │ -                .std.CopyFrameProps(clip).std.SetFrameProp('Descale', self.index + 1)
│ │ -            self.frac_args.pop('width')
│ │ -            self.frac_args.pop('height')
│ │ -            self.rescale = self.kernel.scale(self.descale, clip.width, clip.height, **self.frac_args) \
│ │ -                .std.CopyFrameProps(clip).std.SetFrameProp('Rescale', self.index + 1)
│ │ -            if self.credit_mask_bh:
│ │ -                base_height_desc = self.kernel.descale(clip, self.base_height * (clip.width / clip.height), self.base_height)
│ │ -                ref_y = self.kernel.scale(base_height_desc, clip.width, clip.height)
│ │ -            else:
│ │ -                ref_y = self.rescale
│ │ -            
│ │ -        if self.line_mask != False:
│ │ -            if not isinstance(self.line_mask, vs.VideoNode):
│ │ -                try:
│ │ -                    from vsmask.edge import KirschTCanny
│ │ -                except:
│ │ -                    from vsmasktools.edge import KirschTCanny
│ │ -                self.line_mask = KirschTCanny().edgemask(clip, lthr=80 << 8, hthr=150 << 8)
│ │ -            
│ │ -            if self.do_post_double is not None:
│ │ -                self.line_mask = self.line_mask.std.Inflate()
│ │ -
│ │ -            self.line_mask = depth(self.line_mask, 16)
│ │ -            
│ │ -        if self.credit_mask != False or self.credit_mask_thr <= 0:
│ │ -            if not isinstance(self.credit_mask, vs.VideoNode):
│ │ -                self.credit_mask = core.std.Expr([depth(clip, 32), depth(ref_y, 32)], f"x y - abs {self.credit_mask_thr} < 0 1 ?")
│ │ -                self.credit_mask = depth(self.credit_mask, 16, range_out=ColorRange.FULL, range_in=ColorRange.FULL)
│ │ -                self.credit_mask = self.credit_mask.rgvs.RemoveGrain(mode=6)
│ │ -                self.credit_mask = iterate(self.credit_mask, core.std.Maximum, 2)
│ │ -                self.credit_mask = iterate(self.credit_mask, core.std.Inflate, 2 if self.do_post_double is None else 4)
│ │ -            
│ │ -            self.credit_mask = depth(self.credit_mask, 16)
│ │ -        
│ │ -        return self
│ │ -    
│ │ -    def get_diff(self, clip: vs.VideoNode) -> vs.VideoNode:
│ │ -        """
│ │ -            Returns a clip used for diff measuring ala getnative
│ │ -
│ │ -            :param clip:    Clip to compare the rescaled clip to
│ │ -            :return:        Diff clip
│ │ -        """
│ │ -        clip = depth(get_y(clip), 32)
│ │ -        diff = core.std.Expr([depth(self.rescale, 32), clip], ["x y - abs dup 0.015 > swap 0 ?"])
│ │ -        return diff.std.Crop(5, 5, 5, 5).std.PlaneStats()
│ │ -    
│ │ -    def get_upscaled(self, clip: vs.VideoNode, chroma: vs.VideoNode | None = None) -> vs.VideoNode:
│ │ -        """
│ │ -            Generates and returns the fully upscaled & masked & what not clip
│ │ -        """
│ │ -        if self.descale == None or self.rescale == None:
│ │ -            self.generate_clips(clip)
│ │ -
│ │ -        y = depth(get_y(clip), 16)
│ │ -        
│ │ -        if isinstance(self.upscaler, Doubler):
│ │ -            self.doubled = self.upscaler.double(self.descale)
│ │ -        else:
│ │ -            self.upscaler = Scaler.ensure_obj(self.upscaler)
│ │ -            self.doubled = self.upscaler.scale(self.descale, self.descale.width * 2, self.descale.height * 2)
│ │ -
│ │ -        if self.do_post_double is not None:
│ │ -            self.doubled = self.do_post_double(self.doubled)
│ │ -
│ │ -        self.downscaler = Scaler.ensure_obj(self.downscaler)
│ │ -        if hasattr(self, 'frac_args'):
│ │ -            self.frac_args.update({key: value * 2 for (key, value) in self.frac_args.items()})
│ │ -            self.upscale = self.downscaler.scale(self.doubled, clip.width, clip.height, **self.frac_args)
│ │ -            self.upscale = self.upscale.std.CopyFrameProps(self.rescale)
│ │ -        else:
│ │ -            self.upscale = self.downscaler.scale(self.doubled, clip.width, clip.height)
│ │ -
│ │ -        self.upscale = depth(self.upscale, 16)
│ │ -        self.rescale = depth(self.rescale, 16)
│ │ -
│ │ -        if self.line_mask != False:
│ │ -            self.upscale = y.std.MaskedMerge(self.upscale, self.line_mask)
│ │ -
│ │ -        if self.credit_mask != False or self.credit_mask_thr <= 0:
│ │ -            self.upscale = self.upscale.std.MaskedMerge(y, self.credit_mask)
│ │ -
│ │ -        self.upscale = depth(self.upscale, get_depth(clip))
│ │ -        self.upscale = self.upscale if clip.format.color_family == vs.GRAY else join(self.upscale, clip)
│ │ -        return self.upscale if not chroma else join(depth(self.upscale, get_depth(chroma)), depth(chroma, get_depth(chroma)))
│ │ -    
│ │ -    def _return_creditmask(self) -> vs.VideoNode:
│ │ -        return core.std.BlankClip(self.input_clip, format=vs.GRAY16) if self.credit_mask == False else self.credit_mask
│ │ -    
│ │ -    def _return_linemask(self) -> vs.VideoNode:
│ │ -        return core.std.BlankClip(self.input_clip, format=vs.GRAY16) if self.line_mask == False else self.line_mask
│ │ -    
│ │ -    def _return_doubled(self) -> vs.VideoNode:
│ │ -        return core.std.BlankClip(self.input_clip, width=self.input_clip * 2, format=vs.GRAY16) if not self.doubled else self.doubled
│ │ -    
│ │ -DT = DescaleTarget
│ │ -
│ │ -class MixedRescale:
│ │ -    def __init__(self, src: vs.VideoNode, *targets: DescaleTarget) -> None:
│ │ -        """
│ │ -            A naive per-frame diff approach of trying to get the best descale.
│ │ -            Credits to Setsu for most of this class.
│ │ -
│ │ -
│ │ -            Example usage:
│ │ -            ```
│ │ -            t1 = DT(847.1, Bilinear(), base_height=848)
│ │ -            t2 = DescaleTarget(843.75, Bilinear(), base_height=846)
│ │ -
│ │ -            rescaled = MixedRescale(clip, t1, t2)
│ │ -
│ │ -            out(rescaled.final)
│ │ -            out(rescaled.line_mask)
│ │ -            ```
│ │ -        """
│ │ -        clip = depth(src, 32)
│ │ -        y = get_y(clip)
│ │ -
│ │ -        for i, d in enumerate(targets):
│ │ -            d.index = i
│ │ -            d.generate_clips(y)
│ │ -
│ │ -        prop_srcs = [d.get_diff(y) for d in targets]
│ │ -        targets_idx = tuple(range(len(targets)))
│ │ -
│ │ -        blank = core.std.BlankClip(None, 1, 1, vs.GRAY8, src.num_frames, keep=True)
│ │ -
│ │ -        map_prop_srcs = [
│ │ -            blank.std.CopyFrameProps(prop_src).akarin.Expr('x.PlaneStatsAverage', vs.GRAYS)
│ │ -            for prop_src in prop_srcs
│ │ -        ]
│ │ -        
│ │ -        base_frame, idx_frames = blank.get_frame(0), []
│ │ -
│ │ -        for i in targets_idx:
│ │ -            fcurr = base_frame.copy()
│ │ -
│ │ -            fcurr[0][0, 0] = i
│ │ -
│ │ -            idx_frames.append((i, fcurr))
│ │ -
│ │ -        def _select(n: int, f: vs.VideoFrame) -> vs.VideoFrame:
│ │ -            return min(idx_frames, key=lambda i: f[i[0]][0][0, 0])[1]
│ │ -
│ │ -        _select_clip = blank.std.ModifyFrame(map_prop_srcs, _select)
│ │ -
│ │ -        def _selector(clips: list[vs.VideoNode | None]) -> vs.VideoNode:
│ │ -            base = next(filter(None, clips), None)
│ │ -
│ │ -            if base is None:
│ │ -                raise ValueError('Requested clip was None')
│ │ -            
│ │ -            base = base.std.BlankClip(keep=True)
│ │ -            clips = [c or base for c in clips]
│ │ -
│ │ -            return core.std.FrameEval(
│ │ -                base, lambda n, f: clips[f[0][0, 0]], _select_clip
│ │ -            )
│ │ -        
│ │ -        self.upscaled = _selector([t.get_upscaled(t.input_clip) if src.format.color_family == vs.GRAY else t.get_upscaled(t.input_clip, src) for t in targets])
│ │ -        #self.upscaled = depth(self.upscaled, get_depth(src))
│ │ -        self.final = self.upscaled
│ │ -        
│ │ -        self.rescaled = _selector([t.rescale for t in targets])
│ │ -        # These two are not working yet because I need to figure out how to make the base clip up there use varres
│ │ -        #self.descaled = _selector([t.descale for t in targets])
│ │ -        #self.doubled = _selector([t._return_doubled() for t in targets])
│ │ -        self.credit_mask = _selector([t._return_creditmask() for t in targets])
│ │ -        self.line_mask = _selector([t._return_linemask() for t in targets])
│ │ +from vstools import vs, core, get_w, get_y, depth, iterate, ColorRange, join, get_depth
│ │ +from vskernels import Scaler, ScalerT, Kernel, KernelT, Catrom
│ │ +from typing import Callable
│ │ +from math import floor
│ │ +from dataclasses import dataclass
│ │ +
│ │ +from .scale import Doubler, NNEDI_Doubler
│ │ +
│ │ +__all__ = ['DescaleTarget', 'MixedRescale', 'DT']
│ │ +
│ │ +def get_args(clip: vs.VideoNode, base_height: int, height: float, base_width: float = None):
│ │ +    base_height = float(base_height)
│ │ +    src_width = height * clip.width / clip.height
│ │ +    if not base_width:
│ │ +        base_width = clip.width
│ │ +    cropped_width = base_width - 2 * floor((base_width - src_width) / 2)
│ │ +    cropped_height = base_height - 2 * floor((base_height - height) / 2)
│ │ +    fractional_args = dict(height = cropped_height, width = cropped_width, 
│ │ +        src_width = src_width, src_height = height, src_left = (cropped_width - src_width) / 2,
│ │ +        src_top = (cropped_height - height) / 2)
│ │ +    return fractional_args
│ │ +
│ │ +class TargetVals():
│ │ +    input_clip: vs.VideoNode | None = None
│ │ +    descale: vs.VideoNode | None = None
│ │ +    rescale: vs.VideoNode | None = None
│ │ +    doubled: vs.VideoNode | None = None
│ │ +    upscale: vs.VideoNode | None = None
│ │ +
│ │ +    index: int = 0
│ │ +
│ │ +@dataclass
│ │ +class DescaleTarget(TargetVals):
│ │ +    """
│ │ +        Basically an entirely self contained rescaling utility class that can do pretty much everything.
│ │ +
│ │ +        :param height:          Height to be descaled to.
│ │ +        :param kernel:          The kernel used for descaling.
│ │ +        :param upscaler:        Either a vodesfunc doubler or any scaler from vsscale used to upscale/double the descaled clip.
│ │ +        :param downscaler:      Any kernel or scaler used for downscaling the upscaled/doubled clip back to input res.
│ │ +        :param base_height:     Needed for fractional descales.
│ │ +        :param width:           Width to be descaled to. (will be calculated if None)
│ │ +        :param base_width:      Needed for fractional descales. (will be calculated if None)
│ │ +        :param do_post_double:  A function that's called on the doubled clip. Can be used to do sensitive processing on a bigger clip. (e. g. Dehaloing)
│ │ +        :param credit_mask:     Can be used to pass a mask that'll be used or False to disable error masking.
│ │ +        :param credit_mask_thr: The error threshold of the automatically generated credit mask.
│ │ +        :param credit_mask_bh:  Generates an error mask based on a descale using the baseheight. For some reason had better results with this on some shows.
│ │ +        :param line_mask:       Can be used to pass a mask that'll be used or False to disable line masking.
│ │ +        :param bbmod_masks:     Specify rows to be bbmod'ed for a clip to generate the masks on. Will probably be useful for the new border param in descale.
│ │ +    """
│ │ +    height: float
│ │ +    kernel: KernelT = Catrom
│ │ +    upscaler: Doubler | ScalerT = NNEDI_Doubler()
│ │ +    downscaler: ScalerT = Catrom
│ │ +    base_height: int | None = None
│ │ +    width: float | None = None
│ │ +    base_width: int | None = None
│ │ +    do_post_double: Callable[[vs.VideoNode], vs.VideoNode] | None = None
│ │ +    credit_mask: vs.VideoNode | bool | None = None
│ │ +    credit_mask_thr: float = 0.04
│ │ +    credit_mask_bh: bool = False
│ │ +    line_mask: vs.VideoNode | bool | None = None
│ │ +    bbmod_masks: int | list[int] = 0 # Not actually implemented yet lol
│ │ +
│ │ +    def generate_clips(self, clip: vs.VideoNode) -> 'DescaleTarget':
│ │ +        """
│ │ +            Generates descaled and rescaled clips of the given input clip
│ │ +
│ │ +            :param clip:    Clip to descale and rescale
│ │ +        """
│ │ +        self.kernel = Kernel.ensure_obj(self.kernel)
│ │ +        self.input_clip = clip.std.SetFrameProp('Target', self.index + 1)
│ │ +        clip = depth(get_y(clip), 16)
│ │ +        self.height = float(self.height)
│ │ +        if self.height.is_integer():
│ │ +            if not self.width:
│ │ +                self.width = self.height * clip.width / clip.height
│ │ +            self.descale = self.kernel.descale(clip, self.width, self.height)
│ │ +            self.rescale = self.kernel.scale(self.descale, clip.width, clip.height)
│ │ +            ref_y = self.rescale
│ │ +        else:
│ │ +            if self.base_height is None:
│ │ +                raise ValueError("DescaleTarget: height cannot be fractional if you don't pass a base_height.")
│ │ +            if not float(self.base_height).is_integer():
│ │ +                raise ValueError("DescaleTarget: Your base_height has to be an integer.")
│ │ +            if self.base_height < self.height:
│ │ +                raise ValueError("DescaleTarget: Your base_height has to be bigger than your height.")
│ │ +            self.frac_args = get_args(clip, self.base_height, self.height, self.base_width)
│ │ +            self.descale = self.kernel.descale(clip, **self.frac_args)  \
│ │ +                .std.CopyFrameProps(clip).std.SetFrameProp('Descale', self.index + 1)
│ │ +            self.frac_args.pop('width')
│ │ +            self.frac_args.pop('height')
│ │ +            self.rescale = self.kernel.scale(self.descale, clip.width, clip.height, **self.frac_args) \
│ │ +                .std.CopyFrameProps(clip).std.SetFrameProp('Rescale', self.index + 1)
│ │ +            if self.credit_mask_bh:
│ │ +                base_height_desc = self.kernel.descale(clip, self.base_height * (clip.width / clip.height), self.base_height)
│ │ +                ref_y = self.kernel.scale(base_height_desc, clip.width, clip.height)
│ │ +            else:
│ │ +                ref_y = self.rescale
│ │ +            
│ │ +        if self.line_mask != False:
│ │ +            if not isinstance(self.line_mask, vs.VideoNode):
│ │ +                try:
│ │ +                    from vsmask.edge import KirschTCanny
│ │ +                except:
│ │ +                    from vsmasktools.edge import KirschTCanny
│ │ +                self.line_mask = KirschTCanny().edgemask(clip, lthr=80 << 8, hthr=150 << 8)
│ │ +            
│ │ +            if self.do_post_double is not None:
│ │ +                self.line_mask = self.line_mask.std.Inflate()
│ │ +
│ │ +            self.line_mask = depth(self.line_mask, 16)
│ │ +            
│ │ +        if self.credit_mask != False or self.credit_mask_thr <= 0:
│ │ +            if not isinstance(self.credit_mask, vs.VideoNode):
│ │ +                self.credit_mask = core.std.Expr([depth(clip, 32), depth(ref_y, 32)], f"x y - abs {self.credit_mask_thr} < 0 1 ?")
│ │ +                self.credit_mask = depth(self.credit_mask, 16, range_out=ColorRange.FULL, range_in=ColorRange.FULL)
│ │ +                self.credit_mask = self.credit_mask.rgvs.RemoveGrain(mode=6)
│ │ +                self.credit_mask = iterate(self.credit_mask, core.std.Maximum, 2)
│ │ +                self.credit_mask = iterate(self.credit_mask, core.std.Inflate, 2 if self.do_post_double is None else 4)
│ │ +            
│ │ +            self.credit_mask = depth(self.credit_mask, 16)
│ │ +        
│ │ +        return self
│ │ +    
│ │ +    def get_diff(self, clip: vs.VideoNode) -> vs.VideoNode:
│ │ +        """
│ │ +            Returns a clip used for diff measuring ala getnative
│ │ +
│ │ +            :param clip:    Clip to compare the rescaled clip to
│ │ +            :return:        Diff clip
│ │ +        """
│ │ +        clip = depth(get_y(clip), 32)
│ │ +        diff = core.std.Expr([depth(self.rescale, 32), clip], ["x y - abs dup 0.015 > swap 0 ?"])
│ │ +        return diff.std.Crop(5, 5, 5, 5).std.PlaneStats()
│ │ +    
│ │ +    def get_upscaled(self, clip: vs.VideoNode, chroma: vs.VideoNode | None = None) -> vs.VideoNode:
│ │ +        """
│ │ +            Generates and returns the fully upscaled & masked & what not clip
│ │ +        """
│ │ +        if self.descale == None or self.rescale == None:
│ │ +            self.generate_clips(clip)
│ │ +
│ │ +        y = depth(get_y(clip), 16)
│ │ +        
│ │ +        if isinstance(self.upscaler, Doubler):
│ │ +            self.doubled = self.upscaler.double(self.descale)
│ │ +        else:
│ │ +            self.upscaler = Scaler.ensure_obj(self.upscaler)
│ │ +            self.doubled = self.upscaler.scale(self.descale, self.descale.width * 2, self.descale.height * 2)
│ │ +
│ │ +        if self.do_post_double is not None:
│ │ +            self.doubled = self.do_post_double(self.doubled)
│ │ +
│ │ +        self.downscaler = Scaler.ensure_obj(self.downscaler)
│ │ +        if hasattr(self, 'frac_args'):
│ │ +            self.frac_args.update({key: value * 2 for (key, value) in self.frac_args.items()})
│ │ +            self.upscale = self.downscaler.scale(self.doubled, clip.width, clip.height, **self.frac_args)
│ │ +            self.upscale = self.upscale.std.CopyFrameProps(self.rescale)
│ │ +        else:
│ │ +            self.upscale = self.downscaler.scale(self.doubled, clip.width, clip.height)
│ │ +
│ │ +        self.upscale = depth(self.upscale, 16)
│ │ +        self.rescale = depth(self.rescale, 16)
│ │ +
│ │ +        if self.line_mask != False:
│ │ +            self.upscale = y.std.MaskedMerge(self.upscale, self.line_mask)
│ │ +
│ │ +        if self.credit_mask != False or self.credit_mask_thr <= 0:
│ │ +            self.upscale = self.upscale.std.MaskedMerge(y, self.credit_mask)
│ │ +
│ │ +        self.upscale = depth(self.upscale, get_depth(clip))
│ │ +        self.upscale = self.upscale if clip.format.color_family == vs.GRAY else join(self.upscale, clip)
│ │ +        return self.upscale if not chroma else join(depth(self.upscale, get_depth(chroma)), depth(chroma, get_depth(chroma)))
│ │ +    
│ │ +    def _return_creditmask(self) -> vs.VideoNode:
│ │ +        return core.std.BlankClip(self.input_clip, format=vs.GRAY16) if self.credit_mask == False else self.credit_mask
│ │ +    
│ │ +    def _return_linemask(self) -> vs.VideoNode:
│ │ +        return core.std.BlankClip(self.input_clip, format=vs.GRAY16) if self.line_mask == False else self.line_mask
│ │ +    
│ │ +    def _return_doubled(self) -> vs.VideoNode:
│ │ +        return core.std.BlankClip(self.input_clip, width=self.input_clip * 2, format=vs.GRAY16) if not self.doubled else self.doubled
│ │ +    
│ │ +DT = DescaleTarget
│ │ +
│ │ +class MixedRescale:
│ │ +    def __init__(self, src: vs.VideoNode, *targets: DescaleTarget) -> None:
│ │ +        """
│ │ +            A naive per-frame diff approach of trying to get the best descale.
│ │ +            Credits to Setsu for most of this class.
│ │ +
│ │ +
│ │ +            Example usage:
│ │ +            ```
│ │ +            t1 = DT(847.1, Bilinear(), base_height=848)
│ │ +            t2 = DescaleTarget(843.75, Bilinear(), base_height=846)
│ │ +
│ │ +            rescaled = MixedRescale(clip, t1, t2)
│ │ +
│ │ +            out(rescaled.final)
│ │ +            out(rescaled.line_mask)
│ │ +            ```
│ │ +        """
│ │ +        clip = depth(src, 32)
│ │ +        y = get_y(clip)
│ │ +
│ │ +        for i, d in enumerate(targets):
│ │ +            d.index = i
│ │ +            d.generate_clips(y)
│ │ +
│ │ +        prop_srcs = [d.get_diff(y) for d in targets]
│ │ +        targets_idx = tuple(range(len(targets)))
│ │ +
│ │ +        blank = core.std.BlankClip(None, 1, 1, vs.GRAY8, src.num_frames, keep=True)
│ │ +
│ │ +        map_prop_srcs = [
│ │ +            blank.std.CopyFrameProps(prop_src).akarin.Expr('x.PlaneStatsAverage', vs.GRAYS)
│ │ +            for prop_src in prop_srcs
│ │ +        ]
│ │ +        
│ │ +        base_frame, idx_frames = blank.get_frame(0), []
│ │ +
│ │ +        for i in targets_idx:
│ │ +            fcurr = base_frame.copy()
│ │ +
│ │ +            fcurr[0][0, 0] = i
│ │ +
│ │ +            idx_frames.append((i, fcurr))
│ │ +
│ │ +        def _select(n: int, f: vs.VideoFrame) -> vs.VideoFrame:
│ │ +            return min(idx_frames, key=lambda i: f[i[0]][0][0, 0])[1]
│ │ +
│ │ +        _select_clip = blank.std.ModifyFrame(map_prop_srcs, _select)
│ │ +
│ │ +        def _selector(clips: list[vs.VideoNode | None]) -> vs.VideoNode:
│ │ +            base = next(filter(None, clips), None)
│ │ +
│ │ +            if base is None:
│ │ +                raise ValueError('Requested clip was None')
│ │ +            
│ │ +            base = base.std.BlankClip(keep=True)
│ │ +            clips = [c or base for c in clips]
│ │ +
│ │ +            return core.std.FrameEval(
│ │ +                base, lambda n, f: clips[f[0][0, 0]], _select_clip
│ │ +            )
│ │ +        
│ │ +        self.upscaled = _selector([t.get_upscaled(t.input_clip) if src.format.color_family == vs.GRAY else t.get_upscaled(t.input_clip, src) for t in targets])
│ │ +        #self.upscaled = depth(self.upscaled, get_depth(src))
│ │ +        self.final = self.upscaled
│ │ +        
│ │ +        self.rescaled = _selector([t.rescale for t in targets])
│ │ +        # These two are not working yet because I need to figure out how to make the base clip up there use varres
│ │ +        #self.descaled = _selector([t.descale for t in targets])
│ │ +        #self.doubled = _selector([t._return_doubled() for t in targets])
│ │ +        self.credit_mask = _selector([t._return_creditmask() for t in targets])
│ │ +        self.line_mask = _selector([t._return_linemask() for t in targets])
│ │   --- vodesfunc-1.3.1/vodesfunc/misc.py
│ ├── +++ vodesfunc-1.3.2/vodesfunc/misc.py
│ │┄ Ordering differences only
│ │┄ Files 10% similar despite different names
│ │ @@ -1,84 +1,84 @@
│ │ -import vapoursynth as vs
│ │ -core = vs.core
│ │ -
│ │ -from vstools import depth, get_y
│ │ -from functools import partial
│ │ -from typing import Callable
│ │ -
│ │ -
│ │ -def lehmer_merge(*clips: vs.VideoNode, 
│ │ -        lowpass: Callable[[vs.VideoNode], vs.VideoNode]=lambda i: core.std.BoxBlur(i, hradius=3, vradius=3, hpasses=2, vpasses=2)):
│ │ -    """
│ │ -        Perform a lehmer merge using a bunch of clips with the goal of getting the detail from each.
│ │ -        Credits to Zewia
│ │ -
│ │ -        :param clips:       However many clips
│ │ -        :param lowpass:     Callable used to perform the lowpass
│ │ -
│ │ -        :return:            Merged clip
│ │ -    """
│ │ -    clips = list(clips)
│ │ -    count = len(clips)
│ │ -    expr = ""
│ │ -
│ │ -    for i in range(count):
│ │ -        expr += f"src{i} src{count + i} - D{i}! "
│ │ -
│ │ -    for v in range(2):
│ │ -        for i in range(count):
│ │ -            expr += f"D{i}@ {v + 2} pow "
│ │ -        expr += "+ " * (count - 1) + f"P{v}! "
│ │ -
│ │ -    for i in range(count):
│ │ -        expr += f"src{count + i} "
│ │ -    expr += "+ " * (count - 1) + f"{count} / "
│ │ -
│ │ -    expr += "P0@ 0 = 0 P1@ P0@ / ? +"
│ │ -
│ │ -    blur = [lowpass(i) for i in clips]
│ │ -    return core.akarin.Expr(clips + blur, expr)
│ │ -
│ │ -
│ │ -def dirty_prop_set(clip: vs.VideoNode, threshold: int = 1100, luma_scaling: int = 24, prop_name: str = None,
│ │ -                   src_prop_val: any = None, bbm_prop_val: any = None, debug_output: bool = False
│ │ -                   ) -> list[vs.VideoNode]:
│ │ -    """
│ │ -    Dirty-edge-based frameprop setting function using bbm, a brightness difference check and a brightness scaling
│ │ -    (might be a very specific usecase)
│ │ -
│ │ -    Returns both filtered clip and mask in a VideoNode List (0 = clip, 1 = mask)
│ │ -
│ │ -    An example for this would be my tanya script:
│ │ -        Only 720p frames have dirty edges so write a 720 prop if dirty edges are detected.
│ │ -
│ │ -        dirty_prop_set(.., prop_name = 'Rescale', src_prop_val = 812, bbm_prop_val = 720)
│ │ -    """
│ │ -    def _select_frame(n: int, f: vs.VideoFrame, clip_a: vs.VideoNode, clip_b: vs.VideoNode) -> vs.VideoNode:
│ │ -        plane_stats_average = f.props["PlaneStatsAverage"]
│ │ -        #print(f"Frame {n}: {plane_stats_average:.20f}")
│ │ -        return clip_b if plane_stats_average > 0.00010 else clip_a
│ │ -
│ │ -    def _get_mask(n: int, f: vs.VideoFrame, clip_a: vs.VideoNode, clip_b: vs.VideoNode) -> vs.VideoNode:
│ │ -        brightness = f.props["PlaneStatsAverage"]
│ │ -        weighted_thr = threshold * (1 - (1 - brightness)**(brightness ** 2 * luma_scaling))
│ │ -        if debug_output:
│ │ -            print(f"Frame {n}: Average Brightness - {brightness:.20f}, Weighted - {weighted_thr:.20f}")
│ │ -        return core.std.Expr([clip_a, clip_b], [f'y x - {weighted_thr} > 65536 0 ?', ''])
│ │ -
│ │ -    try:
│ │ -        import awsmfunc as awf
│ │ -    except:
│ │ -        raise ModuleNotFoundError('awsmfunc not found!')
│ │ -
│ │ -    clip = depth(clip, 16).std.PlaneStats()  # Wouldn't this be set way earlier?
│ │ -    bbm = awf.bbmod(clip, 1, 1, 1, 1, thresh=50, blur=666)
│ │ -    mask = get_y(core.std.FrameEval(clip, partial(_get_mask, clip_a=clip, clip_b=bbm), clip)).std.PlaneStats()
│ │ -
│ │ -    if(isinstance(src_prop_val, int) and isinstance(bbm_prop_val, int)):
│ │ -        bbm_prop, src_prop = [c.std.SetFrameProp(prop=prop_name, intval=i)
│ │ -                              for c, i in zip([bbm, clip], [bbm_prop_val, src_prop_val])]
│ │ -    else:
│ │ -        bbm_prop, src_prop = [c.std.SetFrameProp(prop=prop_name, data=i)
│ │ -                              for c, i in zip([bbm, clip], [str(bbm_prop_val), str(src_prop_val)])]
│ │ -
│ │ -    return [core.std.FrameEval(clip, partial(_select_frame, clip_a=src_prop, clip_b=bbm_prop), prop_src=mask), mask]
│ │ +import vapoursynth as vs
│ │ +core = vs.core
│ │ +
│ │ +from vstools import depth, get_y
│ │ +from functools import partial
│ │ +from typing import Callable
│ │ +
│ │ +
│ │ +def lehmer_merge(*clips: vs.VideoNode, 
│ │ +        lowpass: Callable[[vs.VideoNode], vs.VideoNode]=lambda i: core.std.BoxBlur(i, hradius=3, vradius=3, hpasses=2, vpasses=2)):
│ │ +    """
│ │ +        Perform a lehmer merge using a bunch of clips with the goal of getting the detail from each.
│ │ +        Credits to Zewia
│ │ +
│ │ +        :param clips:       However many clips
│ │ +        :param lowpass:     Callable used to perform the lowpass
│ │ +
│ │ +        :return:            Merged clip
│ │ +    """
│ │ +    clips = list(clips)
│ │ +    count = len(clips)
│ │ +    expr = ""
│ │ +
│ │ +    for i in range(count):
│ │ +        expr += f"src{i} src{count + i} - D{i}! "
│ │ +
│ │ +    for v in range(2):
│ │ +        for i in range(count):
│ │ +            expr += f"D{i}@ {v + 2} pow "
│ │ +        expr += "+ " * (count - 1) + f"P{v}! "
│ │ +
│ │ +    for i in range(count):
│ │ +        expr += f"src{count + i} "
│ │ +    expr += "+ " * (count - 1) + f"{count} / "
│ │ +
│ │ +    expr += "P0@ 0 = 0 P1@ P0@ / ? +"
│ │ +
│ │ +    blur = [lowpass(i) for i in clips]
│ │ +    return core.akarin.Expr(clips + blur, expr)
│ │ +
│ │ +
│ │ +def dirty_prop_set(clip: vs.VideoNode, threshold: int = 1100, luma_scaling: int = 24, prop_name: str = None,
│ │ +                   src_prop_val: any = None, bbm_prop_val: any = None, debug_output: bool = False
│ │ +                   ) -> list[vs.VideoNode]:
│ │ +    """
│ │ +    Dirty-edge-based frameprop setting function using bbm, a brightness difference check and a brightness scaling
│ │ +    (might be a very specific usecase)
│ │ +
│ │ +    Returns both filtered clip and mask in a VideoNode List (0 = clip, 1 = mask)
│ │ +
│ │ +    An example for this would be my tanya script:
│ │ +        Only 720p frames have dirty edges so write a 720 prop if dirty edges are detected.
│ │ +
│ │ +        dirty_prop_set(.., prop_name = 'Rescale', src_prop_val = 812, bbm_prop_val = 720)
│ │ +    """
│ │ +    def _select_frame(n: int, f: vs.VideoFrame, clip_a: vs.VideoNode, clip_b: vs.VideoNode) -> vs.VideoNode:
│ │ +        plane_stats_average = f.props["PlaneStatsAverage"]
│ │ +        #print(f"Frame {n}: {plane_stats_average:.20f}")
│ │ +        return clip_b if plane_stats_average > 0.00010 else clip_a
│ │ +
│ │ +    def _get_mask(n: int, f: vs.VideoFrame, clip_a: vs.VideoNode, clip_b: vs.VideoNode) -> vs.VideoNode:
│ │ +        brightness = f.props["PlaneStatsAverage"]
│ │ +        weighted_thr = threshold * (1 - (1 - brightness)**(brightness ** 2 * luma_scaling))
│ │ +        if debug_output:
│ │ +            print(f"Frame {n}: Average Brightness - {brightness:.20f}, Weighted - {weighted_thr:.20f}")
│ │ +        return core.std.Expr([clip_a, clip_b], [f'y x - {weighted_thr} > 65536 0 ?', ''])
│ │ +
│ │ +    try:
│ │ +        import awsmfunc as awf
│ │ +    except:
│ │ +        raise ModuleNotFoundError('awsmfunc not found!')
│ │ +
│ │ +    clip = depth(clip, 16).std.PlaneStats()  # Wouldn't this be set way earlier?
│ │ +    bbm = awf.bbmod(clip, 1, 1, 1, 1, thresh=50, blur=666)
│ │ +    mask = get_y(core.std.FrameEval(clip, partial(_get_mask, clip_a=clip, clip_b=bbm), clip)).std.PlaneStats()
│ │ +
│ │ +    if(isinstance(src_prop_val, int) and isinstance(bbm_prop_val, int)):
│ │ +        bbm_prop, src_prop = [c.std.SetFrameProp(prop=prop_name, intval=i)
│ │ +                              for c, i in zip([bbm, clip], [bbm_prop_val, src_prop_val])]
│ │ +    else:
│ │ +        bbm_prop, src_prop = [c.std.SetFrameProp(prop=prop_name, data=i)
│ │ +                              for c, i in zip([bbm, clip], [str(bbm_prop_val), str(src_prop_val)])]
│ │ +
│ │ +    return [core.std.FrameEval(clip, partial(_select_frame, clip_a=src_prop, clip_b=bbm_prop), prop_src=mask), mask]
│ │   --- vodesfunc-1.3.1/vodesfunc/noise.py
│ ├── +++ vodesfunc-1.3.2/vodesfunc/noise.py
│ │┄ Ordering differences only
│ │┄ Files 18% similar despite different names
│ │ @@ -1,130 +1,130 @@
│ │ -import vapoursynth as vs
│ │ -core = vs.core
│ │ -
│ │ -from typing import Sequence, Callable
│ │ -from vstools import get_depth, scale_value, split, normalize_seq, get_neutral_value, get_peak_value, mod4
│ │ -from vskernels import Scaler, Lanczos, BicubicDidee
│ │ -
│ │ -__all__ = [
│ │ -    'adaptive_grain', 'grain', 'ntype4'
│ │ -]
│ │ -
│ │ -ntype4 = {"type": 2, "scale": 0.7, "scaler": BicubicDidee()}
│ │ -
│ │ -def adaptive_grain(clip: vs.VideoNode, strength: float | list[float] = [2.0, 0.5], size: float | list[float] = 3, 
│ │ -    type: int = 3, static: bool = False, temporal_average: int = 25, luma_scaling: float = 6, seed: int = -1, temporal_radius: int = 3,
│ │ -    scale: float = 1, scaler: Scaler = Lanczos(), post_grain: Callable[[vs.VideoNode], vs.VideoNode] | None = None,
│ │ -    fade_edges: bool = True, tv_range: bool = True, lo: int | Sequence[int] | None = None, hi: int | Sequence[int] | None = None,
│ │ -    protect_neutral: bool = True, **kwargs) -> vs.VideoNode:
│ │ -
│ │ -    """
│ │ -        Very frankenstein'd mix of setsu's and the original adptvgrnMod
│ │ -        Only supports https://github.com/wwww-wwww/vs-noise and has some stuff I don't need stripped out.
│ │ -
│ │ -        :param clip:                Input clip.
│ │ -        :param strength:            Grainer strength. Use a list to specify [luma, chroma] graining.
│ │ -                                    Default chroma grain is luma / 5.
│ │ -        :param size:                Grain size. Will be passed as xsize and ysize. Can be adjusted individually with a list.
│ │ -                                    This should not be confused with the resizing of adptvgrnMod. For something similar, use the `scale` param.
│ │ -        :param type:                See vs-noise github for 0-3. Type 4 is type 2 with a 0.7 scale and using BicubicDidee as the scaler.
│ │ -        :param static:              Static or dynamic grain.
│ │ -        :param seed:                Grain seed for the grainer.
│ │ -        :param temporal_average:    Reference frame weighting for temporal softening and grain consistency.
│ │ -        :param temporal_radius:     How many frames the averaging will use.
│ │ -        :param luma_scaling:        Luma scaling passed to the adaptivegrain mask. While use the absolute value on an inverted clip if a negative number is passed.
│ │ -                                    Mainly useful for graining the bright parts of an image.
│ │ -        :param scale:               Makes the grain bigger if > 1 and smaller if < 1 by graining a different sized blankclip and scaling to clip res after.
│ │ -                                    Can be used to tweak sharpness/frequency considering vs-noise always keeps those the same no matter the size.
│ │ -        :param scaler:              Scaler/Kernel used for down- or upscaling the grained blankclip.
│ │ -        :param post_grain:          A callable function to run on the grained blankclip pre scaling. An example use would be to sharpen like I did for something.
│ │ -
│ │ -        :param fade_edges:          Keeps grain from exceeding legal range.
│ │ -                                    With this, values whiclip.height go towards the neutral point, but would generate
│ │ -                                    illegal values if they pointed in the other direction are also limited.
│ │ -                                    This is better at maintaining average values and prevents flickering pixels on OLEDs.
│ │ -        :param tv_range:            TV or PC legal range.
│ │ -        :param lo:                  Overwrite legal range's minimums. Value is scaled from 8-bit to clip depth.
│ │ -        :param hi:                  Overwrite legal range's maximums. Value is scaled from 8-bit to clip depth.
│ │ -        :param protect_neutral:     Disable chroma grain on neutral chroma.
│ │ -        :param kwargs:              Kwargs passed to the grainer.
│ │ -        
│ │ -        :returns: Grained clip.
│ │ -    """
│ │ -    
│ │ -    strength = strength if isinstance(strength, list) else [strength, 0.2 * strength]
│ │ -    size = size if isinstance(size, list) else [size, size]
│ │ -
│ │ -    if type > 4 or type < 0:
│ │ -        raise ValueError('adaptive_grain: Type has to be a number between 0 and 4')
│ │ -
│ │ -    if scale >= 2:
│ │ -        raise ValueError('adaptive_grain: Scale has to be a number below 2. (Default is 1, to disable scaling)')
│ │ -
│ │ -    mask = core.adg.Mask(clip.std.PlaneStats() if luma_scaling >= 0 else clip.std.Invert().std.PlaneStats(), abs(luma_scaling))
│ │ -    ogdepth = get_depth(clip)
│ │ -
│ │ -    def scale_val8x(value: int, chroma: bool = False) -> float:
│ │ -        return scale_value(value, 8, ogdepth, scale_offsets=not tv_range, chroma=chroma)
│ │ -
│ │ -    neutral = [get_neutral_value(clip), get_neutral_value(clip, True)]
│ │ -
│ │ -    if not static and temporal_average > 0:
│ │ -        length = clip.num_frames + temporal_radius - 1
│ │ -    else:
│ │ -        length = clip.num_frames
│ │ -
│ │ -    width = clip.width - (clip.width * scale - clip.width)
│ │ -    height = clip.height - (clip.height * scale - clip.height)
│ │ -
│ │ -    if scale != 1:
│ │ -        width = mod4(width)
│ │ -        height = mod4(height)
│ │ -
│ │ -    blank = clip.std.BlankClip(width, height, length=length, color=normalize_seq(neutral, clip.format.num_planes))
│ │ -    grained = blank.noise.Add(strength[0], strength[1], type=type, xsize=size[0], ysize=size[1], seed=seed, constant=static, **kwargs)
│ │ -
│ │ -    if callable(post_grain):
│ │ -        grained = post_grain(grained)
│ │ -
│ │ -    grained = scaler.scale(grained, clip.width, clip.height)
│ │ -
│ │ -    if not static and temporal_average > 0:
│ │ -        cut = (temporal_radius - 1) // 2
│ │ -        grained = core.std.Merge(grained, core.std.AverageFrames(grained, weights=[1] * temporal_radius), weight=temporal_average / 100)
│ │ -        grained = grained[cut:-cut]
│ │ -
│ │ -    if fade_edges:
│ │ -        if lo is None:
│ │ -            lo = [scale_val8x(16), scale_val8x(16, True)]
│ │ -        elif not isinstance(lo, list):
│ │ -            lo = [scale_val8x(lo), scale_val8x(lo, True)]
│ │ -
│ │ -        if hi is None:
│ │ -            hi = [scale_val8x(235), scale_val8x(240, True)]
│ │ -        elif not isinstance(hi, list):
│ │ -            hi = [scale_val8x(hi), scale_val8x(hi, True)]
│ │ -
│ │ -        limit_expr = "x y {0} - abs - {1} < x y {0} - abs + {2} > or x y {0} - x + ?"
│ │ -        if clip.format.sample_type == vs.INTEGER:
│ │ -            limit_expr = 2 * [limit_expr]
│ │ -        else:
│ │ -            limit_expr = [limit_expr, "x y abs + {2} > x abs y - {1} < or x x y + ?"]
│ │ -
│ │ -        grained = core.std.Expr([clip, grained], [limit_expr[_].format(
│ │ -            neutral[_], lo[_], hi[_]) for _ in range(0, clip.format.num_planes - 1)])
│ │ -
│ │ -        if protect_neutral and strength[1] > 0 and clip.format.color_family == vs.YUV:
│ │ -            format444 = core.query_video_format(vs.YUV, clip.format.sample_type, ogdepth, 0, 0)
│ │ -            neutral_mask = clip.resize.Bicubic(format=format444)
│ │ -            # disable grain if neutral chroma
│ │ -            neutral_mask = core.std.Expr(split(neutral_mask), f"y {neutral[1]} = z {neutral[1]} = and {get_peak_value(clip)} 0 ?")
│ │ -            grained = core.std.MaskedMerge(grained, clip, neutral_mask, planes=[1, 2])
│ │ -    else:
│ │ -        if clip.format.sample_type == vs.INTEGER:
│ │ -            grained = core.std.MergeDiff(clip, grained)
│ │ -        else:
│ │ -            grained = core.std.Expr([clip, grained], [f"y {neutral[_]} - x +" for _ in range(clip.format.num_planes - 1)])
│ │ -
│ │ -    return clip.std.MaskedMerge(grained, mask)
│ │ -
│ │ +import vapoursynth as vs
│ │ +core = vs.core
│ │ +
│ │ +from typing import Sequence, Callable
│ │ +from vstools import get_depth, scale_value, split, normalize_seq, get_neutral_value, get_peak_value, mod4
│ │ +from vskernels import Scaler, Lanczos, BicubicDidee
│ │ +
│ │ +__all__ = [
│ │ +    'adaptive_grain', 'grain', 'ntype4'
│ │ +]
│ │ +
│ │ +ntype4 = {"type": 2, "scale": 0.7, "scaler": BicubicDidee()}
│ │ +
│ │ +def adaptive_grain(clip: vs.VideoNode, strength: float | list[float] = [2.0, 0.5], size: float | list[float] = 3, 
│ │ +    type: int = 3, static: bool = False, temporal_average: int = 25, luma_scaling: float = 6, seed: int = -1, temporal_radius: int = 3,
│ │ +    scale: float = 1, scaler: Scaler = Lanczos(), post_grain: Callable[[vs.VideoNode], vs.VideoNode] | None = None,
│ │ +    fade_edges: bool = True, tv_range: bool = True, lo: int | Sequence[int] | None = None, hi: int | Sequence[int] | None = None,
│ │ +    protect_neutral: bool = True, **kwargs) -> vs.VideoNode:
│ │ +
│ │ +    """
│ │ +        Very frankenstein'd mix of setsu's and the original adptvgrnMod
│ │ +        Only supports https://github.com/wwww-wwww/vs-noise and has some stuff I don't need stripped out.
│ │ +
│ │ +        :param clip:                Input clip.
│ │ +        :param strength:            Grainer strength. Use a list to specify [luma, chroma] graining.
│ │ +                                    Default chroma grain is luma / 5.
│ │ +        :param size:                Grain size. Will be passed as xsize and ysize. Can be adjusted individually with a list.
│ │ +                                    This should not be confused with the resizing of adptvgrnMod. For something similar, use the `scale` param.
│ │ +        :param type:                See vs-noise github for 0-3. Type 4 is type 2 with a 0.7 scale and using BicubicDidee as the scaler.
│ │ +        :param static:              Static or dynamic grain.
│ │ +        :param seed:                Grain seed for the grainer.
│ │ +        :param temporal_average:    Reference frame weighting for temporal softening and grain consistency.
│ │ +        :param temporal_radius:     How many frames the averaging will use.
│ │ +        :param luma_scaling:        Luma scaling passed to the adaptivegrain mask. While use the absolute value on an inverted clip if a negative number is passed.
│ │ +                                    Mainly useful for graining the bright parts of an image.
│ │ +        :param scale:               Makes the grain bigger if > 1 and smaller if < 1 by graining a different sized blankclip and scaling to clip res after.
│ │ +                                    Can be used to tweak sharpness/frequency considering vs-noise always keeps those the same no matter the size.
│ │ +        :param scaler:              Scaler/Kernel used for down- or upscaling the grained blankclip.
│ │ +        :param post_grain:          A callable function to run on the grained blankclip pre scaling. An example use would be to sharpen like I did for something.
│ │ +
│ │ +        :param fade_edges:          Keeps grain from exceeding legal range.
│ │ +                                    With this, values whiclip.height go towards the neutral point, but would generate
│ │ +                                    illegal values if they pointed in the other direction are also limited.
│ │ +                                    This is better at maintaining average values and prevents flickering pixels on OLEDs.
│ │ +        :param tv_range:            TV or PC legal range.
│ │ +        :param lo:                  Overwrite legal range's minimums. Value is scaled from 8-bit to clip depth.
│ │ +        :param hi:                  Overwrite legal range's maximums. Value is scaled from 8-bit to clip depth.
│ │ +        :param protect_neutral:     Disable chroma grain on neutral chroma.
│ │ +        :param kwargs:              Kwargs passed to the grainer.
│ │ +        
│ │ +        :returns: Grained clip.
│ │ +    """
│ │ +    
│ │ +    strength = strength if isinstance(strength, list) else [strength, 0.2 * strength]
│ │ +    size = size if isinstance(size, list) else [size, size]
│ │ +
│ │ +    if type > 4 or type < 0:
│ │ +        raise ValueError('adaptive_grain: Type has to be a number between 0 and 4')
│ │ +
│ │ +    if scale >= 2:
│ │ +        raise ValueError('adaptive_grain: Scale has to be a number below 2. (Default is 1, to disable scaling)')
│ │ +
│ │ +    mask = core.adg.Mask(clip.std.PlaneStats() if luma_scaling >= 0 else clip.std.Invert().std.PlaneStats(), abs(luma_scaling))
│ │ +    ogdepth = get_depth(clip)
│ │ +
│ │ +    def scale_val8x(value: int, chroma: bool = False) -> float:
│ │ +        return scale_value(value, 8, ogdepth, scale_offsets=not tv_range, chroma=chroma)
│ │ +
│ │ +    neutral = [get_neutral_value(clip), get_neutral_value(clip, True)]
│ │ +
│ │ +    if not static and temporal_average > 0:
│ │ +        length = clip.num_frames + temporal_radius - 1
│ │ +    else:
│ │ +        length = clip.num_frames
│ │ +
│ │ +    width = clip.width - (clip.width * scale - clip.width)
│ │ +    height = clip.height - (clip.height * scale - clip.height)
│ │ +
│ │ +    if scale != 1:
│ │ +        width = mod4(width)
│ │ +        height = mod4(height)
│ │ +
│ │ +    blank = clip.std.BlankClip(width, height, length=length, color=normalize_seq(neutral, clip.format.num_planes))
│ │ +    grained = blank.noise.Add(strength[0], strength[1], type=type, xsize=size[0], ysize=size[1], seed=seed, constant=static, **kwargs)
│ │ +
│ │ +    if callable(post_grain):
│ │ +        grained = post_grain(grained)
│ │ +
│ │ +    grained = scaler.scale(grained, clip.width, clip.height)
│ │ +
│ │ +    if not static and temporal_average > 0:
│ │ +        cut = (temporal_radius - 1) // 2
│ │ +        grained = core.std.Merge(grained, core.std.AverageFrames(grained, weights=[1] * temporal_radius), weight=temporal_average / 100)
│ │ +        grained = grained[cut:-cut]
│ │ +
│ │ +    if fade_edges:
│ │ +        if lo is None:
│ │ +            lo = [scale_val8x(16), scale_val8x(16, True)]
│ │ +        elif not isinstance(lo, list):
│ │ +            lo = [scale_val8x(lo), scale_val8x(lo, True)]
│ │ +
│ │ +        if hi is None:
│ │ +            hi = [scale_val8x(235), scale_val8x(240, True)]
│ │ +        elif not isinstance(hi, list):
│ │ +            hi = [scale_val8x(hi), scale_val8x(hi, True)]
│ │ +
│ │ +        limit_expr = "x y {0} - abs - {1} < x y {0} - abs + {2} > or x y {0} - x + ?"
│ │ +        if clip.format.sample_type == vs.INTEGER:
│ │ +            limit_expr = 2 * [limit_expr]
│ │ +        else:
│ │ +            limit_expr = [limit_expr, "x y abs + {2} > x abs y - {1} < or x x y + ?"]
│ │ +
│ │ +        grained = core.std.Expr([clip, grained], [limit_expr[_].format(
│ │ +            neutral[_], lo[_], hi[_]) for _ in range(0, clip.format.num_planes - 1)])
│ │ +
│ │ +        if protect_neutral and strength[1] > 0 and clip.format.color_family == vs.YUV:
│ │ +            format444 = core.query_video_format(vs.YUV, clip.format.sample_type, ogdepth, 0, 0)
│ │ +            neutral_mask = clip.resize.Bicubic(format=format444)
│ │ +            # disable grain if neutral chroma
│ │ +            neutral_mask = core.std.Expr(split(neutral_mask), f"y {neutral[1]} = z {neutral[1]} = and {get_peak_value(clip)} 0 ?")
│ │ +            grained = core.std.MaskedMerge(grained, clip, neutral_mask, planes=[1, 2])
│ │ +    else:
│ │ +        if clip.format.sample_type == vs.INTEGER:
│ │ +            grained = core.std.MergeDiff(clip, grained)
│ │ +        else:
│ │ +            grained = core.std.Expr([clip, grained], [f"y {neutral[_]} - x +" for _ in range(clip.format.num_planes - 1)])
│ │ +
│ │ +    return clip.std.MaskedMerge(grained, mask)
│ │ +
│ │  grain = adaptive_grain
│ │   --- vodesfunc-1.3.1/vodesfunc/types.py
│ ├── +++ vodesfunc-1.3.2/vodesfunc/types.py
│ │┄ Ordering differences only
│ │┄ Files 23% similar despite different names
│ │ @@ -1,28 +1,28 @@
│ │ -from enum import IntEnum
│ │ -from pathlib import Path
│ │ -from typing import TypeVar, Union, Optional
│ │ -from datetime import timedelta
│ │ -
│ │ -__all__: list[str] = [
│ │ -    'PathLike', 'Paths',
│ │ -    'Trim',
│ │ -    'Zone',
│ │ -    'TrackType',
│ │ -]
│ │ -
│ │ -PathLike = TypeVar("PathLike", str, Path)
│ │ -Trim = tuple[int | None, int | None]
│ │ -Zone = tuple[int, int, float | str, str | None]
│ │ -
│ │ -Paths = Union[PathLike, list[PathLike]]
│ │ -
│ │ -# Timedelta (or frame, which will be converted internally), Optional Name
│ │ -Chapter = tuple[timedelta | int, Optional[str]]
│ │ -
│ │ -class TrackType(IntEnum):
│ │ -    VIDEO = 1
│ │ -    AUDIO = 2
│ │ -    SUB = 3
│ │ -    ATTACHMENT = 4
│ │ -    CHAPTERS = 5
│ │ +from enum import IntEnum
│ │ +from pathlib import Path
│ │ +from typing import TypeVar, Union, Optional
│ │ +from datetime import timedelta
│ │ +
│ │ +__all__: list[str] = [
│ │ +    'PathLike', 'Paths',
│ │ +    'Trim',
│ │ +    'Zone',
│ │ +    'TrackType',
│ │ +]
│ │ +
│ │ +PathLike = TypeVar("PathLike", str, Path)
│ │ +Trim = tuple[int | None, int | None]
│ │ +Zone = tuple[int, int, float | str, str | None]
│ │ +
│ │ +Paths = Union[PathLike, list[PathLike]]
│ │ +
│ │ +# Timedelta (or frame, which will be converted internally), Optional Name
│ │ +Chapter = tuple[timedelta | int, Optional[str]]
│ │ +
│ │ +class TrackType(IntEnum):
│ │ +    VIDEO = 1
│ │ +    AUDIO = 2
│ │ +    SUB = 3
│ │ +    ATTACHMENT = 4
│ │ +    CHAPTERS = 5
│ │      MKV = 6
│ │   --- vodesfunc-1.3.1/vodesfunc/util.py
│ ├── +++ vodesfunc-1.3.2/vodesfunc/util.py
│ │┄ Ordering differences only
│ │┄ Files 20% similar despite different names
│ │ @@ -1,201 +1,201 @@
│ │ -import vapoursynth as vs
│ │ -
│ │ -from functools import partial
│ │ -from typing import Callable
│ │ -from pathlib import Path
│ │ -from .types import PathLike, Trim, Zone
│ │ -from .auto.parsing import parse_m2ts_path
│ │ -import os
│ │ -import binascii
│ │ -
│ │ -core = vs.core
│ │ -
│ │ -
│ │ -__all__: list[str] = [
│ │ -    'set_output_source', 'out_src',
│ │ -    'set_output', 'out',
│ │ -    'src_file', 'SRC_FILE', 'src', 'source',
│ │ -]
│ │ -
│ │ -class src_file:
│ │ -
│ │ -    file: Path
│ │ -    src: vs.VideoNode
│ │ -    src_cut: vs.VideoNode
│ │ -    trim: Trim = None
│ │ -
│ │ -    def __init__(self, file: PathLike, trim_start: int = 0, trim_end: int = 0, idx: Callable[[str], vs.VideoNode] = None, force_lsmas: bool = False) -> None:
│ │ -        """
│ │ -            Custom `FileInfo` kind of thing for convenience
│ │ -
│ │ -            :param file:            Either a string based filepath or a Path object
│ │ -            :param trim_start:      At what frame the `src_cut` clip should start
│ │ -            :param trim_end:        At what frame the `src_cut` clip should end
│ │ -            :param idx:             Indexer for the input file. Pass a function that takes a string in and returns a vs.VideoNode.\nDefaults to `vodesfunc.src`
│ │ -            :param force_lsmas:     Forces the use of lsmas inside of `vodesfunc.src`
│ │ -        """
│ │ -        self.file = file if isinstance(file, Path) else Path(file)
│ │ -        self.src = idx(str(self.file.resolve())) if idx else src(str(self.file.resolve()), force_lsmas)
│ │ -        if trim_start is None:
│ │ -            trim_start = 0
│ │ -        if trim_start != 0 or trim_end != 0:
│ │ -            self.trim = (trim_start, trim_end)
│ │ -            if trim_start != 0 and trim_end != 0 and trim_end != None:
│ │ -                self.src_cut = self.src[trim_start: trim_end]
│ │ -            else:
│ │ -                if trim_start != 0:
│ │ -                    self.src_cut = self.src[trim_start:]
│ │ -                elif trim_end != None:
│ │ -                    self.src_cut = self.src[:trim_end]
│ │ -        else:
│ │ -            self.src_cut = self.src
│ │ -
│ │ -        if self.file.suffix.lower() == '.dgi':
│ │ -            if self.file.with_suffix('.m2ts').exists():
│ │ -                self.file = self.file.with_suffix('.m2ts')
│ │ -            else:
│ │ -                self.file = parse_m2ts_path(self.file)
│ │ -
│ │ -SRC_FILE = src_file
│ │ -
│ │ -def src(filePath: str = None, force_lsmas: bool = False, delete_dgi_log: bool = True) -> vs.VideoNode:
│ │ -    """
│ │ -        Uses dgindex as Source and requires dgindexnv in path
│ │ -        to generate files if they don't exist.
│ │ -
│ │ -        :param filepath:        Path to video or dgi file
│ │ -        :param force_lsmas:     Skip dgsource entirely and use lsmas
│ │ -        :param delete_dgi_log:  Delete the .log files dgindexnv creates
│ │ -        :return:                Video Node
│ │ -    """
│ │ -    if filePath.lower().endswith('.dgi'):
│ │ -        return core.dgdecodenv.DGSource(filePath)
│ │ -
│ │ -    import shutil as sh
│ │ -    from pathlib import Path
│ │ -
│ │ -    forceFallBack = sh.which('dgindexnv') is None or not hasattr(core, "dgdecodenv")
│ │ -
│ │ -    # I don't want that to be a hard dependency :trollhd:
│ │ -    try:
│ │ -        import pymediainfo as pym
│ │ -        parsed = pym.MediaInfo.parse(filePath, parse_speed=0.25)
│ │ -        trackmeta = parsed.video_tracks[0].to_data()
│ │ -        format = trackmeta.get('format')
│ │ -        bitdepth = trackmeta.get('bit_depth')
│ │ -        if (format is not None and bitdepth is not None):
│ │ -            if (str(format).strip().lower() == 'avc' and int(bitdepth) > 8):
│ │ -                forceFallBack = True
│ │ -                print(f'Falling back to lsmas for Hi10 ({Path(filePath).name})')
│ │ -            elif(str(format).strip().lower() == 'ffv1'):
│ │ -                forceFallBack = True
│ │ -                print(f'Falling back to lsmas for FFV1 ({Path(filePath).name})')
│ │ -    except OSError:
│ │ -        print('pymediainfo could not find the mediainfo library! (it needs to be in path)')
│ │ -    except:
│ │ -        print('Parsing mediainfo failed. (Do you have pymediainfo installed?)')
│ │ -
│ │ -    if force_lsmas or forceFallBack:
│ │ -        return core.lsmas.LWLibavSource(filePath)
│ │ -
│ │ -    path = Path(filePath)
│ │ -    dgiFile = path.with_suffix('.dgi')
│ │ -
│ │ -    if dgiFile.exists():
│ │ -        return core.dgdecodenv.DGSource(dgiFile.resolve(True))
│ │ -    else:
│ │ -        print("Generating dgi file...")
│ │ -        import os
│ │ -        import subprocess as sub
│ │ -        sub.Popen(f"dgindexnv -i \"{path.name}\" -h -o \"{dgiFile.name}\" -e",
│ │ -                  shell=True, stdout=sub.DEVNULL, cwd=path.parent.resolve(True)).wait()
│ │ -        if path.with_suffix('.log').exists() and delete_dgi_log:
│ │ -            os.remove(path.with_suffix('.log').resolve(True))
│ │ -        return core.dgdecodenv.DGSource(dgiFile.resolve(True))
│ │ -
│ │ -
│ │ -def set_output(clip: vs.VideoNode, name: str = None, frame_info: bool = False, allow_comp: bool = True) -> vs.VideoNode:
│ │ -    """
│ │ -    Outputs a clip. Less to type.
│ │ -    Designed to be used with the good ol 'from vodesfunc import *' and the 'out' alias
│ │ -    """
│ │ -    if name is not None:
│ │ -        clip = clip.std.SetFrameProp('Name', data=name)
│ │ -    if not allow_comp:
│ │ -        clip = clip.std.SetFrameProp('_VSPDisableComp', 1)
│ │ -    if frame_info:
│ │ -        output = _print_frameinfo(clip, name)
│ │ -        output.set_output(len(vs.get_outputs()))
│ │ -    else:
│ │ -        clip.set_output(len(vs.get_outputs()))
│ │ -
│ │ -    return clip
│ │ -
│ │ -
│ │ -def set_output_source(filePath: str | src_file, clip: vs.VideoNode = None, frame_info: bool = False) -> vs.VideoNode:
│ │ -    """
│ │ -    Outputs your source clip while also outputting the audio for it
│ │ -    so scenefiltering becomes less boring
│ │ -
│ │ -    Also returns the clip in case you wanna use it at the start of your script
│ │ -    """
│ │ -    filePath = filePath if isinstance(filePath, str) else str(filePath.file.resolve())
│ │ -
│ │ -    if clip is None:
│ │ -        clip = src(filePath)
│ │ -
│ │ -    clip = clip.std.SetFrameProp('Name', data='Source')
│ │ -    if frame_info:
│ │ -        output = _print_frameinfo(clip, 'Source')
│ │ -        output.set_output(len(vs.get_outputs()))
│ │ -    else:
│ │ -        clip.set_output(len(vs.get_outputs()))
│ │ -
│ │ -    audio = core.bs.AudioSource(filePath)
│ │ -    audio.set_output(len(vs.get_outputs()) + 20)
│ │ -    return clip
│ │ -
│ │ -
│ │ -def _print_frameinfo(clip: vs.VideoNode, title: str = '') -> vs.VideoNode:
│ │ -    style = ("sans-serif,20,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,"
│ │ -             "0,0,0,0,100,100,0,0,1,2,0,7,10,10,10,1")
│ │ -
│ │ -    def FrameProps(n: int, f: vs.VideoFrame, clip: vs.VideoNode) -> vs.VideoNode:
│ │ -        if "_PictType" in f.props:
│ │ -            info = f"Frame {n} of {clip.num_frames}\nPicture type: {f.props['_PictType'].decode()}"
│ │ -        else:
│ │ -            info = f"Frame {n} of {clip.num_frames}\nPicture type: N/A"
│ │ -
│ │ -        clip = core.sub.Subtitle(clip, text=info, style=style)
│ │ -        return clip
│ │ -
│ │ -    clip = core.std.FrameEval(clip, partial(FrameProps, clip=clip), prop_src=clip)
│ │ -    clip = core.sub.Subtitle(clip, text=["".join(['\n'] * 4) + title], style=style)
│ │ -    return clip
│ │ -
│ │ -def uniquify_path(path):
│ │ -    filename, extension = os.path.splitext(path)
│ │ -    counter = 1
│ │ -
│ │ -    while os.path.exists(path):
│ │ -        path = filename + " (" + str(counter) + ")" + extension
│ │ -        counter += 1
│ │ -
│ │ -    return path
│ │ -
│ │ -def get_crc32(file: PathLike) -> str:
│ │ -    buf = open(file, 'rb').read()
│ │ -    buf = (binascii.crc32(buf) & 0xFFFFFFFF)
│ │ -    return "%08X" % buf
│ │ -
│ │ -def is_x264_zone(zone: Zone) -> bool:
│ │ -    if isinstance(zone[2], str):
│ │ -        if len(zone) < 4:
│ │ -            raise ValueError(f"Zone {zone} is invalid.")
│ │ -        return True
│ │ -    else:
│ │ -        return False
│ │ -
│ │ -out = set_output
│ │ -out_src = set_output_source
│ │ -source = src
│ │ +import vapoursynth as vs
│ │ +
│ │ +from functools import partial
│ │ +from typing import Callable
│ │ +from pathlib import Path
│ │ +from .types import PathLike, Trim, Zone
│ │ +from .auto.parsing import parse_m2ts_path
│ │ +import os
│ │ +import binascii
│ │ +
│ │ +core = vs.core
│ │ +
│ │ +
│ │ +__all__: list[str] = [
│ │ +    'set_output_source', 'out_src',
│ │ +    'set_output', 'out',
│ │ +    'src_file', 'SRC_FILE', 'src', 'source',
│ │ +]
│ │ +
│ │ +class src_file:
│ │ +
│ │ +    file: Path
│ │ +    src: vs.VideoNode
│ │ +    src_cut: vs.VideoNode
│ │ +    trim: Trim = None
│ │ +
│ │ +    def __init__(self, file: PathLike, trim_start: int = 0, trim_end: int = 0, idx: Callable[[str], vs.VideoNode] = None, force_lsmas: bool = False) -> None:
│ │ +        """
│ │ +            Custom `FileInfo` kind of thing for convenience
│ │ +
│ │ +            :param file:            Either a string based filepath or a Path object
│ │ +            :param trim_start:      At what frame the `src_cut` clip should start
│ │ +            :param trim_end:        At what frame the `src_cut` clip should end
│ │ +            :param idx:             Indexer for the input file. Pass a function that takes a string in and returns a vs.VideoNode.\nDefaults to `vodesfunc.src`
│ │ +            :param force_lsmas:     Forces the use of lsmas inside of `vodesfunc.src`
│ │ +        """
│ │ +        self.file = file if isinstance(file, Path) else Path(file)
│ │ +        self.src = idx(str(self.file.resolve())) if idx else src(str(self.file.resolve()), force_lsmas)
│ │ +        if trim_start is None:
│ │ +            trim_start = 0
│ │ +        if trim_start != 0 or trim_end != 0:
│ │ +            self.trim = (trim_start, trim_end)
│ │ +            if trim_start != 0 and trim_end != 0 and trim_end != None:
│ │ +                self.src_cut = self.src[trim_start: trim_end]
│ │ +            else:
│ │ +                if trim_start != 0:
│ │ +                    self.src_cut = self.src[trim_start:]
│ │ +                elif trim_end != None:
│ │ +                    self.src_cut = self.src[:trim_end]
│ │ +        else:
│ │ +            self.src_cut = self.src
│ │ +
│ │ +        if self.file.suffix.lower() == '.dgi':
│ │ +            if self.file.with_suffix('.m2ts').exists():
│ │ +                self.file = self.file.with_suffix('.m2ts')
│ │ +            else:
│ │ +                self.file = parse_m2ts_path(self.file)
│ │ +
│ │ +SRC_FILE = src_file
│ │ +
│ │ +def src(filePath: str = None, force_lsmas: bool = False, delete_dgi_log: bool = True) -> vs.VideoNode:
│ │ +    """
│ │ +        Uses dgindex as Source and requires dgindexnv in path
│ │ +        to generate files if they don't exist.
│ │ +
│ │ +        :param filepath:        Path to video or dgi file
│ │ +        :param force_lsmas:     Skip dgsource entirely and use lsmas
│ │ +        :param delete_dgi_log:  Delete the .log files dgindexnv creates
│ │ +        :return:                Video Node
│ │ +    """
│ │ +    if filePath.lower().endswith('.dgi'):
│ │ +        return core.dgdecodenv.DGSource(filePath)
│ │ +
│ │ +    import shutil as sh
│ │ +    from pathlib import Path
│ │ +
│ │ +    forceFallBack = sh.which('dgindexnv') is None or not hasattr(core, "dgdecodenv")
│ │ +
│ │ +    # I don't want that to be a hard dependency :trollhd:
│ │ +    try:
│ │ +        import pymediainfo as pym
│ │ +        parsed = pym.MediaInfo.parse(filePath, parse_speed=0.25)
│ │ +        trackmeta = parsed.video_tracks[0].to_data()
│ │ +        format = trackmeta.get('format')
│ │ +        bitdepth = trackmeta.get('bit_depth')
│ │ +        if (format is not None and bitdepth is not None):
│ │ +            if (str(format).strip().lower() == 'avc' and int(bitdepth) > 8):
│ │ +                forceFallBack = True
│ │ +                print(f'Falling back to lsmas for Hi10 ({Path(filePath).name})')
│ │ +            elif(str(format).strip().lower() == 'ffv1'):
│ │ +                forceFallBack = True
│ │ +                print(f'Falling back to lsmas for FFV1 ({Path(filePath).name})')
│ │ +    except OSError:
│ │ +        print('pymediainfo could not find the mediainfo library! (it needs to be in path)')
│ │ +    except:
│ │ +        print('Parsing mediainfo failed. (Do you have pymediainfo installed?)')
│ │ +
│ │ +    if force_lsmas or forceFallBack:
│ │ +        return core.lsmas.LWLibavSource(filePath)
│ │ +
│ │ +    path = Path(filePath)
│ │ +    dgiFile = path.with_suffix('.dgi')
│ │ +
│ │ +    if dgiFile.exists():
│ │ +        return core.dgdecodenv.DGSource(dgiFile.resolve(True))
│ │ +    else:
│ │ +        print("Generating dgi file...")
│ │ +        import os
│ │ +        import subprocess as sub
│ │ +        sub.Popen(f"dgindexnv -i \"{path.name}\" -h -o \"{dgiFile.name}\" -e",
│ │ +                  shell=True, stdout=sub.DEVNULL, cwd=path.parent.resolve(True)).wait()
│ │ +        if path.with_suffix('.log').exists() and delete_dgi_log:
│ │ +            os.remove(path.with_suffix('.log').resolve(True))
│ │ +        return core.dgdecodenv.DGSource(dgiFile.resolve(True))
│ │ +
│ │ +
│ │ +def set_output(clip: vs.VideoNode, name: str = None, frame_info: bool = False, allow_comp: bool = True) -> vs.VideoNode:
│ │ +    """
│ │ +    Outputs a clip. Less to type.
│ │ +    Designed to be used with the good ol 'from vodesfunc import *' and the 'out' alias
│ │ +    """
│ │ +    if name is not None:
│ │ +        clip = clip.std.SetFrameProp('Name', data=name)
│ │ +    if not allow_comp:
│ │ +        clip = clip.std.SetFrameProp('_VSPDisableComp', 1)
│ │ +    if frame_info:
│ │ +        output = _print_frameinfo(clip, name)
│ │ +        output.set_output(len(vs.get_outputs()))
│ │ +    else:
│ │ +        clip.set_output(len(vs.get_outputs()))
│ │ +
│ │ +    return clip
│ │ +
│ │ +
│ │ +def set_output_source(filePath: str | src_file, clip: vs.VideoNode = None, frame_info: bool = False) -> vs.VideoNode:
│ │ +    """
│ │ +    Outputs your source clip while also outputting the audio for it
│ │ +    so scenefiltering becomes less boring
│ │ +
│ │ +    Also returns the clip in case you wanna use it at the start of your script
│ │ +    """
│ │ +    filePath = filePath if isinstance(filePath, str) else str(filePath.file.resolve())
│ │ +
│ │ +    if clip is None:
│ │ +        clip = src(filePath)
│ │ +
│ │ +    clip = clip.std.SetFrameProp('Name', data='Source')
│ │ +    if frame_info:
│ │ +        output = _print_frameinfo(clip, 'Source')
│ │ +        output.set_output(len(vs.get_outputs()))
│ │ +    else:
│ │ +        clip.set_output(len(vs.get_outputs()))
│ │ +
│ │ +    audio = core.bs.AudioSource(filePath)
│ │ +    audio.set_output(len(vs.get_outputs()) + 20)
│ │ +    return clip
│ │ +
│ │ +
│ │ +def _print_frameinfo(clip: vs.VideoNode, title: str = '') -> vs.VideoNode:
│ │ +    style = ("sans-serif,20,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,"
│ │ +             "0,0,0,0,100,100,0,0,1,2,0,7,10,10,10,1")
│ │ +
│ │ +    def FrameProps(n: int, f: vs.VideoFrame, clip: vs.VideoNode) -> vs.VideoNode:
│ │ +        if "_PictType" in f.props:
│ │ +            info = f"Frame {n} of {clip.num_frames}\nPicture type: {f.props['_PictType'].decode()}"
│ │ +        else:
│ │ +            info = f"Frame {n} of {clip.num_frames}\nPicture type: N/A"
│ │ +
│ │ +        clip = core.sub.Subtitle(clip, text=info, style=style)
│ │ +        return clip
│ │ +
│ │ +    clip = core.std.FrameEval(clip, partial(FrameProps, clip=clip), prop_src=clip)
│ │ +    clip = core.sub.Subtitle(clip, text=["".join(['\n'] * 4) + title], style=style)
│ │ +    return clip
│ │ +
│ │ +def uniquify_path(path):
│ │ +    filename, extension = os.path.splitext(path)
│ │ +    counter = 1
│ │ +
│ │ +    while os.path.exists(path):
│ │ +        path = filename + " (" + str(counter) + ")" + extension
│ │ +        counter += 1
│ │ +
│ │ +    return path
│ │ +
│ │ +def get_crc32(file: PathLike) -> str:
│ │ +    buf = open(file, 'rb').read()
│ │ +    buf = (binascii.crc32(buf) & 0xFFFFFFFF)
│ │ +    return "%08X" % buf
│ │ +
│ │ +def is_x264_zone(zone: Zone) -> bool:
│ │ +    if isinstance(zone[2], str):
│ │ +        if len(zone) < 4:
│ │ +            raise ValueError(f"Zone {zone} is invalid.")
│ │ +        return True
│ │ +    else:
│ │ +        return False
│ │ +
│ │ +out = set_output
│ │ +out_src = set_output_source
│ │ +source = src
│ │   --- vodesfunc-1.3.1/vodesfunc.egg-info/PKG-INFO
│ ├── +++ vodesfunc-1.3.2/vodesfunc.egg-info/PKG-INFO
│ │┄ Files 18% similar despite different names
│ │ @@ -1,35 +1,35 @@
│ │ -Metadata-Version: 2.1
│ │ -Name: vodesfunc
│ │ -Version: 1.3.1
│ │ -Summary: Vodes's Vapoursynth Functions.
│ │ -Author: Vodes
│ │ -Author-email: vodes.imp@gmail.com
│ │ -Maintainer: Vodes
│ │ -Maintainer-email: vodes.imp@gmail.com
│ │ -Project-URL: Source Code, https://github.com/Vodes/vodesfunc
│ │ -Project-URL: Contact, https://discord.gg/Kf94Nv6WVN
│ │ -Classifier: Natural Language :: English
│ │ -Classifier: Intended Audience :: Developers
│ │ -Classifier: Intended Audience :: Other Audience
│ │ -Classifier: Programming Language :: Python :: 3.10
│ │ -Classifier: License :: OSI Approved :: MIT License
│ │ -Classifier: Operating System :: OS Independent
│ │ -Classifier: Typing :: Typed
│ │ -Classifier: Topic :: Multimedia :: Video
│ │ -Classifier: Topic :: Multimedia :: Video :: Display
│ │ -Requires-Python: >=3.10
│ │ -Description-Content-Type: text/markdown
│ │ -License-File: LICENSE
│ │ -
│ │ -# vodesfunc
│ │ -
│ │ -Contains various functions for automation and other stuff I use in my scripts
│ │ -
│ │ -### This is by no means me trying to be professional and as such, the code will not be treated like it.
│ │ -<br>
│ │ -
│ │ -## Installation
│ │ -
│ │ -`pip install vodesfunc` <br>for ~~mostly~~ stable versions
│ │ -
│ │ -`pip install git+https://github.com/Vodes/vodesfunc.git` <br>for absolutely latest
│ │ +Metadata-Version: 2.1
│ │ +Name: vodesfunc
│ │ +Version: 1.3.2
│ │ +Summary: Vodes's Vapoursynth Functions.
│ │ +Author: Vodes
│ │ +Author-email: vodes.imp@gmail.com
│ │ +Maintainer: Vodes
│ │ +Maintainer-email: vodes.imp@gmail.com
│ │ +Project-URL: Source Code, https://github.com/Vodes/vodesfunc
│ │ +Project-URL: Contact, https://discord.gg/Kf94Nv6WVN
│ │ +Classifier: Natural Language :: English
│ │ +Classifier: Intended Audience :: Developers
│ │ +Classifier: Intended Audience :: Other Audience
│ │ +Classifier: Programming Language :: Python :: 3.10
│ │ +Classifier: License :: OSI Approved :: MIT License
│ │ +Classifier: Operating System :: OS Independent
│ │ +Classifier: Typing :: Typed
│ │ +Classifier: Topic :: Multimedia :: Video
│ │ +Classifier: Topic :: Multimedia :: Video :: Display
│ │ +Requires-Python: >=3.10
│ │ +Description-Content-Type: text/markdown
│ │ +License-File: LICENSE
│ │ +
│ │ +# vodesfunc
│ │ +
│ │ +Contains various functions for automation and other stuff I use in my scripts
│ │ +
│ │ +### This is by no means me trying to be professional and as such, the code will not be treated like it.
│ │ +<br>
│ │ +
│ │ +## Installation
│ │ +
│ │ +`pip install vodesfunc` <br>for ~~mostly~~ stable versions
│ │ +
│ │ +`pip install git+https://github.com/Vodes/vodesfunc.git` <br>for absolutely latest
