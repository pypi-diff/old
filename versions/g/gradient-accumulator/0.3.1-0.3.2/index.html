<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="x-ua-compatible" content="IE=edge">
  <meta name="referrer" content="no-referrer" />
  <meta name="generator" content="diffoscope" />
  <link rel="icon" type="image/png" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAADdgAAA3YBfdWCzAAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAAM8SURBVFiF7dZdaJZlGAfw3/O+e9XNjy3XllZzWImBxIpifqTgsmUHBSIeBNFBdRh0UHQ0xGdb66CFBIERZEFRQRRUw0HkQkLMYQSBdpCFWdgSP6jpNn2393k68Nn2bj3vXtb6UOh/cl/39b/u67mem/913zf/4z9GUDw5xNI8n5WIzW9m/QF2YluJmI8203mALzEvLWAerRs4Pz6vSIkZSlsYk0/GkaB0zEgyDgWMlijyWsJuS2fkQwu8pqpMTA0ypeiShG71Bp0rU8Q+A47MWEDgvHZbZl/Av4SpIgxVYB3IqwZDmoUuYkzosDaNchpAoFqkSmgjGPWzLieF1k3JHVsjvCJQHBYaSy9g1E3m+QImQiK9SbNGqJDzuiDZ0lggQJCsyelDq8BB47sbCWTsnvhG3kqcLL833eqF4hk1EOoTOjZjnnaRdq2l6KtMAyl4/g23bKJrun+Mt9uOq7nvqOVbebWYy9Adc1fM/R/3CO780dONbIeFPHsPw+ULeM5ZHTbXHfUtXpxOZzgT5z02UGsZThRzF/ilht9G+fr4zfbfccIxXIa7uVTup69i7LJXaEEqF3on1d9ludBLpVLOVoT1lky9QYtwQ6p3WAVqSyUslWwSbRrkPJrMtgn0iBVk7BPJ4sGE24EPQKW3jLgdzWKLBTbg0yTuZeGkDsp2gcUGDesHGQ/gK5G8nLMigWiCe3jCrnTRiJ9EYjm1ImsUEq5l8hScPXbpsVtlKhfan+pv0yD0ZqmU5XegGBmnDIo/pylj8oYLOP3Eab/v5Zmi6EtZ3vv1FU/2r7LioYSL2dNybbdiMdptFU57++20Vqh+iq/Tap1WpaWY611wmyWyUzxZDbIWTvEV1Ildn5agfBumoUMTtoisFvhebAAHZWxX0ChwTuScvHdVeVykToysMyJ7ittwbmj31J+6IrRDp5XTfBt1WJ+WYnZdMB0F3xlUgD5uDVj2Sa+a4SrzH+FeyHHmw17V112waBOZgP4WczkLZsILar1fpIliMU4XZoK/poE0XHl+N8v6QcGAUbVymnDIZVnzrTXqGzmnhKLxZX/niyiDjIJgwg4Se1GR/Y8idGPysh6fr0i1i/AHMWHgrwUJgNAAAAAASUVORK5CYII=" />
  <title>/srv/diffoscope/bin/diffoscope --no-progress tmp/gradient-accumulator-0.3.1.tar.gz tmp/gradient-accumulator-0.3.2.tar.gz --html versions/g/gradient-accumulator/0.3.1-0.3.2/index.html --text versions/g/gradient-accumulator/0.3.1-0.3.2/diff.txt --markdown versions/g/gradient-accumulator/0.3.1-0.3.2/diff.md</title>
<style>
body.diffoscope {
  background: white;
  color: black;
}
.diffoscope .footer {
  font-size: small;
}
.diffoscope .difference {
  border: outset #888 1px;
  background: #E8E8E8;
  background: rgba(0,0,0,.1);
  padding: 0.5em;
  margin: 0.5em 0;
}
.diffoscope .difference table {
  table-layout: fixed;
  width: 100%;
  border: 0;
}
.diffoscope .difference th,
.diffoscope .difference td {
  border: 0;
}
.diffoscope table.diff {
  border: 0;
  border-collapse:collapse;
  font-size:0.75em;
  font-family: 'Lucida Console', monospace;
  word-break: break-word;
}
.diffoscope table.diff tr:hover td {
  background: #FFFF00;
}
.diffoscope .line {
  color:#8080a0
}
.diffoscope th {
  background: black;
  color: white
}
.diffoscope .diffunmodified td {
  background: #D0D0E0
}
.diffoscope .diffhunk td {
  background: #A0A0A0
}
.diffoscope .diffadded td {
  background: #CCFFCC
}
.diffoscope .diffdeleted td {
  background: #FFCCCC
}
.diffoscope .diffchanged td {
  background: #FFFFA0
}
.diffoscope ins, del {
  background: #E0C880;
  text-decoration: none
}
.diffoscope .dp {
  color: #B08080
}
.diffoscope .comment {
  font-style: italic;
}
.diffoscope .comment.multiline {
  font-style: normal;
  font-family: monospace;
  white-space: pre;
}
.diffoscope .source {
  font-weight: bold;
}
.diffoscope .error {
  border: solid black 1px;
  background: red;
  color: white;
  padding: 0.2em;
}
.diffoscope .anchor {
  margin-left: 0.5em;
  font-size: 80%;
  color: #333;
  text-decoration: none;
  display: none;
}
.diffoscope .diffheader:hover .anchor {
  display: inline;
}
.diffoscope .diffcontrol, .diffoscope .diffcontrol-nochildren {
  float: left;
  margin-right: 0.3em;
  cursor: pointer;
  display: none; /* currently, only available in html-dir output where jquery is enabled */
}
.diffoscope .colines {
  width: 3em;
}
.diffoscope .coldiff {
  width: 99%;
}
.diffoscope .diffsize {
  float: right;
}
.diffoscope table.diff tr.ondemand td, .diffoscope div.ondemand-details {
  background: #f99;
  text-align: center;
  padding: 0.5em 0;
}
.diffoscope table.diff tr.ondemand:hover td, .diffoscope div.ondemand-details:hover {
  background: #faa;
  cursor: pointer;
}
</style>
</head>
<body class="diffoscope">
<div class="difference">
  <div class="diffheader">
  <div class="diffcontrol diffcontrol-double">⊟</div>
  <div><span class="diffsize">53.8 KB</span></div>
  <div><span class="source">tmp/gradient-accumulator-0.3.1.tar.gz</span> vs.</div>
  <div id="top"><span class="source">tmp/gradient-accumulator-0.3.2.tar.gz</span>
    <a class="anchor" href="#top">¶</a>
  </div>
  </div>
  <div class="difference">
    <div class="diffheader">
    <div class="diffcontrol">⊟</div>
    <div><span class="diffsize">300 B</span></div>
    <div id="filetype-from-file---"><span class="source">filetype from file(1)</span>
      <a class="anchor" href="#filetype-from-file---">¶</a>
    </div>
    </div>
<table class="diff">
<colgroup><col class="colines"/><col class="coldiff"/>
<col class="colines"/><col class="coldiff"/></colgroup>
<tr style="display:none;"><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 1, 1 lines modified</td><td colspan="2">Offset 1, 1 lines modified</td></tr>
<tr class="diffchanged"><td class="diffline">1 </td><td class="diffpresent">gzip<span class="dp">·</span>compressed<span class="dp">·</span>data,<span class="dp">·</span>was<span class="dp">·</span>&quot;dist/gradient-accumulator-0.3.<del>1</del>.tar&quot;,<span class="dp">·</span>last<span class="dp">·</span>modified:<span class="dp">·</span><del>Sun</del><span class="dp">·</span><del>Jan</del><span class="dp">·</span><del>29</del><span class="dp">·</span>2<del>2</del>:<del>29</del>:<del>18</del><span class="dp">·</span>2023,<span class="dp">·</span>max<span class="dp">·</span>compression</td><td class="diffline">1 </td><td class="diffpresent">gzip<span class="dp">·</span>compressed<span class="dp">·</span>data,<span class="dp">·</span>was<span class="dp">·</span>&quot;dist/gradient-accumulator-0.3.<ins>2</ins>.tar&quot;,<span class="dp">·</span>last<span class="dp">·</span>modified:<span class="dp">·</span><ins>Thu</ins><span class="dp">·</span><ins>Apr</ins><span class="dp">·</span><ins><span class="dp">·</span>6</ins><span class="dp">·</span>2<ins>1</ins>:<ins>50</ins>:<ins>02</ins><span class="dp">·</span>2023,<span class="dp">·</span>max<span class="dp">·</span>compression</td></tr>
</table>  </div>
  <div class="difference">
    <div class="diffheader">
    <div class="diffcontrol diffcontrol-double">⊟</div>
    <div><span class="diffsize">53.5 KB</span></div>
    <div><span class="source">gradient-accumulator-0.3.1.tar</span> vs.</div>
    <div id="gradient-accumulator--.-.-.tar"><span class="source">gradient-accumulator-0.3.2.tar</span>
      <a class="anchor" href="#gradient-accumulator--.-.-.tar">¶</a>
    </div>
    </div>
    <div class="difference">
      <div class="diffheader">
      <div class="diffcontrol">⊟</div>
      <div><span class="diffsize">6.22 KB</span></div>
      <div id="gradient-accumulator--.-.-.tar---file-list"><span class="source">file list</span>
        <a class="anchor" href="#gradient-accumulator--.-.-.tar---file-list">¶</a>
      </div>
      </div>
<table class="diff">
<colgroup><col class="colines"/><col class="coldiff"/>
<col class="colines"/><col class="coldiff"/></colgroup>
<tr style="display:none;"><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 1, 29 lines modified</td><td colspan="2">Offset 1, 16 lines modified</td></tr>
<tr class="diffchanged"><td class="diffline">1 </td><td class="diffpresent">drwxr-xr-x<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>29</del>:<del>18</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/</td><td class="diffline">1 </td><td class="diffpresent">drwxr-xr-x<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>50</ins>:<ins>02</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/</td></tr>
<tr class="diffchanged"><td class="diffline">2 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>1<del>10</del>0<del>8</del><span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>29</del>:<del>18</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/PKG-INFO</td><td class="diffline">2 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>1<ins>53</ins>0<ins>9</ins><span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>50</ins>:<ins>02</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/PKG-INFO</td></tr>
<tr class="diffchanged"><td class="diffline">3 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><del><span class="dp">·</span>85</del>9<del>0</del><span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>28</del>:<del>35</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/README.md</td><td class="diffline">3 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><ins>120</ins>9<ins>3</ins><span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>49</ins>:<ins>17</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/README.md</td></tr>
<tr class="diffchanged"><td class="diffline">4 </td><td class="diffpresent">drwxr-xr-x<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>29</del>:<del>18</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/gradient_accumulator/</td><td class="diffline">4 </td><td class="diffpresent">drwxr-xr-x<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>50</ins>:<ins>02</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/gradient_accumulator/</td></tr>
<tr class="diffchanged"><td class="diffline">5 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>104<span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>28</del>:<del>35</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/gradient_accumulator/__init__.py</td><td class="diffline">5 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>104<span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>49</ins>:<ins>17</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/gradient_accumulator/__init__.py</td></tr>
<tr class="diffchanged"><td class="diffline">6 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>1<del>1154</del><span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>28</del>:<del>35</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/gradient_accumulator/accumulators.py</td><td class="diffline">6 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>1<ins>0916</ins><span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>49</ins>:<ins>17</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/gradient_accumulator/accumulators.py</td></tr>
<tr class="diffchanged"><td class="diffline">7 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>1882<span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>28</del>:<del>35</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/gradient_accumulator/agc.py</td><td class="diffline">7 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>1882<span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>49</ins>:<ins>17</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/gradient_accumulator/agc.py</td></tr>
<tr class="diffchanged"><td class="diffline">8 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><del><span class="dp">·</span>752</del><span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>28</del>:<del>35</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/gradient_accumulator/layers.py</td><td class="diffline">8 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><ins>2949</ins><span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>49</ins>:<ins>17</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/gradient_accumulator/layers.py</td></tr>
<tr class="diffdeleted"><td class="diffline">9 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(116)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>3192<span class="dp">·</span>2023-01-29<span class="dp">·</span>22:28:35.000000<span class="dp">·</span>gradient-accumulator-0.3.1/gradient_accumulator/utils.py</td><td colspan="2"> </td></tr>
<tr class="diffchanged"><td class="diffline">10 </td><td class="diffpresent">drwxr-xr-x<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>29</del>:<del>18</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/gradient_accumulator.egg-info/</td><td class="diffline">9 </td><td class="diffpresent">drwxr-xr-x<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>50</ins>:<ins>02</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/gradient_accumulator.egg-info/</td></tr>
<tr class="diffchanged"><td class="diffline">11 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>1<del>10</del>0<del>8</del><span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>29</del>:<del>18</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/gradient_accumulator.egg-info/PKG-INFO</td><td class="diffline">10 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>1<ins>53</ins>0<ins>9</ins><span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>50</ins>:<ins>02</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/gradient_accumulator.egg-info/PKG-INFO</td></tr>
<tr class="diffchanged"><td class="diffline">12 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><del>735</del><span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>29</del>:<del>18</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/gradient_accumulator.egg-info/SOURCES.txt</td><td class="diffline">11 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><ins>376</ins><span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>50</ins>:<ins>02</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/gradient_accumulator.egg-info/SOURCES.txt</td></tr>
<tr class="diffchanged"><td class="diffline">13 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>1<span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>29</del>:<del>18</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/gradient_accumulator.egg-info/dependency_links.txt</td><td class="diffline">12 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>1<span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>50</ins>:<ins>02</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/gradient_accumulator.egg-info/dependency_links.txt</td></tr>
<tr class="diffchanged"><td class="diffline">14 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><del>29</del><span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>29</del>:<del>18</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/gradient_accumulator.egg-info/requires.txt</td><td class="diffline">13 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><ins>11</ins><span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>50</ins>:<ins>02</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/gradient_accumulator.egg-info/requires.txt</td></tr>
<tr class="diffchanged"><td class="diffline">15 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>2<del>7</del><span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>29</del>:<del>18</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/gradient_accumulator.egg-info/top_level.txt</td><td class="diffline">14 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>2<ins>1</ins><span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>50</ins>:<ins>02</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/gradient_accumulator.egg-info/top_level.txt</td></tr>
<tr class="diffchanged"><td class="diffline">16 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>79<span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>29</del>:<del>18</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/setup.cfg</td><td class="diffline">15 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>79<span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>50</ins>:<ins>02</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/setup.cfg</td></tr>
<tr class="diffchanged"><td class="diffline">17 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<del>16</del>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>1<del>171</del><span class="dp">·</span>2023-0<del>1</del>-<del>29</del><span class="dp">·</span>2<del>2</del>:<del>28</del>:<del>35</del>.000000<span class="dp">·</span>gradient-accumulator-0.3.<del>1</del>/setup.py</td><td class="diffline">16 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1<ins>22</ins>)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>1<ins>255</ins><span class="dp">·</span>2023-0<ins>4</ins>-<ins>06</ins><span class="dp">·</span>2<ins>1</ins>:<ins>49</ins>:<ins>17</ins>.000000<span class="dp">·</span>gradient-accumulator-0.3.<ins>2</ins>/setup.py</td></tr>
<tr class="diffdeleted"><td class="diffline">18 </td><td class="diffpresent">drwxr-xr-x<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(116)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>2023-01-29<span class="dp">·</span>22:29:18.000000<span class="dp">·</span>gradient-accumulator-0.3.1/tests/</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">19 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(116)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>2023-01-29<span class="dp">·</span>22:28:35.000000<span class="dp">·</span>gradient-accumulator-0.3.1/tests/__init__.py</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">20 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(116)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>2713<span class="dp">·</span>2023-01-29<span class="dp">·</span>22:28:35.000000<span class="dp">·</span>gradient-accumulator-0.3.1/tests/test_adaptive_gradient_clipping.py</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">21 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(116)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>3323<span class="dp">·</span>2023-01-29<span class="dp">·</span>22:28:35.000000<span class="dp">·</span>gradient-accumulator-0.3.1/tests/test_expected_result.py</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">22 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(116)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>2699<span class="dp">·</span>2023-01-29<span class="dp">·</span>22:28:35.000000<span class="dp">·</span>gradient-accumulator-0.3.1/tests/test_mixed_precision.py</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">23 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(116)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>3041<span class="dp">·</span>2023-01-29<span class="dp">·</span>22:28:35.000000<span class="dp">·</span>gradient-accumulator-0.3.1/tests/test_multi_gpu.py</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">24 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(116)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>4493<span class="dp">·</span>2023-01-29<span class="dp">·</span>22:28:35.000000<span class="dp">·</span>gradient-accumulator-0.3.1/tests/test_multi_gpu_benchmark.py</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">25 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(116)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>4332<span class="dp">·</span>2023-01-29<span class="dp">·</span>22:28:35.000000<span class="dp">·</span>gradient-accumulator-0.3.1/tests/test_multitask.py</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">26 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(116)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>2536<span class="dp">·</span>2023-01-29<span class="dp">·</span>22:28:35.000000<span class="dp">·</span>gradient-accumulator-0.3.1/tests/test_optimizer_distribute.py</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">27 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(116)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>3959<span class="dp">·</span>2023-01-29<span class="dp">·</span>22:28:35.000000<span class="dp">·</span>gradient-accumulator-0.3.1/tests/test_optimizer_invariance.py</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">28 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(116)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>4021<span class="dp">·</span>2023-01-29<span class="dp">·</span>22:28:35.000000<span class="dp">·</span>gradient-accumulator-0.3.1/tests/test_optimizer_wrapper.py</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">29 </td><td class="diffpresent">-rw-r--r--<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>0<span class="dp">·</span>runner<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(1001)<span class="dp">·</span>docker<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(116)<span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>1911<span class="dp">·</span>2023-01-29<span class="dp">·</span>22:28:35.000000<span class="dp">·</span>gradient-accumulator-0.3.1/tests/test_train_mnist.py</td><td colspan="2"> </td></tr>
</table>    </div>
    <div class="difference">
      <div class="diffheader">
      <div class="diffcontrol diffcontrol-double">⊟</div>
      <div><span class="diffsize">13.2 KB</span></div>
      <div><span class="source">gradient-accumulator-0.3.1/PKG-INFO</span> vs.</div>
      <div id="gradient-accumulator--.-.-.tar---gradient-accumulator--.-.--PKG-INFO"><span class="source">gradient-accumulator-0.3.2/PKG-INFO</span>
        <a class="anchor" href="#gradient-accumulator--.-.-.tar---gradient-accumulator--.-.--PKG-INFO">¶</a>
      </div>
      </div>
      <div class="comment">Files 17% similar despite different names
      </div>
<table class="diff">
<colgroup><col class="colines"/><col class="coldiff"/>
<col class="colines"/><col class="coldiff"/></colgroup>
<tr style="display:none;"><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 1, 30 lines modified</td><td colspan="2">Offset 1, 32 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">1 </td><td class="diffpresent">Metadata-Version:<span class="dp">·</span>2.1</td><td class="diffline">1 </td><td class="diffpresent">Metadata-Version:<span class="dp">·</span>2.1</td></tr>
<tr class="diffunmodified"><td class="diffline">2 </td><td class="diffpresent">Name:<span class="dp">·</span>gradient-accumulator</td><td class="diffline">2 </td><td class="diffpresent">Name:<span class="dp">·</span>gradient-accumulator</td></tr>
<tr class="diffchanged"><td class="diffline">3 </td><td class="diffpresent">Version:<span class="dp">·</span>0.3.<del>1</del></td><td class="diffline">3 </td><td class="diffpresent">Version:<span class="dp">·</span>0.3.<ins>2</ins></td></tr>
<tr class="diffunmodified"><td class="diffline">4 </td><td class="diffpresent">Summary:<span class="dp">·</span>Package<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>in<span class="dp">·</span>TensorFlow</td><td class="diffline">4 </td><td class="diffpresent">Summary:<span class="dp">·</span>Package<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>in<span class="dp">·</span>TensorFlow</td></tr>
<tr class="diffunmodified"><td class="diffline">5 </td><td class="diffpresent">Home-page:<span class="dp">·</span>https://github.com/andreped/GradientAccumulator</td><td class="diffline">5 </td><td class="diffpresent">Home-page:<span class="dp">·</span>https://github.com/andreped/GradientAccumulator</td></tr>
<tr class="diffunmodified"><td class="diffline">6 </td><td class="diffpresent">Author:<span class="dp">·</span>André<span class="dp">·</span>Pedersen<span class="dp">·</span>and<span class="dp">·</span>David<span class="dp">·</span>Bouget</td><td class="diffline">6 </td><td class="diffpresent">Author:<span class="dp">·</span>André<span class="dp">·</span>Pedersen<span class="dp">·</span>and<span class="dp">·</span>David<span class="dp">·</span>Bouget</td></tr>
<tr class="diffunmodified"><td class="diffline">7 </td><td class="diffpresent">Author-email:<span class="dp">·</span>andrped94@gmail.com</td><td class="diffline">7 </td><td class="diffpresent">Author-email:<span class="dp">·</span>andrped94@gmail.com</td></tr>
<tr class="diffunmodified"><td class="diffline">8 </td><td class="diffpresent">License:<span class="dp">·</span>UNKNOWN</td><td class="diffline">8 </td><td class="diffpresent">License:<span class="dp">·</span>UNKNOWN</td></tr>
<tr class="diffunmodified"><td class="diffline">9 </td><td class="diffpresent">Description:<span class="dp">·</span>&lt;div<span class="dp">·</span>align=&quot;center&quot;&gt;</td><td class="diffline">9 </td><td class="diffpresent">Description:<span class="dp">·</span>&lt;div<span class="dp">·</span>align=&quot;center&quot;&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">10 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;h1<span class="dp">·</span>align=&quot;center&quot;&gt;GradientAccumulator&lt;/h1&gt;</td><td class="diffline">10 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;h1<span class="dp">·</span>align=&quot;center&quot;&gt;GradientAccumulator&lt;/h1&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">11 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;h3<span class="dp">·</span>align=&quot;center&quot;&gt;Seemless<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>for<span class="dp">·</span>TensorFlow<span class="dp">·</span>2&lt;/h3&gt;</td><td class="diffline">11 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;h3<span class="dp">·</span>align=&quot;center&quot;&gt;Seemless<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>for<span class="dp">·</span>TensorFlow<span class="dp">·</span>2&lt;/h3&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">12 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">12 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">13 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![Pip<span class="dp">·</span>Downloads](https://img.shields.io/pypi/dm/gradient-accumulator?label=pip%20downloads&amp;logo=python)](https://pypi.org/project/gradient-accumulator/)</td><td class="diffline">13 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![Pip<span class="dp">·</span>Downloads](https://img.shields.io/pypi/dm/gradient-accumulator?label=pip%20downloads&amp;logo=python)](https://pypi.org/project/gradient-accumulator/)</td></tr>
<tr class="diffunmodified"><td class="diffline">14 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![PyPI<span class="dp">·</span>version](https://badge.fury.io/py/gradient-accumulator.svg)](https://badge.fury.io/py/gradient-accumulator)</td><td class="diffline">14 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![PyPI<span class="dp">·</span>version](https://badge.fury.io/py/gradient-accumulator.svg)](https://badge.fury.io/py/gradient-accumulator)</td></tr>
<tr class="diffunmodified"><td class="diffline">15 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)</td><td class="diffline">15 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)</td></tr>
<tr class="diffchanged"><td class="diffline">16 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.758<del>1815</del>.svg)](https://doi.org/10.5281/zenodo.758<del>1815</del>)</td><td class="diffline">16 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.758<ins>2309</ins>.svg)](https://doi.org/10.5281/zenodo.758<ins>2309</ins>)</td></tr>
<tr class="diffunmodified"><td class="diffline">17 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![CI](https://github.com/andreped/GradientAccumulator/workflows/CI/badge.svg)](https://github.com/andreped/GradientAccumulator/actions)</td><td class="diffline">17 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![CI](https://github.com/andreped/GradientAccumulator/workflows/CI/badge.svg)](https://github.com/andreped/GradientAccumulator/actions)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">18 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![codecov](https://codecov.io/gh/andreped/GradientAccumulator/branch/main/graph/badge.svg?token=MWLK71V750)](https://codecov.io/gh/andreped/GradientAccumulator)</td></tr>
<tr class="diffunmodified"><td class="diffline">18 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">19 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">19 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>**GradientAccumulator**<span class="dp">·</span>was<span class="dp">·</span>developed<span class="dp">·</span>by<span class="dp">·</span>SINTEF<span class="dp">·</span>Health<span class="dp">·</span>due<span class="dp">·</span>to<span class="dp">·</span>the<span class="dp">·</span>lack<span class="dp">·</span>of<span class="dp">·</span>an<span class="dp">·</span>easy-to-use<span class="dp">·</span>method<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>in<span class="dp">·</span>TensorFlow<span class="dp">·</span>2.</td><td class="diffline">20 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>**GradientAccumulator**<span class="dp">·</span>was<span class="dp">·</span>developed<span class="dp">·</span>by<span class="dp">·</span>SINTEF<span class="dp">·</span>Health<span class="dp">·</span>due<span class="dp">·</span>to<span class="dp">·</span>the<span class="dp">·</span>lack<span class="dp">·</span>of<span class="dp">·</span>an<span class="dp">·</span>easy-to-use<span class="dp">·</span>method<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>in<span class="dp">·</span>TensorFlow<span class="dp">·</span>2.</td></tr>
<tr class="diffunmodified"><td class="diffline">20 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">21 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffchanged"><td class="diffline">21 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>The<span class="dp">·</span>package<span class="dp">·</span>is<span class="dp">·</span>available<span class="dp">·</span>on<span class="dp">·</span>PyPI<span class="dp">·</span>and<span class="dp">·</span>is<span class="dp">·</span>compatible<span class="dp">·</span>with<span class="dp">·</span>and<span class="dp">·</span>have<span class="dp">·</span>been<span class="dp">·</span>tested<span class="dp">·</span>against<span class="dp">·</span>TF<span class="dp">·</span><del>&gt;=<span class="dp">·</span></del>2.<del>3</del><span class="dp">·</span>and<span class="dp">·</span>Python<del><span class="dp">·</span>&gt;=<span class="dp">·</span>3.6<span class="dp">·</span>(tested<span class="dp">·</span>with</del><span class="dp">·</span>3.6-3.1<del>0)</del>,<span class="dp">·</span>and<span class="dp">·</span>works<span class="dp">·</span>cross-platform<span class="dp">·</span>(Ubuntu,<span class="dp">·</span>Windows,<span class="dp">·</span>macOS).</td><td class="diffline">22 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>The<span class="dp">·</span>package<span class="dp">·</span>is<span class="dp">·</span>available<span class="dp">·</span>on<span class="dp">·</span>PyPI<span class="dp">·</span>and<span class="dp">·</span>is<span class="dp">·</span>compatible<span class="dp">·</span>with<span class="dp">·</span>and<span class="dp">·</span>have<span class="dp">·</span>been<span class="dp">·</span>tested<span class="dp">·</span>against<span class="dp">·</span><ins>`</ins>TF<span class="dp">·</span><ins>2</ins><ins>.2-</ins>2.<ins>12</ins><ins>`</ins><span class="dp">·</span>and<span class="dp">·</span><ins>`</ins>Python<span class="dp">·</span>3.6-3.1<ins>2`</ins>,<span class="dp">·</span>and<span class="dp">·</span>works<span class="dp">·</span>cross-platform<span class="dp">·</span>(Ubuntu,<span class="dp">·</span>Windows,<span class="dp">·</span>macOS).</td></tr>
<tr class="diffunmodified"><td class="diffline">22 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/div&gt;</td><td class="diffline">23 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/div&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">23 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">24 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">25 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">24 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>##<span class="dp">·</span>What?</td><td class="diffline">26 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>##<span class="dp">·</span>What?</td></tr>
<tr class="diffunmodified"><td class="diffline">25 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Gradient<span class="dp">·</span>accumulation<span class="dp">·</span>(GA)<span class="dp">·</span>enables<span class="dp">·</span>reduced<span class="dp">·</span>GPU<span class="dp">·</span>memory<span class="dp">·</span>consumption<span class="dp">·</span>through<span class="dp">·</span>dividing<span class="dp">·</span>a<span class="dp">·</span>batch<span class="dp">·</span>into<span class="dp">·</span>smaller<span class="dp">·</span>reduced<span class="dp">·</span>batches,<span class="dp">·</span>and<span class="dp">·</span>performing<span class="dp">·</span>gradient<span class="dp">·</span>computation<span class="dp">·</span>either<span class="dp">·</span>in<span class="dp">·</span>a<span class="dp">·</span>distributing<span class="dp">·</span>setting<span class="dp">·</span>across<span class="dp">·</span>multiple<span class="dp">·</span>GPUs<span class="dp">·</span>or<span class="dp">·</span>sequentially<span class="dp">·</span>on<span class="dp">·</span>the<span class="dp">·</span>same<span class="dp">·</span>GPU.<span class="dp">·</span>When<span class="dp">·</span>the<span class="dp">·</span>full<span class="dp">·</span>batch<span class="dp">·</span>is<span class="dp">·</span>processed,<span class="dp">·</span>the<span class="dp">·</span>gradients<span class="dp">·</span>are<span class="dp">·</span>the<span class="dp">·</span>_accumulated_<span class="dp">·</span>to<span class="dp">·</span>produce<span class="dp">·</span>the<span class="dp">·</span>full<span class="dp">·</span>batch<span class="dp">·</span>gradient.</td><td class="diffline">27 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Gradient<span class="dp">·</span>accumulation<span class="dp">·</span>(GA)<span class="dp">·</span>enables<span class="dp">·</span>reduced<span class="dp">·</span>GPU<span class="dp">·</span>memory<span class="dp">·</span>consumption<span class="dp">·</span>through<span class="dp">·</span>dividing<span class="dp">·</span>a<span class="dp">·</span>batch<span class="dp">·</span>into<span class="dp">·</span>smaller<span class="dp">·</span>reduced<span class="dp">·</span>batches,<span class="dp">·</span>and<span class="dp">·</span>performing<span class="dp">·</span>gradient<span class="dp">·</span>computation<span class="dp">·</span>either<span class="dp">·</span>in<span class="dp">·</span>a<span class="dp">·</span>distributing<span class="dp">·</span>setting<span class="dp">·</span>across<span class="dp">·</span>multiple<span class="dp">·</span>GPUs<span class="dp">·</span>or<span class="dp">·</span>sequentially<span class="dp">·</span>on<span class="dp">·</span>the<span class="dp">·</span>same<span class="dp">·</span>GPU.<span class="dp">·</span>When<span class="dp">·</span>the<span class="dp">·</span>full<span class="dp">·</span>batch<span class="dp">·</span>is<span class="dp">·</span>processed,<span class="dp">·</span>the<span class="dp">·</span>gradients<span class="dp">·</span>are<span class="dp">·</span>the<span class="dp">·</span>_accumulated_<span class="dp">·</span>to<span class="dp">·</span>produce<span class="dp">·</span>the<span class="dp">·</span>full<span class="dp">·</span>batch<span class="dp">·</span>gradient.</td></tr>
<tr class="diffunmodified"><td class="diffline">26 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">28 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">27 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;p<span class="dp">·</span>align=&quot;center&quot;&gt;</td><td class="diffline">29 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;p<span class="dp">·</span>align=&quot;center&quot;&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">28 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;img<span class="dp">·</span>src=&quot;assets/grad_accum.png&quot;<span class="dp">·</span>width=&quot;50%&quot;&gt;</td><td class="diffline">30 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;img<span class="dp">·</span>src=&quot;assets/grad_accum.png&quot;<span class="dp">·</span>width=&quot;50%&quot;&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">29 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/p&gt;</td><td class="diffline">31 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/p&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">30 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">32 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffhunk"><td colspan="2">Offset 33, 15 lines modified</td><td colspan="2">Offset 35, 15 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">33 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>In<span class="dp">·</span>TensorFlow<span class="dp">·</span>2,<span class="dp">·</span>there<span class="dp">·</span>did<span class="dp">·</span>not<span class="dp">·</span>exist<span class="dp">·</span>a<span class="dp">·</span>plug-and-play<span class="dp">·</span>method<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>with<span class="dp">·</span>any<span class="dp">·</span>custom<span class="dp">·</span>pipeline.<span class="dp">·</span>Hence,<span class="dp">·</span>we<span class="dp">·</span>have<span class="dp">·</span>implemented<span class="dp">·</span>two<span class="dp">·</span>generic<span class="dp">·</span>TF2-compatible<span class="dp">·</span>approaches:</td><td class="diffline">35 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>In<span class="dp">·</span>TensorFlow<span class="dp">·</span>2,<span class="dp">·</span>there<span class="dp">·</span>did<span class="dp">·</span>not<span class="dp">·</span>exist<span class="dp">·</span>a<span class="dp">·</span>plug-and-play<span class="dp">·</span>method<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>with<span class="dp">·</span>any<span class="dp">·</span>custom<span class="dp">·</span>pipeline.<span class="dp">·</span>Hence,<span class="dp">·</span>we<span class="dp">·</span>have<span class="dp">·</span>implemented<span class="dp">·</span>two<span class="dp">·</span>generic<span class="dp">·</span>TF2-compatible<span class="dp">·</span>approaches:</td></tr>
<tr class="diffunmodified"><td class="diffline">34 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">36 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">35 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>Method<span class="dp">·</span>|<span class="dp">·</span>Usage<span class="dp">·</span>|</td><td class="diffline">37 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>Method<span class="dp">·</span>|<span class="dp">·</span>Usage<span class="dp">·</span>|</td></tr>
<tr class="diffunmodified"><td class="diffline">36 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>-<span class="dp">·</span>|<span class="dp">·</span>-<span class="dp">·</span>|</td><td class="diffline">38 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>-<span class="dp">·</span>|<span class="dp">·</span>-<span class="dp">·</span>|</td></tr>
<tr class="diffunmodified"><td class="diffline">37 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>`GradientAccumulateModel`<span class="dp">·</span>|<span class="dp">·</span>`model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=model.input,<span class="dp">·</span>outputs=model.output)`<span class="dp">·</span>|</td><td class="diffline">39 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>`GradientAccumulateModel`<span class="dp">·</span>|<span class="dp">·</span>`model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=model.input,<span class="dp">·</span>outputs=model.output)`<span class="dp">·</span>|</td></tr>
<tr class="diffunmodified"><td class="diffline">38 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>`GradientAccumulateOptimizer`<span class="dp">·</span>|<span class="dp">·</span>`opt<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateOptimizer(accum_steps=4,<span class="dp">·</span>optimizer=tf.keras.optimizers.SGD(1e-2))`<span class="dp">·</span>|</td><td class="diffline">40 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>`GradientAccumulateOptimizer`<span class="dp">·</span>|<span class="dp">·</span>`opt<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateOptimizer(accum_steps=4,<span class="dp">·</span>optimizer=tf.keras.optimizers.SGD(1e-2))`<span class="dp">·</span>|</td></tr>
<tr class="diffunmodified"><td class="diffline">39 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">41 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffchanged"><td class="diffline">40 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Both<span class="dp">·</span>approaches<span class="dp">·</span>control<span class="dp">·</span>how<span class="dp">·</span>frequently<span class="dp">·</span>the<span class="dp">·</span>weigths<span class="dp">·</span>are<span class="dp">·</span>updated,<span class="dp">·</span>but<span class="dp">·</span>in<span class="dp">·</span>their<span class="dp">·</span>own<span class="dp">·</span>way.<span class="dp">·</span>Approach<span class="dp">·</span>(1)<span class="dp">·</span>is<span class="dp">·</span>for<span class="dp">·</span>single-GPU<span class="dp">·</span>only,<span class="dp">·</span>whereas<span class="dp">·</span>(2)<span class="dp">·</span>supports<span class="dp">·</span>both<span class="dp">·</span>single-GPU<span class="dp">·</span>and<span class="dp">·</span>distributed<span class="dp">·</span>training<span class="dp">·</span>(multi-GPU).</td><td class="diffline">42 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Both<span class="dp">·</span>approaches<span class="dp">·</span>control<span class="dp">·</span>how<span class="dp">·</span>frequently<span class="dp">·</span>the<span class="dp">·</span>weigths<span class="dp">·</span>are<span class="dp">·</span>updated,<span class="dp">·</span>but<span class="dp">·</span>in<span class="dp">·</span>their<span class="dp">·</span>own<span class="dp">·</span>way.<span class="dp">·</span>Approach<span class="dp">·</span>(1)<span class="dp">·</span>is<span class="dp">·</span>for<span class="dp">·</span>single-GPU<span class="dp">·</span>only,<span class="dp">·</span>whereas<span class="dp">·</span>(2)<span class="dp">·</span>supports<span class="dp">·</span>both<span class="dp">·</span>single-GPU<span class="dp">·</span>and<span class="dp">·</span>distributed<span class="dp">·</span>training<span class="dp">·</span>(multi-GPU).<ins><span class="dp">·</span>However,<span class="dp">·</span>note<span class="dp">·</span>that<span class="dp">·</span>(2)<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>yet<span class="dp">·</span>working<span class="dp">·</span>as<span class="dp">·</span>intended.<span class="dp">·</span>Hence,<span class="dp">·</span>use<span class="dp">·</span>(1)<span class="dp">·</span>for<span class="dp">·</span>most<span class="dp">·</span>applications.</ins></td></tr>
<tr class="diffunmodified"><td class="diffline">41 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">43 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">42 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Our<span class="dp">·</span>implementations<span class="dp">·</span>enable<span class="dp">·</span>theoretically<span class="dp">·</span>**infinitely<span class="dp">·</span>large<span class="dp">·</span>batch<span class="dp">·</span>size**,<span class="dp">·</span>with<span class="dp">·</span>**identical<span class="dp">·</span>memory<span class="dp">·</span>consumption**<span class="dp">·</span>as<span class="dp">·</span>for<span class="dp">·</span>a<span class="dp">·</span>regular<span class="dp">·</span>mini<span class="dp">·</span>batch.<span class="dp">·</span>If<span class="dp">·</span>a<span class="dp">·</span>single<span class="dp">·</span>GPU<span class="dp">·</span>is<span class="dp">·</span>used,<span class="dp">·</span>this<span class="dp">·</span>comes<span class="dp">·</span>at<span class="dp">·</span>the<span class="dp">·</span>cost<span class="dp">·</span>of<span class="dp">·</span>increased<span class="dp">·</span>training<span class="dp">·</span>runtime.<span class="dp">·</span>Multiple<span class="dp">·</span>GPUs<span class="dp">·</span>could<span class="dp">·</span>be<span class="dp">·</span>used<span class="dp">·</span>to<span class="dp">·</span>increase<span class="dp">·</span>runtime<span class="dp">·</span>performance.</td><td class="diffline">44 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Our<span class="dp">·</span>implementations<span class="dp">·</span>enable<span class="dp">·</span>theoretically<span class="dp">·</span>**infinitely<span class="dp">·</span>large<span class="dp">·</span>batch<span class="dp">·</span>size**,<span class="dp">·</span>with<span class="dp">·</span>**identical<span class="dp">·</span>memory<span class="dp">·</span>consumption**<span class="dp">·</span>as<span class="dp">·</span>for<span class="dp">·</span>a<span class="dp">·</span>regular<span class="dp">·</span>mini<span class="dp">·</span>batch.<span class="dp">·</span>If<span class="dp">·</span>a<span class="dp">·</span>single<span class="dp">·</span>GPU<span class="dp">·</span>is<span class="dp">·</span>used,<span class="dp">·</span>this<span class="dp">·</span>comes<span class="dp">·</span>at<span class="dp">·</span>the<span class="dp">·</span>cost<span class="dp">·</span>of<span class="dp">·</span>increased<span class="dp">·</span>training<span class="dp">·</span>runtime.<span class="dp">·</span>Multiple<span class="dp">·</span>GPUs<span class="dp">·</span>could<span class="dp">·</span>be<span class="dp">·</span>used<span class="dp">·</span>to<span class="dp">·</span>increase<span class="dp">·</span>runtime<span class="dp">·</span>performance.</td></tr>
<tr class="diffunmodified"><td class="diffline">43 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">45 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">44 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>As<span class="dp">·</span>batch<span class="dp">·</span>normalization<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>natively<span class="dp">·</span>compatible<span class="dp">·</span>with<span class="dp">·</span>GA,<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping<span class="dp">·</span>has<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>as<span class="dp">·</span>an<span class="dp">·</span>alternative.<span class="dp">·</span>We<span class="dp">·</span>have<span class="dp">·</span>also<span class="dp">·</span>added<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>mixed<span class="dp">·</span>precision<span class="dp">·</span>and<span class="dp">·</span>both<span class="dp">·</span>GPU<span class="dp">·</span>and<span class="dp">·</span>TPU<span class="dp">·</span>support.</td><td class="diffline">46 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>As<span class="dp">·</span>batch<span class="dp">·</span>normalization<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>natively<span class="dp">·</span>compatible<span class="dp">·</span>with<span class="dp">·</span>GA,<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping<span class="dp">·</span>has<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>as<span class="dp">·</span>an<span class="dp">·</span>alternative.<span class="dp">·</span>We<span class="dp">·</span>have<span class="dp">·</span>also<span class="dp">·</span>added<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>mixed<span class="dp">·</span>precision<span class="dp">·</span>and<span class="dp">·</span>both<span class="dp">·</span>GPU<span class="dp">·</span>and<span class="dp">·</span>TPU<span class="dp">·</span>support.</td></tr>
<tr class="diffunmodified"><td class="diffline">45 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">47 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">46 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">48 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">47 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>##<span class="dp">·</span>Install</td><td class="diffline">49 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>##<span class="dp">·</span>Install</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 63, 15 lines modified</td><td colspan="2">Offset 65, 15 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">63 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">65 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">64 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>model<span class="dp">·</span>=<span class="dp">·</span>Model(...)</td><td class="diffline">66 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>model<span class="dp">·</span>=<span class="dp">·</span>Model(...)</td></tr>
<tr class="diffunmodified"><td class="diffline">65 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=model.input,<span class="dp">·</span>outputs=model.output)</td><td class="diffline">67 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=model.input,<span class="dp">·</span>outputs=model.output)</td></tr>
<tr class="diffunmodified"><td class="diffline">66 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td><td class="diffline">68 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffunmodified"><td class="diffline">67 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">69 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">68 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Then<span class="dp">·</span>simply<span class="dp">·</span>use<span class="dp">·</span>the<span class="dp">·</span>`model`<span class="dp">·</span>as<span class="dp">·</span>you<span class="dp">·</span>normally<span class="dp">·</span>would!</td><td class="diffline">70 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Then<span class="dp">·</span>simply<span class="dp">·</span>use<span class="dp">·</span>the<span class="dp">·</span>`model`<span class="dp">·</span>as<span class="dp">·</span>you<span class="dp">·</span>normally<span class="dp">·</span>would!</td></tr>
<tr class="diffunmodified"><td class="diffline">69 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">71 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffchanged"><td class="diffline">70 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details<del><span class="dp">·</span>open</del>&gt;</td><td class="diffline">72 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">71 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td><td class="diffline">73 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">72 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">74 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">73 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>Mixed<span class="dp">·</span>precision&lt;/summary&gt;</td><td class="diffline">75 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>Mixed<span class="dp">·</span>precision&lt;/summary&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">74 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">76 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">75 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>There<span class="dp">·</span>has<span class="dp">·</span>also<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>experimental<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>mixed<span class="dp">·</span>precision:</td><td class="diffline">77 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>There<span class="dp">·</span>has<span class="dp">·</span>also<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>experimental<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>mixed<span class="dp">·</span>precision:</td></tr>
<tr class="diffunmodified"><td class="diffline">76 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td><td class="diffline">78 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffunmodified"><td class="diffline">77 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>from<span class="dp">·</span>tensorflow.keras<span class="dp">·</span>import<span class="dp">·</span>mixed_precision</td><td class="diffline">79 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>from<span class="dp">·</span>tensorflow.keras<span class="dp">·</span>import<span class="dp">·</span>mixed_precision</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 89, 27 lines modified</td><td colspan="2">Offset 91, 64 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">89 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>mixed_precision.set_global_policy(&#x27;mixed_bfloat16&#x27;)</td><td class="diffline">91 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>mixed_precision.set_global_policy(&#x27;mixed_bfloat16&#x27;)</td></tr>
<tr class="diffunmodified"><td class="diffline">90 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td><td class="diffline">92 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffunmodified"><td class="diffline">91 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">93 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">92 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>There<span class="dp">·</span>is<span class="dp">·</span>also<span class="dp">·</span>an<span class="dp">·</span>example<span class="dp">·</span>of<span class="dp">·</span>how<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>with<span class="dp">·</span>mixed<span class="dp">·</span>precision<span class="dp">·</span>[here](https://github.com/andreped/GradientAccumulator/blob/main/tests/test_mixed_precision.py#L58).</td><td class="diffline">94 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>There<span class="dp">·</span>is<span class="dp">·</span>also<span class="dp">·</span>an<span class="dp">·</span>example<span class="dp">·</span>of<span class="dp">·</span>how<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>with<span class="dp">·</span>mixed<span class="dp">·</span>precision<span class="dp">·</span>[here](https://github.com/andreped/GradientAccumulator/blob/main/tests/test_mixed_precision.py#L58).</td></tr>
<tr class="diffunmodified"><td class="diffline">93 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/details&gt;</td><td class="diffline">95 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">94 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">96 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">95 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">97 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffchanged"><td class="diffline">96 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details<del><span class="dp">·</span>open</del>&gt;</td><td class="diffline">98 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">97 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td><td class="diffline">99 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">98 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">100 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">99 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>Distributed<span class="dp">·</span>training<span class="dp">·</span>with<span class="dp">·</span>multiple<span class="dp">·</span>GPUs&lt;/summary&gt;</td><td class="diffline">101 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>Distributed<span class="dp">·</span>training<span class="dp">·</span>with<span class="dp">·</span>multiple<span class="dp">·</span>GPUs&lt;/summary&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">100 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>In<span class="dp">·</span>order<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>multiple<span class="dp">·</span>GPUs,<span class="dp">·</span>you<span class="dp">·</span>will<span class="dp">·</span>have<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>the<span class="dp">·</span>Optimizer<span class="dp">·</span>wrapper:</td><td class="diffline">102 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>In<span class="dp">·</span>order<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>multiple<span class="dp">·</span>GPUs,<span class="dp">·</span>you<span class="dp">·</span>will<span class="dp">·</span>have<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>the<span class="dp">·</span>Optimizer<span class="dp">·</span>wrapper:</td></tr>
<tr class="diffunmodified"><td class="diffline">101 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td><td class="diffline">103 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffunmodified"><td class="diffline">102 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>opt<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateOptimizer(accum_steps=4,<span class="dp">·</span>optimizer=tf.keras.optimizers.SGD(1e-2))</td><td class="diffline">104 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>opt<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateOptimizer(accum_steps=4,<span class="dp">·</span>optimizer=tf.keras.optimizers.SGD(1e-2))</td></tr>
<tr class="diffunmodified"><td class="diffline">103 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td><td class="diffline">105 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffunmodified"><td class="diffline">104 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">106 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">105 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Just<span class="dp">·</span>remember<span class="dp">·</span>to<span class="dp">·</span>wrap<span class="dp">·</span>the<span class="dp">·</span>optimizer<span class="dp">·</span>within<span class="dp">·</span>the<span class="dp">·</span>`tf.distribute.MirroredStrategy`.<span class="dp">·</span>For<span class="dp">·</span>an<span class="dp">·</span>example,<span class="dp">·</span>see<span class="dp">·</span>[here](https://github.com/andreped/GradientAccumulator/blob/main/tests/test_optimizer_distribute.py).</td><td class="diffline">107 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Just<span class="dp">·</span>remember<span class="dp">·</span>to<span class="dp">·</span>wrap<span class="dp">·</span>the<span class="dp">·</span>optimizer<span class="dp">·</span>within<span class="dp">·</span>the<span class="dp">·</span>`tf.distribute.MirroredStrategy`.<span class="dp">·</span>For<span class="dp">·</span>an<span class="dp">·</span>example,<span class="dp">·</span>see<span class="dp">·</span>[here](https://github.com/andreped/GradientAccumulator/blob/main/tests/test_optimizer_distribute.py).</td></tr>
<tr class="diffunmodified"><td class="diffline">106 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">108 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">109 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>**DISCLAIMER:<span class="dp">·</span>The<span class="dp">·</span>GradientAccumulateOptimizer<span class="dp">·</span>is<span class="dp">·</span>a<span class="dp">·</span>VERY<span class="dp">·</span>experimental<span class="dp">·</span>feature.<span class="dp">·</span>It<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>reaching<span class="dp">·</span>the<span class="dp">·</span>same<span class="dp">·</span>results<span class="dp">·</span>as<span class="dp">·</span>GradientAccumulateModel<span class="dp">·</span>with<span class="dp">·</span>a<span class="dp">·</span>single<span class="dp">·</span>GPU,<span class="dp">·</span>and<span class="dp">·</span>does<span class="dp">·</span>not<span class="dp">·</span>work<span class="dp">·</span>(yet)<span class="dp">·</span>with<span class="dp">·</span>multiple<span class="dp">·</span>GPUs.<span class="dp">·</span>Hence,<span class="dp">·</span>I<span class="dp">·</span>would<span class="dp">·</span>recommend<span class="dp">·</span>using<span class="dp">·</span>GradientAccumulateModel<span class="dp">·</span>with<span class="dp">·</span>a<span class="dp">·</span>single<span class="dp">·</span>GPU<span class="dp">·</span>in<span class="dp">·</span>its<span class="dp">·</span>current<span class="dp">·</span>state.**</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">110 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">111 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/details&gt;</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">112 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">113 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">114 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details&gt;</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">115 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">116 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">117 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>HuggingFace<span class="dp">·</span>:hugs:&lt;/summary&gt;</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">118 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Note<span class="dp">·</span>that<span class="dp">·</span>HuggingFace<span class="dp">·</span>provides<span class="dp">·</span>a<span class="dp">·</span>variety<span class="dp">·</span>of<span class="dp">·</span>different<span class="dp">·</span>pretrained<span class="dp">·</span>models.<span class="dp">·</span>However,<span class="dp">·</span>it<span class="dp">·</span>was<span class="dp">·</span>observed<span class="dp">·</span>that<span class="dp">·</span>when<span class="dp">·</span>loading<span class="dp">·</span>these<span class="dp">·</span>models<span class="dp">·</span>into<span class="dp">·</span>TensorFlow,<span class="dp">·</span>the<span class="dp">·</span>computational<span class="dp">·</span>graph<span class="dp">·</span>may<span class="dp">·</span>not<span class="dp">·</span>be<span class="dp">·</span>set<span class="dp">·</span>up<span class="dp">·</span>correctly,<span class="dp">·</span>such<span class="dp">·</span>that<span class="dp">·</span>the<span class="dp">·</span>`model.input`<span class="dp">·</span>and<span class="dp">·</span>`model.output`<span class="dp">·</span>exist.</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">119 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">120 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>To<span class="dp">·</span>fix<span class="dp">·</span>this,<span class="dp">·</span>we<span class="dp">·</span>basically<span class="dp">·</span>wrap<span class="dp">·</span>the<span class="dp">·</span>model<span class="dp">·</span>into<span class="dp">·</span>a<span class="dp">·</span>new<span class="dp">·</span>`tf.keras.Model`,<span class="dp">·</span>but<span class="dp">·</span>define<span class="dp">·</span>the<span class="dp">·</span>inputs<span class="dp">·</span>and<span class="dp">·</span>outputs<span class="dp">·</span>ourselves:</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">121 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">122 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>from<span class="dp">·</span>gradient_accumulator<span class="dp">·</span>import<span class="dp">·</span>GradientAccumulateModel</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">123 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>from<span class="dp">·</span>tensorflow.keras.layers<span class="dp">·</span>import<span class="dp">·</span>Input</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">124 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>from<span class="dp">·</span>tensorflow.keras.models<span class="dp">·</span>import<span class="dp">·</span>Model</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">125 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>from<span class="dp">·</span>transformers<span class="dp">·</span>import<span class="dp">·</span>TFx</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">126 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">127 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>#load<span class="dp">·</span>your<span class="dp">·</span>model<span class="dp">·</span>checkpoint</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">128 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>HF_model<span class="dp">·</span>=<span class="dp">·</span>TFx.from_pretrained(checkpoint)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">129 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">130 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>#<span class="dp">·</span>define<span class="dp">·</span>model<span class="dp">·</span>inputs<span class="dp">·</span>and<span class="dp">·</span>outputs<span class="dp">·</span>-&gt;<span class="dp">·</span>for<span class="dp">·</span>different<span class="dp">·</span>models,<span class="dp">·</span>different<span class="dp">·</span>inputs/outputs<span class="dp">·</span>need<span class="dp">·</span>to<span class="dp">·</span>be<span class="dp">·</span>defined</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">131 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>input_ids<span class="dp">·</span>=<span class="dp">·</span>tf.keras.Input(shape=(None,),<span class="dp">·</span>dtype=&#x27;int32&#x27;,<span class="dp">·</span>name=&quot;input_ids&quot;)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">132 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>attention_mask<span class="dp">·</span>=<span class="dp">·</span>tf.keras.Input(shape=(None,),<span class="dp">·</span>dtype=&#x27;int32&#x27;,<span class="dp">·</span>name=&quot;attention_mask&quot;)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">133 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>model_input={&#x27;input_ids&#x27;:<span class="dp">·</span>input_ids,<span class="dp">·</span>&#x27;attention_mask&#x27;:<span class="dp">·</span>attention_mask}</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">134 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">135 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>#create<span class="dp">·</span>a<span class="dp">·</span>new<span class="dp">·</span>Model<span class="dp">·</span>which<span class="dp">·</span>has<span class="dp">·</span>model.input<span class="dp">·</span>and<span class="dp">·</span>model.output<span class="dp">·</span>properties</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">136 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>new_model<span class="dp">·</span>=<span class="dp">·</span>Model(inputs=model_input,<span class="dp">·</span>outputs=HF_model(model_input))</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">137 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">138 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>#create<span class="dp">·</span>the<span class="dp">·</span>GA<span class="dp">·</span>model</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">139 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=new_model.input,<span class="dp">·</span>outputs=new_model.output)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">140 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">141 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">142 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>For<span class="dp">·</span>more<span class="dp">·</span>details,<span class="dp">·</span>see<span class="dp">·</span>[this](https://github.com/andreped/GradientAccumulator/blob/main/notebooks/GA_for_HuggingFace_TF_models.ipynb)<span class="dp">·</span>jupyter<span class="dp">·</span>notebook.</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">143 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">107 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/details&gt;</td><td class="diffline">144 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">108 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">145 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">146 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">147 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">109 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details&gt;</td><td class="diffline">148 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">110 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td><td class="diffline">149 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">111 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">150 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">112 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>Adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping&lt;/summary&gt;</td><td class="diffline">151 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>Adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping&lt;/summary&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">113 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">152 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="error"><td colspan="4">
Max diff block lines reached; 5511/13451 bytes (40.97%) of diff not shown.
</td></tr></table>    </div>
    <div class="difference">
      <div class="diffheader">
      <div class="diffcontrol diffcontrol-double">⊟</div>
      <div><span class="diffsize">10.5 KB</span></div>
      <div><span class="source">gradient-accumulator-0.3.1/README.md</span> vs.</div>
      <div id="gradient-accumulator--.-.-.tar---gradient-accumulator--.-.--README.md"><span class="source">gradient-accumulator-0.3.2/README.md</span>
        <a class="anchor" href="#gradient-accumulator--.-.-.tar---gradient-accumulator--.-.--README.md">¶</a>
      </div>
      </div>
      <div class="comment">Files 24% similar despite different names
      </div>
<table class="diff">
<colgroup><col class="colines"/><col class="coldiff"/>
<col class="colines"/><col class="coldiff"/></colgroup>
<tr style="display:none;"><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 1, 22 lines modified</td><td colspan="2">Offset 1, 24 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">1 </td><td class="diffpresent">&lt;div<span class="dp">·</span>align=&quot;center&quot;&gt;</td><td class="diffline">1 </td><td class="diffpresent">&lt;div<span class="dp">·</span>align=&quot;center&quot;&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">2 </td><td class="diffpresent">&lt;h1<span class="dp">·</span>align=&quot;center&quot;&gt;GradientAccumulator&lt;/h1&gt;</td><td class="diffline">2 </td><td class="diffpresent">&lt;h1<span class="dp">·</span>align=&quot;center&quot;&gt;GradientAccumulator&lt;/h1&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">3 </td><td class="diffpresent">&lt;h3<span class="dp">·</span>align=&quot;center&quot;&gt;Seemless<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>for<span class="dp">·</span>TensorFlow<span class="dp">·</span>2&lt;/h3&gt;</td><td class="diffline">3 </td><td class="diffpresent">&lt;h3<span class="dp">·</span>align=&quot;center&quot;&gt;Seemless<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>for<span class="dp">·</span>TensorFlow<span class="dp">·</span>2&lt;/h3&gt;</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">4 </td><td class="diffpresent">[![Pip<span class="dp">·</span>Downloads](https://img.shields.io/pypi/dm/gradient-accumulator?label=pip%20downloads&amp;logo=python)](https://pypi.org/project/gradient-accumulator/)</td><td class="diffline">4 </td><td class="diffpresent">[![Pip<span class="dp">·</span>Downloads](https://img.shields.io/pypi/dm/gradient-accumulator?label=pip%20downloads&amp;logo=python)](https://pypi.org/project/gradient-accumulator/)</td></tr>
<tr class="diffunmodified"><td class="diffline">5 </td><td class="diffpresent">[![PyPI<span class="dp">·</span>version](https://badge.fury.io/py/gradient-accumulator.svg)](https://badge.fury.io/py/gradient-accumulator)</td><td class="diffline">5 </td><td class="diffpresent">[![PyPI<span class="dp">·</span>version](https://badge.fury.io/py/gradient-accumulator.svg)](https://badge.fury.io/py/gradient-accumulator)</td></tr>
<tr class="diffunmodified"><td class="diffline">6 </td><td class="diffpresent">[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)</td><td class="diffline">6 </td><td class="diffpresent">[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)</td></tr>
<tr class="diffchanged"><td class="diffline">7 </td><td class="diffpresent">[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.758<del>1815</del>.svg)](https://doi.org/10.5281/zenodo.758<del>1815</del>)</td><td class="diffline">7 </td><td class="diffpresent">[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.758<ins>2309</ins>.svg)](https://doi.org/10.5281/zenodo.758<ins>2309</ins>)</td></tr>
<tr class="diffunmodified"><td class="diffline">8 </td><td class="diffpresent">[![CI](https://github.com/andreped/GradientAccumulator/workflows/CI/badge.svg)](https://github.com/andreped/GradientAccumulator/actions)</td><td class="diffline">8 </td><td class="diffpresent">[![CI](https://github.com/andreped/GradientAccumulator/workflows/CI/badge.svg)](https://github.com/andreped/GradientAccumulator/actions)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">9 </td><td class="diffpresent">[![codecov](https://codecov.io/gh/andreped/GradientAccumulator/branch/main/graph/badge.svg?token=MWLK71V750)](https://codecov.io/gh/andreped/GradientAccumulator)</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">9 </td><td class="diffpresent">**GradientAccumulator**<span class="dp">·</span>was<span class="dp">·</span>developed<span class="dp">·</span>by<span class="dp">·</span>SINTEF<span class="dp">·</span>Health<span class="dp">·</span>due<span class="dp">·</span>to<span class="dp">·</span>the<span class="dp">·</span>lack<span class="dp">·</span>of<span class="dp">·</span>an<span class="dp">·</span>easy-to-use<span class="dp">·</span>method<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>in<span class="dp">·</span>TensorFlow<span class="dp">·</span>2.</td><td class="diffline">10 </td><td class="diffpresent">**GradientAccumulator**<span class="dp">·</span>was<span class="dp">·</span>developed<span class="dp">·</span>by<span class="dp">·</span>SINTEF<span class="dp">·</span>Health<span class="dp">·</span>due<span class="dp">·</span>to<span class="dp">·</span>the<span class="dp">·</span>lack<span class="dp">·</span>of<span class="dp">·</span>an<span class="dp">·</span>easy-to-use<span class="dp">·</span>method<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>in<span class="dp">·</span>TensorFlow<span class="dp">·</span>2.</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffchanged"><td class="diffline">10 </td><td class="diffpresent">The<span class="dp">·</span>package<span class="dp">·</span>is<span class="dp">·</span>available<span class="dp">·</span>on<span class="dp">·</span>PyPI<span class="dp">·</span>and<span class="dp">·</span>is<span class="dp">·</span>compatible<span class="dp">·</span>with<span class="dp">·</span>and<span class="dp">·</span>have<span class="dp">·</span>been<span class="dp">·</span>tested<span class="dp">·</span>against<span class="dp">·</span>TF<span class="dp">·</span><del>&gt;=<span class="dp">·</span></del>2.<del>3</del><span class="dp">·</span>and<span class="dp">·</span>Python<del><span class="dp">·</span>&gt;=<span class="dp">·</span>3.6<span class="dp">·</span>(tested<span class="dp">·</span>with</del><span class="dp">·</span>3.6-3.1<del>0)</del>,<span class="dp">·</span>and<span class="dp">·</span>works<span class="dp">·</span>cross-platform<span class="dp">·</span>(Ubuntu,<span class="dp">·</span>Windows,<span class="dp">·</span>macOS).</td><td class="diffline">11 </td><td class="diffpresent">The<span class="dp">·</span>package<span class="dp">·</span>is<span class="dp">·</span>available<span class="dp">·</span>on<span class="dp">·</span>PyPI<span class="dp">·</span>and<span class="dp">·</span>is<span class="dp">·</span>compatible<span class="dp">·</span>with<span class="dp">·</span>and<span class="dp">·</span>have<span class="dp">·</span>been<span class="dp">·</span>tested<span class="dp">·</span>against<span class="dp">·</span><ins>`</ins>TF<span class="dp">·</span><ins>2</ins><ins>.2-</ins>2.<ins>12</ins><ins>`</ins><span class="dp">·</span>and<span class="dp">·</span><ins>`</ins>Python<span class="dp">·</span>3.6-3.1<ins>2`</ins>,<span class="dp">·</span>and<span class="dp">·</span>works<span class="dp">·</span>cross-platform<span class="dp">·</span>(Ubuntu,<span class="dp">·</span>Windows,<span class="dp">·</span>macOS).</td></tr>
<tr class="diffunmodified"><td class="diffline">11 </td><td class="diffpresent">&lt;/div&gt;</td><td class="diffline">12 </td><td class="diffpresent">&lt;/div&gt;</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">12 </td><td class="diffpresent">##<span class="dp">·</span>What?</td><td class="diffline">13 </td><td class="diffpresent">##<span class="dp">·</span>What?</td></tr>
<tr class="diffunmodified"><td class="diffline">13 </td><td class="diffpresent">Gradient<span class="dp">·</span>accumulation<span class="dp">·</span>(GA)<span class="dp">·</span>enables<span class="dp">·</span>reduced<span class="dp">·</span>GPU<span class="dp">·</span>memory<span class="dp">·</span>consumption<span class="dp">·</span>through<span class="dp">·</span>dividing<span class="dp">·</span>a<span class="dp">·</span>batch<span class="dp">·</span>into<span class="dp">·</span>smaller<span class="dp">·</span>reduced<span class="dp">·</span>batches,<span class="dp">·</span>and<span class="dp">·</span>performing<span class="dp">·</span>gradient<span class="dp">·</span>computation<span class="dp">·</span>either<span class="dp">·</span>in<span class="dp">·</span>a<span class="dp">·</span>distributing<span class="dp">·</span>setting<span class="dp">·</span>across<span class="dp">·</span>multiple<span class="dp">·</span>GPUs<span class="dp">·</span>or<span class="dp">·</span>sequentially<span class="dp">·</span>on<span class="dp">·</span>the<span class="dp">·</span>same<span class="dp">·</span>GPU.<span class="dp">·</span>When<span class="dp">·</span>the<span class="dp">·</span>full<span class="dp">·</span>batch<span class="dp">·</span>is<span class="dp">·</span>processed,<span class="dp">·</span>the<span class="dp">·</span>gradients<span class="dp">·</span>are<span class="dp">·</span>the<span class="dp">·</span>_accumulated_<span class="dp">·</span>to<span class="dp">·</span>produce<span class="dp">·</span>the<span class="dp">·</span>full<span class="dp">·</span>batch<span class="dp">·</span>gradient.</td><td class="diffline">14 </td><td class="diffpresent">Gradient<span class="dp">·</span>accumulation<span class="dp">·</span>(GA)<span class="dp">·</span>enables<span class="dp">·</span>reduced<span class="dp">·</span>GPU<span class="dp">·</span>memory<span class="dp">·</span>consumption<span class="dp">·</span>through<span class="dp">·</span>dividing<span class="dp">·</span>a<span class="dp">·</span>batch<span class="dp">·</span>into<span class="dp">·</span>smaller<span class="dp">·</span>reduced<span class="dp">·</span>batches,<span class="dp">·</span>and<span class="dp">·</span>performing<span class="dp">·</span>gradient<span class="dp">·</span>computation<span class="dp">·</span>either<span class="dp">·</span>in<span class="dp">·</span>a<span class="dp">·</span>distributing<span class="dp">·</span>setting<span class="dp">·</span>across<span class="dp">·</span>multiple<span class="dp">·</span>GPUs<span class="dp">·</span>or<span class="dp">·</span>sequentially<span class="dp">·</span>on<span class="dp">·</span>the<span class="dp">·</span>same<span class="dp">·</span>GPU.<span class="dp">·</span>When<span class="dp">·</span>the<span class="dp">·</span>full<span class="dp">·</span>batch<span class="dp">·</span>is<span class="dp">·</span>processed,<span class="dp">·</span>the<span class="dp">·</span>gradients<span class="dp">·</span>are<span class="dp">·</span>the<span class="dp">·</span>_accumulated_<span class="dp">·</span>to<span class="dp">·</span>produce<span class="dp">·</span>the<span class="dp">·</span>full<span class="dp">·</span>batch<span class="dp">·</span>gradient.</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">14 </td><td class="diffpresent">&lt;p<span class="dp">·</span>align=&quot;center&quot;&gt;</td><td class="diffline">15 </td><td class="diffpresent">&lt;p<span class="dp">·</span>align=&quot;center&quot;&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">15 </td><td class="diffpresent">&lt;img<span class="dp">·</span>src=&quot;assets/grad_accum.png&quot;<span class="dp">·</span>width=&quot;50%&quot;&gt;</td><td class="diffline">16 </td><td class="diffpresent">&lt;img<span class="dp">·</span>src=&quot;assets/grad_accum.png&quot;<span class="dp">·</span>width=&quot;50%&quot;&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">16 </td><td class="diffpresent">&lt;/p&gt;</td><td class="diffline">17 </td><td class="diffpresent">&lt;/p&gt;</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffhunk"><td colspan="2">Offset 25, 15 lines modified</td><td colspan="2">Offset 27, 15 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">25 </td><td class="diffpresent">In<span class="dp">·</span>TensorFlow<span class="dp">·</span>2,<span class="dp">·</span>there<span class="dp">·</span>did<span class="dp">·</span>not<span class="dp">·</span>exist<span class="dp">·</span>a<span class="dp">·</span>plug-and-play<span class="dp">·</span>method<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>with<span class="dp">·</span>any<span class="dp">·</span>custom<span class="dp">·</span>pipeline.<span class="dp">·</span>Hence,<span class="dp">·</span>we<span class="dp">·</span>have<span class="dp">·</span>implemented<span class="dp">·</span>two<span class="dp">·</span>generic<span class="dp">·</span>TF2-compatible<span class="dp">·</span>approaches:</td><td class="diffline">27 </td><td class="diffpresent">In<span class="dp">·</span>TensorFlow<span class="dp">·</span>2,<span class="dp">·</span>there<span class="dp">·</span>did<span class="dp">·</span>not<span class="dp">·</span>exist<span class="dp">·</span>a<span class="dp">·</span>plug-and-play<span class="dp">·</span>method<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>with<span class="dp">·</span>any<span class="dp">·</span>custom<span class="dp">·</span>pipeline.<span class="dp">·</span>Hence,<span class="dp">·</span>we<span class="dp">·</span>have<span class="dp">·</span>implemented<span class="dp">·</span>two<span class="dp">·</span>generic<span class="dp">·</span>TF2-compatible<span class="dp">·</span>approaches:</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">26 </td><td class="diffpresent">|<span class="dp">·</span>Method<span class="dp">·</span>|<span class="dp">·</span>Usage<span class="dp">·</span>|</td><td class="diffline">28 </td><td class="diffpresent">|<span class="dp">·</span>Method<span class="dp">·</span>|<span class="dp">·</span>Usage<span class="dp">·</span>|</td></tr>
<tr class="diffunmodified"><td class="diffline">27 </td><td class="diffpresent">|<span class="dp">·</span>-<span class="dp">·</span>|<span class="dp">·</span>-<span class="dp">·</span>|</td><td class="diffline">29 </td><td class="diffpresent">|<span class="dp">·</span>-<span class="dp">·</span>|<span class="dp">·</span>-<span class="dp">·</span>|</td></tr>
<tr class="diffunmodified"><td class="diffline">28 </td><td class="diffpresent">|<span class="dp">·</span>`GradientAccumulateModel`<span class="dp">·</span>|<span class="dp">·</span>`model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=model.input,<span class="dp">·</span>outputs=model.output)`<span class="dp">·</span>|</td><td class="diffline">30 </td><td class="diffpresent">|<span class="dp">·</span>`GradientAccumulateModel`<span class="dp">·</span>|<span class="dp">·</span>`model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=model.input,<span class="dp">·</span>outputs=model.output)`<span class="dp">·</span>|</td></tr>
<tr class="diffunmodified"><td class="diffline">29 </td><td class="diffpresent">|<span class="dp">·</span>`GradientAccumulateOptimizer`<span class="dp">·</span>|<span class="dp">·</span>`opt<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateOptimizer(accum_steps=4,<span class="dp">·</span>optimizer=tf.keras.optimizers.SGD(1e-2))`<span class="dp">·</span>|</td><td class="diffline">31 </td><td class="diffpresent">|<span class="dp">·</span>`GradientAccumulateOptimizer`<span class="dp">·</span>|<span class="dp">·</span>`opt<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateOptimizer(accum_steps=4,<span class="dp">·</span>optimizer=tf.keras.optimizers.SGD(1e-2))`<span class="dp">·</span>|</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffchanged"><td class="diffline">30 </td><td class="diffpresent">Both<span class="dp">·</span>approaches<span class="dp">·</span>control<span class="dp">·</span>how<span class="dp">·</span>frequently<span class="dp">·</span>the<span class="dp">·</span>weigths<span class="dp">·</span>are<span class="dp">·</span>updated,<span class="dp">·</span>but<span class="dp">·</span>in<span class="dp">·</span>their<span class="dp">·</span>own<span class="dp">·</span>way.<span class="dp">·</span>Approach<span class="dp">·</span>(1)<span class="dp">·</span>is<span class="dp">·</span>for<span class="dp">·</span>single-GPU<span class="dp">·</span>only,<span class="dp">·</span>whereas<span class="dp">·</span>(2)<span class="dp">·</span>supports<span class="dp">·</span>both<span class="dp">·</span>single-GPU<span class="dp">·</span>and<span class="dp">·</span>distributed<span class="dp">·</span>training<span class="dp">·</span>(multi-GPU).</td><td class="diffline">32 </td><td class="diffpresent">Both<span class="dp">·</span>approaches<span class="dp">·</span>control<span class="dp">·</span>how<span class="dp">·</span>frequently<span class="dp">·</span>the<span class="dp">·</span>weigths<span class="dp">·</span>are<span class="dp">·</span>updated,<span class="dp">·</span>but<span class="dp">·</span>in<span class="dp">·</span>their<span class="dp">·</span>own<span class="dp">·</span>way.<span class="dp">·</span>Approach<span class="dp">·</span>(1)<span class="dp">·</span>is<span class="dp">·</span>for<span class="dp">·</span>single-GPU<span class="dp">·</span>only,<span class="dp">·</span>whereas<span class="dp">·</span>(2)<span class="dp">·</span>supports<span class="dp">·</span>both<span class="dp">·</span>single-GPU<span class="dp">·</span>and<span class="dp">·</span>distributed<span class="dp">·</span>training<span class="dp">·</span>(multi-GPU).<ins><span class="dp">·</span>However,<span class="dp">·</span>note<span class="dp">·</span>that<span class="dp">·</span>(2)<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>yet<span class="dp">·</span>working<span class="dp">·</span>as<span class="dp">·</span>intended.<span class="dp">·</span>Hence,<span class="dp">·</span>use<span class="dp">·</span>(1)<span class="dp">·</span>for<span class="dp">·</span>most<span class="dp">·</span>applications.</ins></td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">31 </td><td class="diffpresent">Our<span class="dp">·</span>implementations<span class="dp">·</span>enable<span class="dp">·</span>theoretically<span class="dp">·</span>**infinitely<span class="dp">·</span>large<span class="dp">·</span>batch<span class="dp">·</span>size**,<span class="dp">·</span>with<span class="dp">·</span>**identical<span class="dp">·</span>memory<span class="dp">·</span>consumption**<span class="dp">·</span>as<span class="dp">·</span>for<span class="dp">·</span>a<span class="dp">·</span>regular<span class="dp">·</span>mini<span class="dp">·</span>batch.<span class="dp">·</span>If<span class="dp">·</span>a<span class="dp">·</span>single<span class="dp">·</span>GPU<span class="dp">·</span>is<span class="dp">·</span>used,<span class="dp">·</span>this<span class="dp">·</span>comes<span class="dp">·</span>at<span class="dp">·</span>the<span class="dp">·</span>cost<span class="dp">·</span>of<span class="dp">·</span>increased<span class="dp">·</span>training<span class="dp">·</span>runtime.<span class="dp">·</span>Multiple<span class="dp">·</span>GPUs<span class="dp">·</span>could<span class="dp">·</span>be<span class="dp">·</span>used<span class="dp">·</span>to<span class="dp">·</span>increase<span class="dp">·</span>runtime<span class="dp">·</span>performance.</td><td class="diffline">33 </td><td class="diffpresent">Our<span class="dp">·</span>implementations<span class="dp">·</span>enable<span class="dp">·</span>theoretically<span class="dp">·</span>**infinitely<span class="dp">·</span>large<span class="dp">·</span>batch<span class="dp">·</span>size**,<span class="dp">·</span>with<span class="dp">·</span>**identical<span class="dp">·</span>memory<span class="dp">·</span>consumption**<span class="dp">·</span>as<span class="dp">·</span>for<span class="dp">·</span>a<span class="dp">·</span>regular<span class="dp">·</span>mini<span class="dp">·</span>batch.<span class="dp">·</span>If<span class="dp">·</span>a<span class="dp">·</span>single<span class="dp">·</span>GPU<span class="dp">·</span>is<span class="dp">·</span>used,<span class="dp">·</span>this<span class="dp">·</span>comes<span class="dp">·</span>at<span class="dp">·</span>the<span class="dp">·</span>cost<span class="dp">·</span>of<span class="dp">·</span>increased<span class="dp">·</span>training<span class="dp">·</span>runtime.<span class="dp">·</span>Multiple<span class="dp">·</span>GPUs<span class="dp">·</span>could<span class="dp">·</span>be<span class="dp">·</span>used<span class="dp">·</span>to<span class="dp">·</span>increase<span class="dp">·</span>runtime<span class="dp">·</span>performance.</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">32 </td><td class="diffpresent">As<span class="dp">·</span>batch<span class="dp">·</span>normalization<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>natively<span class="dp">·</span>compatible<span class="dp">·</span>with<span class="dp">·</span>GA,<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping<span class="dp">·</span>has<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>as<span class="dp">·</span>an<span class="dp">·</span>alternative.<span class="dp">·</span>We<span class="dp">·</span>have<span class="dp">·</span>also<span class="dp">·</span>added<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>mixed<span class="dp">·</span>precision<span class="dp">·</span>and<span class="dp">·</span>both<span class="dp">·</span>GPU<span class="dp">·</span>and<span class="dp">·</span>TPU<span class="dp">·</span>support.</td><td class="diffline">34 </td><td class="diffpresent">As<span class="dp">·</span>batch<span class="dp">·</span>normalization<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>natively<span class="dp">·</span>compatible<span class="dp">·</span>with<span class="dp">·</span>GA,<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping<span class="dp">·</span>has<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>as<span class="dp">·</span>an<span class="dp">·</span>alternative.<span class="dp">·</span>We<span class="dp">·</span>have<span class="dp">·</span>also<span class="dp">·</span>added<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>mixed<span class="dp">·</span>precision<span class="dp">·</span>and<span class="dp">·</span>both<span class="dp">·</span>GPU<span class="dp">·</span>and<span class="dp">·</span>TPU<span class="dp">·</span>support.</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">33 </td><td class="diffpresent">##<span class="dp">·</span>Install</td><td class="diffline">35 </td><td class="diffpresent">##<span class="dp">·</span>Install</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 55, 15 lines modified</td><td colspan="2">Offset 57, 15 lines modified</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">55 </td><td class="diffpresent">model<span class="dp">·</span>=<span class="dp">·</span>Model(...)</td><td class="diffline">57 </td><td class="diffpresent">model<span class="dp">·</span>=<span class="dp">·</span>Model(...)</td></tr>
<tr class="diffunmodified"><td class="diffline">56 </td><td class="diffpresent">model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=model.input,<span class="dp">·</span>outputs=model.output)</td><td class="diffline">58 </td><td class="diffpresent">model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=model.input,<span class="dp">·</span>outputs=model.output)</td></tr>
<tr class="diffunmodified"><td class="diffline">57 </td><td class="diffpresent">```</td><td class="diffline">59 </td><td class="diffpresent">```</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">58 </td><td class="diffpresent">Then<span class="dp">·</span>simply<span class="dp">·</span>use<span class="dp">·</span>the<span class="dp">·</span>`model`<span class="dp">·</span>as<span class="dp">·</span>you<span class="dp">·</span>normally<span class="dp">·</span>would!</td><td class="diffline">60 </td><td class="diffpresent">Then<span class="dp">·</span>simply<span class="dp">·</span>use<span class="dp">·</span>the<span class="dp">·</span>`model`<span class="dp">·</span>as<span class="dp">·</span>you<span class="dp">·</span>normally<span class="dp">·</span>would!</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffchanged"><td class="diffline">59 </td><td class="diffpresent">&lt;details<del><span class="dp">·</span>open</del>&gt;</td><td class="diffline">61 </td><td class="diffpresent">&lt;details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">60 </td><td class="diffpresent">&lt;summary&gt;</td><td class="diffline">62 </td><td class="diffpresent">&lt;summary&gt;</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">61 </td><td class="diffpresent">####<span class="dp">·</span>Mixed<span class="dp">·</span>precision&lt;/summary&gt;</td><td class="diffline">63 </td><td class="diffpresent">####<span class="dp">·</span>Mixed<span class="dp">·</span>precision&lt;/summary&gt;</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">62 </td><td class="diffpresent">There<span class="dp">·</span>has<span class="dp">·</span>also<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>experimental<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>mixed<span class="dp">·</span>precision:</td><td class="diffline">64 </td><td class="diffpresent">There<span class="dp">·</span>has<span class="dp">·</span>also<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>experimental<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>mixed<span class="dp">·</span>precision:</td></tr>
<tr class="diffunmodified"><td class="diffline">63 </td><td class="diffpresent">```</td><td class="diffline">65 </td><td class="diffpresent">```</td></tr>
<tr class="diffunmodified"><td class="diffline">64 </td><td class="diffpresent">from<span class="dp">·</span>tensorflow.keras<span class="dp">·</span>import<span class="dp">·</span>mixed_precision</td><td class="diffline">66 </td><td class="diffpresent">from<span class="dp">·</span>tensorflow.keras<span class="dp">·</span>import<span class="dp">·</span>mixed_precision</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 81, 27 lines modified</td><td colspan="2">Offset 83, 64 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">81 </td><td class="diffpresent">mixed_precision.set_global_policy(&#x27;mixed_bfloat16&#x27;)</td><td class="diffline">83 </td><td class="diffpresent">mixed_precision.set_global_policy(&#x27;mixed_bfloat16&#x27;)</td></tr>
<tr class="diffunmodified"><td class="diffline">82 </td><td class="diffpresent">```</td><td class="diffline">84 </td><td class="diffpresent">```</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">83 </td><td class="diffpresent">There<span class="dp">·</span>is<span class="dp">·</span>also<span class="dp">·</span>an<span class="dp">·</span>example<span class="dp">·</span>of<span class="dp">·</span>how<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>with<span class="dp">·</span>mixed<span class="dp">·</span>precision<span class="dp">·</span>[here](https://github.com/andreped/GradientAccumulator/blob/main/tests/test_mixed_precision.py#L58).</td><td class="diffline">85 </td><td class="diffpresent">There<span class="dp">·</span>is<span class="dp">·</span>also<span class="dp">·</span>an<span class="dp">·</span>example<span class="dp">·</span>of<span class="dp">·</span>how<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>with<span class="dp">·</span>mixed<span class="dp">·</span>precision<span class="dp">·</span>[here](https://github.com/andreped/GradientAccumulator/blob/main/tests/test_mixed_precision.py#L58).</td></tr>
<tr class="diffunmodified"><td class="diffline">84 </td><td class="diffpresent">&lt;/details&gt;</td><td class="diffline">86 </td><td class="diffpresent">&lt;/details&gt;</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffchanged"><td class="diffline">85 </td><td class="diffpresent">&lt;details<del><span class="dp">·</span>open</del>&gt;</td><td class="diffline">87 </td><td class="diffpresent">&lt;details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">86 </td><td class="diffpresent">&lt;summary&gt;</td><td class="diffline">88 </td><td class="diffpresent">&lt;summary&gt;</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">87 </td><td class="diffpresent">####<span class="dp">·</span>Distributed<span class="dp">·</span>training<span class="dp">·</span>with<span class="dp">·</span>multiple<span class="dp">·</span>GPUs&lt;/summary&gt;</td><td class="diffline">89 </td><td class="diffpresent">####<span class="dp">·</span>Distributed<span class="dp">·</span>training<span class="dp">·</span>with<span class="dp">·</span>multiple<span class="dp">·</span>GPUs&lt;/summary&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">88 </td><td class="diffpresent">In<span class="dp">·</span>order<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>multiple<span class="dp">·</span>GPUs,<span class="dp">·</span>you<span class="dp">·</span>will<span class="dp">·</span>have<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>the<span class="dp">·</span>Optimizer<span class="dp">·</span>wrapper:</td><td class="diffline">90 </td><td class="diffpresent">In<span class="dp">·</span>order<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>multiple<span class="dp">·</span>GPUs,<span class="dp">·</span>you<span class="dp">·</span>will<span class="dp">·</span>have<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>the<span class="dp">·</span>Optimizer<span class="dp">·</span>wrapper:</td></tr>
<tr class="diffunmodified"><td class="diffline">89 </td><td class="diffpresent">```</td><td class="diffline">91 </td><td class="diffpresent">```</td></tr>
<tr class="diffunmodified"><td class="diffline">90 </td><td class="diffpresent">opt<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateOptimizer(accum_steps=4,<span class="dp">·</span>optimizer=tf.keras.optimizers.SGD(1e-2))</td><td class="diffline">92 </td><td class="diffpresent">opt<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateOptimizer(accum_steps=4,<span class="dp">·</span>optimizer=tf.keras.optimizers.SGD(1e-2))</td></tr>
<tr class="diffunmodified"><td class="diffline">91 </td><td class="diffpresent">```</td><td class="diffline">93 </td><td class="diffpresent">```</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">92 </td><td class="diffpresent">Just<span class="dp">·</span>remember<span class="dp">·</span>to<span class="dp">·</span>wrap<span class="dp">·</span>the<span class="dp">·</span>optimizer<span class="dp">·</span>within<span class="dp">·</span>the<span class="dp">·</span>`tf.distribute.MirroredStrategy`.<span class="dp">·</span>For<span class="dp">·</span>an<span class="dp">·</span>example,<span class="dp">·</span>see<span class="dp">·</span>[here](https://github.com/andreped/GradientAccumulator/blob/main/tests/test_optimizer_distribute.py).</td><td class="diffline">94 </td><td class="diffpresent">Just<span class="dp">·</span>remember<span class="dp">·</span>to<span class="dp">·</span>wrap<span class="dp">·</span>the<span class="dp">·</span>optimizer<span class="dp">·</span>within<span class="dp">·</span>the<span class="dp">·</span>`tf.distribute.MirroredStrategy`.<span class="dp">·</span>For<span class="dp">·</span>an<span class="dp">·</span>example,<span class="dp">·</span>see<span class="dp">·</span>[here](https://github.com/andreped/GradientAccumulator/blob/main/tests/test_optimizer_distribute.py).</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">95 </td><td class="diffpresent">**DISCLAIMER:<span class="dp">·</span>The<span class="dp">·</span>GradientAccumulateOptimizer<span class="dp">·</span>is<span class="dp">·</span>a<span class="dp">·</span>VERY<span class="dp">·</span>experimental<span class="dp">·</span>feature.<span class="dp">·</span>It<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>reaching<span class="dp">·</span>the<span class="dp">·</span>same<span class="dp">·</span>results<span class="dp">·</span>as<span class="dp">·</span>GradientAccumulateModel<span class="dp">·</span>with<span class="dp">·</span>a<span class="dp">·</span>single<span class="dp">·</span>GPU,<span class="dp">·</span>and<span class="dp">·</span>does<span class="dp">·</span>not<span class="dp">·</span>work<span class="dp">·</span>(yet)<span class="dp">·</span>with<span class="dp">·</span>multiple<span class="dp">·</span>GPUs.<span class="dp">·</span>Hence,<span class="dp">·</span>I<span class="dp">·</span>would<span class="dp">·</span>recommend<span class="dp">·</span>using<span class="dp">·</span>GradientAccumulateModel<span class="dp">·</span>with<span class="dp">·</span>a<span class="dp">·</span>single<span class="dp">·</span>GPU<span class="dp">·</span>in<span class="dp">·</span>its<span class="dp">·</span>current<span class="dp">·</span>state.**</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">96 </td><td class="diffpresent">&lt;/details&gt;</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">97 </td><td class="diffpresent">&lt;details&gt;</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">98 </td><td class="diffpresent">&lt;summary&gt;</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">99 </td><td class="diffpresent">####<span class="dp">·</span>HuggingFace<span class="dp">·</span>:hugs:&lt;/summary&gt;</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">100 </td><td class="diffpresent">Note<span class="dp">·</span>that<span class="dp">·</span>HuggingFace<span class="dp">·</span>provides<span class="dp">·</span>a<span class="dp">·</span>variety<span class="dp">·</span>of<span class="dp">·</span>different<span class="dp">·</span>pretrained<span class="dp">·</span>models.<span class="dp">·</span>However,<span class="dp">·</span>it<span class="dp">·</span>was<span class="dp">·</span>observed<span class="dp">·</span>that<span class="dp">·</span>when<span class="dp">·</span>loading<span class="dp">·</span>these<span class="dp">·</span>models<span class="dp">·</span>into<span class="dp">·</span>TensorFlow,<span class="dp">·</span>the<span class="dp">·</span>computational<span class="dp">·</span>graph<span class="dp">·</span>may<span class="dp">·</span>not<span class="dp">·</span>be<span class="dp">·</span>set<span class="dp">·</span>up<span class="dp">·</span>correctly,<span class="dp">·</span>such<span class="dp">·</span>that<span class="dp">·</span>the<span class="dp">·</span>`model.input`<span class="dp">·</span>and<span class="dp">·</span>`model.output`<span class="dp">·</span>exist.</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">101 </td><td class="diffpresent">To<span class="dp">·</span>fix<span class="dp">·</span>this,<span class="dp">·</span>we<span class="dp">·</span>basically<span class="dp">·</span>wrap<span class="dp">·</span>the<span class="dp">·</span>model<span class="dp">·</span>into<span class="dp">·</span>a<span class="dp">·</span>new<span class="dp">·</span>`tf.keras.Model`,<span class="dp">·</span>but<span class="dp">·</span>define<span class="dp">·</span>the<span class="dp">·</span>inputs<span class="dp">·</span>and<span class="dp">·</span>outputs<span class="dp">·</span>ourselves:</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">102 </td><td class="diffpresent">```</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">103 </td><td class="diffpresent">from<span class="dp">·</span>gradient_accumulator<span class="dp">·</span>import<span class="dp">·</span>GradientAccumulateModel</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">104 </td><td class="diffpresent">from<span class="dp">·</span>tensorflow.keras.layers<span class="dp">·</span>import<span class="dp">·</span>Input</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">105 </td><td class="diffpresent">from<span class="dp">·</span>tensorflow.keras.models<span class="dp">·</span>import<span class="dp">·</span>Model</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">106 </td><td class="diffpresent">from<span class="dp">·</span>transformers<span class="dp">·</span>import<span class="dp">·</span>TFx</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">107 </td><td class="diffpresent">#load<span class="dp">·</span>your<span class="dp">·</span>model<span class="dp">·</span>checkpoint</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">108 </td><td class="diffpresent">HF_model<span class="dp">·</span>=<span class="dp">·</span>TFx.from_pretrained(checkpoint)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">109 </td><td class="diffpresent">#<span class="dp">·</span>define<span class="dp">·</span>model<span class="dp">·</span>inputs<span class="dp">·</span>and<span class="dp">·</span>outputs<span class="dp">·</span>-&gt;<span class="dp">·</span>for<span class="dp">·</span>different<span class="dp">·</span>models,<span class="dp">·</span>different<span class="dp">·</span>inputs/outputs<span class="dp">·</span>need<span class="dp">·</span>to<span class="dp">·</span>be<span class="dp">·</span>defined</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">110 </td><td class="diffpresent">input_ids<span class="dp">·</span>=<span class="dp">·</span>tf.keras.Input(shape=(None,),<span class="dp">·</span>dtype=&#x27;int32&#x27;,<span class="dp">·</span>name=&quot;input_ids&quot;)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">111 </td><td class="diffpresent">attention_mask<span class="dp">·</span>=<span class="dp">·</span>tf.keras.Input(shape=(None,),<span class="dp">·</span>dtype=&#x27;int32&#x27;,<span class="dp">·</span>name=&quot;attention_mask&quot;)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">112 </td><td class="diffpresent">model_input={&#x27;input_ids&#x27;:<span class="dp">·</span>input_ids,<span class="dp">·</span>&#x27;attention_mask&#x27;:<span class="dp">·</span>attention_mask}</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">113 </td><td class="diffpresent">#create<span class="dp">·</span>a<span class="dp">·</span>new<span class="dp">·</span>Model<span class="dp">·</span>which<span class="dp">·</span>has<span class="dp">·</span>model.input<span class="dp">·</span>and<span class="dp">·</span>model.output<span class="dp">·</span>properties</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">114 </td><td class="diffpresent">new_model<span class="dp">·</span>=<span class="dp">·</span>Model(inputs=model_input,<span class="dp">·</span>outputs=HF_model(model_input))</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">115 </td><td class="diffpresent">#create<span class="dp">·</span>the<span class="dp">·</span>GA<span class="dp">·</span>model</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">116 </td><td class="diffpresent">model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=new_model.input,<span class="dp">·</span>outputs=new_model.output)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">117 </td><td class="diffpresent">```</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">118 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">119 </td><td class="diffpresent">For<span class="dp">·</span>more<span class="dp">·</span>details,<span class="dp">·</span>see<span class="dp">·</span>[this](https://github.com/andreped/GradientAccumulator/blob/main/notebooks/GA_for_HuggingFace_TF_models.ipynb)<span class="dp">·</span>jupyter<span class="dp">·</span>notebook.</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">93 </td><td class="diffpresent">&lt;/details&gt;</td><td class="diffline">120 </td><td class="diffpresent">&lt;/details&gt;</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">94 </td><td class="diffpresent">&lt;details&gt;</td><td class="diffline">121 </td><td class="diffpresent">&lt;details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">95 </td><td class="diffpresent">&lt;summary&gt;</td><td class="diffline">122 </td><td class="diffpresent">&lt;summary&gt;</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">96 </td><td class="diffpresent">####<span class="dp">·</span>Adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping&lt;/summary&gt;</td><td class="diffline">123 </td><td class="diffpresent">####<span class="dp">·</span>Adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping&lt;/summary&gt;</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">97 </td><td class="diffpresent">There<span class="dp">·</span>has<span class="dp">·</span>also<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping,<span class="dp">·</span>based<span class="dp">·</span>on<span class="dp">·</span>[this](https://github.com/sayakpaul/Adaptive-Gradient-Clipping)<span class="dp">·</span>implementation:</td><td class="diffline">124 </td><td class="diffpresent">There<span class="dp">·</span>has<span class="dp">·</span>also<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping,<span class="dp">·</span>based<span class="dp">·</span>on<span class="dp">·</span>[this](https://github.com/sayakpaul/Adaptive-Gradient-Clipping)<span class="dp">·</span>implementation:</td></tr>
<tr class="diffunmodified"><td class="diffline">98 </td><td class="diffpresent">```</td><td class="diffline">125 </td><td class="diffpresent">```</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 113, 15 lines modified</td><td colspan="2">Offset 152, 15 lines modified</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">113 </td><td class="diffpresent">&lt;details&gt;</td><td class="diffline">152 </td><td class="diffpresent">&lt;details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">114 </td><td class="diffpresent">&lt;summary&gt;</td><td class="diffline">153 </td><td class="diffpresent">&lt;summary&gt;</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="error"><td colspan="4">
Max diff block lines reached; 3880/10628 bytes (36.51%) of diff not shown.
</td></tr></table>    </div>
    <div class="difference">
      <div class="diffheader">
      <div class="diffcontrol diffcontrol-double">⊟</div>
      <div><span class="diffsize">8.51 KB</span></div>
      <div><span class="source">gradient-accumulator-0.3.1/gradient_accumulator/accumulators.py</span> vs.</div>
      <div id="gradient-accumulator--.-.-.tar---gradient-accumulator--.-.--gradient_accumulator-accumulators.py"><span class="source">gradient-accumulator-0.3.2/gradient_accumulator/accumulators.py</span>
        <a class="anchor" href="#gradient-accumulator--.-.-.tar---gradient-accumulator--.-.--gradient_accumulator-accumulators.py">¶</a>
      </div>
      </div>
      <div class="comment">Files 10% similar despite different names
      </div>
<table class="diff">
<colgroup><col class="colines"/><col class="coldiff"/>
<col class="colines"/><col class="coldiff"/></colgroup>
<tr style="display:none;"><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 1, 11 lines modified</td><td colspan="2">Offset 1, 17 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">1 </td><td class="diffpresent">import<span class="dp">·</span>tensorflow<span class="dp">·</span>as<span class="dp">·</span>tf</td><td class="diffline">1 </td><td class="diffpresent">import<span class="dp">·</span>tensorflow<span class="dp">·</span>as<span class="dp">·</span>tf</td></tr>
<tr class="diffunmodified"><td class="diffline">2 </td><td class="diffpresent">from<span class="dp">·</span>.<span class="dp">·</span>import<span class="dp">·</span>agc</td><td class="diffline">2 </td><td class="diffpresent">from<span class="dp">·</span>.<span class="dp">·</span>import<span class="dp">·</span>agc</td></tr>
<tr class="diffchanged"><td class="diffline">3 </td><td class="diffpresent">from<span class="dp">·</span>tensorflow_addons.utils<span class="dp">·</span>import<span class="dp">·</span>types</td><td class="diffline">3 </td><td class="diffpresent"><ins>#</ins>from<span class="dp">·</span>tensorflow_addons.utils<span class="dp">·</span>import<span class="dp">·</span>types</td></tr>
<tr class="diffchanged"><td class="diffline">4 </td><td class="diffpresent">from<span class="dp">·</span>typeguard<span class="dp">·</span>import<span class="dp">·</span>typechecked</td><td class="diffline">4 </td><td class="diffpresent"><ins>#</ins>from<span class="dp">·</span>typeguard<span class="dp">·</span>import<span class="dp">·</span>typechecked</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">5 </td><td class="diffpresent">#<span class="dp">·</span>need<span class="dp">·</span>to<span class="dp">·</span>dynamically<span class="dp">·</span>handle<span class="dp">·</span>which<span class="dp">·</span>Optimizer<span class="dp">·</span>class<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>dependent<span class="dp">·</span>on<span class="dp">·</span>tf<span class="dp">·</span>version</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">6 </td><td class="diffpresent">opt<span class="dp">·</span>=<span class="dp">·</span>tf.keras.optimizers.Optimizer</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">7 </td><td class="diffpresent">if<span class="dp">·</span>int(tf.version.VERSION.split(&quot;.&quot;)[1])<span class="dp">·</span>&gt;<span class="dp">·</span>10:</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">8 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>opt<span class="dp">·</span>=<span class="dp">·</span>tf.keras.optimizers.legacy.Optimizer</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">5 </td><td class="diffpresent">#<span class="dp">·</span>https://stackoverflow.com/a/66524901</td><td class="diffline">9 </td><td class="diffpresent">#<span class="dp">·</span>https://stackoverflow.com/a/66524901</td></tr>
<tr class="diffunmodified"><td class="diffline">6 </td><td class="diffpresent">#<span class="dp">·</span>https://keras.io/guides/customizing_what_happens_in_fit/</td><td class="diffline">10 </td><td class="diffpresent">#<span class="dp">·</span>https://keras.io/guides/customizing_what_happens_in_fit/</td></tr>
<tr class="diffunmodified"><td class="diffline">7 </td><td class="diffpresent">@tf.keras.utils.register_keras_serializable()<span class="dp">·</span><span class="dp">·</span>#<span class="dp">·</span>adding<span class="dp">·</span>this<span class="dp">·</span>avoids<span class="dp">·</span>needing<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>custom_objects<span class="dp">·</span>when<span class="dp">·</span>loading<span class="dp">·</span>model</td><td class="diffline">11 </td><td class="diffpresent">@tf.keras.utils.register_keras_serializable()<span class="dp">·</span><span class="dp">·</span>#<span class="dp">·</span>adding<span class="dp">·</span>this<span class="dp">·</span>avoids<span class="dp">·</span>needing<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>custom_objects<span class="dp">·</span>when<span class="dp">·</span>loading<span class="dp">·</span>model</td></tr>
<tr class="diffunmodified"><td class="diffline">8 </td><td class="diffpresent">class<span class="dp">·</span>GradientAccumulateModel(tf.keras.Model):</td><td class="diffline">12 </td><td class="diffpresent">class<span class="dp">·</span>GradientAccumulateModel(tf.keras.Model):</td></tr>
<tr class="diffunmodified"><td class="diffline">9 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>__init__(self,<span class="dp">·</span>accum_steps=1,<span class="dp">·</span>mixed_precision=False,<span class="dp">·</span>use_agc=False,<span class="dp">·</span>clip_factor=0.01,<span class="dp">·</span>eps=1e-3,<span class="dp">·</span>*args,<span class="dp">·</span>**kwargs):</td><td class="diffline">13 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>__init__(self,<span class="dp">·</span>accum_steps=1,<span class="dp">·</span>mixed_precision=False,<span class="dp">·</span>use_agc=False,<span class="dp">·</span>clip_factor=0.01,<span class="dp">·</span>eps=1e-3,<span class="dp">·</span>*args,<span class="dp">·</span>**kwargs):</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 104, 25 lines modified</td><td colspan="2">Offset 110, 17 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">104 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)<span class="dp">·</span>for<span class="dp">·</span>i,<span class="dp">·</span>v<span class="dp">·</span>in<span class="dp">·</span>enumerate(self.trainable_variables)</td><td class="diffline">110 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)<span class="dp">·</span>for<span class="dp">·</span>i,<span class="dp">·</span>v<span class="dp">·</span>in<span class="dp">·</span>enumerate(self.trainable_variables)</td></tr>
<tr class="diffunmodified"><td class="diffline">105 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>]</td><td class="diffline">111 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>]</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">106 </td><td class="diffpresent">#<span class="dp">·</span>Implementation<span class="dp">·</span>was<span class="dp">·</span>derived<span class="dp">·</span>from:</td><td class="diffline">112 </td><td class="diffpresent">#<span class="dp">·</span>Implementation<span class="dp">·</span>was<span class="dp">·</span>derived<span class="dp">·</span>from:</td></tr>
<tr class="diffunmodified"><td class="diffline">107 </td><td class="diffpresent">#<span class="dp">·</span>https://github.com/fsx950223/addons/blob/67c1e8ea19e82c3f2a5706674dd81f15ab5002a2/tensorflow_addons/optimizers/gradient_accumulator.py</td><td class="diffline">113 </td><td class="diffpresent">#<span class="dp">·</span>https://github.com/fsx950223/addons/blob/67c1e8ea19e82c3f2a5706674dd81f15ab5002a2/tensorflow_addons/optimizers/gradient_accumulator.py</td></tr>
<tr class="diffunmodified"><td class="diffline">108 </td><td class="diffpresent">@tf.keras.utils.register_keras_serializable()</td><td class="diffline">114 </td><td class="diffpresent">@tf.keras.utils.register_keras_serializable()</td></tr>
<tr class="diffchanged"><td class="diffline">109 </td><td class="diffpresent">class<span class="dp">·</span>GradientAccumulateOptimizer(<del>tf.keras.</del>o<del>ptimizers.O</del>pt<del>imizer</del>):</td><td class="diffline">115 </td><td class="diffpresent">class<span class="dp">·</span>GradientAccumulateOptimizer(opt):</td></tr>
<tr class="diffunmodified"><td class="diffline">110 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;&quot;&quot;Optimizer<span class="dp">·</span>wrapper<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation.&quot;&quot;&quot;</td><td class="diffline">116 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;&quot;&quot;Optimizer<span class="dp">·</span>wrapper<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation.&quot;&quot;&quot;</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">117 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>__init__(self,<span class="dp">·</span>optimizer=&quot;SGD&quot;,<span class="dp">·</span>accum_steps=1,<span class="dp">·</span>reduction:<span class="dp">·</span>str<span class="dp">·</span>=<span class="dp">·</span>&quot;MEAN&quot;,<span class="dp">·</span>name:<span class="dp">·</span>str<span class="dp">·</span>=<span class="dp">·</span>&quot;GradientAccumulateOptimizer&quot;,<span class="dp">·</span>**kwargs):</td></tr>
<tr class="diffdeleted"><td class="diffline">111 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>@typechecked</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">112 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>__init__(</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">113 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self,</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">114 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>optimizer,<span class="dp">·</span><span class="dp">·</span>#<span class="dp">·</span>:<span class="dp">·</span>types.Optimizer,<span class="dp">·</span><span class="dp">·</span>#<span class="dp">·</span>having<span class="dp">·</span>this<span class="dp">·</span>results<span class="dp">·</span>in<span class="dp">·</span>TypeError<span class="dp">·</span>-&gt;<span class="dp">·</span>expected<span class="dp">·</span>OptimizerV2<span class="dp">·</span>or<span class="dp">·</span>str,<span class="dp">·</span>got<span class="dp">·</span>dict<span class="dp">·</span>instead</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">115 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_steps:<span class="dp">·</span>types.TensorLike<span class="dp">·</span>=<span class="dp">·</span>4,</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">116 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>reduction:<span class="dp">·</span>str<span class="dp">·</span>=<span class="dp">·</span>&quot;MEAN&quot;,</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">117 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>name:<span class="dp">·</span>str<span class="dp">·</span>=<span class="dp">·</span>&quot;GradientAccumulateOptimizer&quot;,</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">118 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>**kwargs,</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">119 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>):</td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">120 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>r&quot;&quot;&quot;Construct<span class="dp">·</span>a<span class="dp">·</span>new<span class="dp">·</span>GradientAccumulateOptimizer<span class="dp">·</span>optimizer.</td><td class="diffline">118 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>r&quot;&quot;&quot;Construct<span class="dp">·</span>a<span class="dp">·</span>new<span class="dp">·</span>GradientAccumulateOptimizer<span class="dp">·</span>optimizer.</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">121 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Args:</td><td class="diffline">119 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Args:</td></tr>
<tr class="diffunmodified"><td class="diffline">122 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>optimizer:<span class="dp">·</span>str<span class="dp">·</span>or<span class="dp">·</span>`tf.keras.optimizers.Optimizer`<span class="dp">·</span>that<span class="dp">·</span>will<span class="dp">·</span>be</td><td class="diffline">120 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>optimizer:<span class="dp">·</span>str<span class="dp">·</span>or<span class="dp">·</span>`tf.keras.optimizers.Optimizer`<span class="dp">·</span>that<span class="dp">·</span>will<span class="dp">·</span>be</td></tr>
<tr class="diffunmodified"><td class="diffline">123 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>used<span class="dp">·</span>to<span class="dp">·</span>compute<span class="dp">·</span>and<span class="dp">·</span>apply<span class="dp">·</span>gradients.</td><td class="diffline">121 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>used<span class="dp">·</span>to<span class="dp">·</span>compute<span class="dp">·</span>and<span class="dp">·</span>apply<span class="dp">·</span>gradients.</td></tr>
<tr class="diffunmodified"><td class="diffline">124 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_steps:<span class="dp">·</span>int<span class="dp">·</span>&gt;<span class="dp">·</span>0.<span class="dp">·</span>Update<span class="dp">·</span>gradient<span class="dp">·</span>in<span class="dp">·</span>every<span class="dp">·</span>accumulation<span class="dp">·</span>steps.</td><td class="diffline">122 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_steps:<span class="dp">·</span>int<span class="dp">·</span>&gt;<span class="dp">·</span>0.<span class="dp">·</span>Update<span class="dp">·</span>gradient<span class="dp">·</span>in<span class="dp">·</span>every<span class="dp">·</span>accumulation<span class="dp">·</span>steps.</td></tr>
<tr class="diffunmodified"><td class="diffline">125 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>reduction:<span class="dp">·</span>str.<span class="dp">·</span>Which<span class="dp">·</span>gradient<span class="dp">·</span>reduction<span class="dp">·</span>method<span class="dp">·</span>to<span class="dp">·</span>use.<span class="dp">·</span>Defaults<span class="dp">·</span>to<span class="dp">·</span>&#x27;SUM&#x27;.</td><td class="diffline">123 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>reduction:<span class="dp">·</span>str.<span class="dp">·</span>Which<span class="dp">·</span>gradient<span class="dp">·</span>reduction<span class="dp">·</span>method<span class="dp">·</span>to<span class="dp">·</span>use.<span class="dp">·</span>Defaults<span class="dp">·</span>to<span class="dp">·</span>&#x27;SUM&#x27;.</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 131, 23 lines modified</td><td colspan="2">Offset 129, 21 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">131 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>**kwargs:<span class="dp">·</span>keyword<span class="dp">·</span>arguments.<span class="dp">·</span>Allowed<span class="dp">·</span>to<span class="dp">·</span>be<span class="dp">·</span>{`clipnorm`,</td><td class="diffline">129 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>**kwargs:<span class="dp">·</span>keyword<span class="dp">·</span>arguments.<span class="dp">·</span>Allowed<span class="dp">·</span>to<span class="dp">·</span>be<span class="dp">·</span>{`clipnorm`,</td></tr>
<tr class="diffunmodified"><td class="diffline">132 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>`clipvalue`,<span class="dp">·</span>`lr`,<span class="dp">·</span>`decay`}.<span class="dp">·</span>`clipnorm`<span class="dp">·</span>is<span class="dp">·</span>clip<span class="dp">·</span>gradients<span class="dp">·</span>by</td><td class="diffline">130 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>`clipvalue`,<span class="dp">·</span>`lr`,<span class="dp">·</span>`decay`}.<span class="dp">·</span>`clipnorm`<span class="dp">·</span>is<span class="dp">·</span>clip<span class="dp">·</span>gradients<span class="dp">·</span>by</td></tr>
<tr class="diffunmodified"><td class="diffline">133 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>norm;<span class="dp">·</span>`clipvalue`<span class="dp">·</span>is<span class="dp">·</span>clip<span class="dp">·</span>gradients<span class="dp">·</span>by<span class="dp">·</span>value,<span class="dp">·</span>`decay`<span class="dp">·</span>is</td><td class="diffline">131 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>norm;<span class="dp">·</span>`clipvalue`<span class="dp">·</span>is<span class="dp">·</span>clip<span class="dp">·</span>gradients<span class="dp">·</span>by<span class="dp">·</span>value,<span class="dp">·</span>`decay`<span class="dp">·</span>is</td></tr>
<tr class="diffunmodified"><td class="diffline">134 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>included<span class="dp">·</span>for<span class="dp">·</span>backward<span class="dp">·</span>compatibility<span class="dp">·</span>to<span class="dp">·</span>allow<span class="dp">·</span>time<span class="dp">·</span>inverse</td><td class="diffline">132 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>included<span class="dp">·</span>for<span class="dp">·</span>backward<span class="dp">·</span>compatibility<span class="dp">·</span>to<span class="dp">·</span>allow<span class="dp">·</span>time<span class="dp">·</span>inverse</td></tr>
<tr class="diffunmodified"><td class="diffline">135 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>decay<span class="dp">·</span>of<span class="dp">·</span>learning<span class="dp">·</span>rate.<span class="dp">·</span>`lr`<span class="dp">·</span>is<span class="dp">·</span>included<span class="dp">·</span>for<span class="dp">·</span>backward</td><td class="diffline">133 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>decay<span class="dp">·</span>of<span class="dp">·</span>learning<span class="dp">·</span>rate.<span class="dp">·</span>`lr`<span class="dp">·</span>is<span class="dp">·</span>included<span class="dp">·</span>for<span class="dp">·</span>backward</td></tr>
<tr class="diffunmodified"><td class="diffline">136 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>compatibility,<span class="dp">·</span>recommended<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>`learning_rate`<span class="dp">·</span>instead.</td><td class="diffline">134 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>compatibility,<span class="dp">·</span>recommended<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>`learning_rate`<span class="dp">·</span>instead.</td></tr>
<tr class="diffunmodified"><td class="diffline">137 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;&quot;&quot;</td><td class="diffline">135 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;&quot;&quot;</td></tr>
<tr class="diffdeleted"><td class="diffline">138 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self.optimizer<span class="dp">·</span>=<span class="dp">·</span>optimizer</td><td colspan="2"> </td></tr>
<tr class="diffchanged"><td class="diffline">139 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self.<del>_</del>optimizer<span class="dp">·</span>=<span class="dp">·</span>tf.keras.optimizers.get(optimizer)</td><td class="diffline">136 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self.optimizer<span class="dp">·</span>=<span class="dp">·</span>tf.keras.optimizers.get(optimizer)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">137 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self.accum_steps<span class="dp">·</span>=<span class="dp">·</span>accum_steps</td></tr>
<tr class="diffunmodified"><td class="diffline">140 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self.reduction<span class="dp">·</span>=<span class="dp">·</span>reduction</td><td class="diffline">138 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self.reduction<span class="dp">·</span>=<span class="dp">·</span>reduction</td></tr>
<tr class="diffdeleted"><td class="diffline">141 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self._gradients<span class="dp">·</span>=<span class="dp">·</span>[]</td><td colspan="2"> </td></tr>
<tr class="diffdeleted"><td class="diffline">142 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self._accum_steps<span class="dp">·</span>=<span class="dp">·</span>accum_steps</td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">143 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>super().__init__(name,<span class="dp">·</span>**kwargs)</td><td class="diffline">139 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>super().__init__(name,<span class="dp">·</span>**kwargs)</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">144 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>_create_slots(self,<span class="dp">·</span>var_list):</td><td class="diffline">140 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>_create_slots(self,<span class="dp">·</span>var_list):</td></tr>
<tr class="diffchanged"><td class="diffline">145 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self.<del>_</del>optimizer._create_slots(var_list=var_list)</td><td class="diffline">141 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self.optimizer._create_slots(var_list=var_list)</td></tr>
<tr class="diffunmodified"><td class="diffline">146 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>for<span class="dp">·</span>var<span class="dp">·</span>in<span class="dp">·</span>var_list:</td><td class="diffline">142 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>for<span class="dp">·</span>var<span class="dp">·</span>in<span class="dp">·</span>var_list:</td></tr>
<tr class="diffunmodified"><td class="diffline">147 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self.add_slot(var,<span class="dp">·</span>&quot;ga&quot;)</td><td class="diffline">143 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self.add_slot(var,<span class="dp">·</span>&quot;ga&quot;)</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">148 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self._gradients<span class="dp">·</span>=<span class="dp">·</span>[self.get_slot(var,<span class="dp">·</span>&quot;ga&quot;)<span class="dp">·</span>for<span class="dp">·</span>var<span class="dp">·</span>in<span class="dp">·</span>var_list]</td><td class="diffline">144 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self._gradients<span class="dp">·</span>=<span class="dp">·</span>[self.get_slot(var,<span class="dp">·</span>&quot;ga&quot;)<span class="dp">·</span>for<span class="dp">·</span>var<span class="dp">·</span>in<span class="dp">·</span>var_list]</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">149 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>@property</td><td class="diffline">145 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>@property</td></tr>
<tr class="diffunmodified"><td class="diffline">150 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>gradients(self):</td><td class="diffline">146 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>gradients(self):</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 158, 77 lines modified</td><td colspan="2">Offset 154, 77 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">158 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td><td class="diffline">154 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td></tr>
<tr class="diffunmodified"><td class="diffline">159 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>return<span class="dp">·</span>list(</td><td class="diffline">155 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>return<span class="dp">·</span>list(</td></tr>
<tr class="diffunmodified"><td class="diffline">160 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>gradient.read_value()<span class="dp">·</span>if<span class="dp">·</span>gradient<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>None<span class="dp">·</span>else<span class="dp">·</span>gradient</td><td class="diffline">156 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>gradient.read_value()<span class="dp">·</span>if<span class="dp">·</span>gradient<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>None<span class="dp">·</span>else<span class="dp">·</span>gradient</td></tr>
<tr class="diffunmodified"><td class="diffline">161 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>in<span class="dp">·</span>self._gradients</td><td class="diffline">157 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>in<span class="dp">·</span>self._gradients</td></tr>
<tr class="diffunmodified"><td class="diffline">162 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td><td class="diffline">158 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">163 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>apply_gradients(self,<span class="dp">·</span>grads_and_vars,<span class="dp">·</span>name=None,<span class="dp">·</span>**kwargs):</td><td class="diffline">159 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>apply_gradients(self,<span class="dp">·</span>grads_and_vars,<span class="dp">·</span>name=None,<span class="dp">·</span>**kwargs):</td></tr>
<tr class="diffchanged"><td class="diffline">164 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self.<del>_</del>optimizer._iterations<span class="dp">·</span>=<span class="dp">·</span>self.iterations</td><td class="diffline">160 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self.optimizer._iterations<span class="dp">·</span>=<span class="dp">·</span>self.iterations</td></tr>
<tr class="diffunmodified"><td class="diffline">165 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>return<span class="dp">·</span>super().apply_gradients(grads_and_vars,<span class="dp">·</span>name,<span class="dp">·</span>**kwargs)</td><td class="diffline">161 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>return<span class="dp">·</span>super().apply_gradients(grads_and_vars,<span class="dp">·</span>name,<span class="dp">·</span>**kwargs)</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">166 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>@tf.function</td><td class="diffline">162 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>@tf.function</td></tr>
<tr class="diffunmodified"><td class="diffline">167 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>_resource_apply_dense(self,<span class="dp">·</span>grad,<span class="dp">·</span>var,<span class="dp">·</span>apply_state=None):</td><td class="diffline">163 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>_resource_apply_dense(self,<span class="dp">·</span>grad,<span class="dp">·</span>var,<span class="dp">·</span>apply_state=None):</td></tr>
<tr class="diffunmodified"><td class="diffline">168 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_gradient<span class="dp">·</span>=<span class="dp">·</span>self.get_slot(var,<span class="dp">·</span>&quot;ga&quot;)</td><td class="diffline">164 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_gradient<span class="dp">·</span>=<span class="dp">·</span>self.get_slot(var,<span class="dp">·</span>&quot;ga&quot;)</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">169 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>if<span class="dp">·</span>accum_gradient<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>None<span class="dp">·</span>and<span class="dp">·</span>grad<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>None:</td><td class="diffline">165 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>if<span class="dp">·</span>accum_gradient<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>None<span class="dp">·</span>and<span class="dp">·</span>grad<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>None:</td></tr>
<tr class="diffunmodified"><td class="diffline">170 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>if<span class="dp">·</span>self.reduction<span class="dp">·</span>==<span class="dp">·</span>&quot;MEAN&quot;:</td><td class="diffline">166 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>if<span class="dp">·</span>self.reduction<span class="dp">·</span>==<span class="dp">·</span>&quot;MEAN&quot;:</td></tr>
<tr class="diffchanged"><td class="diffline">171 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>grad<span class="dp">·</span>/=<span class="dp">·</span>tf.cast(self.<del>_</del>accum_steps,<span class="dp">·</span>grad.dtype)</td><td class="diffline">167 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>grad<span class="dp">·</span>/=<span class="dp">·</span>tf.cast(self.accum_steps,<span class="dp">·</span>grad.dtype)</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">172 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_gradient.assign_add(</td><td class="diffline">168 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_gradient.assign_add(</td></tr>
<tr class="diffunmodified"><td class="diffline">173 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>grad,<span class="dp">·</span>use_locking=self._use_locking,<span class="dp">·</span>read_value=False</td><td class="diffline">169 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>grad,<span class="dp">·</span>use_locking=self._use_locking,<span class="dp">·</span>read_value=False</td></tr>
<tr class="diffunmodified"><td class="diffline">174 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td><td class="diffline">170 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">175 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>_apply():</td><td class="diffline">171 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>_apply():</td></tr>
<tr class="diffchanged"><td class="diffline">176 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>if<span class="dp">·</span>&quot;apply_state&quot;<span class="dp">·</span>in<span class="dp">·</span>self.<del>_</del>optimizer._dense_apply_args:</td><td class="diffline">172 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>if<span class="dp">·</span>&quot;apply_state&quot;<span class="dp">·</span>in<span class="dp">·</span>self.optimizer._dense_apply_args:</td></tr>
<tr class="diffchanged"><td class="diffline">177 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>train_op<span class="dp">·</span>=<span class="dp">·</span>self.<del>_</del>optimizer._resource_apply_dense(</td><td class="diffline">173 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>train_op<span class="dp">·</span>=<span class="dp">·</span>self.optimizer._resource_apply_dense(</td></tr>
<tr class="diffunmodified"><td class="diffline">178 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_gradient.read_value(),<span class="dp">·</span>var,<span class="dp">·</span>apply_state=apply_state</td><td class="diffline">174 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_gradient.read_value(),<span class="dp">·</span>var,<span class="dp">·</span>apply_state=apply_state</td></tr>
<tr class="diffunmodified"><td class="diffline">179 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td><td class="diffline">175 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td></tr>
<tr class="diffunmodified"><td class="diffline">180 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>else:</td><td class="diffline">176 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>else:</td></tr>
<tr class="diffchanged"><td class="diffline">181 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>train_op<span class="dp">·</span>=<span class="dp">·</span>self.<del>_</del>optimizer._resource_apply_dense(</td><td class="diffline">177 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>train_op<span class="dp">·</span>=<span class="dp">·</span>self.optimizer._resource_apply_dense(</td></tr>
<tr class="diffunmodified"><td class="diffline">182 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_gradient.read_value(),<span class="dp">·</span>var</td><td class="diffline">178 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_gradient.read_value(),<span class="dp">·</span>var</td></tr>
<tr class="diffunmodified"><td class="diffline">183 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td><td class="diffline">179 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td></tr>
<tr class="diffunmodified"><td class="diffline">184 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>reset_op<span class="dp">·</span>=<span class="dp">·</span>accum_gradient.assign(</td><td class="diffline">180 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>reset_op<span class="dp">·</span>=<span class="dp">·</span>accum_gradient.assign(</td></tr>
<tr class="diffunmodified"><td class="diffline">185 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>tf.zeros_like(accum_gradient),</td><td class="diffline">181 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>tf.zeros_like(accum_gradient),</td></tr>
<tr class="diffunmodified"><td class="diffline">186 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>use_locking=self._use_locking,</td><td class="diffline">182 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>use_locking=self._use_locking,</td></tr>
<tr class="diffunmodified"><td class="diffline">187 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>read_value=False,</td><td class="diffline">183 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>read_value=False,</td></tr>
<tr class="diffunmodified"><td class="diffline">188 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td><td class="diffline">184 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td></tr>
<tr class="diffunmodified"><td class="diffline">189 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>return<span class="dp">·</span>tf.group(train_op,<span class="dp">·</span>reset_op)</td><td class="diffline">185 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>return<span class="dp">·</span>tf.group(train_op,<span class="dp">·</span>reset_op)</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">190 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>apply_op<span class="dp">·</span>=<span class="dp">·</span>tf.cond(</td><td class="diffline">186 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>apply_op<span class="dp">·</span>=<span class="dp">·</span>tf.cond(</td></tr>
<tr class="diffchanged"><td class="diffline">191 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(self.iterations<span class="dp">·</span>+<span class="dp">·</span>1)<span class="dp">·</span>%<span class="dp">·</span>self.<del>_</del>accum_steps<span class="dp">·</span>==<span class="dp">·</span>0,<span class="dp">·</span>_apply,<span class="dp">·</span>lambda:<span class="dp">·</span>tf.no_op()</td><td class="diffline">187 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>(self.iterations<span class="dp">·</span>+<span class="dp">·</span>1)<span class="dp">·</span>%<span class="dp">·</span>self.accum_steps<span class="dp">·</span>==<span class="dp">·</span>0,<span class="dp">·</span>_apply,<span class="dp">·</span>lambda:<span class="dp">·</span>tf.no_op()</td></tr>
<tr class="diffunmodified"><td class="diffline">192 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td><td class="diffline">188 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td></tr>
<tr class="diffunmodified"><td class="diffline">193 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>return<span class="dp">·</span>apply_op</td><td class="diffline">189 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>return<span class="dp">·</span>apply_op</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">194 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>@tf.function</td><td class="diffline">190 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>@tf.function</td></tr>
<tr class="diffchanged"><td class="diffline">195 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>_resource_apply_sparse(self,<span class="dp">·</span>grad<del>:<span class="dp">·</span>types.TensorLike</del>,<span class="dp">·</span>var,<span class="dp">·</span>indices,<span class="dp">·</span>apply_state):</td><td class="diffline">191 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>_resource_apply_sparse(self,<span class="dp">·</span>grad,<span class="dp">·</span>var,<span class="dp">·</span>indices,<span class="dp">·</span>apply_state):</td></tr>
<tr class="diffunmodified"><td class="diffline">196 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_gradient<span class="dp">·</span>=<span class="dp">·</span>self.get_slot(var,<span class="dp">·</span>&quot;ga&quot;)</td><td class="diffline">192 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_gradient<span class="dp">·</span>=<span class="dp">·</span>self.get_slot(var,<span class="dp">·</span>&quot;ga&quot;)</td></tr>
<tr class="diffunmodified"><td class="diffline">197 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>if<span class="dp">·</span>accum_gradient<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>None<span class="dp">·</span>and<span class="dp">·</span>grad<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>None:</td><td class="diffline">193 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>if<span class="dp">·</span>accum_gradient<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>None<span class="dp">·</span>and<span class="dp">·</span>grad<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>None:</td></tr>
<tr class="diffunmodified"><td class="diffline">198 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self._resource_scatter_add(accum_gradient,<span class="dp">·</span>indices,<span class="dp">·</span>grad)</td><td class="diffline">194 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>self._resource_scatter_add(accum_gradient,<span class="dp">·</span>indices,<span class="dp">·</span>grad)</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">199 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>_apply():</td><td class="diffline">195 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>def<span class="dp">·</span>_apply():</td></tr>
<tr class="diffchanged"><td class="diffline">200 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>if<span class="dp">·</span>&quot;apply_state&quot;<span class="dp">·</span>in<span class="dp">·</span>self.<del>_</del>optimizer._sparse_apply_args:</td><td class="diffline">196 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>if<span class="dp">·</span>&quot;apply_state&quot;<span class="dp">·</span>in<span class="dp">·</span>self.optimizer._sparse_apply_args:</td></tr>
<tr class="diffchanged"><td class="diffline">201 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>train_op<span class="dp">·</span>=<span class="dp">·</span>self.<del>_</del>optimizer._resource_apply_sparse(</td><td class="diffline">197 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>train_op<span class="dp">·</span>=<span class="dp">·</span>self.optimizer._resource_apply_sparse(</td></tr>
<tr class="diffunmodified"><td class="diffline">202 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_gradient.sparse_read(indices),</td><td class="diffline">198 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>accum_gradient.sparse_read(indices),</td></tr>
<tr class="diffunmodified"><td class="diffline">203 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>var,</td><td class="diffline">199 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>var,</td></tr>
<tr class="diffunmodified"><td class="diffline">204 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>indices,</td><td class="diffline">200 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>indices,</td></tr>
<tr class="diffunmodified"><td class="diffline">205 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>apply_state=apply_state,</td><td class="diffline">201 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>apply_state=apply_state,</td></tr>
<tr class="diffunmodified"><td class="diffline">206 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td><td class="diffline">202 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>)</td></tr>
<tr class="error"><td colspan="4">
Max diff block lines reached; 2272/8544 bytes (26.59%) of diff not shown.
</td></tr></table>    </div>
    <div class="difference">
      <div class="diffheader">
      <div class="diffcontrol diffcontrol-double">⊟</div>
      <div><span class="diffsize">147 B</span></div>
      <div><span class="source">gradient-accumulator-0.3.1/gradient_accumulator/agc.py</span> vs.</div>
      <div id="gradient-accumulator--.-.-.tar---gradient-accumulator--.-.--gradient_accumulator-agc.py"><span class="source">gradient-accumulator-0.3.2/gradient_accumulator/agc.py</span>
        <a class="anchor" href="#gradient-accumulator--.-.-.tar---gradient-accumulator--.-.--gradient_accumulator-agc.py">¶</a>
      </div>
      </div>
      <div class="comment">Files identical despite different names
      </div>
    </div>
    <div class="difference">
      <div class="diffheader">
      <div class="diffcontrol diffcontrol-double">⊟</div>
      <div><span class="diffsize">13.3 KB</span></div>
      <div><span class="source">gradient-accumulator-0.3.1/gradient_accumulator.egg-info/PKG-INFO</span> vs.</div>
      <div id="gradient-accumulator--.-.-.tar---gradient-accumulator--.-.--gradient_accumulator.egg-info-PKG-INFO"><span class="source">gradient-accumulator-0.3.2/gradient_accumulator.egg-info/PKG-INFO</span>
        <a class="anchor" href="#gradient-accumulator--.-.-.tar---gradient-accumulator--.-.--gradient_accumulator.egg-info-PKG-INFO">¶</a>
      </div>
      </div>
      <div class="comment">Files 17% similar despite different names
      </div>
<table class="diff">
<colgroup><col class="colines"/><col class="coldiff"/>
<col class="colines"/><col class="coldiff"/></colgroup>
<tr style="display:none;"><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 1, 30 lines modified</td><td colspan="2">Offset 1, 32 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">1 </td><td class="diffpresent">Metadata-Version:<span class="dp">·</span>2.1</td><td class="diffline">1 </td><td class="diffpresent">Metadata-Version:<span class="dp">·</span>2.1</td></tr>
<tr class="diffunmodified"><td class="diffline">2 </td><td class="diffpresent">Name:<span class="dp">·</span>gradient-accumulator</td><td class="diffline">2 </td><td class="diffpresent">Name:<span class="dp">·</span>gradient-accumulator</td></tr>
<tr class="diffchanged"><td class="diffline">3 </td><td class="diffpresent">Version:<span class="dp">·</span>0.3.<del>1</del></td><td class="diffline">3 </td><td class="diffpresent">Version:<span class="dp">·</span>0.3.<ins>2</ins></td></tr>
<tr class="diffunmodified"><td class="diffline">4 </td><td class="diffpresent">Summary:<span class="dp">·</span>Package<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>in<span class="dp">·</span>TensorFlow</td><td class="diffline">4 </td><td class="diffpresent">Summary:<span class="dp">·</span>Package<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>in<span class="dp">·</span>TensorFlow</td></tr>
<tr class="diffunmodified"><td class="diffline">5 </td><td class="diffpresent">Home-page:<span class="dp">·</span>https://github.com/andreped/GradientAccumulator</td><td class="diffline">5 </td><td class="diffpresent">Home-page:<span class="dp">·</span>https://github.com/andreped/GradientAccumulator</td></tr>
<tr class="diffunmodified"><td class="diffline">6 </td><td class="diffpresent">Author:<span class="dp">·</span>André<span class="dp">·</span>Pedersen<span class="dp">·</span>and<span class="dp">·</span>David<span class="dp">·</span>Bouget</td><td class="diffline">6 </td><td class="diffpresent">Author:<span class="dp">·</span>André<span class="dp">·</span>Pedersen<span class="dp">·</span>and<span class="dp">·</span>David<span class="dp">·</span>Bouget</td></tr>
<tr class="diffunmodified"><td class="diffline">7 </td><td class="diffpresent">Author-email:<span class="dp">·</span>andrped94@gmail.com</td><td class="diffline">7 </td><td class="diffpresent">Author-email:<span class="dp">·</span>andrped94@gmail.com</td></tr>
<tr class="diffunmodified"><td class="diffline">8 </td><td class="diffpresent">License:<span class="dp">·</span>UNKNOWN</td><td class="diffline">8 </td><td class="diffpresent">License:<span class="dp">·</span>UNKNOWN</td></tr>
<tr class="diffunmodified"><td class="diffline">9 </td><td class="diffpresent">Description:<span class="dp">·</span>&lt;div<span class="dp">·</span>align=&quot;center&quot;&gt;</td><td class="diffline">9 </td><td class="diffpresent">Description:<span class="dp">·</span>&lt;div<span class="dp">·</span>align=&quot;center&quot;&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">10 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;h1<span class="dp">·</span>align=&quot;center&quot;&gt;GradientAccumulator&lt;/h1&gt;</td><td class="diffline">10 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;h1<span class="dp">·</span>align=&quot;center&quot;&gt;GradientAccumulator&lt;/h1&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">11 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;h3<span class="dp">·</span>align=&quot;center&quot;&gt;Seemless<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>for<span class="dp">·</span>TensorFlow<span class="dp">·</span>2&lt;/h3&gt;</td><td class="diffline">11 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;h3<span class="dp">·</span>align=&quot;center&quot;&gt;Seemless<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>for<span class="dp">·</span>TensorFlow<span class="dp">·</span>2&lt;/h3&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">12 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">12 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">13 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![Pip<span class="dp">·</span>Downloads](https://img.shields.io/pypi/dm/gradient-accumulator?label=pip%20downloads&amp;logo=python)](https://pypi.org/project/gradient-accumulator/)</td><td class="diffline">13 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![Pip<span class="dp">·</span>Downloads](https://img.shields.io/pypi/dm/gradient-accumulator?label=pip%20downloads&amp;logo=python)](https://pypi.org/project/gradient-accumulator/)</td></tr>
<tr class="diffunmodified"><td class="diffline">14 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![PyPI<span class="dp">·</span>version](https://badge.fury.io/py/gradient-accumulator.svg)](https://badge.fury.io/py/gradient-accumulator)</td><td class="diffline">14 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![PyPI<span class="dp">·</span>version](https://badge.fury.io/py/gradient-accumulator.svg)](https://badge.fury.io/py/gradient-accumulator)</td></tr>
<tr class="diffunmodified"><td class="diffline">15 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)</td><td class="diffline">15 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)</td></tr>
<tr class="diffchanged"><td class="diffline">16 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.758<del>1815</del>.svg)](https://doi.org/10.5281/zenodo.758<del>1815</del>)</td><td class="diffline">16 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.758<ins>2309</ins>.svg)](https://doi.org/10.5281/zenodo.758<ins>2309</ins>)</td></tr>
<tr class="diffunmodified"><td class="diffline">17 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![CI](https://github.com/andreped/GradientAccumulator/workflows/CI/badge.svg)](https://github.com/andreped/GradientAccumulator/actions)</td><td class="diffline">17 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![CI](https://github.com/andreped/GradientAccumulator/workflows/CI/badge.svg)](https://github.com/andreped/GradientAccumulator/actions)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">18 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>[![codecov](https://codecov.io/gh/andreped/GradientAccumulator/branch/main/graph/badge.svg?token=MWLK71V750)](https://codecov.io/gh/andreped/GradientAccumulator)</td></tr>
<tr class="diffunmodified"><td class="diffline">18 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">19 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">19 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>**GradientAccumulator**<span class="dp">·</span>was<span class="dp">·</span>developed<span class="dp">·</span>by<span class="dp">·</span>SINTEF<span class="dp">·</span>Health<span class="dp">·</span>due<span class="dp">·</span>to<span class="dp">·</span>the<span class="dp">·</span>lack<span class="dp">·</span>of<span class="dp">·</span>an<span class="dp">·</span>easy-to-use<span class="dp">·</span>method<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>in<span class="dp">·</span>TensorFlow<span class="dp">·</span>2.</td><td class="diffline">20 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>**GradientAccumulator**<span class="dp">·</span>was<span class="dp">·</span>developed<span class="dp">·</span>by<span class="dp">·</span>SINTEF<span class="dp">·</span>Health<span class="dp">·</span>due<span class="dp">·</span>to<span class="dp">·</span>the<span class="dp">·</span>lack<span class="dp">·</span>of<span class="dp">·</span>an<span class="dp">·</span>easy-to-use<span class="dp">·</span>method<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>in<span class="dp">·</span>TensorFlow<span class="dp">·</span>2.</td></tr>
<tr class="diffunmodified"><td class="diffline">20 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">21 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffchanged"><td class="diffline">21 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>The<span class="dp">·</span>package<span class="dp">·</span>is<span class="dp">·</span>available<span class="dp">·</span>on<span class="dp">·</span>PyPI<span class="dp">·</span>and<span class="dp">·</span>is<span class="dp">·</span>compatible<span class="dp">·</span>with<span class="dp">·</span>and<span class="dp">·</span>have<span class="dp">·</span>been<span class="dp">·</span>tested<span class="dp">·</span>against<span class="dp">·</span>TF<span class="dp">·</span><del>&gt;=<span class="dp">·</span></del>2.<del>3</del><span class="dp">·</span>and<span class="dp">·</span>Python<del><span class="dp">·</span>&gt;=<span class="dp">·</span>3.6<span class="dp">·</span>(tested<span class="dp">·</span>with</del><span class="dp">·</span>3.6-3.1<del>0)</del>,<span class="dp">·</span>and<span class="dp">·</span>works<span class="dp">·</span>cross-platform<span class="dp">·</span>(Ubuntu,<span class="dp">·</span>Windows,<span class="dp">·</span>macOS).</td><td class="diffline">22 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>The<span class="dp">·</span>package<span class="dp">·</span>is<span class="dp">·</span>available<span class="dp">·</span>on<span class="dp">·</span>PyPI<span class="dp">·</span>and<span class="dp">·</span>is<span class="dp">·</span>compatible<span class="dp">·</span>with<span class="dp">·</span>and<span class="dp">·</span>have<span class="dp">·</span>been<span class="dp">·</span>tested<span class="dp">·</span>against<span class="dp">·</span><ins>`</ins>TF<span class="dp">·</span><ins>2</ins><ins>.2-</ins>2.<ins>12</ins><ins>`</ins><span class="dp">·</span>and<span class="dp">·</span><ins>`</ins>Python<span class="dp">·</span>3.6-3.1<ins>2`</ins>,<span class="dp">·</span>and<span class="dp">·</span>works<span class="dp">·</span>cross-platform<span class="dp">·</span>(Ubuntu,<span class="dp">·</span>Windows,<span class="dp">·</span>macOS).</td></tr>
<tr class="diffunmodified"><td class="diffline">22 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/div&gt;</td><td class="diffline">23 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/div&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">23 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">24 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">25 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">24 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>##<span class="dp">·</span>What?</td><td class="diffline">26 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>##<span class="dp">·</span>What?</td></tr>
<tr class="diffunmodified"><td class="diffline">25 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Gradient<span class="dp">·</span>accumulation<span class="dp">·</span>(GA)<span class="dp">·</span>enables<span class="dp">·</span>reduced<span class="dp">·</span>GPU<span class="dp">·</span>memory<span class="dp">·</span>consumption<span class="dp">·</span>through<span class="dp">·</span>dividing<span class="dp">·</span>a<span class="dp">·</span>batch<span class="dp">·</span>into<span class="dp">·</span>smaller<span class="dp">·</span>reduced<span class="dp">·</span>batches,<span class="dp">·</span>and<span class="dp">·</span>performing<span class="dp">·</span>gradient<span class="dp">·</span>computation<span class="dp">·</span>either<span class="dp">·</span>in<span class="dp">·</span>a<span class="dp">·</span>distributing<span class="dp">·</span>setting<span class="dp">·</span>across<span class="dp">·</span>multiple<span class="dp">·</span>GPUs<span class="dp">·</span>or<span class="dp">·</span>sequentially<span class="dp">·</span>on<span class="dp">·</span>the<span class="dp">·</span>same<span class="dp">·</span>GPU.<span class="dp">·</span>When<span class="dp">·</span>the<span class="dp">·</span>full<span class="dp">·</span>batch<span class="dp">·</span>is<span class="dp">·</span>processed,<span class="dp">·</span>the<span class="dp">·</span>gradients<span class="dp">·</span>are<span class="dp">·</span>the<span class="dp">·</span>_accumulated_<span class="dp">·</span>to<span class="dp">·</span>produce<span class="dp">·</span>the<span class="dp">·</span>full<span class="dp">·</span>batch<span class="dp">·</span>gradient.</td><td class="diffline">27 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Gradient<span class="dp">·</span>accumulation<span class="dp">·</span>(GA)<span class="dp">·</span>enables<span class="dp">·</span>reduced<span class="dp">·</span>GPU<span class="dp">·</span>memory<span class="dp">·</span>consumption<span class="dp">·</span>through<span class="dp">·</span>dividing<span class="dp">·</span>a<span class="dp">·</span>batch<span class="dp">·</span>into<span class="dp">·</span>smaller<span class="dp">·</span>reduced<span class="dp">·</span>batches,<span class="dp">·</span>and<span class="dp">·</span>performing<span class="dp">·</span>gradient<span class="dp">·</span>computation<span class="dp">·</span>either<span class="dp">·</span>in<span class="dp">·</span>a<span class="dp">·</span>distributing<span class="dp">·</span>setting<span class="dp">·</span>across<span class="dp">·</span>multiple<span class="dp">·</span>GPUs<span class="dp">·</span>or<span class="dp">·</span>sequentially<span class="dp">·</span>on<span class="dp">·</span>the<span class="dp">·</span>same<span class="dp">·</span>GPU.<span class="dp">·</span>When<span class="dp">·</span>the<span class="dp">·</span>full<span class="dp">·</span>batch<span class="dp">·</span>is<span class="dp">·</span>processed,<span class="dp">·</span>the<span class="dp">·</span>gradients<span class="dp">·</span>are<span class="dp">·</span>the<span class="dp">·</span>_accumulated_<span class="dp">·</span>to<span class="dp">·</span>produce<span class="dp">·</span>the<span class="dp">·</span>full<span class="dp">·</span>batch<span class="dp">·</span>gradient.</td></tr>
<tr class="diffunmodified"><td class="diffline">26 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">28 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">27 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;p<span class="dp">·</span>align=&quot;center&quot;&gt;</td><td class="diffline">29 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;p<span class="dp">·</span>align=&quot;center&quot;&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">28 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;img<span class="dp">·</span>src=&quot;assets/grad_accum.png&quot;<span class="dp">·</span>width=&quot;50%&quot;&gt;</td><td class="diffline">30 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;img<span class="dp">·</span>src=&quot;assets/grad_accum.png&quot;<span class="dp">·</span>width=&quot;50%&quot;&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">29 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/p&gt;</td><td class="diffline">31 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/p&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">30 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">32 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffhunk"><td colspan="2">Offset 33, 15 lines modified</td><td colspan="2">Offset 35, 15 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">33 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>In<span class="dp">·</span>TensorFlow<span class="dp">·</span>2,<span class="dp">·</span>there<span class="dp">·</span>did<span class="dp">·</span>not<span class="dp">·</span>exist<span class="dp">·</span>a<span class="dp">·</span>plug-and-play<span class="dp">·</span>method<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>with<span class="dp">·</span>any<span class="dp">·</span>custom<span class="dp">·</span>pipeline.<span class="dp">·</span>Hence,<span class="dp">·</span>we<span class="dp">·</span>have<span class="dp">·</span>implemented<span class="dp">·</span>two<span class="dp">·</span>generic<span class="dp">·</span>TF2-compatible<span class="dp">·</span>approaches:</td><td class="diffline">35 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>In<span class="dp">·</span>TensorFlow<span class="dp">·</span>2,<span class="dp">·</span>there<span class="dp">·</span>did<span class="dp">·</span>not<span class="dp">·</span>exist<span class="dp">·</span>a<span class="dp">·</span>plug-and-play<span class="dp">·</span>method<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>with<span class="dp">·</span>any<span class="dp">·</span>custom<span class="dp">·</span>pipeline.<span class="dp">·</span>Hence,<span class="dp">·</span>we<span class="dp">·</span>have<span class="dp">·</span>implemented<span class="dp">·</span>two<span class="dp">·</span>generic<span class="dp">·</span>TF2-compatible<span class="dp">·</span>approaches:</td></tr>
<tr class="diffunmodified"><td class="diffline">34 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">36 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">35 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>Method<span class="dp">·</span>|<span class="dp">·</span>Usage<span class="dp">·</span>|</td><td class="diffline">37 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>Method<span class="dp">·</span>|<span class="dp">·</span>Usage<span class="dp">·</span>|</td></tr>
<tr class="diffunmodified"><td class="diffline">36 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>-<span class="dp">·</span>|<span class="dp">·</span>-<span class="dp">·</span>|</td><td class="diffline">38 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>-<span class="dp">·</span>|<span class="dp">·</span>-<span class="dp">·</span>|</td></tr>
<tr class="diffunmodified"><td class="diffline">37 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>`GradientAccumulateModel`<span class="dp">·</span>|<span class="dp">·</span>`model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=model.input,<span class="dp">·</span>outputs=model.output)`<span class="dp">·</span>|</td><td class="diffline">39 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>`GradientAccumulateModel`<span class="dp">·</span>|<span class="dp">·</span>`model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=model.input,<span class="dp">·</span>outputs=model.output)`<span class="dp">·</span>|</td></tr>
<tr class="diffunmodified"><td class="diffline">38 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>`GradientAccumulateOptimizer`<span class="dp">·</span>|<span class="dp">·</span>`opt<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateOptimizer(accum_steps=4,<span class="dp">·</span>optimizer=tf.keras.optimizers.SGD(1e-2))`<span class="dp">·</span>|</td><td class="diffline">40 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>|<span class="dp">·</span>`GradientAccumulateOptimizer`<span class="dp">·</span>|<span class="dp">·</span>`opt<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateOptimizer(accum_steps=4,<span class="dp">·</span>optimizer=tf.keras.optimizers.SGD(1e-2))`<span class="dp">·</span>|</td></tr>
<tr class="diffunmodified"><td class="diffline">39 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">41 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffchanged"><td class="diffline">40 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Both<span class="dp">·</span>approaches<span class="dp">·</span>control<span class="dp">·</span>how<span class="dp">·</span>frequently<span class="dp">·</span>the<span class="dp">·</span>weigths<span class="dp">·</span>are<span class="dp">·</span>updated,<span class="dp">·</span>but<span class="dp">·</span>in<span class="dp">·</span>their<span class="dp">·</span>own<span class="dp">·</span>way.<span class="dp">·</span>Approach<span class="dp">·</span>(1)<span class="dp">·</span>is<span class="dp">·</span>for<span class="dp">·</span>single-GPU<span class="dp">·</span>only,<span class="dp">·</span>whereas<span class="dp">·</span>(2)<span class="dp">·</span>supports<span class="dp">·</span>both<span class="dp">·</span>single-GPU<span class="dp">·</span>and<span class="dp">·</span>distributed<span class="dp">·</span>training<span class="dp">·</span>(multi-GPU).</td><td class="diffline">42 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Both<span class="dp">·</span>approaches<span class="dp">·</span>control<span class="dp">·</span>how<span class="dp">·</span>frequently<span class="dp">·</span>the<span class="dp">·</span>weigths<span class="dp">·</span>are<span class="dp">·</span>updated,<span class="dp">·</span>but<span class="dp">·</span>in<span class="dp">·</span>their<span class="dp">·</span>own<span class="dp">·</span>way.<span class="dp">·</span>Approach<span class="dp">·</span>(1)<span class="dp">·</span>is<span class="dp">·</span>for<span class="dp">·</span>single-GPU<span class="dp">·</span>only,<span class="dp">·</span>whereas<span class="dp">·</span>(2)<span class="dp">·</span>supports<span class="dp">·</span>both<span class="dp">·</span>single-GPU<span class="dp">·</span>and<span class="dp">·</span>distributed<span class="dp">·</span>training<span class="dp">·</span>(multi-GPU).<ins><span class="dp">·</span>However,<span class="dp">·</span>note<span class="dp">·</span>that<span class="dp">·</span>(2)<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>yet<span class="dp">·</span>working<span class="dp">·</span>as<span class="dp">·</span>intended.<span class="dp">·</span>Hence,<span class="dp">·</span>use<span class="dp">·</span>(1)<span class="dp">·</span>for<span class="dp">·</span>most<span class="dp">·</span>applications.</ins></td></tr>
<tr class="diffunmodified"><td class="diffline">41 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">43 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">42 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Our<span class="dp">·</span>implementations<span class="dp">·</span>enable<span class="dp">·</span>theoretically<span class="dp">·</span>**infinitely<span class="dp">·</span>large<span class="dp">·</span>batch<span class="dp">·</span>size**,<span class="dp">·</span>with<span class="dp">·</span>**identical<span class="dp">·</span>memory<span class="dp">·</span>consumption**<span class="dp">·</span>as<span class="dp">·</span>for<span class="dp">·</span>a<span class="dp">·</span>regular<span class="dp">·</span>mini<span class="dp">·</span>batch.<span class="dp">·</span>If<span class="dp">·</span>a<span class="dp">·</span>single<span class="dp">·</span>GPU<span class="dp">·</span>is<span class="dp">·</span>used,<span class="dp">·</span>this<span class="dp">·</span>comes<span class="dp">·</span>at<span class="dp">·</span>the<span class="dp">·</span>cost<span class="dp">·</span>of<span class="dp">·</span>increased<span class="dp">·</span>training<span class="dp">·</span>runtime.<span class="dp">·</span>Multiple<span class="dp">·</span>GPUs<span class="dp">·</span>could<span class="dp">·</span>be<span class="dp">·</span>used<span class="dp">·</span>to<span class="dp">·</span>increase<span class="dp">·</span>runtime<span class="dp">·</span>performance.</td><td class="diffline">44 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Our<span class="dp">·</span>implementations<span class="dp">·</span>enable<span class="dp">·</span>theoretically<span class="dp">·</span>**infinitely<span class="dp">·</span>large<span class="dp">·</span>batch<span class="dp">·</span>size**,<span class="dp">·</span>with<span class="dp">·</span>**identical<span class="dp">·</span>memory<span class="dp">·</span>consumption**<span class="dp">·</span>as<span class="dp">·</span>for<span class="dp">·</span>a<span class="dp">·</span>regular<span class="dp">·</span>mini<span class="dp">·</span>batch.<span class="dp">·</span>If<span class="dp">·</span>a<span class="dp">·</span>single<span class="dp">·</span>GPU<span class="dp">·</span>is<span class="dp">·</span>used,<span class="dp">·</span>this<span class="dp">·</span>comes<span class="dp">·</span>at<span class="dp">·</span>the<span class="dp">·</span>cost<span class="dp">·</span>of<span class="dp">·</span>increased<span class="dp">·</span>training<span class="dp">·</span>runtime.<span class="dp">·</span>Multiple<span class="dp">·</span>GPUs<span class="dp">·</span>could<span class="dp">·</span>be<span class="dp">·</span>used<span class="dp">·</span>to<span class="dp">·</span>increase<span class="dp">·</span>runtime<span class="dp">·</span>performance.</td></tr>
<tr class="diffunmodified"><td class="diffline">43 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">45 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">44 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>As<span class="dp">·</span>batch<span class="dp">·</span>normalization<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>natively<span class="dp">·</span>compatible<span class="dp">·</span>with<span class="dp">·</span>GA,<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping<span class="dp">·</span>has<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>as<span class="dp">·</span>an<span class="dp">·</span>alternative.<span class="dp">·</span>We<span class="dp">·</span>have<span class="dp">·</span>also<span class="dp">·</span>added<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>mixed<span class="dp">·</span>precision<span class="dp">·</span>and<span class="dp">·</span>both<span class="dp">·</span>GPU<span class="dp">·</span>and<span class="dp">·</span>TPU<span class="dp">·</span>support.</td><td class="diffline">46 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>As<span class="dp">·</span>batch<span class="dp">·</span>normalization<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>natively<span class="dp">·</span>compatible<span class="dp">·</span>with<span class="dp">·</span>GA,<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping<span class="dp">·</span>has<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>as<span class="dp">·</span>an<span class="dp">·</span>alternative.<span class="dp">·</span>We<span class="dp">·</span>have<span class="dp">·</span>also<span class="dp">·</span>added<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>mixed<span class="dp">·</span>precision<span class="dp">·</span>and<span class="dp">·</span>both<span class="dp">·</span>GPU<span class="dp">·</span>and<span class="dp">·</span>TPU<span class="dp">·</span>support.</td></tr>
<tr class="diffunmodified"><td class="diffline">45 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">47 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">46 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">48 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">47 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>##<span class="dp">·</span>Install</td><td class="diffline">49 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>##<span class="dp">·</span>Install</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 63, 15 lines modified</td><td colspan="2">Offset 65, 15 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">63 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">65 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">64 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>model<span class="dp">·</span>=<span class="dp">·</span>Model(...)</td><td class="diffline">66 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>model<span class="dp">·</span>=<span class="dp">·</span>Model(...)</td></tr>
<tr class="diffunmodified"><td class="diffline">65 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=model.input,<span class="dp">·</span>outputs=model.output)</td><td class="diffline">67 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=model.input,<span class="dp">·</span>outputs=model.output)</td></tr>
<tr class="diffunmodified"><td class="diffline">66 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td><td class="diffline">68 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffunmodified"><td class="diffline">67 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">69 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">68 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Then<span class="dp">·</span>simply<span class="dp">·</span>use<span class="dp">·</span>the<span class="dp">·</span>`model`<span class="dp">·</span>as<span class="dp">·</span>you<span class="dp">·</span>normally<span class="dp">·</span>would!</td><td class="diffline">70 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Then<span class="dp">·</span>simply<span class="dp">·</span>use<span class="dp">·</span>the<span class="dp">·</span>`model`<span class="dp">·</span>as<span class="dp">·</span>you<span class="dp">·</span>normally<span class="dp">·</span>would!</td></tr>
<tr class="diffunmodified"><td class="diffline">69 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">71 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffchanged"><td class="diffline">70 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details<del><span class="dp">·</span>open</del>&gt;</td><td class="diffline">72 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">71 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td><td class="diffline">73 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">72 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">74 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">73 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>Mixed<span class="dp">·</span>precision&lt;/summary&gt;</td><td class="diffline">75 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>Mixed<span class="dp">·</span>precision&lt;/summary&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">74 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">76 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">75 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>There<span class="dp">·</span>has<span class="dp">·</span>also<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>experimental<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>mixed<span class="dp">·</span>precision:</td><td class="diffline">77 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>There<span class="dp">·</span>has<span class="dp">·</span>also<span class="dp">·</span>been<span class="dp">·</span>added<span class="dp">·</span>experimental<span class="dp">·</span>support<span class="dp">·</span>for<span class="dp">·</span>mixed<span class="dp">·</span>precision:</td></tr>
<tr class="diffunmodified"><td class="diffline">76 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td><td class="diffline">78 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffunmodified"><td class="diffline">77 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>from<span class="dp">·</span>tensorflow.keras<span class="dp">·</span>import<span class="dp">·</span>mixed_precision</td><td class="diffline">79 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>from<span class="dp">·</span>tensorflow.keras<span class="dp">·</span>import<span class="dp">·</span>mixed_precision</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 89, 27 lines modified</td><td colspan="2">Offset 91, 64 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">89 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>mixed_precision.set_global_policy(&#x27;mixed_bfloat16&#x27;)</td><td class="diffline">91 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>mixed_precision.set_global_policy(&#x27;mixed_bfloat16&#x27;)</td></tr>
<tr class="diffunmodified"><td class="diffline">90 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td><td class="diffline">92 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffunmodified"><td class="diffline">91 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">93 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">92 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>There<span class="dp">·</span>is<span class="dp">·</span>also<span class="dp">·</span>an<span class="dp">·</span>example<span class="dp">·</span>of<span class="dp">·</span>how<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>with<span class="dp">·</span>mixed<span class="dp">·</span>precision<span class="dp">·</span>[here](https://github.com/andreped/GradientAccumulator/blob/main/tests/test_mixed_precision.py#L58).</td><td class="diffline">94 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>There<span class="dp">·</span>is<span class="dp">·</span>also<span class="dp">·</span>an<span class="dp">·</span>example<span class="dp">·</span>of<span class="dp">·</span>how<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>with<span class="dp">·</span>mixed<span class="dp">·</span>precision<span class="dp">·</span>[here](https://github.com/andreped/GradientAccumulator/blob/main/tests/test_mixed_precision.py#L58).</td></tr>
<tr class="diffunmodified"><td class="diffline">93 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/details&gt;</td><td class="diffline">95 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">94 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">96 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">95 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">97 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffchanged"><td class="diffline">96 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details<del><span class="dp">·</span>open</del>&gt;</td><td class="diffline">98 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">97 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td><td class="diffline">99 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">98 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">100 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">99 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>Distributed<span class="dp">·</span>training<span class="dp">·</span>with<span class="dp">·</span>multiple<span class="dp">·</span>GPUs&lt;/summary&gt;</td><td class="diffline">101 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>Distributed<span class="dp">·</span>training<span class="dp">·</span>with<span class="dp">·</span>multiple<span class="dp">·</span>GPUs&lt;/summary&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">100 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>In<span class="dp">·</span>order<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>multiple<span class="dp">·</span>GPUs,<span class="dp">·</span>you<span class="dp">·</span>will<span class="dp">·</span>have<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>the<span class="dp">·</span>Optimizer<span class="dp">·</span>wrapper:</td><td class="diffline">102 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>In<span class="dp">·</span>order<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>multiple<span class="dp">·</span>GPUs,<span class="dp">·</span>you<span class="dp">·</span>will<span class="dp">·</span>have<span class="dp">·</span>to<span class="dp">·</span>use<span class="dp">·</span>the<span class="dp">·</span>Optimizer<span class="dp">·</span>wrapper:</td></tr>
<tr class="diffunmodified"><td class="diffline">101 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td><td class="diffline">103 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffunmodified"><td class="diffline">102 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>opt<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateOptimizer(accum_steps=4,<span class="dp">·</span>optimizer=tf.keras.optimizers.SGD(1e-2))</td><td class="diffline">104 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>opt<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateOptimizer(accum_steps=4,<span class="dp">·</span>optimizer=tf.keras.optimizers.SGD(1e-2))</td></tr>
<tr class="diffunmodified"><td class="diffline">103 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td><td class="diffline">105 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffunmodified"><td class="diffline">104 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">106 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">105 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Just<span class="dp">·</span>remember<span class="dp">·</span>to<span class="dp">·</span>wrap<span class="dp">·</span>the<span class="dp">·</span>optimizer<span class="dp">·</span>within<span class="dp">·</span>the<span class="dp">·</span>`tf.distribute.MirroredStrategy`.<span class="dp">·</span>For<span class="dp">·</span>an<span class="dp">·</span>example,<span class="dp">·</span>see<span class="dp">·</span>[here](https://github.com/andreped/GradientAccumulator/blob/main/tests/test_optimizer_distribute.py).</td><td class="diffline">107 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Just<span class="dp">·</span>remember<span class="dp">·</span>to<span class="dp">·</span>wrap<span class="dp">·</span>the<span class="dp">·</span>optimizer<span class="dp">·</span>within<span class="dp">·</span>the<span class="dp">·</span>`tf.distribute.MirroredStrategy`.<span class="dp">·</span>For<span class="dp">·</span>an<span class="dp">·</span>example,<span class="dp">·</span>see<span class="dp">·</span>[here](https://github.com/andreped/GradientAccumulator/blob/main/tests/test_optimizer_distribute.py).</td></tr>
<tr class="diffunmodified"><td class="diffline">106 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">108 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">109 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>**DISCLAIMER:<span class="dp">·</span>The<span class="dp">·</span>GradientAccumulateOptimizer<span class="dp">·</span>is<span class="dp">·</span>a<span class="dp">·</span>VERY<span class="dp">·</span>experimental<span class="dp">·</span>feature.<span class="dp">·</span>It<span class="dp">·</span>is<span class="dp">·</span>not<span class="dp">·</span>reaching<span class="dp">·</span>the<span class="dp">·</span>same<span class="dp">·</span>results<span class="dp">·</span>as<span class="dp">·</span>GradientAccumulateModel<span class="dp">·</span>with<span class="dp">·</span>a<span class="dp">·</span>single<span class="dp">·</span>GPU,<span class="dp">·</span>and<span class="dp">·</span>does<span class="dp">·</span>not<span class="dp">·</span>work<span class="dp">·</span>(yet)<span class="dp">·</span>with<span class="dp">·</span>multiple<span class="dp">·</span>GPUs.<span class="dp">·</span>Hence,<span class="dp">·</span>I<span class="dp">·</span>would<span class="dp">·</span>recommend<span class="dp">·</span>using<span class="dp">·</span>GradientAccumulateModel<span class="dp">·</span>with<span class="dp">·</span>a<span class="dp">·</span>single<span class="dp">·</span>GPU<span class="dp">·</span>in<span class="dp">·</span>its<span class="dp">·</span>current<span class="dp">·</span>state.**</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">110 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">111 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/details&gt;</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">112 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">113 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">114 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details&gt;</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">115 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">116 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">117 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>HuggingFace<span class="dp">·</span>:hugs:&lt;/summary&gt;</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">118 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>Note<span class="dp">·</span>that<span class="dp">·</span>HuggingFace<span class="dp">·</span>provides<span class="dp">·</span>a<span class="dp">·</span>variety<span class="dp">·</span>of<span class="dp">·</span>different<span class="dp">·</span>pretrained<span class="dp">·</span>models.<span class="dp">·</span>However,<span class="dp">·</span>it<span class="dp">·</span>was<span class="dp">·</span>observed<span class="dp">·</span>that<span class="dp">·</span>when<span class="dp">·</span>loading<span class="dp">·</span>these<span class="dp">·</span>models<span class="dp">·</span>into<span class="dp">·</span>TensorFlow,<span class="dp">·</span>the<span class="dp">·</span>computational<span class="dp">·</span>graph<span class="dp">·</span>may<span class="dp">·</span>not<span class="dp">·</span>be<span class="dp">·</span>set<span class="dp">·</span>up<span class="dp">·</span>correctly,<span class="dp">·</span>such<span class="dp">·</span>that<span class="dp">·</span>the<span class="dp">·</span>`model.input`<span class="dp">·</span>and<span class="dp">·</span>`model.output`<span class="dp">·</span>exist.</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">119 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">120 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>To<span class="dp">·</span>fix<span class="dp">·</span>this,<span class="dp">·</span>we<span class="dp">·</span>basically<span class="dp">·</span>wrap<span class="dp">·</span>the<span class="dp">·</span>model<span class="dp">·</span>into<span class="dp">·</span>a<span class="dp">·</span>new<span class="dp">·</span>`tf.keras.Model`,<span class="dp">·</span>but<span class="dp">·</span>define<span class="dp">·</span>the<span class="dp">·</span>inputs<span class="dp">·</span>and<span class="dp">·</span>outputs<span class="dp">·</span>ourselves:</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">121 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">122 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>from<span class="dp">·</span>gradient_accumulator<span class="dp">·</span>import<span class="dp">·</span>GradientAccumulateModel</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">123 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>from<span class="dp">·</span>tensorflow.keras.layers<span class="dp">·</span>import<span class="dp">·</span>Input</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">124 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>from<span class="dp">·</span>tensorflow.keras.models<span class="dp">·</span>import<span class="dp">·</span>Model</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">125 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>from<span class="dp">·</span>transformers<span class="dp">·</span>import<span class="dp">·</span>TFx</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">126 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">127 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>#load<span class="dp">·</span>your<span class="dp">·</span>model<span class="dp">·</span>checkpoint</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">128 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>HF_model<span class="dp">·</span>=<span class="dp">·</span>TFx.from_pretrained(checkpoint)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">129 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">130 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>#<span class="dp">·</span>define<span class="dp">·</span>model<span class="dp">·</span>inputs<span class="dp">·</span>and<span class="dp">·</span>outputs<span class="dp">·</span>-&gt;<span class="dp">·</span>for<span class="dp">·</span>different<span class="dp">·</span>models,<span class="dp">·</span>different<span class="dp">·</span>inputs/outputs<span class="dp">·</span>need<span class="dp">·</span>to<span class="dp">·</span>be<span class="dp">·</span>defined</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">131 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>input_ids<span class="dp">·</span>=<span class="dp">·</span>tf.keras.Input(shape=(None,),<span class="dp">·</span>dtype=&#x27;int32&#x27;,<span class="dp">·</span>name=&quot;input_ids&quot;)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">132 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>attention_mask<span class="dp">·</span>=<span class="dp">·</span>tf.keras.Input(shape=(None,),<span class="dp">·</span>dtype=&#x27;int32&#x27;,<span class="dp">·</span>name=&quot;attention_mask&quot;)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">133 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>model_input={&#x27;input_ids&#x27;:<span class="dp">·</span>input_ids,<span class="dp">·</span>&#x27;attention_mask&#x27;:<span class="dp">·</span>attention_mask}</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">134 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">135 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>#create<span class="dp">·</span>a<span class="dp">·</span>new<span class="dp">·</span>Model<span class="dp">·</span>which<span class="dp">·</span>has<span class="dp">·</span>model.input<span class="dp">·</span>and<span class="dp">·</span>model.output<span class="dp">·</span>properties</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">136 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>new_model<span class="dp">·</span>=<span class="dp">·</span>Model(inputs=model_input,<span class="dp">·</span>outputs=HF_model(model_input))</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">137 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">138 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>#create<span class="dp">·</span>the<span class="dp">·</span>GA<span class="dp">·</span>model</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">139 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>model<span class="dp">·</span>=<span class="dp">·</span>GradientAccumulateModel(accum_steps=4,<span class="dp">·</span>inputs=new_model.input,<span class="dp">·</span>outputs=new_model.output)</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">140 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>```</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">141 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">142 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>For<span class="dp">·</span>more<span class="dp">·</span>details,<span class="dp">·</span>see<span class="dp">·</span>[this](https://github.com/andreped/GradientAccumulator/blob/main/notebooks/GA_for_HuggingFace_TF_models.ipynb)<span class="dp">·</span>jupyter<span class="dp">·</span>notebook.</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">143 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">107 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/details&gt;</td><td class="diffline">144 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;/details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">108 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">145 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">146 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">147 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">109 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details&gt;</td><td class="diffline">148 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;details&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">110 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td><td class="diffline">149 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&lt;summary&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">111 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">150 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="diffunmodified"><td class="diffline">112 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>Adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping&lt;/summary&gt;</td><td class="diffline">151 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>####<span class="dp">·</span>Adaptive<span class="dp">·</span>gradient<span class="dp">·</span>clipping&lt;/summary&gt;</td></tr>
<tr class="diffunmodified"><td class="diffline">113 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td><td class="diffline">152 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span></td></tr>
<tr class="error"><td colspan="4">
Max diff block lines reached; 5511/13451 bytes (40.97%) of diff not shown.
</td></tr></table>    </div>
    <div class="difference">
      <div class="diffheader">
      <div class="diffcontrol diffcontrol-double">⊟</div>
      <div><span class="diffsize">1.51 KB</span></div>
      <div><span class="source">gradient-accumulator-0.3.1/setup.py</span> vs.</div>
      <div id="gradient-accumulator--.-.-.tar---gradient-accumulator--.-.--setup.py"><span class="source">gradient-accumulator-0.3.2/setup.py</span>
        <a class="anchor" href="#gradient-accumulator--.-.-.tar---gradient-accumulator--.-.--setup.py">¶</a>
      </div>
      </div>
      <div class="comment">Files 15% similar despite different names
      </div>
<table class="diff">
<colgroup><col class="colines"/><col class="coldiff"/>
<col class="colines"/><col class="coldiff"/></colgroup>
<tr style="display:none;"><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr class="diffhunk"><td colspan="2">Offset 1, 33 lines modified</td><td colspan="2">Offset 1, 34 lines modified</td></tr>
<tr class="diffunmodified"><td class="diffline">1 </td><td class="diffpresent">import<span class="dp">·</span>setuptools</td><td class="diffline">1 </td><td class="diffpresent">import<span class="dp">·</span>setuptools</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">2 </td><td class="diffpresent">with<span class="dp">·</span>open(&quot;README.md&quot;,<span class="dp">·</span>&quot;r&quot;,<span class="dp">·</span>encoding=&quot;utf-8&quot;)<span class="dp">·</span>as<span class="dp">·</span>fh:</td><td class="diffline">2 </td><td class="diffpresent">with<span class="dp">·</span>open(&quot;README.md&quot;,<span class="dp">·</span>&quot;r&quot;,<span class="dp">·</span>encoding=&quot;utf-8&quot;)<span class="dp">·</span>as<span class="dp">·</span>fh:</td></tr>
<tr class="diffunmodified"><td class="diffline">3 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>long_description<span class="dp">·</span>=<span class="dp">·</span>fh.read()</td><td class="diffline">3 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>long_description<span class="dp">·</span>=<span class="dp">·</span>fh.read()</td></tr>
<tr class="diffunmodified"><td colspan="2"> </td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">4 </td><td class="diffpresent">setuptools.setup(</td><td class="diffline">4 </td><td class="diffpresent">setuptools.setup(</td></tr>
<tr class="diffunmodified"><td class="diffline">5 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>name=&quot;gradient-accumulator&quot;,</td><td class="diffline">5 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>name=&quot;gradient-accumulator&quot;,</td></tr>
<tr class="diffchanged"><td class="diffline">6 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>version=&quot;0.3.<del>1</del>&quot;,</td><td class="diffline">6 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>version=&quot;0.3.<ins>2</ins>&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">7 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>author=&quot;André<span class="dp">·</span>Pedersen<span class="dp">·</span>and<span class="dp">·</span>David<span class="dp">·</span>Bouget&quot;,</td><td class="diffline">7 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>author=&quot;André<span class="dp">·</span>Pedersen<span class="dp">·</span>and<span class="dp">·</span>David<span class="dp">·</span>Bouget&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">8 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>author_email=&quot;andrped94@gmail.com&quot;,</td><td class="diffline">8 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>author_email=&quot;andrped94@gmail.com&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">9 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>description=&quot;Package<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>in<span class="dp">·</span>TensorFlow&quot;,</td><td class="diffline">9 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>description=&quot;Package<span class="dp">·</span>for<span class="dp">·</span>gradient<span class="dp">·</span>accumulation<span class="dp">·</span>in<span class="dp">·</span>TensorFlow&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">10 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>long_description=long_description,</td><td class="diffline">10 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>long_description=long_description,</td></tr>
<tr class="diffunmodified"><td class="diffline">11 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>long_description_content_type=&quot;text/markdown&quot;,</td><td class="diffline">11 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>long_description_content_type=&quot;text/markdown&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">12 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>url=&quot;https://github.com/andreped/GradientAccumulator&quot;,</td><td class="diffline">12 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>url=&quot;https://github.com/andreped/GradientAccumulator&quot;,</td></tr>
<tr class="diffchanged"><td class="diffline">13 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>packages=setuptools.find_packages(exclude=(&#x27;tests&#x27;)),</td><td class="diffline">13 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>packages=setuptools.find_packages(exclude=(&#x27;tests&#x27;<ins>,<span class="dp">·</span>&#x27;notebooks&#x27;</ins>)),</td></tr>
<tr class="diffunmodified"><td class="diffline">14 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>install_requires=[</td><td class="diffline">14 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>install_requires=[</td></tr>
<tr class="diffchanged"><td class="diffline">15 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;tensorflow&quot;<del>,</del></td><td class="diffline">15 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;tensorflow&quot;</td></tr>
<tr class="diffdeleted"><td class="diffline">16 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;tensorflow-addons&quot;</td><td colspan="2"> </td></tr>
<tr class="diffunmodified"><td class="diffline">17 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>],</td><td class="diffline">16 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>],</td></tr>
<tr class="diffunmodified"><td class="diffline">18 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>classifiers=[</td><td class="diffline">17 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>classifiers=[</td></tr>
<tr class="diffunmodified"><td class="diffline">19 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Development<span class="dp">·</span>Status<span class="dp">·</span>::<span class="dp">·</span>4<span class="dp">·</span>-<span class="dp">·</span>Beta&quot;,</td><td class="diffline">18 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Development<span class="dp">·</span>Status<span class="dp">·</span>::<span class="dp">·</span>4<span class="dp">·</span>-<span class="dp">·</span>Beta&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">20 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Intended<span class="dp">·</span>Audience<span class="dp">·</span>::<span class="dp">·</span>Developers&quot;,</td><td class="diffline">19 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Intended<span class="dp">·</span>Audience<span class="dp">·</span>::<span class="dp">·</span>Developers&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">21 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Topic<span class="dp">·</span>::<span class="dp">·</span>Scientific/Engineering<span class="dp">·</span>::<span class="dp">·</span>Artificial<span class="dp">·</span>Intelligence&quot;,</td><td class="diffline">20 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Topic<span class="dp">·</span>::<span class="dp">·</span>Scientific/Engineering<span class="dp">·</span>::<span class="dp">·</span>Artificial<span class="dp">·</span>Intelligence&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">22 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Programming<span class="dp">·</span>Language<span class="dp">·</span>::<span class="dp">·</span>Python<span class="dp">·</span>::<span class="dp">·</span>3.6&quot;,</td><td class="diffline">21 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Programming<span class="dp">·</span>Language<span class="dp">·</span>::<span class="dp">·</span>Python<span class="dp">·</span>::<span class="dp">·</span>3.6&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">23 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Programming<span class="dp">·</span>Language<span class="dp">·</span>::<span class="dp">·</span>Python<span class="dp">·</span>::<span class="dp">·</span>3.7&quot;,</td><td class="diffline">22 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Programming<span class="dp">·</span>Language<span class="dp">·</span>::<span class="dp">·</span>Python<span class="dp">·</span>::<span class="dp">·</span>3.7&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">24 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Programming<span class="dp">·</span>Language<span class="dp">·</span>::<span class="dp">·</span>Python<span class="dp">·</span>::<span class="dp">·</span>3.8&quot;,</td><td class="diffline">23 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Programming<span class="dp">·</span>Language<span class="dp">·</span>::<span class="dp">·</span>Python<span class="dp">·</span>::<span class="dp">·</span>3.8&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">25 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Programming<span class="dp">·</span>Language<span class="dp">·</span>::<span class="dp">·</span>Python<span class="dp">·</span>::<span class="dp">·</span>3.9&quot;,</td><td class="diffline">24 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Programming<span class="dp">·</span>Language<span class="dp">·</span>::<span class="dp">·</span>Python<span class="dp">·</span>::<span class="dp">·</span>3.9&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">26 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Programming<span class="dp">·</span>Language<span class="dp">·</span>::<span class="dp">·</span>Python<span class="dp">·</span>::<span class="dp">·</span>3.10&quot;,</td><td class="diffline">25 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Programming<span class="dp">·</span>Language<span class="dp">·</span>::<span class="dp">·</span>Python<span class="dp">·</span>::<span class="dp">·</span>3.10&quot;,</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">26 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Programming<span class="dp">·</span>Language<span class="dp">·</span>::<span class="dp">·</span>Python<span class="dp">·</span>::<span class="dp">·</span>3.11&quot;,</td></tr>
<tr class="diffadded"><td colspan="2"> </td><td class="diffline">27 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Programming<span class="dp">·</span>Language<span class="dp">·</span>::<span class="dp">·</span>Python<span class="dp">·</span>::<span class="dp">·</span>3.12&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">27 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;License<span class="dp">·</span>::<span class="dp">·</span>OSI<span class="dp">·</span>Approved<span class="dp">·</span>::<span class="dp">·</span>MIT<span class="dp">·</span>License&quot;,</td><td class="diffline">28 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;License<span class="dp">·</span>::<span class="dp">·</span>OSI<span class="dp">·</span>Approved<span class="dp">·</span>::<span class="dp">·</span>MIT<span class="dp">·</span>License&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">28 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Operating<span class="dp">·</span>System<span class="dp">·</span>::<span class="dp">·</span>OS<span class="dp">·</span>Independent&quot;</td><td class="diffline">29 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>&quot;Operating<span class="dp">·</span>System<span class="dp">·</span>::<span class="dp">·</span>OS<span class="dp">·</span>Independent&quot;</td></tr>
<tr class="diffunmodified"><td class="diffline">29 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>],</td><td class="diffline">30 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>],</td></tr>
<tr class="diffunmodified"><td class="diffline">30 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>python_requires=&quot;&gt;=3.6&quot;,</td><td class="diffline">31 </td><td class="diffpresent"><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span><span class="dp">·</span>python_requires=&quot;&gt;=3.6&quot;,</td></tr>
<tr class="diffunmodified"><td class="diffline">31 </td><td class="diffpresent">)</td><td class="diffline">32 </td><td class="diffpresent">)</td></tr>
</table>    </div>
  </div>
</div>
<div class="footer">
Generated by
<a href="https://diffoscope.org" rel="noopener noreferrer" target="_blank">
diffoscope</a> 238
</div>
</body>
</html>

