--- tmp/pandas_dq-1.2.tar.gz
+++ tmp/pandas_dq-1.3.tar.gz
├── filetype from file(1)
│ @@ -1 +1 @@
│ -gzip compressed data, was "pandas_dq-1.2.tar", last modified: Mon Apr  3 20:17:06 2023, max compression
│ +gzip compressed data, was "pandas_dq-1.3.tar", last modified: Thu Apr  6 13:45:48 2023, max compression
│   --- pandas_dq-1.2.tar
├── +++ pandas_dq-1.3.tar
│ ├── file list
│ │ @@ -1,15 +1,15 @@
│ │ -drwxrwxrwx   0 ram       (1000) ram       (1000)        0 2023-04-03 20:17:06.734071 pandas_dq-1.2/
│ │ --rwxrwxrwx   0 ram       (1000) ram       (1000)    11357 2023-04-02 23:27:15.000000 pandas_dq-1.2/LICENSE
│ │ --rwxrwxrwx   0 ram       (1000) ram       (1000)      610 2022-04-07 23:06:53.000000 pandas_dq-1.2/MANIFEST.in
│ │ --rwxrwxrwx   0 ram       (1000) ram       (1000)     8894 2023-04-03 20:17:06.730071 pandas_dq-1.2/PKG-INFO
│ │ --rwxrwxrwx   0 ram       (1000) ram       (1000)     7239 2023-04-03 20:10:30.000000 pandas_dq-1.2/README.md
│ │ -drwxrwxrwx   0 ram       (1000) ram       (1000)        0 2023-04-03 20:17:06.710075 pandas_dq-1.2/pandas_dq.egg-info/
│ │ --rwxrwxrwx   0 ram       (1000) ram       (1000)     8894 2023-04-03 20:17:06.000000 pandas_dq-1.2/pandas_dq.egg-info/PKG-INFO
│ │ --rwxrwxrwx   0 ram       (1000) ram       (1000)      232 2023-04-03 20:17:06.000000 pandas_dq-1.2/pandas_dq.egg-info/SOURCES.txt
│ │ --rwxrwxrwx   0 ram       (1000) ram       (1000)        1 2023-04-03 20:17:06.000000 pandas_dq-1.2/pandas_dq.egg-info/dependency_links.txt
│ │ --rwxrwxrwx   0 ram       (1000) ram       (1000)       49 2023-04-03 20:17:06.000000 pandas_dq-1.2/pandas_dq.egg-info/requires.txt
│ │ --rwxrwxrwx   0 ram       (1000) ram       (1000)       10 2023-04-03 20:17:06.000000 pandas_dq-1.2/pandas_dq.egg-info/top_level.txt
│ │ --rwxrwxrwx   0 ram       (1000) ram       (1000)    28221 2023-04-03 20:14:29.000000 pandas_dq-1.2/pandas_dq.py
│ │ --rwxrwxrwx   0 ram       (1000) ram       (1000)       52 2023-04-03 00:50:45.000000 pandas_dq-1.2/requirements.txt
│ │ --rwxrwxrwx   0 ram       (1000) ram       (1000)       38 2023-04-03 20:17:06.734071 pandas_dq-1.2/setup.cfg
│ │ --rwxrwxrwx   0 ram       (1000) ram       (1000)      883 2023-04-03 20:12:28.000000 pandas_dq-1.2/setup.py
│ │ +drwxrwxrwx   0 ram       (1000) ram       (1000)        0 2023-04-06 13:45:48.149118 pandas_dq-1.3/
│ │ +-rwxrwxrwx   0 ram       (1000) ram       (1000)    11357 2023-04-02 23:27:15.000000 pandas_dq-1.3/LICENSE
│ │ +-rwxrwxrwx   0 ram       (1000) ram       (1000)      610 2022-04-07 23:06:53.000000 pandas_dq-1.3/MANIFEST.in
│ │ +-rwxrwxrwx   0 ram       (1000) ram       (1000)     9263 2023-04-06 13:45:48.143108 pandas_dq-1.3/PKG-INFO
│ │ +-rwxrwxrwx   0 ram       (1000) ram       (1000)     7600 2023-04-06 13:42:11.000000 pandas_dq-1.3/README.md
│ │ +drwxrwxrwx   0 ram       (1000) ram       (1000)        0 2023-04-06 13:45:48.108118 pandas_dq-1.3/pandas_dq.egg-info/
│ │ +-rwxrwxrwx   0 ram       (1000) ram       (1000)     9263 2023-04-06 13:45:47.000000 pandas_dq-1.3/pandas_dq.egg-info/PKG-INFO
│ │ +-rwxrwxrwx   0 ram       (1000) ram       (1000)      232 2023-04-06 13:45:47.000000 pandas_dq-1.3/pandas_dq.egg-info/SOURCES.txt
│ │ +-rwxrwxrwx   0 ram       (1000) ram       (1000)        1 2023-04-06 13:45:47.000000 pandas_dq-1.3/pandas_dq.egg-info/dependency_links.txt
│ │ +-rwxrwxrwx   0 ram       (1000) ram       (1000)       49 2023-04-06 13:45:47.000000 pandas_dq-1.3/pandas_dq.egg-info/requires.txt
│ │ +-rwxrwxrwx   0 ram       (1000) ram       (1000)       10 2023-04-06 13:45:47.000000 pandas_dq-1.3/pandas_dq.egg-info/top_level.txt
│ │ +-rwxrwxrwx   0 ram       (1000) ram       (1000)    36614 2023-04-06 13:37:47.000000 pandas_dq-1.3/pandas_dq.py
│ │ +-rwxrwxrwx   0 ram       (1000) ram       (1000)       52 2023-04-03 00:50:45.000000 pandas_dq-1.3/requirements.txt
│ │ +-rwxrwxrwx   0 ram       (1000) ram       (1000)       38 2023-04-06 13:45:48.152119 pandas_dq-1.3/setup.cfg
│ │ +-rwxrwxrwx   0 ram       (1000) ram       (1000)      883 2023-04-06 12:40:45.000000 pandas_dq-1.3/setup.py
│ │   --- pandas_dq-1.2/LICENSE
│ ├── +++ pandas_dq-1.3/LICENSE
│ │┄ Files identical despite different names
│ │   --- pandas_dq-1.2/MANIFEST.in
│ ├── +++ pandas_dq-1.3/MANIFEST.in
│ │┄ Files identical despite different names
│ │   --- pandas_dq-1.2/PKG-INFO
│ ├── +++ pandas_dq-1.3/pandas_dq.egg-info/PKG-INFO
│ │┄ Files 3% similar despite different names
│ │ @@ -1,10 +1,10 @@
│ │  Metadata-Version: 2.1
│ │ -Name: pandas_dq
│ │ -Version: 1.2
│ │ +Name: pandas-dq
│ │ +Version: 1.3
│ │  Summary: Clean your data using a scikit-learn transformer in a single line of code
│ │  Home-page: https://github.com/AutoViML/pandas_dq
│ │  Author: Ram Seshadri
│ │  License: Apache License 2.0
│ │  Description: # pandas_dq
│ │          Analyze and clean your data in a single line of code with a Scikit-Learn compatible Transformer.
│ │          
│ │ @@ -122,16 +122,17 @@
│ │          Once you import it, you can define the object by giving several options such as:
│ │          
│ │          **Arguments**
│ │          
│ │          <b>Caution:</b> X_train and y_train must be pandas Dataframes or pandas Series. I have not tested it on numpy arrays. You can try your luck.
│ │          
│ │          `find_dq` has only 3 arguments:
│ │ -        - `df`: default is a pandas DataFrame.
│ │ +        - `data`: You can provide any kind of file format (string) or even a pandas DataFrame (df). It reads parquet, csv, feather, arrow, all kinds of file formats straight from disk. You just have to tell it the path to the file and the name of the file.
│ │          - `target`: default: `None`. Otherwise, it should be a string name representing the name of a column in df. You can leave it as `None` if you don't want any target related issues.
│ │ +        - `csv_engine`: default is `pandas`. If you want to load your file using any other backend engine such as `arrow` or `parquet` please specify it here.
│ │           - `verbose`: This has 2 possible states:
│ │            - `0` silent output. Great for running where it prints only high level data quality issues.
│ │            - `1` more verbiage. Great for knowing details behind each issue and what the suggestions are.
│ │          
│ │          `Fix_DQ` has slightly more arguments:
│ │          - `quantile`: float (0.75): Define a threshold for IQR for outlier detection. Could be any float between 0 and 1. If quantile is set to `None`, then no outlier detection will take place.
│ │          - `cat_fill_value`: string ("missing"): Define a fill value for missing categories in your object or categorical variables. This is a global default for your entire dataset. I will try to change it to a dictionary so that you can specify different values for different columns.
│ │ ├── html2text {}
│ │ │ @@ -1,8 +1,8 @@
│ │ │ -Metadata-Version: 2.1 Name: pandas_dq Version: 1.2 Summary: Clean your data
│ │ │ +Metadata-Version: 2.1 Name: pandas-dq Version: 1.3 Summary: Clean your data
│ │ │  using a scikit-learn transformer in a single line of code Home-page: https://
│ │ │  github.com/AutoViML/pandas_dq Author: Ram Seshadri License: Apache License 2.0
│ │ │  Description: # pandas_dq Analyze and clean your data in a single line of code
│ │ │  with a Scikit-Learn compatible Transformer. # Table of Contents
│ │ │      * What_is_pandas_dq
│ │ │      * How_to_use_pandas_dq
│ │ │      * How_to_install_pandas_dq
│ │ │ @@ -76,36 +76,40 @@
│ │ │  import find_dq find_dq(df, target=target, verbose=0) ``` ## API
│ │ │  pandas_dq has a very simple API with the following inputs. You need to create a
│ │ │  sklearn-compatible transformer pipeline object by importing Fix_DQ from
│ │ │  pandas_dq library.
│ │ │  Once you import it, you can define the object by giving several options such
│ │ │  as: **Arguments** Caution: X_train and y_train must be pandas Dataframes or
│ │ │  pandas Series. I have not tested it on numpy arrays. You can try your luck.
│ │ │ -`find_dq` has only 3 arguments: - `df`: default is a pandas DataFrame. -
│ │ │ -`target`: default: `None`. Otherwise, it should be a string name representing
│ │ │ -the name of a column in df. You can leave it as `None` if you don't want any
│ │ │ -target related issues. - `verbose`: This has 2 possible states: - `0` silent
│ │ │ -output. Great for running where it prints only high level data quality issues.
│ │ │ -- `1` more verbiage. Great for knowing details behind each issue and what the
│ │ │ -suggestions are. `Fix_DQ` has slightly more arguments: - `quantile`: float
│ │ │ -(0.75): Define a threshold for IQR for outlier detection. Could be any float
│ │ │ -between 0 and 1. If quantile is set to `None`, then no outlier detection will
│ │ │ -take place. - `cat_fill_value`: string ("missing"): Define a fill value for
│ │ │ -missing categories in your object or categorical variables. This is a global
│ │ │ -default for your entire dataset. I will try to change it to a dictionary so
│ │ │ -that you can specify different values for different columns. -
│ │ │ -`num_fill_value`: integer or float (999): Define a fill value for missing
│ │ │ -numbers in your integer or float variables. This is a global default for your
│ │ │ -entire dataset. I will try to change it to a dictionary so that you can specify
│ │ │ -different values for different columns. - `rare_threshold`: float (0.05):
│ │ │ -Define a threshold for rare categories. If a certain category in a column is
│ │ │ -less 5% (say) of samples, then it will considered rare. All rare categories
│ │ │ -will be merged with a category value called "Rare". - `correlation_threshold`:
│ │ │ -float (0.8): Define a correlation limit. Anything above this limit, the
│ │ │ -variable will be dropped.
│ │ │ +`find_dq` has only 3 arguments: - `data`: You can provide any kind of file
│ │ │ +format (string) or even a pandas DataFrame (df). It reads parquet, csv,
│ │ │ +feather, arrow, all kinds of file formats straight from disk. You just have to
│ │ │ +tell it the path to the file and the name of the file. - `target`: default:
│ │ │ +`None`. Otherwise, it should be a string name representing the name of a column
│ │ │ +in df. You can leave it as `None` if you don't want any target related issues.
│ │ │ +- `csv_engine`: default is `pandas`. If you want to load your file using any
│ │ │ +other backend engine such as `arrow` or `parquet` please specify it here. -
│ │ │ +`verbose`: This has 2 possible states: - `0` silent output. Great for running
│ │ │ +where it prints only high level data quality issues. - `1` more verbiage. Great
│ │ │ +for knowing details behind each issue and what the suggestions are. `Fix_DQ`
│ │ │ +has slightly more arguments: - `quantile`: float (0.75): Define a threshold for
│ │ │ +IQR for outlier detection. Could be any float between 0 and 1. If quantile is
│ │ │ +set to `None`, then no outlier detection will take place. - `cat_fill_value`:
│ │ │ +string ("missing"): Define a fill value for missing categories in your object
│ │ │ +or categorical variables. This is a global default for your entire dataset. I
│ │ │ +will try to change it to a dictionary so that you can specify different values
│ │ │ +for different columns. - `num_fill_value`: integer or float (999): Define a
│ │ │ +fill value for missing numbers in your integer or float variables. This is a
│ │ │ +global default for your entire dataset. I will try to change it to a dictionary
│ │ │ +so that you can specify different values for different columns. -
│ │ │ +`rare_threshold`: float (0.05): Define a threshold for rare categories. If a
│ │ │ +certain category in a column is less 5% (say) of samples, then it will
│ │ │ +considered rare. All rare categories will be merged with a category value
│ │ │ +called "Rare". - `correlation_threshold`: float (0.8): Define a correlation
│ │ │ +limit. Anything above this limit, the variable will be dropped.
│ │ │  ## Maintainers * [@AutoViML](https://github.com/AutoViML) ## Contributing See
│ │ │  [the contributing file](CONTRIBUTING.md)! PRs accepted. ## License Apache
│ │ │  License 2.0 Â© 2020 Ram Seshadri ## Note of Gratitude This libray would not
│ │ │  have been possible without the help of ChatGPT and Bard. This library is
│ │ │  dedicated to the thousands of people who worked to create LLM's. ## DISCLAIMER
│ │ │  This project is not an official Google project. It is not supported by Google
│ │ │  and Google specifically disclaims all warranties as to its quality,
│ │   --- pandas_dq-1.2/README.md
│ ├── +++ pandas_dq-1.3/README.md
│ │┄ Files 4% similar despite different names
│ │ @@ -115,16 +115,17 @@
│ │  Once you import it, you can define the object by giving several options such as:
│ │  
│ │  **Arguments**
│ │  
│ │  <b>Caution:</b> X_train and y_train must be pandas Dataframes or pandas Series. I have not tested it on numpy arrays. You can try your luck.
│ │  
│ │  `find_dq` has only 3 arguments:
│ │ -- `df`: default is a pandas DataFrame.
│ │ +- `data`: You can provide any kind of file format (string) or even a pandas DataFrame (df). It reads parquet, csv, feather, arrow, all kinds of file formats straight from disk. You just have to tell it the path to the file and the name of the file.
│ │  - `target`: default: `None`. Otherwise, it should be a string name representing the name of a column in df. You can leave it as `None` if you don't want any target related issues.
│ │ +- `csv_engine`: default is `pandas`. If you want to load your file using any other backend engine such as `arrow` or `parquet` please specify it here.
│ │   - `verbose`: This has 2 possible states:
│ │    - `0` silent output. Great for running where it prints only high level data quality issues.
│ │    - `1` more verbiage. Great for knowing details behind each issue and what the suggestions are.
│ │  
│ │  `Fix_DQ` has slightly more arguments:
│ │  - `quantile`: float (0.75): Define a threshold for IQR for outlier detection. Could be any float between 0 and 1. If quantile is set to `None`, then no outlier detection will take place.
│ │  - `cat_fill_value`: string ("missing"): Define a fill value for missing categories in your object or categorical variables. This is a global default for your entire dataset. I will try to change it to a dictionary so that you can specify different values for different columns.
│ │ ├── html2text {}
│ │ │ @@ -73,36 +73,40 @@
│ │ │  import find_dq find_dq(df, target=target, verbose=0) ``` ## API
│ │ │  pandas_dq has a very simple API with the following inputs. You need to create a
│ │ │  sklearn-compatible transformer pipeline object by importing Fix_DQ from
│ │ │  pandas_dq library.
│ │ │  Once you import it, you can define the object by giving several options such
│ │ │  as: **Arguments** Caution: X_train and y_train must be pandas Dataframes or
│ │ │  pandas Series. I have not tested it on numpy arrays. You can try your luck.
│ │ │ -`find_dq` has only 3 arguments: - `df`: default is a pandas DataFrame. -
│ │ │ -`target`: default: `None`. Otherwise, it should be a string name representing
│ │ │ -the name of a column in df. You can leave it as `None` if you don't want any
│ │ │ -target related issues. - `verbose`: This has 2 possible states: - `0` silent
│ │ │ -output. Great for running where it prints only high level data quality issues.
│ │ │ -- `1` more verbiage. Great for knowing details behind each issue and what the
│ │ │ -suggestions are. `Fix_DQ` has slightly more arguments: - `quantile`: float
│ │ │ -(0.75): Define a threshold for IQR for outlier detection. Could be any float
│ │ │ -between 0 and 1. If quantile is set to `None`, then no outlier detection will
│ │ │ -take place. - `cat_fill_value`: string ("missing"): Define a fill value for
│ │ │ -missing categories in your object or categorical variables. This is a global
│ │ │ -default for your entire dataset. I will try to change it to a dictionary so
│ │ │ -that you can specify different values for different columns. -
│ │ │ -`num_fill_value`: integer or float (999): Define a fill value for missing
│ │ │ -numbers in your integer or float variables. This is a global default for your
│ │ │ -entire dataset. I will try to change it to a dictionary so that you can specify
│ │ │ -different values for different columns. - `rare_threshold`: float (0.05):
│ │ │ -Define a threshold for rare categories. If a certain category in a column is
│ │ │ -less 5% (say) of samples, then it will considered rare. All rare categories
│ │ │ -will be merged with a category value called "Rare". - `correlation_threshold`:
│ │ │ -float (0.8): Define a correlation limit. Anything above this limit, the
│ │ │ -variable will be dropped.
│ │ │ +`find_dq` has only 3 arguments: - `data`: You can provide any kind of file
│ │ │ +format (string) or even a pandas DataFrame (df). It reads parquet, csv,
│ │ │ +feather, arrow, all kinds of file formats straight from disk. You just have to
│ │ │ +tell it the path to the file and the name of the file. - `target`: default:
│ │ │ +`None`. Otherwise, it should be a string name representing the name of a column
│ │ │ +in df. You can leave it as `None` if you don't want any target related issues.
│ │ │ +- `csv_engine`: default is `pandas`. If you want to load your file using any
│ │ │ +other backend engine such as `arrow` or `parquet` please specify it here. -
│ │ │ +`verbose`: This has 2 possible states: - `0` silent output. Great for running
│ │ │ +where it prints only high level data quality issues. - `1` more verbiage. Great
│ │ │ +for knowing details behind each issue and what the suggestions are. `Fix_DQ`
│ │ │ +has slightly more arguments: - `quantile`: float (0.75): Define a threshold for
│ │ │ +IQR for outlier detection. Could be any float between 0 and 1. If quantile is
│ │ │ +set to `None`, then no outlier detection will take place. - `cat_fill_value`:
│ │ │ +string ("missing"): Define a fill value for missing categories in your object
│ │ │ +or categorical variables. This is a global default for your entire dataset. I
│ │ │ +will try to change it to a dictionary so that you can specify different values
│ │ │ +for different columns. - `num_fill_value`: integer or float (999): Define a
│ │ │ +fill value for missing numbers in your integer or float variables. This is a
│ │ │ +global default for your entire dataset. I will try to change it to a dictionary
│ │ │ +so that you can specify different values for different columns. -
│ │ │ +`rare_threshold`: float (0.05): Define a threshold for rare categories. If a
│ │ │ +certain category in a column is less 5% (say) of samples, then it will
│ │ │ +considered rare. All rare categories will be merged with a category value
│ │ │ +called "Rare". - `correlation_threshold`: float (0.8): Define a correlation
│ │ │ +limit. Anything above this limit, the variable will be dropped.
│ │ │  ## Maintainers * [@AutoViML](https://github.com/AutoViML) ## Contributing See
│ │ │  [the contributing file](CONTRIBUTING.md)! PRs accepted. ## License Apache
│ │ │  License 2.0 Â© 2020 Ram Seshadri ## Note of Gratitude This libray would not
│ │ │  have been possible without the help of ChatGPT and Bard. This library is
│ │ │  dedicated to the thousands of people who worked to create LLM's. ## DISCLAIMER
│ │ │  This project is not an official Google project. It is not supported by Google
│ │ │  and Google specifically disclaims all warranties as to its quality,
│ │   --- pandas_dq-1.2/pandas_dq.egg-info/PKG-INFO
│ ├── +++ pandas_dq-1.3/PKG-INFO
│ │┄ Files 4% similar despite different names
│ │ @@ -1,10 +1,10 @@
│ │  Metadata-Version: 2.1
│ │ -Name: pandas-dq
│ │ -Version: 1.2
│ │ +Name: pandas_dq
│ │ +Version: 1.3
│ │  Summary: Clean your data using a scikit-learn transformer in a single line of code
│ │  Home-page: https://github.com/AutoViML/pandas_dq
│ │  Author: Ram Seshadri
│ │  License: Apache License 2.0
│ │  Description: # pandas_dq
│ │          Analyze and clean your data in a single line of code with a Scikit-Learn compatible Transformer.
│ │          
│ │ @@ -122,16 +122,17 @@
│ │          Once you import it, you can define the object by giving several options such as:
│ │          
│ │          **Arguments**
│ │          
│ │          <b>Caution:</b> X_train and y_train must be pandas Dataframes or pandas Series. I have not tested it on numpy arrays. You can try your luck.
│ │          
│ │          `find_dq` has only 3 arguments:
│ │ -        - `df`: default is a pandas DataFrame.
│ │ +        - `data`: You can provide any kind of file format (string) or even a pandas DataFrame (df). It reads parquet, csv, feather, arrow, all kinds of file formats straight from disk. You just have to tell it the path to the file and the name of the file.
│ │          - `target`: default: `None`. Otherwise, it should be a string name representing the name of a column in df. You can leave it as `None` if you don't want any target related issues.
│ │ +        - `csv_engine`: default is `pandas`. If you want to load your file using any other backend engine such as `arrow` or `parquet` please specify it here.
│ │           - `verbose`: This has 2 possible states:
│ │            - `0` silent output. Great for running where it prints only high level data quality issues.
│ │            - `1` more verbiage. Great for knowing details behind each issue and what the suggestions are.
│ │          
│ │          `Fix_DQ` has slightly more arguments:
│ │          - `quantile`: float (0.75): Define a threshold for IQR for outlier detection. Could be any float between 0 and 1. If quantile is set to `None`, then no outlier detection will take place.
│ │          - `cat_fill_value`: string ("missing"): Define a fill value for missing categories in your object or categorical variables. This is a global default for your entire dataset. I will try to change it to a dictionary so that you can specify different values for different columns.
│ │ ├── html2text {}
│ │ │ @@ -1,8 +1,8 @@
│ │ │ -Metadata-Version: 2.1 Name: pandas-dq Version: 1.2 Summary: Clean your data
│ │ │ +Metadata-Version: 2.1 Name: pandas_dq Version: 1.3 Summary: Clean your data
│ │ │  using a scikit-learn transformer in a single line of code Home-page: https://
│ │ │  github.com/AutoViML/pandas_dq Author: Ram Seshadri License: Apache License 2.0
│ │ │  Description: # pandas_dq Analyze and clean your data in a single line of code
│ │ │  with a Scikit-Learn compatible Transformer. # Table of Contents
│ │ │      * What_is_pandas_dq
│ │ │      * How_to_use_pandas_dq
│ │ │      * How_to_install_pandas_dq
│ │ │ @@ -76,36 +76,40 @@
│ │ │  import find_dq find_dq(df, target=target, verbose=0) ``` ## API
│ │ │  pandas_dq has a very simple API with the following inputs. You need to create a
│ │ │  sklearn-compatible transformer pipeline object by importing Fix_DQ from
│ │ │  pandas_dq library.
│ │ │  Once you import it, you can define the object by giving several options such
│ │ │  as: **Arguments** Caution: X_train and y_train must be pandas Dataframes or
│ │ │  pandas Series. I have not tested it on numpy arrays. You can try your luck.
│ │ │ -`find_dq` has only 3 arguments: - `df`: default is a pandas DataFrame. -
│ │ │ -`target`: default: `None`. Otherwise, it should be a string name representing
│ │ │ -the name of a column in df. You can leave it as `None` if you don't want any
│ │ │ -target related issues. - `verbose`: This has 2 possible states: - `0` silent
│ │ │ -output. Great for running where it prints only high level data quality issues.
│ │ │ -- `1` more verbiage. Great for knowing details behind each issue and what the
│ │ │ -suggestions are. `Fix_DQ` has slightly more arguments: - `quantile`: float
│ │ │ -(0.75): Define a threshold for IQR for outlier detection. Could be any float
│ │ │ -between 0 and 1. If quantile is set to `None`, then no outlier detection will
│ │ │ -take place. - `cat_fill_value`: string ("missing"): Define a fill value for
│ │ │ -missing categories in your object or categorical variables. This is a global
│ │ │ -default for your entire dataset. I will try to change it to a dictionary so
│ │ │ -that you can specify different values for different columns. -
│ │ │ -`num_fill_value`: integer or float (999): Define a fill value for missing
│ │ │ -numbers in your integer or float variables. This is a global default for your
│ │ │ -entire dataset. I will try to change it to a dictionary so that you can specify
│ │ │ -different values for different columns. - `rare_threshold`: float (0.05):
│ │ │ -Define a threshold for rare categories. If a certain category in a column is
│ │ │ -less 5% (say) of samples, then it will considered rare. All rare categories
│ │ │ -will be merged with a category value called "Rare". - `correlation_threshold`:
│ │ │ -float (0.8): Define a correlation limit. Anything above this limit, the
│ │ │ -variable will be dropped.
│ │ │ +`find_dq` has only 3 arguments: - `data`: You can provide any kind of file
│ │ │ +format (string) or even a pandas DataFrame (df). It reads parquet, csv,
│ │ │ +feather, arrow, all kinds of file formats straight from disk. You just have to
│ │ │ +tell it the path to the file and the name of the file. - `target`: default:
│ │ │ +`None`. Otherwise, it should be a string name representing the name of a column
│ │ │ +in df. You can leave it as `None` if you don't want any target related issues.
│ │ │ +- `csv_engine`: default is `pandas`. If you want to load your file using any
│ │ │ +other backend engine such as `arrow` or `parquet` please specify it here. -
│ │ │ +`verbose`: This has 2 possible states: - `0` silent output. Great for running
│ │ │ +where it prints only high level data quality issues. - `1` more verbiage. Great
│ │ │ +for knowing details behind each issue and what the suggestions are. `Fix_DQ`
│ │ │ +has slightly more arguments: - `quantile`: float (0.75): Define a threshold for
│ │ │ +IQR for outlier detection. Could be any float between 0 and 1. If quantile is
│ │ │ +set to `None`, then no outlier detection will take place. - `cat_fill_value`:
│ │ │ +string ("missing"): Define a fill value for missing categories in your object
│ │ │ +or categorical variables. This is a global default for your entire dataset. I
│ │ │ +will try to change it to a dictionary so that you can specify different values
│ │ │ +for different columns. - `num_fill_value`: integer or float (999): Define a
│ │ │ +fill value for missing numbers in your integer or float variables. This is a
│ │ │ +global default for your entire dataset. I will try to change it to a dictionary
│ │ │ +so that you can specify different values for different columns. -
│ │ │ +`rare_threshold`: float (0.05): Define a threshold for rare categories. If a
│ │ │ +certain category in a column is less 5% (say) of samples, then it will
│ │ │ +considered rare. All rare categories will be merged with a category value
│ │ │ +called "Rare". - `correlation_threshold`: float (0.8): Define a correlation
│ │ │ +limit. Anything above this limit, the variable will be dropped.
│ │ │  ## Maintainers * [@AutoViML](https://github.com/AutoViML) ## Contributing See
│ │ │  [the contributing file](CONTRIBUTING.md)! PRs accepted. ## License Apache
│ │ │  License 2.0 Â© 2020 Ram Seshadri ## Note of Gratitude This libray would not
│ │ │  have been possible without the help of ChatGPT and Bard. This library is
│ │ │  dedicated to the thousands of people who worked to create LLM's. ## DISCLAIMER
│ │ │  This project is not an official Google project. It is not supported by Google
│ │ │  and Google specifically disclaims all warranties as to its quality,
│ │   --- pandas_dq-1.2/setup.py
│ ├── +++ pandas_dq-1.3/setup.py
│ │┄ Files 0% similar despite different names
│ │ @@ -1,15 +1,15 @@
│ │  import setuptools
│ │  
│ │  with open("README.md", "r", encoding="utf-8") as fh:
│ │      long_description = fh.read()
│ │  
│ │  setuptools.setup(
│ │      name="pandas_dq",
│ │ -    version="1.2",
│ │ +    version="1.3",
│ │      author="Ram Seshadri",
│ │      # author_email="author@example.com",
│ │      description="Clean your data using a scikit-learn transformer in a single line of code",
│ │      long_description=long_description,
│ │      long_description_content_type="text/markdown",
│ │      license='Apache License 2.0',
│ │      url="https://github.com/AutoViML/pandas_dq",
