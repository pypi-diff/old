--- tmp/faciesmapperpro-2.0.3.tar.gz
+++ tmp/faciesmapperpro-2.0.4.tar.gz
├── filetype from file(1)
│ @@ -1 +1 @@
│ -gzip compressed data, was "faciesmapperpro-2.0.3.tar", last modified: Fri Apr  7 11:26:27 2023, max compression
│ +gzip compressed data, was "faciesmapperpro-2.0.4.tar", last modified: Fri Apr  7 14:52:27 2023, max compression
│   --- faciesmapperpro-2.0.3.tar
├── +++ faciesmapperpro-2.0.4.tar
│ ├── file list
│ │ @@ -1,17 +1,17 @@
│ │ -drwxrwxrwx   0        0        0        0 2023-04-07 11:26:27.469118 faciesmapperpro-2.0.3/
│ │ --rw-rw-rw-   0        0        0     1094 2023-03-23 13:11:53.000000 faciesmapperpro-2.0.3/LICENSE
│ │ --rw-rw-rw-   0        0        0       24 2023-03-23 13:24:29.000000 faciesmapperpro-2.0.3/MANIFEST.in
│ │ --rw-rw-rw-   0        0        0      707 2023-04-07 11:26:27.467806 faciesmapperpro-2.0.3/PKG-INFO
│ │ --rw-rw-rw-   0        0        0       66 2023-03-23 13:11:53.000000 faciesmapperpro-2.0.3/README.md
│ │ -drwxrwxrwx   0        0        0        0 2023-04-07 11:26:27.416464 faciesmapperpro-2.0.3/faciesmapperpro/
│ │ --rw-rw-rw-   0        0        0    10136 2023-04-07 11:24:58.000000 faciesmapperpro-2.0.3/faciesmapperpro/data_processor.py
│ │ --rw-rw-rw-   0        0        0       21 2023-03-24 09:17:28.000000 faciesmapperpro-2.0.3/faciesmapperpro/version.py
│ │ -drwxrwxrwx   0        0        0        0 2023-04-07 11:26:27.463118 faciesmapperpro-2.0.3/faciesmapperpro.egg-info/
│ │ --rw-rw-rw-   0        0        0      707 2023-04-07 11:26:27.000000 faciesmapperpro-2.0.3/faciesmapperpro.egg-info/PKG-INFO
│ │ --rw-rw-rw-   0        0        0      310 2023-04-07 11:26:27.000000 faciesmapperpro-2.0.3/faciesmapperpro.egg-info/SOURCES.txt
│ │ --rw-rw-rw-   0        0        0        1 2023-04-07 11:26:27.000000 faciesmapperpro-2.0.3/faciesmapperpro.egg-info/dependency_links.txt
│ │ --rw-rw-rw-   0        0        0       27 2023-04-07 11:26:27.000000 faciesmapperpro-2.0.3/faciesmapperpro.egg-info/requires.txt
│ │ --rw-rw-rw-   0        0        0       16 2023-04-07 11:26:27.000000 faciesmapperpro-2.0.3/faciesmapperpro.egg-info/top_level.txt
│ │ --rw-rw-rw-   0        0        0       26 2023-04-06 10:39:24.000000 faciesmapperpro-2.0.3/requirements.txt
│ │ --rw-rw-rw-   0        0        0       42 2023-04-07 11:26:27.469490 faciesmapperpro-2.0.3/setup.cfg
│ │ --rw-rw-rw-   0        0        0     1031 2023-04-07 11:17:06.000000 faciesmapperpro-2.0.3/setup.py
│ │ +drwxrwxrwx   0        0        0        0 2023-04-07 14:52:27.300550 faciesmapperpro-2.0.4/
│ │ +-rw-rw-rw-   0        0        0     1094 2023-03-23 13:11:53.000000 faciesmapperpro-2.0.4/LICENSE
│ │ +-rw-rw-rw-   0        0        0       24 2023-03-23 13:24:29.000000 faciesmapperpro-2.0.4/MANIFEST.in
│ │ +-rw-rw-rw-   0        0        0      707 2023-04-07 14:52:27.299550 faciesmapperpro-2.0.4/PKG-INFO
│ │ +-rw-rw-rw-   0        0        0       66 2023-03-23 13:11:53.000000 faciesmapperpro-2.0.4/README.md
│ │ +drwxrwxrwx   0        0        0        0 2023-04-07 14:52:27.274550 faciesmapperpro-2.0.4/faciesmapperpro/
│ │ +-rw-rw-rw-   0        0        0    10521 2023-04-07 14:52:03.000000 faciesmapperpro-2.0.4/faciesmapperpro/data_processor.py
│ │ +-rw-rw-rw-   0        0        0       21 2023-03-24 09:17:28.000000 faciesmapperpro-2.0.4/faciesmapperpro/version.py
│ │ +drwxrwxrwx   0        0        0        0 2023-04-07 14:52:27.297551 faciesmapperpro-2.0.4/faciesmapperpro.egg-info/
│ │ +-rw-rw-rw-   0        0        0      707 2023-04-07 14:52:27.000000 faciesmapperpro-2.0.4/faciesmapperpro.egg-info/PKG-INFO
│ │ +-rw-rw-rw-   0        0        0      310 2023-04-07 14:52:27.000000 faciesmapperpro-2.0.4/faciesmapperpro.egg-info/SOURCES.txt
│ │ +-rw-rw-rw-   0        0        0        1 2023-04-07 14:52:27.000000 faciesmapperpro-2.0.4/faciesmapperpro.egg-info/dependency_links.txt
│ │ +-rw-rw-rw-   0        0        0       27 2023-04-07 14:52:27.000000 faciesmapperpro-2.0.4/faciesmapperpro.egg-info/requires.txt
│ │ +-rw-rw-rw-   0        0        0       16 2023-04-07 14:52:27.000000 faciesmapperpro-2.0.4/faciesmapperpro.egg-info/top_level.txt
│ │ +-rw-rw-rw-   0        0        0       26 2023-04-06 10:39:24.000000 faciesmapperpro-2.0.4/requirements.txt
│ │ +-rw-rw-rw-   0        0        0       42 2023-04-07 14:52:27.300550 faciesmapperpro-2.0.4/setup.cfg
│ │ +-rw-rw-rw-   0        0        0     1031 2023-04-07 14:52:01.000000 faciesmapperpro-2.0.4/setup.py
│ │   --- faciesmapperpro-2.0.3/LICENSE
│ ├── +++ faciesmapperpro-2.0.4/LICENSE
│ │┄ Files identical despite different names
│ │   --- faciesmapperpro-2.0.3/PKG-INFO
│ ├── +++ faciesmapperpro-2.0.4/PKG-INFO
│ │┄ Files 1% similar despite different names
│ │ @@ -1,9 +1,9 @@
│ │  Metadata-Version: 2.1
│ │  Name: faciesmapperpro
│ │ -Version: 2.0.3
│ │ +Version: 2.0.4
│ │  Summary: FaciesMapperPro aims to automate the process of facies interpretation in borehole images using deep learning techniques.                     The system is designed to be integrated with Techlog; a software platform developed by SLB for enabling the integration                     of all wellbore-centric data types into multi-discipline workflows including geological data analysis.                    In 2.0.3 I use concurrent programming and also modify the requirements.txt file for easy installation.
│ │  Author: Srv
│ │  Author-email: smukherjee10@slb.com
│ │  Maintainer: Srv
│ │  Maintainer-email: smukherjee10@slb.com
│ │  License-File: LICENSE
│ │   --- faciesmapperpro-2.0.3/faciesmapperpro/data_processor.py
│ ├── +++ faciesmapperpro-2.0.4/faciesmapperpro/data_processor.py
│ │┄ Files 14% similar despite different names
│ │ @@ -3,15 +3,16 @@
│ │  import time
│ │  import io
│ │  
│ │  import dataikuapi
│ │  import numpy as np
│ │  import pandas as pd
│ │  from PIL import Image
│ │ -from multiprocessing import Pool
│ │ +import threading
│ │ +import queue
│ │  
│ │  import TechlogDatabase as db
│ │  
│ │  class DataProcessor:
│ │      def __init__(self, fmi_array, tdep):
│ │          self.fmi_array = fmi_array
│ │          self.tdep = tdep
│ │ @@ -126,74 +127,53 @@
│ │          X_norm *= 255
│ │          
│ │          # Convert to type uint8
│ │          X = X_norm.astype('uint8')   
│ │  
│ │          return df_final, X
│ │      
│ │ -    def _predict_single_image(self, base64_str):
│ │ -        """
│ │ -        Predicts facies for a single image represented as a base64 string
│ │ -        """
│ │ -        client = dataikuapi.APINodeClient("http://136.252.73.83:12000", "faciesmapperpro")
│ │ -        class_labels = ['Mature Paleosol', 'Heterolithic Shale', 'Silt stone', 'Massive Sand', 'Immature Paleosol', 'Heterolithic Sandstone', 'Laminated Sand', 'CrossBedded Sandstone', 'Undefined']
│ │ -
│ │ -        payload = {'input': base64_str}
│ │ -        prediction = client.predict_record("predict-facies", payload)
│ │ -        prediction_result = prediction.get("result", {})
│ │ -        prediction_value = prediction_result.get("prediction")
│ │ -        if prediction_value is not None:
│ │ -            print('prediction value: ', prediction_value)
│ │ -            label = class_labels[int(prediction_value)-1]
│ │ -            print('label: ', label)             
│ │ -            max_prob = max(prediction_result['probas'].values())
│ │ -            predicted_probability = np.round(max_prob, 2) * 100
│ │ -        else:
│ │ -            # handle missing prediction value
│ │ -            print('prediction_value from json is None')
│ │ -            label = "unknown"
│ │ -            predicted_probability = 0
│ │ -
│ │ -        return label, predicted_probability
│ │ -
│ │      @timer_decorator
│ │ -    def predict(self, df, img_data):
│ │ +    def predict(df, img_data):
│ │          """
│ │          This function takes in a dataframe of subsampled images, preprocesses them, and makes predictions using a trained model
│ │          Arguments:
│ │          - df: A pandas dataframe containing subsampled images and their corresponding heights
│ │          - img_data: A numpy array containing the subsampled images
│ │ -        - wellname: Name of the well to create a new zone for
│ │          
│ │          Returns:
│ │          - res_df: A pandas dataframe with predicted facies and corresponding probabilities
│ │          """
│ │          res_df = df.copy()
│ │ +        n_threads = 4
│ │ +        chunk_size = int(img_data.shape[0] / n_threads)
│ │  
│ │ -        # Split img_data into smaller chunks to process in parallel
│ │ -        n_processes = 4 # can adjust based on available CPU cores
│ │ -        chunks = np.array_split(img_data, n_processes)
│ │ -
│ │ -        # Process each chunk in parallel using a multiprocessing.Pool
│ │ -        with Pool(n_processes) as pool:
│ │ -            results = pool.map(
│ │ -                lambda chunk: [self._predict_single_image(
│ │ -                    base64.b64encode(Image.fromarray(img_data_c.astype(np.uint8)).save(
│ │ -                        io.BytesIO(), format='PNG'
│ │ -                    ).getvalue()).decode('utf-8')
│ │ -                ) for img_data_c in chunk], 
│ │ -                chunks
│ │ -            )
│ │ -
│ │ -        # Concatenate results from each process into final output dataframe
│ │ -        predicted_class_labels, predicted_probabilities = [], []
│ │ -        for result in results:
│ │ -            for label, predicted_probability in result:
│ │ -                predicted_class_labels.append(label)
│ │ -                predicted_probabilities.append(predicted_probability)
│ │ +        # Create a queue to store results from each thread
│ │ +        result_queue = queue.Queue()
│ │ +
│ │ +        # Create and start worker threads
│ │ +        threads = []
│ │ +        for i in range(n_threads):
│ │ +            start_idx = i * chunk_size
│ │ +            end_idx = start_idx + chunk_size
│ │ +            img_chunk = img_data[start_idx:end_idx]
│ │ +            thread = threading.Thread(target=predict_worker, args=(df, img_chunk, result_queue))
│ │ +            threads.append(thread)
│ │ +            thread.start()
│ │ +
│ │ +        # Wait for threads to finish
│ │ +        for thread in threads:
│ │ +            thread.join()
│ │ +
│ │ +        # Combine results from each thread into final dataframe
│ │ +        predicted_class_labels = []
│ │ +        predicted_probabilities = []
│ │ +        while not result_queue.empty():
│ │ +            img_chunk, class_labels_chunk, probabilities_chunk = result_queue.get()
│ │ +            predicted_class_labels.extend(class_labels_chunk)
│ │ +            predicted_probabilities.extend(probabilities_chunk)
│ │  
│ │          res_df['predicted_facies'] = predicted_class_labels
│ │          res_df['probability'] = predicted_probabilities
│ │  
│ │          return res_df
│ │      
│ │      def createNewZone(self, df):
│ │ @@ -243,8 +223,40 @@
│ │          # Create dataset and save variable
│ │          db.datasetCreate(wellName, datasetName, 'MD', 'Measured Depth', 'm', reference)
│ │          db.datasetTypeChange(wellName, datasetName, 'interval')
│ │          if db.variableSave(wellName, datasetName, var, 'Zone Name', unit, zones):
│ │              print('The variable %s.%s.%s has been successfully created.'%(wellName, datasetName, var))
│ │          else:
│ │              print('ERROR: The variable %s.%s.%s cannot be created.'%(wellName, datasetName, var))
│ │ +
│ │ +def predict_worker(img_chunk, result_queue):
│ │ +        """
│ │ +        A worker function that makes predictions for a chunk of images and adds the result to a queue.
│ │ +        """
│ │ +        class_labels = ['Mature Paleosol', 'Heterolithic Shale', 'Silt stone', 'Massive Sand', 'Immature Paleosol', 'Heterolithic Sandstone', 'Laminated Sand', 'CrossBedded Sandstone', 'Undefined']
│ │ +
│ │ +        client = dataikuapi.APINodeClient("http://136.252.73.83:12000", "faciesmapperpro")
│ │ +        predicted_class_labels = []
│ │ +        predicted_probabilities = []
│ │ +
│ │ +        for i in range(img_chunk.shape[0]):
│ │ +            img_data_c = (img_chunk[i]).astype(np.uint8)  # convert to uint8
│ │ +            image = Image.fromarray(img_data_c)
│ │ +            buffer = io.BytesIO()
│ │ +            image.save(buffer, format='PNG')
│ │ +            base64_str = base64.b64encode(buffer.getvalue()).decode('utf-8')
│ │ +
│ │ +            payload = {'input': base64_str}
│ │ +            prediction = client.predict_record("predict-facies", payload)
│ │ +            prediction_result = prediction.get("result", {})
│ │ +            prediction_value = prediction_result.get("prediction")
│ │ +            if prediction_value is not None:
│ │ +                label = class_labels[int(prediction_value)-1]
│ │ +                predicted_class_labels.append(label)
│ │ +                max_prob = max(prediction_result['probas'].values())
│ │ +                predicted_probabilities.append(np.round(max_prob, 2) * 100)            
│ │ +            else:
│ │ +                predicted_class_labels.append("unknown")
│ │ +                predicted_probabilities.append(0)
│ │ +
│ │ +        result_queue.put((img_chunk, predicted_class_labels, predicted_probabilities))
│ │   --- faciesmapperpro-2.0.3/faciesmapperpro.egg-info/PKG-INFO
│ ├── +++ faciesmapperpro-2.0.4/faciesmapperpro.egg-info/PKG-INFO
│ │┄ Files 1% similar despite different names
│ │ @@ -1,9 +1,9 @@
│ │  Metadata-Version: 2.1
│ │  Name: faciesmapperpro
│ │ -Version: 2.0.3
│ │ +Version: 2.0.4
│ │  Summary: FaciesMapperPro aims to automate the process of facies interpretation in borehole images using deep learning techniques.                     The system is designed to be integrated with Techlog; a software platform developed by SLB for enabling the integration                     of all wellbore-centric data types into multi-discipline workflows including geological data analysis.                    In 2.0.3 I use concurrent programming and also modify the requirements.txt file for easy installation.
│ │  Author: Srv
│ │  Author-email: smukherjee10@slb.com
│ │  Maintainer: Srv
│ │  Maintainer-email: smukherjee10@slb.com
│ │  License-File: LICENSE
│ │   --- faciesmapperpro-2.0.3/setup.py
│ ├── +++ faciesmapperpro-2.0.4/setup.py
│ │┄ Files 1% similar despite different names
│ │ @@ -3,15 +3,15 @@
│ │  
│ │  # list dependencies from file
│ │  with open('requirements.txt') as f:
│ │      content = f.readlines()
│ │  requirements = [x.strip() for x in content]
│ │  
│ │  setup(name='faciesmapperpro',
│ │ -      version='2.0.3',
│ │ +      version='2.0.4',
│ │        author='Srv',
│ │        author_email='smukherjee10@slb.com',
│ │        maintainer='Srv',
│ │        maintainer_email='smukherjee10@slb.com',
│ │        description="FaciesMapperPro aims to automate the process of facies interpretation in borehole images using deep learning techniques. \
│ │                      The system is designed to be integrated with Techlog; a software platform developed by SLB for enabling the integration \
│ │                      of all wellbore-centric data types into multi-discipline workflows including geological data analysis.\
