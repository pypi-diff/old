# Comparing `tmp/mmpose-1.0.0rc0.tar.gz` & `tmp/mmpose-1.0.0rc1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist/mmpose-1.0.0rc0.tar", last modified: Fri Oct 14 13:06:48 2022, max compression
+gzip compressed data, was "dist/mmpose-1.0.0rc1.tar", last modified: Wed Mar 15 09:51:10 2023, max compression
```

## Comparing `mmpose-1.0.0rc0.tar` & `mmpose-1.0.0rc1.tar`

### file list

```diff
@@ -1,633 +1,740 @@
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/
--rw-r--r--   0 runner    (1001) docker     (121)      198 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (121)    24681 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (121)    21572 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/README.md
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/
--rw-r--r--   0 runner    (1001) docker     (121)     9725 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/300w.py
--rw-r--r--   0 runner    (1001) docker     (121)     2727 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/aflw.py
--rw-r--r--   0 runner    (1001) docker     (121)     4400 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/aic.py
--rw-r--r--   0 runner    (1001) docker     (121)     5415 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/animalpose.py
--rw-r--r--   0 runner    (1001) docker     (121)     4508 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/ap10k.py
--rw-r--r--   0 runner    (1001) docker     (121)     4273 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/atrw.py
--rw-r--r--   0 runner    (1001) docker     (121)     4417 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/campus.py
--rw-r--r--   0 runner    (1001) docker     (121)     5252 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/coco.py
--rw-r--r--   0 runner    (1001) docker     (121)    30735 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/coco_wholebody.py
--rw-r--r--   0 runner    (1001) docker     (121)    11174 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/coco_wholebody_face.py
--rw-r--r--   0 runner    (1001) docker     (121)     4998 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/coco_wholebody_hand.py
--rw-r--r--   0 runner    (1001) docker     (121)     3920 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/cofw.py
--rw-r--r--   0 runner    (1001) docker     (121)     4341 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/crowdpose.py
--rw-r--r--   0 runner    (1001) docker     (121)     1951 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/deepfashion_full.py
--rw-r--r--   0 runner    (1001) docker     (121)     1292 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/deepfashion_lower.py
--rw-r--r--   0 runner    (1001) docker     (121)     1610 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/deepfashion_upper.py
--rw-r--r--   0 runner    (1001) docker     (121)     7150 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/fly.py
--rw-r--r--   0 runner    (1001) docker     (121)     4879 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/freihand2d.py
--rw-r--r--   0 runner    (1001) docker     (121)     4589 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/h36m.py
--rw-r--r--   0 runner    (1001) docker     (121)    31008 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/halpe.py
--rw-r--r--   0 runner    (1001) docker     (121)     5586 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/horse10.py
--rw-r--r--   0 runner    (1001) docker     (121)     4773 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/interhand2d.py
--rw-r--r--   0 runner    (1001) docker     (121)    13089 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/interhand3d.py
--rw-r--r--   0 runner    (1001) docker     (121)     4056 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/jhmdb.py
--rw-r--r--   0 runner    (1001) docker     (121)     7793 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/locust.py
--rw-r--r--   0 runner    (1001) docker     (121)     5364 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/macaque.py
--rw-r--r--   0 runner    (1001) docker     (121)     4684 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/mhp.py
--rw-r--r--   0 runner    (1001) docker     (121)     4307 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/mpi_inf_3dhp.py
--rw-r--r--   0 runner    (1001) docker     (121)     4610 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/mpii.py
--rw-r--r--   0 runner    (1001) docker     (121)    10582 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/mpii_trb.py
--rw-r--r--   0 runner    (1001) docker     (121)     5316 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/ochuman.py
--rw-r--r--   0 runner    (1001) docker     (121)     4776 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/onehand10k.py
--rw-r--r--   0 runner    (1001) docker     (121)     5000 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/panoptic_body3d.py
--rw-r--r--   0 runner    (1001) docker     (121)     4817 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/panoptic_hand2d.py
--rw-r--r--   0 runner    (1001) docker     (121)     5116 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/posetrack18.py
--rw-r--r--   0 runner    (1001) docker     (121)     5364 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/rhd2d.py
--rw-r--r--   0 runner    (1001) docker     (121)     4416 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/shelf.py
--rw-r--r--   0 runner    (1001) docker     (121)    14292 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/wflw.py
--rw-r--r--   0 runner    (1001) docker     (121)     2237 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/zebra.py
--rw-r--r--   0 runner    (1001) docker     (121)     1194 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/default_runtime.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/
--rw-r--r--   0 runner    (1001) docker     (121)     4198 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_hrnet-w32_8xb64-210e_animalpose-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4198 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_hrnet-w48_8xb64-210e_animalpose-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3247 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res101_8xb64-210e_animalpose-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3247 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res152_8xb32-210e_animalpose-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3245 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res50_8xb64-210e_animalpose-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/
--rw-r--r--   0 runner    (1001) docker     (121)     4850 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_hrnet-w32_8xb64-210e_ap10k-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4850 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_hrnet-w48_8xb64-210e_ap10k-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3899 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_res101_8xb64-210e_ap10k-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3897 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_res50_8xb64-210e_ap10k-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/
--rw-r--r--   0 runner    (1001) docker     (121)     3337 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res101_8xb64-210e_locust-160x160.py
--rw-r--r--   0 runner    (1001) docker     (121)     3337 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res152_8xb32-210e_locust-160x160.py
--rw-r--r--   0 runner    (1001) docker     (121)     3335 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res50_8xb64-210e_locust-160x160.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/
--rw-r--r--   0 runner    (1001) docker     (121)     3332 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res101_8xb64-210e_zebra-160x160.py
--rw-r--r--   0 runner    (1001) docker     (121)     3332 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res152_8xb32-210e_zebra-160x160.py
--rw-r--r--   0 runner    (1001) docker     (121)     3330 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res50_8xb64-210e_zebra-160x160.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/integral_regression/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/
--rw-r--r--   0 runner    (1001) docker     (121)     3813 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_8xb64-210e_coco-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3850 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_debias-8xb64-210e_coco-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3811 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_dsnt-8xb64-210e_coco-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/simcc/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/
--rw-r--r--   0 runner    (1001) docker     (121)     3612 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_mobilenetv2_wo-deconv-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3512 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_res50_8xb32-140e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3425 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_res50_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3529 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_vipnas-mbv3_8xb64-210e_coco-256x192.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/simcc/mpii/
--rw-r--r--   0 runner    (1001) docker     (121)     3432 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/simcc/mpii/simcc_res50_wo-deconv-8xb64-210e_mpii-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/aic/
--rw-r--r--   0 runner    (1001) docker     (121)     4391 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/aic/td-hm_hrnet-w32_8xb64-210e_aic-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3440 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/aic/td-hm_res101_8xb64-210e_aic-256x192.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/
--rw-r--r--   0 runner    (1001) docker     (121)     2390 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/hrnet_coco.yml
--rw-r--r--   0 runner    (1001) docker     (121)     2333 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/litehrnet_coco.yml
--rw-r--r--   0 runner    (1001) docker     (121)     2239 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/mspn_coco.yml
--rw-r--r--   0 runner    (1001) docker     (121)     4284 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_2xmspn50_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4248 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_2xrsn50_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4288 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_3xmspn50_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4252 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_3xrsn50_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4288 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_4xmspn50_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3300 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_alexnet_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3468 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_cpm_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3468 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_cpm_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3378 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hourglass52_8xb32-210e_coco-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3378 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hourglass52_8xb32-210e_coco-384x384.py
--rw-r--r--   0 runner    (1001) docker     (121)     5182 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-base_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     5182 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-base_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     5183 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-small_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     5183 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-small_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4349 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4349 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4793 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_coarsedropout-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4380 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_dark-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4380 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_dark-8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)      153 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_fp16-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4715 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_gridmask-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4500 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_photometric-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4377 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_udp-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4377 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_udp-8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4472 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_udp-regress-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4349 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4349 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4380 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_dark-8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4380 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_dark-8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4377 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_udp-8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4377 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_udp-8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4024 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-18_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4024 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-18_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4024 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-30_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4024 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-30_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3462 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_mobilenetv2_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3462 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_mobilenetv2_8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4259 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_mspn50_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3602 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_pvt-s_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3627 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_pvtv2-b2_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3398 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3398 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3429 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_dark-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3429 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_dark-8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3398 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3398 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3429 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_dark-8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3429 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_dark-8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3396 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3396 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3427 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_dark-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3427 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_dark-8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)      149 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_fp16-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3394 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest101_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3394 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest101_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3394 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest200_8xb16-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3394 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest200_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3394 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest269_8xb16-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3394 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest269_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3392 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest50_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3392 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest50_8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3399 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d101_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3399 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d101_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3399 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d152_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3399 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d152_8xb48-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3397 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d50_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3397 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d50_8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3413 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext101_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3413 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext101_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3413 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext152_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3413 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext152_8xb48-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3398 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext50_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3398 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext50_8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4228 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_rsn18_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4223 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_rsn50_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3489 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet101_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3489 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet101_8xb48-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3487 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet50_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3487 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet50_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3397 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet101_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3397 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet101_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3320 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet152_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3320 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet152_8xb48-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3395 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet50_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3395 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet50_8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3400 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv1_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3400 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv1_8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3409 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv2_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3409 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv2_8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3921 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-b-p4-w7_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3923 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-b-p4-w7_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4231 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-l-p4-w7_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4232 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-l-p4-w7_8xb32-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3914 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-t-p4-w7_8xb32-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3420 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vgg16-bn_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3452 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vipnas-mbv3_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3369 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vipnas-res50_8xb64-210e_coco-256x192.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/
--rw-r--r--   0 runner    (1001) docker     (121)     4398 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_hrnet-w32_8xb64-210e_crowdpose-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3447 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res101_8xb64-210e_crowdpose-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3447 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res101_8xb64-210e_crowdpose-320x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3447 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res152_8xb64-210e_crowdpose-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3445 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res50_8xb64-210e_crowdpose-256x192.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/
--rw-r--r--   0 runner    (1001) docker     (121)     3360 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub1-368x368.py
--rw-r--r--   0 runner    (1001) docker     (121)     3360 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub2-368x368.py
--rw-r--r--   0 runner    (1001) docker     (121)     3360 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub3-368x368.py
--rw-r--r--   0 runner    (1001) docker     (121)     3385 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub1-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3385 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub2-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3385 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub3-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3308 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub1-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3308 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub2-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3308 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub3-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/
--rw-r--r--   0 runner    (1001) docker     (121)     3373 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_cpm_8xb64-210e_mpii-368x368.py
--rw-r--r--   0 runner    (1001) docker     (121)     3205 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hourglass52_8xb32-210e_mpii-384x384.py
--rw-r--r--   0 runner    (1001) docker     (121)     3205 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hourglass52_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4176 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w32_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4207 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w32_dark-8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4176 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w48_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4207 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w48_dark-8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3859 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_litehrnet-18_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3859 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_litehrnet-30_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3260 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_mobilenetv2_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3225 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_res101_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3225 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_res152_8xb32-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3223 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_res50_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3226 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnetv1d101_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3226 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnetv1d152_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3224 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnetv1d50_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3240 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnext152_8xb32-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3316 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_scnet101_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3314 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_scnet50_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3224 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_seresnet101_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3147 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_seresnet152_8xb32-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3222 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_seresnet50_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3227 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_shufflenetv1_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3236 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_shufflenetv2_8xb64-210e_mpii-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/
--rw-r--r--   0 runner    (1001) docker     (121)     4520 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w32_8xb64-20e_posetrack18-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4520 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w32_8xb64-20e_posetrack18-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4520 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w48_8xb64-20e_posetrack18-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4520 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w48_8xb64-20e_posetrack18-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3472 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_res50_8xb64-20e_posetrack18-256x192.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/
--rw-r--r--   0 runner    (1001) docker     (121)     3628 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_mobilenetv2_rle-pretrained-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3406 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res101_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3421 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res101_rle-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3406 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res152_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3421 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res152_rle-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3421 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res152_rle-8xb64-210e_coco-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3404 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3419 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_rle-8xb64-210e_coco-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3583 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_rle-pretrained-8xb64-210e_coco-256x192.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/
--rw-r--r--   0 runner    (1001) docker     (121)     3251 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res101_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3251 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res152_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3249 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res50_8xb64-210e_mpii-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3237 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res50_rle-8xb64-210e_mpii-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/300w/
--rw-r--r--   0 runner    (1001) docker     (121)     4464 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/300w/td-hm_hrnetv2-w18_8xb64-60e_300w-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/aflw/
--rw-r--r--   0 runner    (1001) docker     (121)     4459 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/aflw/td-hm_hrnetv2-w18_8xb64-60e_aflw-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4490 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/aflw/td-hm_hrnetv2-w18_dark-8xb64-60e_aflw-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/
--rw-r--r--   0 runner    (1001) docker     (121)     3282 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hourglass52_8xb32-60e_coco-wholebody-face-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4434 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hrnetv2-w18_8xb32-60e_coco-wholebody-face-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4465 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hrnetv2-w18_dark-8xb32-60e_coco-wholebody-face-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3331 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_mobilenetv2_8xb32-60e_coco-wholebody-face-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3294 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_res50_8xb32-60e_coco-wholebody-face-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3385 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_scnet50_8xb32-60e_coco-wholebody-face-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/cofw/
--rw-r--r--   0 runner    (1001) docker     (121)     4422 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/cofw/td-hm_hrnetv2-w18_8xb64-60e_cofw-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/
--rw-r--r--   0 runner    (1001) docker     (121)     4445 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_8xb64-60e_wflw-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4446 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_awing-8xb64-60e_wflw-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4476 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_dark-8xb64-60e_wflw-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/
--rw-r--r--   0 runner    (1001) docker     (121)     3294 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hourglass52_8xb32-210e_coco-wholebody-hand-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4435 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hrnetv2-w18_8xb32-210e_coco-wholebody-hand-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4466 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hrnetv2-w18_dark-8xb32-210e_coco-wholebody-hand-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3859 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_litehrnet-w18_8xb32-210e_coco-wholebody-hand-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3332 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_mobilenetv2_8xb32-210e_coco-wholebody-hand-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3295 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_res50_8xb32-210e_coco-wholebody-hand-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3386 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_scnet50_8xb32-210e_coco-wholebody-hand-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/freihand2d/
--rw-r--r--   0 runner    (1001) docker     (121)     3724 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/freihand2d/td-hm_res50_8xb64-100e_freihand2d-224x224.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/
--rw-r--r--   0 runner    (1001) docker     (121)     4436 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_8xb64-210e_onehand10k-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4467 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_dark-8xb64-210e_onehand10k-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4436 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_udp-8xb64-210e_onehand10k-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3346 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_mobilenetv2_8xb64-210e_onehand10k-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3309 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_res50_8xb32-210e_onehand10k-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/
--rw-r--r--   0 runner    (1001) docker     (121)     4410 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_8xb64-210e_rhd2d-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4441 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_dark-8xb64-210e_rhd2d-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     4410 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_udp-8xb64-210e_rhd2d-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3320 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_mobilenetv2_8xb64-210e_rhd2d-256x256.py
--rw-r--r--   0 runner    (1001) docker     (121)     3283 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_res50_8xb64-210e_rhd2d-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/onehand10k/
--rw-r--r--   0 runner    (1001) docker     (121)     3296 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/onehand10k/td-reg_res50_8xb64-210e_onehand10k-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/rhd2d/
--rw-r--r--   0 runner    (1001) docker     (121)     3270 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/rhd2d/td-reg_res50_8xb64-210e_rhd2d-256x256.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/
--rw-r--r--   0 runner    (1001) docker     (121)     4367 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_8xb64-210e_coco-wholebody-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4367 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_8xb64-210e_coco-wholebody-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4398 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_dark-8xb64-210e_coco-wholebody-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4367 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_8xb32-210e_coco-wholebody-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     4367 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_8xb32-210e_coco-wholebody-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     4398 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_dark-8xb32-210e_coco-wholebody-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3416 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res101_8xb32-210e_coco-wholebody-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3416 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res101_8xb32-210e_coco-wholebody-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3416 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res152_8xb32-210e_coco-wholebody-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3416 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res152_8xb32-210e_coco-wholebody-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3414 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res50_8xb64-210e_coco-wholebody-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3414 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res50_8xb64-210e_coco-wholebody-384x288.py
--rw-r--r--   0 runner    (1001) docker     (121)     3470 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-mbv3_8xb64-210e_coco-wholebody-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3501 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-mbv3_dark-8xb64-210e_coco-wholebody-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3410 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-res50_8xb64-210e_coco-wholebody-256x192.py
--rw-r--r--   0 runner    (1001) docker     (121)     3441 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-res50_dark-8xb64-210e_coco-wholebody-256x192.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/
--rw-r--r--   0 runner    (1001) docker     (121)     1934 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/image_demo.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/
--rw-r--r--   0 runner    (1001) docker     (121)     9234 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/cascade_rcnn_x101_64x4d_fpn_1class.py
--rw-r--r--   0 runner    (1001) docker     (121)     8608 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/cascade_rcnn_x101_64x4d_fpn_coco.py
--rw-r--r--   0 runner    (1001) docker     (121)     5869 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/faster_rcnn_r50_fpn_1class.py
--rw-r--r--   0 runner    (1001) docker     (121)     6482 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py
--rw-r--r--   0 runner    (1001) docker     (121)     8524 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/mask_rcnn_r50_fpn_2x_coco.py
--rw-r--r--   0 runner    (1001) docker     (121)     4435 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/ssdlite_mobilenetv2-scratch_8xb24-600e_coco.py
--rw-r--r--   0 runner    (1001) docker     (121)     4480 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/yolov3_d53_320_273e_coco.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/mmtracking_cfg/
--rw-r--r--   0 runner    (1001) docker     (121)    11566 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/mmtracking_cfg/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py
--rw-r--r--   0 runner    (1001) docker     (121)    11604 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/mmtracking_cfg/tracktor_faster-rcnn_r50_fpn_4e_mot17-private.py
--rw-r--r--   0 runner    (1001) docker     (121)     6394 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/topdown_demo_with_mmdet.py
--rw-r--r--   0 runner    (1001) docker     (121)     6017 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/topdown_face_demo.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/webcam_cfg/
--rw-r--r--   0 runner    (1001) docker     (121)     5675 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/webcam_cfg/pose_estimation.py
--rw-r--r--   0 runner    (1001) docker     (121)      634 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/webcam_cfg/test_camera.py
--rw-r--r--   0 runner    (1001) docker     (121)     1904 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/demo/webcam_demo.py
--rw-r--r--   0 runner    (1001) docker     (121)      200 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/model-index.yml
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/analysis_tools/
--rw-r--r--   0 runner    (1001) docker     (121)     5567 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/analysis_tools/analyze_logs.py
--rw-r--r--   0 runner    (1001) docker     (121)     3658 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/analysis_tools/get_flops.py
--rw-r--r--   0 runner    (1001) docker     (121)      643 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/analysis_tools/print_config.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/
--rw-r--r--   0 runner    (1001) docker     (121)     4794 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/h36m_to_coco.py
--rw-r--r--   0 runner    (1001) docker     (121)     1649 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/mat2json.py
--rw-r--r--   0 runner    (1001) docker     (121)    13482 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/parse_animalpose_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     2817 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/parse_cofw_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     6251 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/parse_deepposekit_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     5595 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/parse_macaquepose_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)    15559 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/preprocess_h36m.py
--rw-r--r--   0 runner    (1001) docker     (121)    12309 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/preprocess_mpi_inf_3dhp.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/deployment/
--rw-r--r--   0 runner    (1001) docker     (121)     4827 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/deployment/mmpose2torchserve.py
--rw-r--r--   0 runner    (1001) docker     (121)     2709 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/deployment/mmpose_handler.py
--rw-r--r--   0 runner    (1001) docker     (121)     5941 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/deployment/pytorch2onnx.py
--rw-r--r--   0 runner    (1001) docker     (121)     2688 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/deployment/test_torchserver.py
--rw-r--r--   0 runner    (1001) docker     (121)      527 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/dist_test.sh
--rw-r--r--   0 runner    (1001) docker     (121)      490 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/dist_train.sh
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/misc/
--rw-r--r--   0 runner    (1001) docker     (121)     5793 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/misc/browse_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     4658 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/misc/keypoints2coco_without_mmdet.py
--rw-r--r--   0 runner    (1001) docker     (121)     1258 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/misc/publish_model.py
--rw-r--r--   0 runner    (1001) docker     (121)      614 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/slurm_test.sh
--rw-r--r--   0 runner    (1001) docker     (121)      622 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/slurm_train.sh
--rw-r--r--   0 runner    (1001) docker     (121)     4665 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/test.py
--rw-r--r--   0 runner    (1001) docker     (121)     5450 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/.mim/tools/train.py
--rw-r--r--   0 runner    (1001) docker     (121)     1031 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/apis/
--rw-r--r--   0 runner    (1001) docker     (121)      148 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     6533 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/inference.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/
--rw-r--r--   0 runner    (1001) docker     (121)      122 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/
--rw-r--r--   0 runner    (1001) docker     (121)      704 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2348 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/base_visualizer_node.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/helper_nodes/
--rw-r--r--   0 runner    (1001) docker     (121)      244 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/helper_nodes/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     5909 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/helper_nodes/monitor_node.py
--rw-r--r--   0 runner    (1001) docker     (121)     5401 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/helper_nodes/object_assigner_node.py
--rw-r--r--   0 runner    (1001) docker     (121)     4220 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/helper_nodes/recorder_node.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/model_nodes/
--rw-r--r--   0 runner    (1001) docker     (121)      202 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/model_nodes/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     5398 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/model_nodes/detector_node.py
--rw-r--r--   0 runner    (1001) docker     (121)     5455 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/model_nodes/pose_estimator_node.py
--rw-r--r--   0 runner    (1001) docker     (121)    15620 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/node.py
--rw-r--r--   0 runner    (1001) docker     (121)      113 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/registry.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/visualizer_nodes/
--rw-r--r--   0 runner    (1001) docker     (121)      367 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/visualizer_nodes/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     4636 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/visualizer_nodes/bigeye_effect_node.py
--rw-r--r--   0 runner    (1001) docker     (121)     5023 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/visualizer_nodes/notice_board_node.py
--rw-r--r--   0 runner    (1001) docker     (121)     6135 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/visualizer_nodes/object_visualizer_node.py
--rw-r--r--   0 runner    (1001) docker     (121)     5755 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/visualizer_nodes/sunglasses_effect_node.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/utils/
--rw-r--r--   0 runner    (1001) docker     (121)     1021 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     7022 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/utils/buffer.py
--rw-r--r--   0 runner    (1001) docker     (121)     5178 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/utils/event.py
--rw-r--r--   0 runner    (1001) docker     (121)     1005 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/utils/image_capture.py
--rw-r--r--   0 runner    (1001) docker     (121)     6484 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/utils/message.py
--rw-r--r--   0 runner    (1001) docker     (121)    11529 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/utils/misc.py
--rw-r--r--   0 runner    (1001) docker     (121)     6554 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/utils/pose.py
--rw-r--r--   0 runner    (1001) docker     (121)    12158 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/apis/webcam/webcam_executor.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/codecs/
--rw-r--r--   0 runner    (1001) docker     (121)      517 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    21417 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/associative_embedding.py
--rw-r--r--   0 runner    (1001) docker     (121)     2279 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/base.py
--rw-r--r--   0 runner    (1001) docker     (121)     3653 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/integral_regression_label.py
--rw-r--r--   0 runner    (1001) docker     (121)     4570 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/megvii_heatmap.py
--rw-r--r--   0 runner    (1001) docker     (121)     5380 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/msra_heatmap.py
--rw-r--r--   0 runner    (1001) docker     (121)     2992 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/regression_label.py
--rw-r--r--   0 runner    (1001) docker     (121)     9391 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/simcc_label.py
--rw-r--r--   0 runner    (1001) docker     (121)     7307 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/udp_heatmap.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/codecs/utils/
--rw-r--r--   0 runner    (1001) docker     (121)      862 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     6615 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/utils/gaussian_heatmap.py
--rw-r--r--   0 runner    (1001) docker     (121)     2395 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/utils/offset_heatmap.py
--rw-r--r--   0 runner    (1001) docker     (121)     5169 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/utils/post_processing.py
--rw-r--r--   0 runner    (1001) docker     (121)     5629 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/codecs/utils/refinement.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/datasets/
--rw-r--r--   0 runner    (1001) docker     (121)      178 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3080 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/builder.py
--rw-r--r--   0 runner    (1001) docker     (121)      879 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/dataset_wrappers.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/
--rw-r--r--   0 runner    (1001) docker     (121)      338 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/
--rw-r--r--   0 runner    (1001) docker     (121)      539 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3323 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/animalpose_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     5517 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/ap10k_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     3237 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/atrw_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     3651 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/fly_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     3414 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/horse10_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     5368 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/locust_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     3358 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/macaque_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     4768 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/zebra_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/base/
--rw-r--r--   0 runner    (1001) docker     (121)      142 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/base/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    15222 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/base/base_coco_style_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/body/
--rw-r--r--   0 runner    (1001) docker     (121)      693 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/body/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3211 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/body/aic_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     3249 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/body/coco_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     3229 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/body/crowdpose_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     5484 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/body/jhmdb_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     3306 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/body/mhp_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     8272 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/body/mpii_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     6206 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/body/mpii_trb_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     3611 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/body/ochuman_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     3302 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/body/posetrack18_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)    16527 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/body/posetrack18_video_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/face/
--rw-r--r--   0 runner    (1001) docker     (121)      389 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/face/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     5343 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/face/aflw_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     4951 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/face/coco_wholebody_face_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     2879 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/face/cofw_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     4889 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/face/face_300w_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     4867 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/face/wflw_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/fashion/
--rw-r--r--   0 runner    (1001) docker     (121)      134 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/fashion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     5843 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/fashion/deepfashion_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/hand/
--rw-r--r--   0 runner    (1001) docker     (121)      440 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/hand/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     5918 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/hand/coco_wholebody_hand_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     5140 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/hand/freihand_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     3470 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/hand/onehand10k_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     5435 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/hand/panoptic_hand2d_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     3421 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/hand/rhd2d_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     7649 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/wholebody/
--rw-r--r--   0 runner    (1001) docker     (121)      197 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/wholebody/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     5190 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/wholebody/coco_wholebody_dataset.py
--rw-r--r--   0 runner    (1001) docker     (121)     2935 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/datasets/wholebody/halpe_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/datasets/transforms/
--rw-r--r--   0 runner    (1001) docker     (121)      832 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/transforms/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    17356 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/transforms/bottomup_transforms.py
--rw-r--r--   0 runner    (1001) docker     (121)    36009 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/transforms/common_transforms.py
--rw-r--r--   0 runner    (1001) docker     (121)     6389 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/transforms/formatting.py
--rw-r--r--   0 runner    (1001) docker     (121)     2114 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/transforms/loading.py
--rw-r--r--   0 runner    (1001) docker     (121)     4357 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/datasets/transforms/topdown_transforms.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/engine/
--rw-r--r--   0 runner    (1001) docker     (121)       89 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/engine/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/engine/hooks/
--rw-r--r--   0 runner    (1001) docker     (121)      139 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/engine/hooks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     6890 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/engine/hooks/visualization_hook.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/evaluation/
--rw-r--r--   0 runner    (1001) docker     (121)      135 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/evaluation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/evaluation/functional/
--rw-r--r--   0 runner    (1001) docker     (121)      558 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/evaluation/functional/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    11832 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/evaluation/functional/keypoint_eval.py
--rw-r--r--   0 runner    (1001) docker     (121)     5609 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/evaluation/functional/nms.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/evaluation/metrics/
--rw-r--r--   0 runner    (1001) docker     (121)      475 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/evaluation/metrics/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    28980 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/evaluation/metrics/coco_metric.py
--rw-r--r--   0 runner    (1001) docker     (121)     8572 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/evaluation/metrics/coco_wholebody_metric.py
--rw-r--r--   0 runner    (1001) docker     (121)    33498 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/evaluation/metrics/keypoint_2d_metrics.py
--rw-r--r--   0 runner    (1001) docker     (121)    10198 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/evaluation/metrics/posetrack18_metric.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/models/
--rw-r--r--   0 runner    (1001) docker     (121)      602 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/models/backbones/
--rw-r--r--   0 runner    (1001) docker     (121)     1365 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2007 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/alexnet.py
--rw-r--r--   0 runner    (1001) docker     (121)      848 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/base_backbone.py
--rw-r--r--   0 runner    (1001) docker     (121)     6174 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/cpm.py
--rw-r--r--   0 runner    (1001) docker     (121)     6746 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/hourglass.py
--rw-r--r--   0 runner    (1001) docker     (121)     6848 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/hourglass_ae.py
--rw-r--r--   0 runner    (1001) docker     (121)    30414 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/hrformer.py
--rw-r--r--   0 runner    (1001) docker     (121)    22592 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/hrnet.py
--rw-r--r--   0 runner    (1001) docker     (121)    36829 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/litehrnet.py
--rw-r--r--   0 runner    (1001) docker     (121)    10150 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/mobilenet_v2.py
--rw-r--r--   0 runner    (1001) docker     (121)     7175 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/mobilenet_v3.py
--rw-r--r--   0 runner    (1001) docker     (121)    19753 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/mspn.py
--rw-r--r--   0 runner    (1001) docker     (121)    21991 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/pvt.py
--rw-r--r--   0 runner    (1001) docker     (121)    12565 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/regnet.py
--rw-r--r--   0 runner    (1001) docker     (121)    12745 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/resnest.py
--rw-r--r--   0 runner    (1001) docker     (121)    25333 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/resnet.py
--rw-r--r--   0 runner    (1001) docker     (121)     6986 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/resnext.py
--rw-r--r--   0 runner    (1001) docker     (121)    22957 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/rsn.py
--rw-r--r--   0 runner    (1001) docker     (121)     8248 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/scnet.py
--rw-r--r--   0 runner    (1001) docker     (121)     4929 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/seresnet.py
--rw-r--r--   0 runner    (1001) docker     (121)     7469 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/seresnext.py
--rw-r--r--   0 runner    (1001) docker     (121)    12144 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/shufflenet_v1.py
--rw-r--r--   0 runner    (1001) docker     (121)    10818 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/shufflenet_v2.py
--rw-r--r--   0 runner    (1001) docker     (121)    29209 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/swin.py
--rw-r--r--   0 runner    (1001) docker     (121)    10566 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/tcn.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/models/backbones/utils/
--rw-r--r--   0 runner    (1001) docker     (121)      392 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)      914 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/utils/channel_shuffle.py
--rw-r--r--   0 runner    (1001) docker     (121)     1984 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/utils/ckpt_convert.py
--rw-r--r--   0 runner    (1001) docker     (121)     4196 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/utils/inverted_residual.py
--rw-r--r--   0 runner    (1001) docker     (121)     1056 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/utils/make_divisible.py
--rw-r--r--   0 runner    (1001) docker     (121)     1991 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/utils/se_layer.py
--rw-r--r--   0 runner    (1001) docker     (121)    45804 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/utils/transformer.py
--rw-r--r--   0 runner    (1001) docker     (121)     2947 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (121)     8824 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/v2v_net.py
--rw-r--r--   0 runner    (1001) docker     (121)     7461 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/vgg.py
--rw-r--r--   0 runner    (1001) docker     (121)     6184 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/vipnas_mbv3.py
--rw-r--r--   0 runner    (1001) docker     (121)    22076 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/backbones/vipnas_resnet.py
--rw-r--r--   0 runner    (1001) docker     (121)      836 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/models/data_preprocessors/
--rw-r--r--   0 runner    (1001) docker     (121)      136 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/data_preprocessors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)      265 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/data_preprocessors/data_preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/models/heads/
--rw-r--r--   0 runner    (1001) docker     (121)      482 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     4705 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/base_head.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/
--rw-r--r--   0 runner    (1001) docker     (121)      295 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    12401 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/cpm_head.py
--rw-r--r--   0 runner    (1001) docker     (121)    16239 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/heatmap_head.py
--rw-r--r--   0 runner    (1001) docker     (121)    16554 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/mix_head.py
--rw-r--r--   0 runner    (1001) docker     (121)    16505 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/mspn_head.py
--rw-r--r--   0 runner    (1001) docker     (121)    15519 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/simcc_head.py
--rw-r--r--   0 runner    (1001) docker     (121)     9311 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/vipnas_head.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/models/heads/regression_heads/
--rw-r--r--   0 runner    (1001) docker     (121)      313 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/regression_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     7144 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/regression_heads/dsnt_head.py
--rw-r--r--   0 runner    (1001) docker     (121)    15039 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/regression_heads/integral_regression_head.py
--rw-r--r--   0 runner    (1001) docker     (121)     6579 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/regression_heads/regression_head.py
--rw-r--r--   0 runner    (1001) docker     (121)     8151 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/heads/regression_heads/rle_head.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/models/losses/
--rw-r--r--   0 runner    (1001) docker     (121)      940 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/losses/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     4972 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/losses/classification_loss.py
--rw-r--r--   0 runner    (1001) docker     (121)     2773 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/losses/heatmap_loss.py
--rw-r--r--   0 runner    (1001) docker     (121)     1049 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/losses/loss_wrappers.py
--rw-r--r--   0 runner    (1001) docker     (121)     7814 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/losses/mse_loss.py
--rw-r--r--   0 runner    (1001) docker     (121)     9718 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/losses/multi_loss_factory.py
--rw-r--r--   0 runner    (1001) docker     (121)    18334 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/losses/regression_loss.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/models/necks/
--rw-r--r--   0 runner    (1001) docker     (121)      217 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/necks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     8775 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/necks/fpn.py
--rw-r--r--   0 runner    (1001) docker     (121)     1234 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/necks/gap_neck.py
--rw-r--r--   0 runner    (1001) docker     (121)    12528 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/necks/posewarper_neck.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/models/pose_estimators/
--rw-r--r--   0 runner    (1001) docker     (121)      126 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/pose_estimators/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3936 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/pose_estimators/base.py
--rw-r--r--   0 runner    (1001) docker     (121)     8391 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/pose_estimators/topdown.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/models/utils/
--rw-r--r--   0 runner    (1001) docker     (121)      219 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3204 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/utils/ckpt_convert.py
--rw-r--r--   0 runner    (1001) docker     (121)     2098 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/utils/geometry.py
--rw-r--r--   0 runner    (1001) docker     (121)     1174 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/utils/ops.py
--rw-r--r--   0 runner    (1001) docker     (121)     2657 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/utils/realnvp.py
--rw-r--r--   0 runner    (1001) docker     (121)     2706 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/utils/regularizations.py
--rw-r--r--   0 runner    (1001) docker     (121)     8286 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/utils/transformer.py
--rw-r--r--   0 runner    (1001) docker     (121)     3495 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/models/utils/tta.py
--rw-r--r--   0 runner    (1001) docker     (121)     1458 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/registry.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/structures/
--rw-r--r--   0 runner    (1001) docker     (121)      717 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/structures/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/structures/bbox/
--rw-r--r--   0 runner    (1001) docker     (121)      441 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/structures/bbox/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    11589 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/structures/bbox/transforms.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/structures/keypoint/
--rw-r--r--   0 runner    (1001) docker     (121)      118 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/structures/keypoint/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2394 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/structures/keypoint/transforms.py
--rw-r--r--   0 runner    (1001) docker     (121)    10214 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/structures/multilevel_pixel_data.py
--rw-r--r--   0 runner    (1001) docker     (121)     3424 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/structures/pose_data_sample.py
--rw-r--r--   0 runner    (1001) docker     (121)     3709 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/structures/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/testing/
--rw-r--r--   0 runner    (1001) docker     (121)      155 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/testing/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     7404 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/testing/_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/utils/
--rw-r--r--   0 runner    (1001) docker     (121)      424 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    10679 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/utils/camera.py
--rw-r--r--   0 runner    (1001) docker     (121)      428 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/utils/collect_env.py
--rw-r--r--   0 runner    (1001) docker     (121)     1836 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/utils/hooks.py
--rw-r--r--   0 runner    (1001) docker     (121)      967 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/utils/logger.py
--rw-r--r--   0 runner    (1001) docker     (121)     4079 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/utils/setup_env.py
--rw-r--r--   0 runner    (1001) docker     (121)     2211 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/utils/tensor_utils.py
--rw-r--r--   0 runner    (1001) docker     (121)     3743 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/utils/timer.py
--rw-r--r--   0 runner    (1001) docker     (121)     1078 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/utils/typing.py
--rw-r--r--   0 runner    (1001) docker     (121)      983 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/version.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/mmpose/visualization/
--rw-r--r--   0 runner    (1001) docker     (121)      133 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/visualization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    20860 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/mmpose/visualization/local_visualizer.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose.egg-info/
--rw-r--r--   0 runner    (1001) docker     (121)    24681 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (121)    37120 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (121)        1 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (121)        1 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose.egg-info/not-zip-safe
--rw-r--r--   0 runner    (1001) docker     (121)      577 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (121)        7 2022-10-14 13:06:47.000000 mmpose-1.0.0rc0/mmpose.egg-info/top_level.txt
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/requirements/
--rw-r--r--   0 runner    (1001) docker     (121)       56 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/requirements/albu.txt
--rw-r--r--   0 runner    (1001) docker     (121)       66 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/requirements/build.txt
--rw-r--r--   0 runner    (1001) docker     (121)      181 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/requirements/docs.txt
--rw-r--r--   0 runner    (1001) docker     (121)       24 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/requirements/mminstall.txt
--rw-r--r--   0 runner    (1001) docker     (121)        9 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/requirements/optional.txt
--rw-r--r--   0 runner    (1001) docker     (121)       69 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/requirements/poseval.txt
--rw-r--r--   0 runner    (1001) docker     (121)       89 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/requirements/readthedocs.txt
--rw-r--r--   0 runner    (1001) docker     (121)      138 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/requirements/runtime.txt
--rw-r--r--   0 runner    (1001) docker     (121)       99 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/requirements/tests.txt
--rw-r--r--   0 runner    (1001) docker     (121)      678 2022-10-14 13:06:48.000000 mmpose-1.0.0rc0/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (121)     6984 2022-10-14 13:06:45.000000 mmpose-1.0.0rc0/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/
+-rw-r--r--   0 runner    (1001) docker     (123)      198 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (123)    26601 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)    23305 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/README.md
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/
+-rw-r--r--   0 runner    (1001) docker     (123)     6588 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/300w.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2227 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/aflw.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4400 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/aic.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5415 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/animalpose.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4508 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/ap10k.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4273 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/atrw.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4417 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/campus.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5252 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/coco.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6151 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/coco_aic.py
+-rw-r--r--   0 runner    (1001) docker     (123)    30735 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/coco_wholebody.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7566 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/coco_wholebody_face.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4998 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/coco_wholebody_hand.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2936 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/cofw.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4341 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/crowdpose.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1951 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/deepfashion_full.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1292 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/deepfashion_lower.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1610 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/deepfashion_upper.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7150 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/fly.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4879 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/freihand2d.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4589 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/h36m.py
+-rw-r--r--   0 runner    (1001) docker     (123)    31008 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/halpe.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5586 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/horse10.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4773 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/interhand2d.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13089 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/interhand3d.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4056 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/jhmdb.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7793 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/locust.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5364 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/macaque.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4684 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/mhp.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4307 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/mpi_inf_3dhp.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4610 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/mpii.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10582 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/mpii_trb.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5316 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/ochuman.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4776 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/onehand10k.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5000 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/panoptic_body3d.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4817 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/panoptic_hand2d.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5116 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/posetrack18.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5364 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/rhd2d.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4416 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/shelf.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9472 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/wflw.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2237 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/zebra.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1196 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/default_runtime.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/rtmpose/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/rtmpose/ap10k/
+-rw-r--r--   0 runner    (1001) docker     (123)     7016 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/rtmpose/ap10k/rtmpose-m_8xb64-210e_ap10k-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/
+-rw-r--r--   0 runner    (1001) docker     (123)     4175 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_hrnet-w32_8xb64-210e_animalpose-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4175 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_hrnet-w48_8xb64-210e_animalpose-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3224 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res101_8xb64-210e_animalpose-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3224 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res152_8xb32-210e_animalpose-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3222 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res50_8xb64-210e_animalpose-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/
+-rw-r--r--   0 runner    (1001) docker     (123)     6590 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/cspnext-m_udp_8xb64-210e_ap10k-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1399 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/resnet_ap10k.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     4673 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_hrnet-w32_8xb64-210e_ap10k-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4673 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_hrnet-w48_8xb64-210e_ap10k-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3722 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_res101_8xb64-210e_ap10k-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3720 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_res50_8xb64-210e_ap10k-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/
+-rw-r--r--   0 runner    (1001) docker     (123)     3310 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res101_8xb64-210e_locust-160x160.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3310 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res152_8xb32-210e_locust-160x160.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3308 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res50_8xb64-210e_locust-160x160.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/
+-rw-r--r--   0 runner    (1001) docker     (123)     3305 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res101_8xb64-210e_zebra-160x160.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3305 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res152_8xb32-210e_zebra-160x160.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3303 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res50_8xb64-210e_zebra-160x160.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/associative_embedding/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/associative_embedding/coco/
+-rw-r--r--   0 runner    (1001) docker     (123)     4457 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/associative_embedding/coco/ae_hrnet-w32_8xb24-300e_coco-512x512.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/cid/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/cid/coco/
+-rw-r--r--   0 runner    (1001) docker     (123)     4786 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/cid/coco/cid_hrnet-w32_8xb20-140e_coco-512x512.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4786 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/cid/coco/cid_hrnet-w48_8xb20-140e_coco-512x512.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/dekr/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/dekr/coco/
+-rw-r--r--   0 runner    (1001) docker     (123)     5365 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_8xb10-140e_coco-512x512.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5397 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w48_8xb10-140e_coco-640x640.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/dekr/crowdpose/
+-rw-r--r--   0 runner    (1001) docker     (123)     5408 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/dekr/crowdpose/dekr_hrnet-w32_8xb10-300e_crowdpose-512x512.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5439 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/dekr/crowdpose/dekr_hrnet-w48_8xb5-300e_crowdpose-640x640.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/integral_regression/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/
+-rw-r--r--   0 runner    (1001) docker     (123)     3750 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_8xb64-210e_coco-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3787 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_debias-8xb64-210e_coco-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3748 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_dsnt-8xb64-210e_coco-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/
+-rw-r--r--   0 runner    (1001) docker     (123)     7705 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-l_8xb256-420e_aic-coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7705 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-l_8xb256-420e_aic-coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6677 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-l_8xb256-420e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7712 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-m_8xb256-420e_aic-coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7712 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-m_8xb256-420e_aic-coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6680 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-m_8xb256-420e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7710 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-s_8xb256-420e_aic-coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6677 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-s_8xb256-420e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7772 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-t_8xb256-420e_aic-coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6744 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-t_8xb256-420e_coco-256x192.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/crowdpose/
+-rw-r--r--   0 runner    (1001) docker     (123)     6753 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/crowdpose/rtmpose-m_8xb64-210e_crowdpose-256x192.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/mpii/
+-rw-r--r--   0 runner    (1001) docker     (123)     6481 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/rtmpose/mpii/rtmpose-m_8xb64-210e_mpii-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/
+-rw-r--r--   0 runner    (1001) docker     (123)      852 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/mobilenetv2_coco.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     1313 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/resnet_coco.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     3570 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_mobilenetv2_wo-deconv-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3470 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_res50_8xb32-140e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3383 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_res50_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3487 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_vipnas-mbv3_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)      818 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/vipnas_coco.yml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/mpii/
+-rw-r--r--   0 runner    (1001) docker     (123)     3367 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/mpii/simcc_res50_wo-deconv-8xb64-210e_mpii-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/aic/
+-rw-r--r--   0 runner    (1001) docker     (123)     4368 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/aic/td-hm_hrnet-w32_8xb64-210e_aic-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3417 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/aic/td-hm_res101_8xb64-210e_aic-256x192.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/
+-rw-r--r--   0 runner    (1001) docker     (123)     7654 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-l_udp_8xb256-210e_aic-coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6249 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-l_udp_8xb256-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7657 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-m_udp_8xb256-210e_aic-coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6252 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-m_udp_8xb256-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7645 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-s_udp_8xb256-210e_aic-coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6241 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-s_udp_8xb256-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7663 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-tiny_udp_8xb256-210e_aic-coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6259 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-tiny_udp_8xb256-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1328 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/hourglass_coco.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     2405 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/hrnet_coco.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     2333 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/litehrnet_coco.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     2239 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/mspn_coco.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     4250 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_2xmspn50_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4214 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_2xrsn50_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4254 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_3xmspn50_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4218 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_3xrsn50_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4254 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_4xmspn50_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4392 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-base-simple_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4345 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-base_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4394 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge-simple_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4347 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4394 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-large-simple_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4347 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-large_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4531 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-small-simple_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4484 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-small_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3277 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_alexnet_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3445 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_cpm_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3445 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_cpm_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3355 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hourglass52_8xb32-210e_coco-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3355 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hourglass52_8xb32-210e_coco-384x384.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5140 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-base_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5140 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-base_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5141 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-small_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5141 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-small_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4326 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4326 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5743 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-aic-256x192-combine.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5237 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-aic-256x192-merge.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4770 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_coarsedropout-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4357 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_dark-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4357 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_dark-8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)      153 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_fp16-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4692 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_gridmask-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4477 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_photometric-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4354 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_udp-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4354 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_udp-8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4449 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_udp-regress-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4326 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4326 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4357 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_dark-8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4357 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_dark-8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4354 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_udp-8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4354 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_udp-8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4001 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-18_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4001 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-18_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4001 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-30_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4001 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-30_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3439 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_mobilenetv2_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3439 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_mobilenetv2_8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4225 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_mspn50_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3579 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_pvt-s_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3604 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_pvtv2-b2_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3375 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3375 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3406 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_dark-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3406 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_dark-8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3375 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3375 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3406 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_dark-8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3431 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_dark-8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3373 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3373 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3404 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_dark-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3404 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_dark-8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)      149 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_fp16-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3371 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest101_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3371 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest101_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3371 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest200_8xb16-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3371 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest200_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3371 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest269_8xb16-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3371 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest269_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3369 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest50_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3369 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest50_8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3376 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d101_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3376 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d101_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3376 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d152_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3376 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d152_8xb48-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3374 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d50_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3374 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d50_8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3390 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext101_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3390 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext101_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3390 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext152_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3390 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext152_8xb48-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3375 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext50_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3375 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext50_8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4194 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_rsn18_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4189 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_rsn50_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3466 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet101_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3466 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet101_8xb48-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3464 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet50_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3464 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet50_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3374 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet101_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3374 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet101_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3297 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet152_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3297 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet152_8xb48-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3372 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet50_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3372 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet50_8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3377 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv1_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3377 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv1_8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3386 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv2_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3386 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv2_8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3898 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-b-p4-w7_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3900 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-b-p4-w7_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4190 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-l-p4-w7_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4191 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-l-p4-w7_8xb32-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3891 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-t-p4-w7_8xb32-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3397 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vgg16-bn_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3429 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vipnas-mbv3_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3346 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vipnas-res50_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5187 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/vitpose_coco.yml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/
+-rw-r--r--   0 runner    (1001) docker     (123)     6282 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/cspnext-m_udp_8xb64-210e_crowpose-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4375 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_hrnet-w32_8xb64-210e_crowdpose-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3424 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res101_8xb64-210e_crowdpose-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3424 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res101_8xb64-210e_crowdpose-320x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3424 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res152_8xb64-210e_crowdpose-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3422 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res50_8xb64-210e_crowdpose-256x192.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/
+-rw-r--r--   0 runner    (1001) docker     (123)     3311 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub1-368x368.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3311 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub2-368x368.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3311 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub3-368x368.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3336 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub1-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3336 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub2-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3336 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub3-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3259 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub1-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3259 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub2-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3259 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub3-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/
+-rw-r--r--   0 runner    (1001) docker     (123)     6013 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/cspnext-m_udp_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3345 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_cpm_8xb64-210e_mpii-368x368.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3177 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hourglass52_8xb32-210e_mpii-384x384.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3177 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hourglass52_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4148 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w32_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4179 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w32_dark-8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4148 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w48_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4179 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w48_dark-8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3831 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_litehrnet-18_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3831 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_litehrnet-30_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3232 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_mobilenetv2_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3197 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_res101_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3197 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_res152_8xb32-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3195 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_res50_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3198 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnetv1d101_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3198 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnetv1d152_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3196 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnetv1d50_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3212 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnext152_8xb32-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3288 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_scnet101_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3286 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_scnet50_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3196 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_seresnet101_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3119 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_seresnet152_8xb32-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3194 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_seresnet50_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3199 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_shufflenetv1_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3208 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_shufflenetv2_8xb64-210e_mpii-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/
+-rw-r--r--   0 runner    (1001) docker     (123)     4518 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w32_8xb64-20e_posetrack18-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4518 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w32_8xb64-20e_posetrack18-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4518 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w48_8xb64-20e_posetrack18-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4518 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w48_8xb64-20e_posetrack18-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3470 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_res50_8xb64-20e_posetrack18-256x192.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/
+-rw-r--r--   0 runner    (1001) docker     (123)     3598 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_mobilenetv2_rle-pretrained-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3376 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res101_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3391 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res101_rle-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3376 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res152_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3391 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res152_rle-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3391 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res152_rle-8xb64-210e_coco-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3374 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3389 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_rle-8xb64-210e_coco-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3553 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_rle-pretrained-8xb64-210e_coco-256x192.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/
+-rw-r--r--   0 runner    (1001) docker     (123)     3198 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res101_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3198 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res152_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3196 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res50_8xb64-210e_mpii-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3184 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res50_rle-8xb64-210e_mpii-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/rtmpose/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/rtmpose/coco_wholebody_face/
+-rw-r--r--   0 runner    (1001) docker     (123)     6552 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/rtmpose/coco_wholebody_face/rtmpose-m_8xb32-60e_coco-wholebody-face-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/rtmpose/wflw/
+-rw-r--r--   0 runner    (1001) docker     (123)     6526 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/rtmpose/wflw/rtmpose-m_8xb64-60e_wflw-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/300w/
+-rw-r--r--   0 runner    (1001) docker     (123)     4435 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/300w/td-hm_hrnetv2-w18_8xb64-60e_300w-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/aflw/
+-rw-r--r--   0 runner    (1001) docker     (123)     4429 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/aflw/td-hm_hrnetv2-w18_8xb64-60e_aflw-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4460 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/aflw/td-hm_hrnetv2-w18_dark-8xb64-60e_aflw-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/
+-rw-r--r--   0 runner    (1001) docker     (123)     3253 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hourglass52_8xb32-60e_coco-wholebody-face-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4405 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hrnetv2-w18_8xb32-60e_coco-wholebody-face-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4436 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hrnetv2-w18_dark-8xb32-60e_coco-wholebody-face-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3302 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_mobilenetv2_8xb32-60e_coco-wholebody-face-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3265 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_res50_8xb32-60e_coco-wholebody-face-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3356 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_scnet50_8xb32-60e_coco-wholebody-face-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/cofw/
+-rw-r--r--   0 runner    (1001) docker     (123)     4400 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/cofw/td-hm_hrnetv2-w18_8xb64-60e_cofw-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/
+-rw-r--r--   0 runner    (1001) docker     (123)      862 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/hrnetv2_wflw.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     4416 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_8xb64-60e_wflw-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4417 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_awing-8xb64-60e_wflw-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4447 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_dark-8xb64-60e_wflw-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/rtmpose/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/rtmpose/coco_wholebody_hand/
+-rw-r--r--   0 runner    (1001) docker     (123)     6573 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/rtmpose/coco_wholebody_hand/rtmpose-m_8xb32-210e_coco-wholebody-hand-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/
+-rw-r--r--   0 runner    (1001) docker     (123)     3263 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hourglass52_8xb32-210e_coco-wholebody-hand-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4404 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hrnetv2-w18_8xb32-210e_coco-wholebody-hand-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4435 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hrnetv2-w18_dark-8xb32-210e_coco-wholebody-hand-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3828 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_litehrnet-w18_8xb32-210e_coco-wholebody-hand-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3301 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_mobilenetv2_8xb32-210e_coco-wholebody-hand-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3264 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_res50_8xb32-210e_coco-wholebody-hand-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3355 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_scnet50_8xb32-210e_coco-wholebody-hand-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/freihand2d/
+-rw-r--r--   0 runner    (1001) docker     (123)     3710 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/freihand2d/td-hm_res50_8xb64-100e_freihand2d-224x224.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/
+-rw-r--r--   0 runner    (1001) docker     (123)      877 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/resnet_onehand10k.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     4405 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_8xb64-210e_onehand10k-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4436 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_dark-8xb64-210e_onehand10k-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4405 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_udp-8xb64-210e_onehand10k-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3315 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_mobilenetv2_8xb64-210e_onehand10k-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3278 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_res50_8xb32-210e_onehand10k-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/
+-rw-r--r--   0 runner    (1001) docker     (123)     4379 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_8xb64-210e_rhd2d-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4410 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_dark-8xb64-210e_rhd2d-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4379 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_udp-8xb64-210e_rhd2d-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3289 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_mobilenetv2_8xb64-210e_rhd2d-256x256.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3252 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_res50_8xb64-210e_rhd2d-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/onehand10k/
+-rw-r--r--   0 runner    (1001) docker     (123)     3258 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/onehand10k/td-reg_res50_8xb64-210e_onehand10k-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/rhd2d/
+-rw-r--r--   0 runner    (1001) docker     (123)     3232 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/rhd2d/td-reg_res50_8xb64-210e_rhd2d-256x256.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/rtmpose/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/rtmpose/coco-wholebody/
+-rw-r--r--   0 runner    (1001) docker     (123)     6596 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/rtmpose/coco-wholebody/rtmpose-l_8xb32-270e_coco-wholebody-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6596 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/rtmpose/coco-wholebody/rtmpose-l_8xb64-270e_coco-wholebody-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6599 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/rtmpose/coco-wholebody/rtmpose-m_8xb64-270e_coco-wholebody-256x192.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/
+-rw-r--r--   0 runner    (1001) docker     (123)     6127 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/cspnext-l_udp_8xb64-210e_coco-wholebody-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6130 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/cspnext-m_udp_8xb64-210e_coco-wholebody-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4344 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_8xb64-210e_coco-wholebody-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4344 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_8xb64-210e_coco-wholebody-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4375 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_dark-8xb64-210e_coco-wholebody-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4344 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_8xb32-210e_coco-wholebody-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4344 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_8xb32-210e_coco-wholebody-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4375 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_dark-8xb32-210e_coco-wholebody-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3393 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res101_8xb32-210e_coco-wholebody-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3393 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res101_8xb32-210e_coco-wholebody-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3393 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res152_8xb32-210e_coco-wholebody-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3393 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res152_8xb32-210e_coco-wholebody-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3391 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res50_8xb64-210e_coco-wholebody-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3391 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res50_8xb64-210e_coco-wholebody-384x288.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3447 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-mbv3_8xb64-210e_coco-wholebody-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3478 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-mbv3_dark-8xb64-210e_coco-wholebody-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3387 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-res50_8xb64-210e_coco-wholebody-256x192.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3418 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-res50_dark-8xb64-210e_coco-wholebody-256x192.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/
+-rw-r--r--   0 runner    (1001) docker     (123)     5619 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/bottomup_demo.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2142 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/image_demo.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3026 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/inferencer_demo.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/
+-rw-r--r--   0 runner    (1001) docker     (123)     9234 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/cascade_rcnn_x101_64x4d_fpn_1class.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8608 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/cascade_rcnn_x101_64x4d_fpn_coco.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5869 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/faster_rcnn_r50_fpn_1class.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6482 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8524 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/mask_rcnn_r50_fpn_2x_coco.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4435 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/ssdlite_mobilenetv2-scratch_8xb24-600e_coco.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4480 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/yolov3_d53_320_273e_coco.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10552 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/yolox-s_8xb8-300e_coco-face.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/mmtracking_cfg/
+-rw-r--r--   0 runner    (1001) docker     (123)    11566 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/mmtracking_cfg/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11604 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/mmtracking_cfg/tracktor_faster-rcnn_r50_fpn_4e_mot17-private.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7753 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/topdown_demo_with_mmdet.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/webcam_cfg/
+-rw-r--r--   0 runner    (1001) docker     (123)     5669 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/webcam_cfg/pose_estimation.py
+-rw-r--r--   0 runner    (1001) docker     (123)      634 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/webcam_cfg/test_camera.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1904 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/demo/webcam_demo.py
+-rw-r--r--   0 runner    (1001) docker     (123)      708 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/model-index.yml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/analysis_tools/
+-rw-r--r--   0 runner    (1001) docker     (123)     5567 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/analysis_tools/analyze_logs.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3555 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/analysis_tools/get_flops.py
+-rw-r--r--   0 runner    (1001) docker     (123)      643 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/analysis_tools/print_config.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/
+-rw-r--r--   0 runner    (1001) docker     (123)     4794 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/h36m_to_coco.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1649 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/mat2json.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13482 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/parse_animalpose_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2817 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/parse_cofw_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6251 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/parse_deepposekit_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5595 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/parse_macaquepose_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15559 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/preprocess_h36m.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12309 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/preprocess_mpi_inf_3dhp.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/dist_test.sh
+-rw-r--r--   0 runner    (1001) docker     (123)      490 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/dist_train.sh
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/misc/
+-rw-r--r--   0 runner    (1001) docker     (123)     5799 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/misc/browse_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4658 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/misc/keypoints2coco_without_mmdet.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2103 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/misc/publish_model.py
+-rw-r--r--   0 runner    (1001) docker     (123)      614 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/slurm_test.sh
+-rw-r--r--   0 runner    (1001) docker     (123)      622 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/slurm_train.sh
+-rw-r--r--   0 runner    (1001) docker     (123)     4430 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/test.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/torchserve/
+-rw-r--r--   0 runner    (1001) docker     (123)     4827 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/torchserve/mmpose2torchserve.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2709 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/torchserve/mmpose_handler.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2688 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/torchserve/test_torchserver.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5280 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/.mim/tools/train.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1031 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/apis/
+-rw-r--r--   0 runner    (1001) docker     (123)      300 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8046 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/inference.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/apis/inferencers/
+-rw-r--r--   0 runner    (1001) docker     (123)      196 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/inferencers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17449 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/inferencers/base_mmpose_inferencer.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11198 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/inferencers/mmpose_inferencer.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10005 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/inferencers/pose2d_inferencer.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/apis/inferencers/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)      133 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/inferencers/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1694 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/inferencers/utils/default_det_models.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/
+-rw-r--r--   0 runner    (1001) docker     (123)      122 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/
+-rw-r--r--   0 runner    (1001) docker     (123)      704 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2348 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/base_visualizer_node.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/helper_nodes/
+-rw-r--r--   0 runner    (1001) docker     (123)      244 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/helper_nodes/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5909 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/helper_nodes/monitor_node.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5401 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/helper_nodes/object_assigner_node.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4220 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/helper_nodes/recorder_node.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/model_nodes/
+-rw-r--r--   0 runner    (1001) docker     (123)      202 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/model_nodes/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5395 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/model_nodes/detector_node.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5350 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/model_nodes/pose_estimator_node.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15620 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/node.py
+-rw-r--r--   0 runner    (1001) docker     (123)      113 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/registry.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/visualizer_nodes/
+-rw-r--r--   0 runner    (1001) docker     (123)      367 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/visualizer_nodes/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4636 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/visualizer_nodes/bigeye_effect_node.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5023 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/visualizer_nodes/notice_board_node.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6135 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/visualizer_nodes/object_visualizer_node.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5755 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/visualizer_nodes/sunglasses_effect_node.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)     1021 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7022 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/utils/buffer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5178 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/utils/event.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1005 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/utils/image_capture.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6484 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/utils/message.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11425 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/utils/misc.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6554 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/utils/pose.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12158 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/apis/webcam/webcam_executor.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/codecs/
+-rw-r--r--   0 runner    (1001) docker     (123)      617 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20970 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/associative_embedding.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2505 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10341 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/decoupled_heatmap.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4279 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/integral_regression_label.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4815 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/megvii_heatmap.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5625 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/msra_heatmap.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3371 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/regression_label.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11162 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/simcc_label.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12184 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/spr.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7726 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/udp_heatmap.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/codecs/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)     1261 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7031 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/utils/gaussian_heatmap.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4017 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/utils/instance_property.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5352 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/utils/offset_heatmap.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6184 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/utils/post_processing.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7221 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/codecs/utils/refinement.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/datasets/
+-rw-r--r--   0 runner    (1001) docker     (123)      306 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3039 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/builder.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3685 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/dataset_wrappers.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/
+-rw-r--r--   0 runner    (1001) docker     (123)      338 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/
+-rw-r--r--   0 runner    (1001) docker     (123)      539 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3323 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/animalpose_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3249 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/ap10k_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3237 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/atrw_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3651 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/fly_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3414 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/horse10_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5368 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/locust_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3358 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/macaque_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4768 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/zebra_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/base/
+-rw-r--r--   0 runner    (1001) docker     (123)      142 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/base/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16987 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/base/base_coco_style_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/body/
+-rw-r--r--   0 runner    (1001) docker     (123)      693 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/body/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3211 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/body/aic_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3249 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/body/coco_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3229 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/body/crowdpose_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5484 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/body/jhmdb_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3306 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/body/mhp_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8675 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/body/mpii_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6616 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/body/mpii_trb_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3611 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/body/ochuman_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3302 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/body/posetrack18_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16527 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/body/posetrack18_video_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/face/
+-rw-r--r--   0 runner    (1001) docker     (123)      389 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/face/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5343 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/face/aflw_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4951 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/face/coco_wholebody_face_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2879 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/face/cofw_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4889 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/face/face_300w_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4867 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/face/wflw_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/fashion/
+-rw-r--r--   0 runner    (1001) docker     (123)      134 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/fashion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5843 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/fashion/deepfashion_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/hand/
+-rw-r--r--   0 runner    (1001) docker     (123)      440 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/hand/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6108 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/hand/coco_wholebody_hand_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5140 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/hand/freihand_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3470 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/hand/onehand10k_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5435 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/hand/panoptic_hand2d_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3421 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/hand/rhd2d_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7649 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/wholebody/
+-rw-r--r--   0 runner    (1001) docker     (123)      197 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/wholebody/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5421 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/wholebody/coco_wholebody_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2935 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/datasets/wholebody/halpe_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4552 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/samplers.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/datasets/transforms/
+-rw-r--r--   0 runner    (1001) docker     (123)      895 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/transforms/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    18636 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/transforms/bottomup_transforms.py
+-rw-r--r--   0 runner    (1001) docker     (123)    36948 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/transforms/common_transforms.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1761 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/transforms/converting.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8000 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/transforms/formatting.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2114 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/transforms/loading.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4357 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/datasets/transforms/topdown_transforms.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/engine/
+-rw-r--r--   0 runner    (1001) docker     (123)       89 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/engine/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/engine/hooks/
+-rw-r--r--   0 runner    (1001) docker     (123)      194 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/engine/hooks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2755 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/engine/hooks/ema_hook.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7024 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/engine/hooks/visualization_hook.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/engine/optim_wrappers/
+-rw-r--r--   0 runner    (1001) docker     (123)      170 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/engine/optim_wrappers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2956 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/engine/optim_wrappers/layer_decay_optim_wrapper.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/evaluation/
+-rw-r--r--   0 runner    (1001) docker     (123)      135 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/evaluation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/evaluation/functional/
+-rw-r--r--   0 runner    (1001) docker     (123)      558 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/evaluation/functional/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11832 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/evaluation/functional/keypoint_eval.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11122 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/evaluation/functional/nms.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/evaluation/metrics/
+-rw-r--r--   0 runner    (1001) docker     (123)      569 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/evaluation/metrics/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24250 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/evaluation/metrics/coco_metric.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12760 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/evaluation/metrics/coco_wholebody_metric.py
+-rw-r--r--   0 runner    (1001) docker     (123)    39347 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/evaluation/metrics/keypoint_2d_metrics.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9402 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/evaluation/metrics/keypoint_partition_metric.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8875 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/evaluation/metrics/posetrack18_metric.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/models/
+-rw-r--r--   0 runner    (1001) docker     (123)      602 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/models/backbones/
+-rw-r--r--   0 runner    (1001) docker     (123)     1365 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2007 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/alexnet.py
+-rw-r--r--   0 runner    (1001) docker     (123)      848 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/base_backbone.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6174 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/cpm.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6746 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/hourglass.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6848 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/hourglass_ae.py
+-rw-r--r--   0 runner    (1001) docker     (123)    30414 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/hrformer.py
+-rw-r--r--   0 runner    (1001) docker     (123)    22592 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/hrnet.py
+-rw-r--r--   0 runner    (1001) docker     (123)    36829 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/litehrnet.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10150 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/mobilenet_v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7175 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/mobilenet_v3.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19753 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/mspn.py
+-rw-r--r--   0 runner    (1001) docker     (123)    21991 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/pvt.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12565 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/regnet.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12745 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/resnest.py
+-rw-r--r--   0 runner    (1001) docker     (123)    25333 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6986 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/resnext.py
+-rw-r--r--   0 runner    (1001) docker     (123)    22957 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/rsn.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8248 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/scnet.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4929 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/seresnet.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7469 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/seresnext.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12144 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/shufflenet_v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10818 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/shufflenet_v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)    29134 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/swin.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10566 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/tcn.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/models/backbones/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)      392 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      914 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/utils/channel_shuffle.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1984 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/utils/ckpt_convert.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4196 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/utils/inverted_residual.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1056 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/utils/make_divisible.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1991 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/utils/se_layer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2947 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8824 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/v2v_net.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7461 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/vgg.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6184 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/vipnas_mbv3.py
+-rw-r--r--   0 runner    (1001) docker     (123)    22076 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/backbones/vipnas_resnet.py
+-rw-r--r--   0 runner    (1001) docker     (123)      836 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/models/data_preprocessors/
+-rw-r--r--   0 runner    (1001) docker     (123)      136 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/data_preprocessors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      265 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/data_preprocessors/data_preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/models/heads/
+-rw-r--r--   0 runner    (1001) docker     (123)      655 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5597 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/base_head.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/models/heads/coord_cls_heads/
+-rw-r--r--   0 runner    (1001) docker     (123)      154 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/coord_cls_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11539 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/coord_cls_heads/rtmcc_head.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16090 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/coord_cls_heads/simcc_head.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/
+-rw-r--r--   0 runner    (1001) docker     (123)      373 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11155 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/ae_head.py
+-rw-r--r--   0 runner    (1001) docker     (123)    31170 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/cid_head.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12403 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/cpm_head.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16983 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/heatmap_head.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16554 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/mix_head.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16505 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/mspn_head.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9341 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/vipnas_head.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/models/heads/hybrid_heads/
+-rw-r--r--   0 runner    (1001) docker     (123)      111 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/hybrid_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    23744 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/hybrid_heads/dekr_head.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/models/heads/regression_heads/
+-rw-r--r--   0 runner    (1001) docker     (123)      313 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/regression_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7144 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/regression_heads/dsnt_head.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15039 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/regression_heads/integral_regression_head.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6579 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/regression_heads/regression_head.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8151 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/heads/regression_heads/rle_head.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/models/losses/
+-rw-r--r--   0 runner    (1001) docker     (123)      914 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/losses/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4167 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/losses/ae_loss.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7458 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/losses/classification_loss.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16723 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/losses/heatmap_loss.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2644 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/losses/loss_wrappers.py
+-rw-r--r--   0 runner    (1001) docker     (123)    21225 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/losses/regression_loss.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/models/necks/
+-rw-r--r--   0 runner    (1001) docker     (123)      217 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/necks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8775 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/necks/fpn.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1267 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/necks/gap_neck.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12528 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/necks/posewarper_neck.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/models/pose_estimators/
+-rw-r--r--   0 runner    (1001) docker     (123)      195 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/pose_estimators/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7560 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/pose_estimators/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6959 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/pose_estimators/bottomup.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7626 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/pose_estimators/topdown.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/models/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)      293 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3204 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/utils/ckpt_convert.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2098 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/utils/geometry.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1174 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/utils/ops.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2657 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/utils/realnvp.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2706 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/utils/regularizations.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9365 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/utils/rtmcc_block.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13244 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/utils/transformer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6190 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/models/utils/tta.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5375 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/registry.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/structures/
+-rw-r--r--   0 runner    (1001) docker     (123)      753 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/structures/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/structures/bbox/
+-rw-r--r--   0 runner    (1001) docker     (123)      441 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/structures/bbox/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11589 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/structures/bbox/transforms.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/structures/keypoint/
+-rw-r--r--   0 runner    (1001) docker     (123)      118 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/structures/keypoint/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2395 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/structures/keypoint/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10214 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/structures/multilevel_pixel_data.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3424 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/structures/pose_data_sample.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4606 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/structures/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/testing/
+-rw-r--r--   0 runner    (1001) docker     (123)      304 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/testing/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8666 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/testing/_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10679 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/utils/camera.py
+-rw-r--r--   0 runner    (1001) docker     (123)      428 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/utils/collect_env.py
+-rw-r--r--   0 runner    (1001) docker     (123)      772 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/utils/config_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1836 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/utils/hooks.py
+-rw-r--r--   0 runner    (1001) docker     (123)      967 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/utils/logger.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4079 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/utils/setup_env.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2211 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/utils/tensor_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3743 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/utils/timer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1167 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/utils/typing.py
+-rw-r--r--   0 runner    (1001) docker     (123)      983 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/version.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose/visualization/
+-rw-r--r--   0 runner    (1001) docker     (123)      133 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/visualization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    22648 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/visualization/local_visualizer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5370 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/mmpose/visualization/simcc_vis.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (123)    26601 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)    43717 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose.egg-info/not-zip-safe
+-rw-r--r--   0 runner    (1001) docker     (123)      508 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        7 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/mmpose.egg-info/top_level.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/requirements/
+-rw-r--r--   0 runner    (1001) docker     (123)       56 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/requirements/albu.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       66 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/requirements/build.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      181 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/requirements/docs.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       38 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/requirements/mminstall.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        9 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/requirements/optional.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       69 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/requirements/poseval.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      103 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/requirements/readthedocs.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      101 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/requirements/runtime.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       99 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/requirements/tests.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      678 2023-03-15 09:51:10.000000 mmpose-1.0.0rc1/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (123)     6911 2023-03-15 09:51:07.000000 mmpose-1.0.0rc1/setup.py
```

### Comparing `mmpose-1.0.0rc0/PKG-INFO` & `mmpose-1.0.0rc1/PKG-INFO`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mmpose
-Version: 1.0.0rc0
+Version: 1.0.0rc1
 Summary: OpenMMLab Pose Estimation Toolbox and Benchmark.
 Home-page: https://github.com/open-mmlab/mmpose
 Author: MMPose Contributors
 Author-email: openmmlab@gmail.com
 License: Apache License 2.0
 Description: <div align="center">
           <img src="resources/mmpose-logo.png" width="450"/>
@@ -35,30 +35,47 @@
         [![Percentage of issues still open](https://isitmaintained.com/badge/open/open-mmlab/mmpose.svg)](https://github.com/open-mmlab/mmpose/issues)
         
         [Documentation](https://mmpose.readthedocs.io/en/1.x/) |
         [Installation](https://mmpose.readthedocs.io/en/1.x/installation.html) |
         [Model Zoo](https://mmpose.readthedocs.io/en/1.x/model_zoo.html) |
         [Papers](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/algorithms.html) |
         [Update News](https://mmpose.readthedocs.io/en/1.x/notes/changelog.html) |
-        [Reporting Issues](https://github.com/open-mmlab/mmpose/issues/new/choose)
+        [Reporting Issues](https://github.com/open-mmlab/mmpose/issues/new/choose) |
+        [RTMPose](/projects/rtmpose/)
         
         </div>
         
+        <div align="center">
+          <a href="https://openmmlab.medium.com/" style="text-decoration:none;">
+            <img src="https://user-images.githubusercontent.com/25839884/218352562-cdded397-b0f3-4ca1-b8dd-a60df8dca75b.png" width="3%" alt="" /></a>
+          <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
+          <a href="https://discord.com/channels/1037617289144569886/1046608014234370059" style="text-decoration:none;">
+            <img src="https://user-images.githubusercontent.com/25839884/218347213-c080267f-cbb6-443e-8532-8e1ed9a58ea9.png" width="3%" alt="" /></a>
+          <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
+          <a href="https://twitter.com/OpenMMLab" style="text-decoration:none;">
+            <img src="https://user-images.githubusercontent.com/25839884/218346637-d30c8a0f-3eba-4699-8131-512fb06d46db.png" width="3%" alt="" /></a>
+          <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
+          <a href="https://www.youtube.com/openmmlab" style="text-decoration:none;">
+            <img src="https://user-images.githubusercontent.com/25839884/218346691-ceb2116a-465a-40af-8424-9f30d2348ca9.png" width="3%" alt="" /></a>
+        </div>
+        
         ## Introduction
         
         English | [](README_CN.md)
         
         MMPose is an open-source toolbox for pose estimation based on PyTorch.
         It is a part of the [OpenMMLab project](https://github.com/open-mmlab).
         
         The master branch works with **PyTorch 1.6+**.
         
         https://user-images.githubusercontent.com/15977946/124654387-0fd3c500-ded1-11eb-84f6-24eeddbf4d91.mp4
         
-        <details open>
+        <br/>
+        
+        <details close>
         <summary><b>Major Features</b></summary>
         
         - **Support diverse tasks**
         
           We support a wide spectrum of mainstream pose analysis tasks in current research community, including 2d multi-person human pose estimation, 2d hand pose estimation, 2d face landmark detection, 133 keypoint whole-body human pose estimation, 3d human mesh recovery, fashion landmark detection and animal pose estimation.
           See [Demo](demo/docs/) for more information.
         
@@ -78,29 +95,45 @@
           pose estimation framework by combining different modules.
           We provide detailed documentation and API reference, as well as unittests.
         
         </details>
         
         ## What's New
         
-        - 2022-10-14: MMPose [v1.0.0rc0](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0rc0) is released. Major updates include:
+        - We are excited to release **RTMPose**, a real-time pose estimation framework including:
+        
+          - A family of lightweight pose estimation models with state-of-the-art performance
+          - Inference APIs for Python, C++, C#, Java, etc. Easy to integrate into your applications and empower real-time stable pose estimation
+          - Cross-platform deployment with various backends
+          - A step-by-step guide to training and deploying your own models
+        
+          Checkout our [project page](/projects/rtmpose/) and [technical report](https://arxiv.org/abs/2303.07399) for more information!
+        
+        ![rtmpose_intro](https://user-images.githubusercontent.com/13503330/219269619-935499e5-bdd9-49ea-8104-3c7796dbd862.png)
+        
+        - Welcome to [*projects of MMPose*](/projects/README.md), where you can access to the latest features of MMPose, and share your ideas and codes with the community at once. Contribution to MMPose will be simple and smooth:
+        
+          - Provide an easy and agile way to integrate algorithms, features and applications into MMPose
+          - Allow flexible code structure and style; only need a short code review process
+          - Build individual projects with full power of MMPose but not bound up with heavy frameworks
+          - Checkout new projects:
+            - [RTMPose](/projects/rtmpose/)
+            - [YOLOX-Pose (coming soon)](<>)
+            - [MMPose4AIGC (coming soon)](<>)
+          - Become a contributors and make MMPose greater. Start your journey from the [example project](/projects/example_project/)
+        
+        <br/>
+        
+        - 2022-03-15: MMPose [v1.0.0rc1](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0rc1) is released. Major updates include:
+        
+          - Release [RTMPose](/projects/rtmpose/), a high-performance real-time pose estimation framework based on MMPose
+          - Support [ViTPose](/configs/body_2d_keypoint/topdown_heatmap/coco/vitpose_coco.md) (NeurIPS'22), [CID](/configs/body_2d_keypoint/cid/coco/hrnet_coco.md) (CVPR'22) and [DEKR](/configs/body_2d_keypoint/dekr/) (CVPR'21)
+          - Add [*Inferencer*](/docs/en/user_guides/inference.md#out-of-the-box-inferencer), a convenient interface for inference and visualization
         
-          - Support 4 light-weight pose estimation algorithms
-            - SimCC (ECCV'22): [paper](https://doi.org/10.48550/arxiv.2107.03332) | [models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/simcc/README.md)
-            - Debias-IPR (ICCV'21): [paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Gu_Removing_the_Bias_of_Integral_Pose_Regression_ICCV_2021_paper.pdf) | [models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/integral_regression/README.md)
-            - IPR (ECCV'18): [paper](https://arxiv.org/abs/1711.08229) | [models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/integral_regression/README.md)
-            - DSNT (ArXiv'18): [paper](https://arxiv.org/abs/1801.07372v2) | [models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/integral_regression/README.md)
-          - Add [Colab tutorial](https://github.com/open-mmlab/mmpose/blob/1.x/demo/MMPose_Tutorial.ipynb) for MMPose v1.0
-        
-        - 2022-09-01: MMPose [v1.0.0b0](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0b0) is released!
-        
-          - This release introduced major refactoring to MMPose towards better performance, extensibility and user-friendliness.
-          - Built upon a brand new and flexible training & test engine, which is still in progress. Welcome to try according to [the documentation](https://mmpose.readthedocs.io/en/1.x/).
-          - There are BC-breaking changes. Please check [the migration tutorial](https://mmpose.readthedocs.io/en/1.x/migration.html).
-          - The beta and release candidate versions will last until the end of 2022, and during the release candidate, we will develop on the `1.x` branch. And we will still maintain 0.x version still at least the end of 2023.
+          See the full [release note](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0rc1) for more exciting updates brought by MMPose v1.0.0rc1!
         
         ## Installation
         
         Below are quick steps for installation:
         
         ```shell
         conda create -n open-mmlab python=3.8 pytorch==1.10.1 torchvision==0.11.2 cudatoolkit=11.3 -c pytorch -y
@@ -285,17 +318,16 @@
         
 Keywords: computer vision,pose estimation
 Platform: UNKNOWN
 Classifier: Development Status :: 4 - Beta
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.5
-Classifier: Programming Language :: Python :: 3.6
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
+Requires-Python: >=3.7
 Description-Content-Type: text/markdown
 Provides-Extra: all
 Provides-Extra: tests
 Provides-Extra: optional
 Provides-Extra: mim
```

#### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: mmpose Version: 1.0.0rc0 Summary: OpenMMLab Pose
+Metadata-Version: 2.1 Name: mmpose Version: 1.0.0rc1 Summary: OpenMMLab Pose
 Estimation Toolbox and Benchmark. Home-page: https://github.com/open-mmlab/
 mmpose Author: MMPose Contributors Author-email: openmmlab@gmail.com License:
 Apache License 2.0 Description:
                           [resources/mmpose-logo.png]
                                        
            OpenMMLab website HOT  OpenMMLab platform TRY_IT_OUT
                                        
@@ -20,83 +20,90 @@
        mmlab/mmpose.svg)](https://github.com/open-mmlab/mmpose/issues)
          [Documentation](https://mmpose.readthedocs.io/en/1.x/) |
 [Installation](https://mmpose.readthedocs.io/en/1.x/installation.html) |
     [Model Zoo](https://mmpose.readthedocs.io/en/1.x/model_zoo.html) |
       [Papers](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
   algorithms.html) | [Update News](https://mmpose.readthedocs.io/en/1.x/
  notes/changelog.html) | [Reporting Issues](https://github.com/open-mmlab/
-                           mmpose/issues/new/choose)
+         mmpose/issues/new/choose) | [RTMPose](/projects/rtmpose/)
+
 ## Introduction English | [](README_CN.md) MMPose is an open-source
 toolbox for pose estimation based on PyTorch. It is a part of the [OpenMMLab
 project](https://github.com/open-mmlab). The master branch works with **PyTorch
 1.6+**. https://user-images.githubusercontent.com/15977946/124654387-0fd3c500-
-ded1-11eb-84f6-24eeddbf4d91.mp4  Major Features - **Support diverse tasks** We
-support a wide spectrum of mainstream pose analysis tasks in current research
-community, including 2d multi-person human pose estimation, 2d hand pose
-estimation, 2d face landmark detection, 133 keypoint whole-body human pose
-estimation, 3d human mesh recovery, fashion landmark detection and animal pose
-estimation. See [Demo](demo/docs/) for more information. - **Higher efficiency
-and higher accuracy** MMPose implements multiple state-of-the-art (SOTA) deep
-learning models, including both top-down & bottom-up approaches. We achieve
-faster training speed and higher accuracy than other popular codebases, such as
-[HRNet](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch). See
-[benchmark.md](docs/en/notes/benchmark.md) for more information. - **Support
-for various datasets** The toolbox directly supports multiple popular and
-representative datasets, COCO, AIC, MPII, MPII-TRB, OCHuman etc. See
-[dataset_zoo](docs/en/dataset_zoo) for more information. - **Well designed,
-tested and documented** We decompose MMPose into different components and one
-can easily construct a customized pose estimation framework by combining
-different modules. We provide detailed documentation and API reference, as well
-as unittests.  ## What's New - 2022-10-14: MMPose [v1.0.0rc0](https://
-github.com/open-mmlab/mmpose/releases/tag/v1.0.0rc0) is released. Major updates
-include: - Support 4 light-weight pose estimation algorithms - SimCC (ECCV'22):
-[paper](https://doi.org/10.48550/arxiv.2107.03332) | [models](https://
-github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/simcc/README.md)
-- Debias-IPR (ICCV'21): [paper](https://openaccess.thecvf.com/content/ICCV2021/
-papers/Gu_Removing_the_Bias_of_Integral_Pose_Regression_ICCV_2021_paper.pdf) |
-[models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/
-body_2d_keypoint/integral_regression/README.md) - IPR (ECCV'18): [paper](https:
-//arxiv.org/abs/1711.08229) | [models](https://github.com/open-mmlab/mmpose/
-blob/1.x/configs/body_2d_keypoint/integral_regression/README.md) - DSNT
-(ArXiv'18): [paper](https://arxiv.org/abs/1801.07372v2) | [models](https://
-github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/
-integral_regression/README.md) - Add [Colab tutorial](https://github.com/open-
-mmlab/mmpose/blob/1.x/demo/MMPose_Tutorial.ipynb) for MMPose v1.0 - 2022-09-01:
-MMPose [v1.0.0b0](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0b0)
-is released! - This release introduced major refactoring to MMPose towards
-better performance, extensibility and user-friendliness. - Built upon a brand
-new and flexible training & test engine, which is still in progress. Welcome to
-try according to [the documentation](https://mmpose.readthedocs.io/en/1.x/). -
-There are BC-breaking changes. Please check [the migration tutorial](https://
-mmpose.readthedocs.io/en/1.x/migration.html). - The beta and release candidate
-versions will last until the end of 2022, and during the release candidate, we
-will develop on the `1.x` branch. And we will still maintain 0.x version still
-at least the end of 2023. ## Installation Below are quick steps for
-installation: ```shell conda create -n open-mmlab python=3.8 pytorch==1.10.1
-torchvision==0.11.2 cudatoolkit=11.3 -c pytorch -y conda activate open-mmlab
-pip install openmim git clone -b 1.x https://github.com/open-mmlab/mmpose.git
-cd mmpose mim install -e . ``` Please refer to [installation.md](https://
-mmpose.readthedocs.io/en/1.x/installation.html) for more detailed installation
-and dataset preparation. ## Getting Started We provided a series of tutorials
-about the basic usage of MMPose for new users: - [About Configs](https://
-mmpose.readthedocs.io/en/1.x/user_guides/configs.html) - [Add New Dataset]
-(https://mmpose.readthedocs.io/en/1.x/user_guides/prepare_datasets.html) -
-[Keypoint Encoding & Decoding](https://mmpose.readthedocs.io/en/1.x/
-user_guides/codecs.html) - [Inference with Existing Models](https://
-mmpose.readthedocs.io/en/1.x/user_guides/inference.html) - [Train and Test]
-(https://mmpose.readthedocs.io/en/1.x/user_guides/train_and_test.html) -
-[Visualization Tools](https://mmpose.readthedocs.io/en/1.x/user_guides/
-visualization.html) - [Other Useful Tools](https://mmpose.readthedocs.io/en/
-1.x/user_guides/useful_tools.html) ## Model Zoo Results and models are
-available in the **README.md** of each method's config directory. A summary can
-be found in the [Model Zoo](https://mmpose.readthedocs.io/en/1.x/modelzoo.html)
-page.  Supported algorithms: - [x] [DeepPose](https://mmpose.readthedocs.io/en/
-1.x/model_zoo_papers/algorithms.html#deeppose-cvpr-2014) (CVPR'2014) - [x]
-[CPM](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/backbones.html#cpm-
-cvpr-2016) (CVPR'2016) - [x] [Hourglass](https://mmpose.readthedocs.io/en/1.x/
+ded1-11eb-84f6-24eeddbf4d91.mp4
+ Major Features - **Support diverse tasks** We support a wide spectrum of
+mainstream pose analysis tasks in current research community, including 2d
+multi-person human pose estimation, 2d hand pose estimation, 2d face landmark
+detection, 133 keypoint whole-body human pose estimation, 3d human mesh
+recovery, fashion landmark detection and animal pose estimation. See [Demo]
+(demo/docs/) for more information. - **Higher efficiency and higher accuracy**
+MMPose implements multiple state-of-the-art (SOTA) deep learning models,
+including both top-down & bottom-up approaches. We achieve faster training
+speed and higher accuracy than other popular codebases, such as [HRNet](https:/
+/github.com/leoxiaobin/deep-high-resolution-net.pytorch). See [benchmark.md]
+(docs/en/notes/benchmark.md) for more information. - **Support for various
+datasets** The toolbox directly supports multiple popular and representative
+datasets, COCO, AIC, MPII, MPII-TRB, OCHuman etc. See [dataset_zoo](docs/en/
+dataset_zoo) for more information. - **Well designed, tested and documented**
+We decompose MMPose into different components and one can easily construct a
+customized pose estimation framework by combining different modules. We provide
+detailed documentation and API reference, as well as unittests.  ## What's New
+- We are excited to release **RTMPose**, a real-time pose estimation framework
+including: - A family of lightweight pose estimation models with state-of-the-
+art performance - Inference APIs for Python, C++, C#, Java, etc. Easy to
+integrate into your applications and empower real-time stable pose estimation -
+Cross-platform deployment with various backends - A step-by-step guide to
+training and deploying your own models Checkout our [project page](/projects/
+rtmpose/) and [technical report](https://arxiv.org/abs/2303.07399) for more
+information! ![rtmpose_intro](https://user-images.githubusercontent.com/
+13503330/219269619-935499e5-bdd9-49ea-8104-3c7796dbd862.png) - Welcome to
+[*projects of MMPose*](/projects/README.md), where you can access to the latest
+features of MMPose, and share your ideas and codes with the community at once.
+Contribution to MMPose will be simple and smooth: - Provide an easy and agile
+way to integrate algorithms, features and applications into MMPose - Allow
+flexible code structure and style; only need a short code review process -
+Build individual projects with full power of MMPose but not bound up with heavy
+frameworks - Checkout new projects: - [RTMPose](/projects/rtmpose/) - [YOLOX-
+Pose (coming soon)](<>) - [MMPose4AIGC (coming soon)](<>) - Become a
+contributors and make MMPose greater. Start your journey from the [example
+project](/projects/example_project/)
+- 2022-03-15: MMPose [v1.0.0rc1](https://github.com/open-mmlab/mmpose/releases/
+tag/v1.0.0rc1) is released. Major updates include: - Release [RTMPose](/
+projects/rtmpose/), a high-performance real-time pose estimation framework
+based on MMPose - Support [ViTPose](/configs/body_2d_keypoint/topdown_heatmap/
+coco/vitpose_coco.md) (NeurIPS'22), [CID](/configs/body_2d_keypoint/cid/coco/
+hrnet_coco.md) (CVPR'22) and [DEKR](/configs/body_2d_keypoint/dekr/) (CVPR'21)
+- Add [*Inferencer*](/docs/en/user_guides/inference.md#out-of-the-box-
+inferencer), a convenient interface for inference and visualization See the
+full [release note](https://github.com/open-mmlab/mmpose/releases/tag/
+v1.0.0rc1) for more exciting updates brought by MMPose v1.0.0rc1! ##
+Installation Below are quick steps for installation: ```shell conda create -
+n open-mmlab python=3.8 pytorch==1.10.1 torchvision==0.11.2 cudatoolkit=11.3 -
+c pytorch -y conda activate open-mmlab pip install openmim git clone -b 1.x
+https://github.com/open-mmlab/mmpose.git cd mmpose mim install -e . ``` Please
+refer to [installation.md](https://mmpose.readthedocs.io/en/1.x/
+installation.html) for more detailed installation and dataset preparation. ##
+Getting Started We provided a series of tutorials about the basic usage of
+MMPose for new users: - [About Configs](https://mmpose.readthedocs.io/en/1.x/
+user_guides/configs.html) - [Add New Dataset](https://mmpose.readthedocs.io/en/
+1.x/user_guides/prepare_datasets.html) - [Keypoint Encoding & Decoding](https:/
+/mmpose.readthedocs.io/en/1.x/user_guides/codecs.html) - [Inference with
+Existing Models](https://mmpose.readthedocs.io/en/1.x/user_guides/
+inference.html) - [Train and Test](https://mmpose.readthedocs.io/en/1.x/
+user_guides/train_and_test.html) - [Visualization Tools](https://
+mmpose.readthedocs.io/en/1.x/user_guides/visualization.html) - [Other Useful
+Tools](https://mmpose.readthedocs.io/en/1.x/user_guides/useful_tools.html) ##
+Model Zoo Results and models are available in the **README.md** of each
+method's config directory. A summary can be found in the [Model Zoo](https://
+mmpose.readthedocs.io/en/1.x/modelzoo.html) page.  Supported algorithms: - [x]
+[DeepPose](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
+algorithms.html#deeppose-cvpr-2014) (CVPR'2014) - [x] [CPM](https://
+mmpose.readthedocs.io/en/1.x/model_zoo_papers/backbones.html#cpm-cvpr-2016)
+(CVPR'2016) - [x] [Hourglass](https://mmpose.readthedocs.io/en/1.x/
 model_zoo_papers/backbones.html#hourglass-eccv-2016) (ECCV'2016) - [ ]
 [SimpleBaseline3D](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
 algorithms.html#simplebaseline3d-iccv-2017) (ICCV'2017) - [ ] [Associative
 Embedding](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
 algorithms.html#associative-embedding-nips-2017) (NeurIPS'2017) - [x]
 [SimpleBaseline2D](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
 algorithms.html#simplebaseline2d-eccv-2018) (ECCV'2018) - [x] [DSNT](https://
@@ -285,12 +292,11 @@
 toolbox. - [MMGeneration](https://github.com/open-mmlab/mmgeneration):
 OpenMMLab image and video generative models toolbox. - [MMDeploy](https://
 github.com/open-mmlab/mmdeploy): OpenMMLab Model Deployment Framework.
 Keywords: computer vision,pose estimation Platform: UNKNOWN Classifier:
 Development Status :: 4 - Beta Classifier: License :: OSI Approved :: Apache
 Software License Classifier: Operating System :: OS Independent Classifier:
 Programming Language :: Python :: 3 Classifier: Programming Language :: Python
-:: 3.5 Classifier: Programming Language :: Python :: 3.6 Classifier:
-Programming Language :: Python :: 3.7 Classifier: Programming Language ::
-Python :: 3.8 Classifier: Programming Language :: Python :: 3.9 Description-
+:: 3.7 Classifier: Programming Language :: Python :: 3.8 Classifier:
+Programming Language :: Python :: 3.9 Requires-Python: >=3.7 Description-
 Content-Type: text/markdown Provides-Extra: all Provides-Extra: tests Provides-
 Extra: optional Provides-Extra: mim
```

### Comparing `mmpose-1.0.0rc0/README.md` & `mmpose-1.0.0rc1/README.md`

 * *Files 14% similar despite different names*

```diff
@@ -27,30 +27,47 @@
 [![Percentage of issues still open](https://isitmaintained.com/badge/open/open-mmlab/mmpose.svg)](https://github.com/open-mmlab/mmpose/issues)
 
 [Documentation](https://mmpose.readthedocs.io/en/1.x/) |
 [Installation](https://mmpose.readthedocs.io/en/1.x/installation.html) |
 [Model Zoo](https://mmpose.readthedocs.io/en/1.x/model_zoo.html) |
 [Papers](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/algorithms.html) |
 [Update News](https://mmpose.readthedocs.io/en/1.x/notes/changelog.html) |
-[Reporting Issues](https://github.com/open-mmlab/mmpose/issues/new/choose)
+[Reporting Issues](https://github.com/open-mmlab/mmpose/issues/new/choose) |
+[RTMPose](/projects/rtmpose/)
 
 </div>
 
+<div align="center">
+  <a href="https://openmmlab.medium.com/" style="text-decoration:none;">
+    <img src="https://user-images.githubusercontent.com/25839884/218352562-cdded397-b0f3-4ca1-b8dd-a60df8dca75b.png" width="3%" alt="" /></a>
+  <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
+  <a href="https://discord.com/channels/1037617289144569886/1046608014234370059" style="text-decoration:none;">
+    <img src="https://user-images.githubusercontent.com/25839884/218347213-c080267f-cbb6-443e-8532-8e1ed9a58ea9.png" width="3%" alt="" /></a>
+  <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
+  <a href="https://twitter.com/OpenMMLab" style="text-decoration:none;">
+    <img src="https://user-images.githubusercontent.com/25839884/218346637-d30c8a0f-3eba-4699-8131-512fb06d46db.png" width="3%" alt="" /></a>
+  <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
+  <a href="https://www.youtube.com/openmmlab" style="text-decoration:none;">
+    <img src="https://user-images.githubusercontent.com/25839884/218346691-ceb2116a-465a-40af-8424-9f30d2348ca9.png" width="3%" alt="" /></a>
+</div>
+
 ## Introduction
 
 English | [](README_CN.md)
 
 MMPose is an open-source toolbox for pose estimation based on PyTorch.
 It is a part of the [OpenMMLab project](https://github.com/open-mmlab).
 
 The master branch works with **PyTorch 1.6+**.
 
 https://user-images.githubusercontent.com/15977946/124654387-0fd3c500-ded1-11eb-84f6-24eeddbf4d91.mp4
 
-<details open>
+<br/>
+
+<details close>
 <summary><b>Major Features</b></summary>
 
 - **Support diverse tasks**
 
   We support a wide spectrum of mainstream pose analysis tasks in current research community, including 2d multi-person human pose estimation, 2d hand pose estimation, 2d face landmark detection, 133 keypoint whole-body human pose estimation, 3d human mesh recovery, fashion landmark detection and animal pose estimation.
   See [Demo](demo/docs/) for more information.
 
@@ -70,29 +87,45 @@
   pose estimation framework by combining different modules.
   We provide detailed documentation and API reference, as well as unittests.
 
 </details>
 
 ## What's New
 
-- 2022-10-14: MMPose [v1.0.0rc0](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0rc0) is released. Major updates include:
+- We are excited to release **RTMPose**, a real-time pose estimation framework including:
+
+  - A family of lightweight pose estimation models with state-of-the-art performance
+  - Inference APIs for Python, C++, C#, Java, etc. Easy to integrate into your applications and empower real-time stable pose estimation
+  - Cross-platform deployment with various backends
+  - A step-by-step guide to training and deploying your own models
+
+  Checkout our [project page](/projects/rtmpose/) and [technical report](https://arxiv.org/abs/2303.07399) for more information!
+
+![rtmpose_intro](https://user-images.githubusercontent.com/13503330/219269619-935499e5-bdd9-49ea-8104-3c7796dbd862.png)
+
+- Welcome to [*projects of MMPose*](/projects/README.md), where you can access to the latest features of MMPose, and share your ideas and codes with the community at once. Contribution to MMPose will be simple and smooth:
+
+  - Provide an easy and agile way to integrate algorithms, features and applications into MMPose
+  - Allow flexible code structure and style; only need a short code review process
+  - Build individual projects with full power of MMPose but not bound up with heavy frameworks
+  - Checkout new projects:
+    - [RTMPose](/projects/rtmpose/)
+    - [YOLOX-Pose (coming soon)](<>)
+    - [MMPose4AIGC (coming soon)](<>)
+  - Become a contributors and make MMPose greater. Start your journey from the [example project](/projects/example_project/)
+
+<br/>
+
+- 2022-03-15: MMPose [v1.0.0rc1](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0rc1) is released. Major updates include:
+
+  - Release [RTMPose](/projects/rtmpose/), a high-performance real-time pose estimation framework based on MMPose
+  - Support [ViTPose](/configs/body_2d_keypoint/topdown_heatmap/coco/vitpose_coco.md) (NeurIPS'22), [CID](/configs/body_2d_keypoint/cid/coco/hrnet_coco.md) (CVPR'22) and [DEKR](/configs/body_2d_keypoint/dekr/) (CVPR'21)
+  - Add [*Inferencer*](/docs/en/user_guides/inference.md#out-of-the-box-inferencer), a convenient interface for inference and visualization
 
-  - Support 4 light-weight pose estimation algorithms
-    - SimCC (ECCV'22): [paper](https://doi.org/10.48550/arxiv.2107.03332) | [models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/simcc/README.md)
-    - Debias-IPR (ICCV'21): [paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Gu_Removing_the_Bias_of_Integral_Pose_Regression_ICCV_2021_paper.pdf) | [models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/integral_regression/README.md)
-    - IPR (ECCV'18): [paper](https://arxiv.org/abs/1711.08229) | [models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/integral_regression/README.md)
-    - DSNT (ArXiv'18): [paper](https://arxiv.org/abs/1801.07372v2) | [models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/integral_regression/README.md)
-  - Add [Colab tutorial](https://github.com/open-mmlab/mmpose/blob/1.x/demo/MMPose_Tutorial.ipynb) for MMPose v1.0
-
-- 2022-09-01: MMPose [v1.0.0b0](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0b0) is released!
-
-  - This release introduced major refactoring to MMPose towards better performance, extensibility and user-friendliness.
-  - Built upon a brand new and flexible training & test engine, which is still in progress. Welcome to try according to [the documentation](https://mmpose.readthedocs.io/en/1.x/).
-  - There are BC-breaking changes. Please check [the migration tutorial](https://mmpose.readthedocs.io/en/1.x/migration.html).
-  - The beta and release candidate versions will last until the end of 2022, and during the release candidate, we will develop on the `1.x` branch. And we will still maintain 0.x version still at least the end of 2023.
+  See the full [release note](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0rc1) for more exciting updates brought by MMPose v1.0.0rc1!
 
 ## Installation
 
 Below are quick steps for installation:
 
 ```shell
 conda create -n open-mmlab python=3.8 pytorch==1.10.1 torchvision==0.11.2 cudatoolkit=11.3 -c pytorch -y
```

#### html2text {}

```diff
@@ -16,83 +16,90 @@
        mmlab/mmpose.svg)](https://github.com/open-mmlab/mmpose/issues)
          [Documentation](https://mmpose.readthedocs.io/en/1.x/) |
 [Installation](https://mmpose.readthedocs.io/en/1.x/installation.html) |
     [Model Zoo](https://mmpose.readthedocs.io/en/1.x/model_zoo.html) |
       [Papers](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
   algorithms.html) | [Update News](https://mmpose.readthedocs.io/en/1.x/
  notes/changelog.html) | [Reporting Issues](https://github.com/open-mmlab/
-                           mmpose/issues/new/choose)
+         mmpose/issues/new/choose) | [RTMPose](/projects/rtmpose/)
+
 ## Introduction English | [](README_CN.md) MMPose is an open-source
 toolbox for pose estimation based on PyTorch. It is a part of the [OpenMMLab
 project](https://github.com/open-mmlab). The master branch works with **PyTorch
 1.6+**. https://user-images.githubusercontent.com/15977946/124654387-0fd3c500-
-ded1-11eb-84f6-24eeddbf4d91.mp4  Major Features - **Support diverse tasks** We
-support a wide spectrum of mainstream pose analysis tasks in current research
-community, including 2d multi-person human pose estimation, 2d hand pose
-estimation, 2d face landmark detection, 133 keypoint whole-body human pose
-estimation, 3d human mesh recovery, fashion landmark detection and animal pose
-estimation. See [Demo](demo/docs/) for more information. - **Higher efficiency
-and higher accuracy** MMPose implements multiple state-of-the-art (SOTA) deep
-learning models, including both top-down & bottom-up approaches. We achieve
-faster training speed and higher accuracy than other popular codebases, such as
-[HRNet](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch). See
-[benchmark.md](docs/en/notes/benchmark.md) for more information. - **Support
-for various datasets** The toolbox directly supports multiple popular and
-representative datasets, COCO, AIC, MPII, MPII-TRB, OCHuman etc. See
-[dataset_zoo](docs/en/dataset_zoo) for more information. - **Well designed,
-tested and documented** We decompose MMPose into different components and one
-can easily construct a customized pose estimation framework by combining
-different modules. We provide detailed documentation and API reference, as well
-as unittests.  ## What's New - 2022-10-14: MMPose [v1.0.0rc0](https://
-github.com/open-mmlab/mmpose/releases/tag/v1.0.0rc0) is released. Major updates
-include: - Support 4 light-weight pose estimation algorithms - SimCC (ECCV'22):
-[paper](https://doi.org/10.48550/arxiv.2107.03332) | [models](https://
-github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/simcc/README.md)
-- Debias-IPR (ICCV'21): [paper](https://openaccess.thecvf.com/content/ICCV2021/
-papers/Gu_Removing_the_Bias_of_Integral_Pose_Regression_ICCV_2021_paper.pdf) |
-[models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/
-body_2d_keypoint/integral_regression/README.md) - IPR (ECCV'18): [paper](https:
-//arxiv.org/abs/1711.08229) | [models](https://github.com/open-mmlab/mmpose/
-blob/1.x/configs/body_2d_keypoint/integral_regression/README.md) - DSNT
-(ArXiv'18): [paper](https://arxiv.org/abs/1801.07372v2) | [models](https://
-github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/
-integral_regression/README.md) - Add [Colab tutorial](https://github.com/open-
-mmlab/mmpose/blob/1.x/demo/MMPose_Tutorial.ipynb) for MMPose v1.0 - 2022-09-01:
-MMPose [v1.0.0b0](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0b0)
-is released! - This release introduced major refactoring to MMPose towards
-better performance, extensibility and user-friendliness. - Built upon a brand
-new and flexible training & test engine, which is still in progress. Welcome to
-try according to [the documentation](https://mmpose.readthedocs.io/en/1.x/). -
-There are BC-breaking changes. Please check [the migration tutorial](https://
-mmpose.readthedocs.io/en/1.x/migration.html). - The beta and release candidate
-versions will last until the end of 2022, and during the release candidate, we
-will develop on the `1.x` branch. And we will still maintain 0.x version still
-at least the end of 2023. ## Installation Below are quick steps for
-installation: ```shell conda create -n open-mmlab python=3.8 pytorch==1.10.1
-torchvision==0.11.2 cudatoolkit=11.3 -c pytorch -y conda activate open-mmlab
-pip install openmim git clone -b 1.x https://github.com/open-mmlab/mmpose.git
-cd mmpose mim install -e . ``` Please refer to [installation.md](https://
-mmpose.readthedocs.io/en/1.x/installation.html) for more detailed installation
-and dataset preparation. ## Getting Started We provided a series of tutorials
-about the basic usage of MMPose for new users: - [About Configs](https://
-mmpose.readthedocs.io/en/1.x/user_guides/configs.html) - [Add New Dataset]
-(https://mmpose.readthedocs.io/en/1.x/user_guides/prepare_datasets.html) -
-[Keypoint Encoding & Decoding](https://mmpose.readthedocs.io/en/1.x/
-user_guides/codecs.html) - [Inference with Existing Models](https://
-mmpose.readthedocs.io/en/1.x/user_guides/inference.html) - [Train and Test]
-(https://mmpose.readthedocs.io/en/1.x/user_guides/train_and_test.html) -
-[Visualization Tools](https://mmpose.readthedocs.io/en/1.x/user_guides/
-visualization.html) - [Other Useful Tools](https://mmpose.readthedocs.io/en/
-1.x/user_guides/useful_tools.html) ## Model Zoo Results and models are
-available in the **README.md** of each method's config directory. A summary can
-be found in the [Model Zoo](https://mmpose.readthedocs.io/en/1.x/modelzoo.html)
-page.  Supported algorithms: - [x] [DeepPose](https://mmpose.readthedocs.io/en/
-1.x/model_zoo_papers/algorithms.html#deeppose-cvpr-2014) (CVPR'2014) - [x]
-[CPM](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/backbones.html#cpm-
-cvpr-2016) (CVPR'2016) - [x] [Hourglass](https://mmpose.readthedocs.io/en/1.x/
+ded1-11eb-84f6-24eeddbf4d91.mp4
+ Major Features - **Support diverse tasks** We support a wide spectrum of
+mainstream pose analysis tasks in current research community, including 2d
+multi-person human pose estimation, 2d hand pose estimation, 2d face landmark
+detection, 133 keypoint whole-body human pose estimation, 3d human mesh
+recovery, fashion landmark detection and animal pose estimation. See [Demo]
+(demo/docs/) for more information. - **Higher efficiency and higher accuracy**
+MMPose implements multiple state-of-the-art (SOTA) deep learning models,
+including both top-down & bottom-up approaches. We achieve faster training
+speed and higher accuracy than other popular codebases, such as [HRNet](https:/
+/github.com/leoxiaobin/deep-high-resolution-net.pytorch). See [benchmark.md]
+(docs/en/notes/benchmark.md) for more information. - **Support for various
+datasets** The toolbox directly supports multiple popular and representative
+datasets, COCO, AIC, MPII, MPII-TRB, OCHuman etc. See [dataset_zoo](docs/en/
+dataset_zoo) for more information. - **Well designed, tested and documented**
+We decompose MMPose into different components and one can easily construct a
+customized pose estimation framework by combining different modules. We provide
+detailed documentation and API reference, as well as unittests.  ## What's New
+- We are excited to release **RTMPose**, a real-time pose estimation framework
+including: - A family of lightweight pose estimation models with state-of-the-
+art performance - Inference APIs for Python, C++, C#, Java, etc. Easy to
+integrate into your applications and empower real-time stable pose estimation -
+Cross-platform deployment with various backends - A step-by-step guide to
+training and deploying your own models Checkout our [project page](/projects/
+rtmpose/) and [technical report](https://arxiv.org/abs/2303.07399) for more
+information! ![rtmpose_intro](https://user-images.githubusercontent.com/
+13503330/219269619-935499e5-bdd9-49ea-8104-3c7796dbd862.png) - Welcome to
+[*projects of MMPose*](/projects/README.md), where you can access to the latest
+features of MMPose, and share your ideas and codes with the community at once.
+Contribution to MMPose will be simple and smooth: - Provide an easy and agile
+way to integrate algorithms, features and applications into MMPose - Allow
+flexible code structure and style; only need a short code review process -
+Build individual projects with full power of MMPose but not bound up with heavy
+frameworks - Checkout new projects: - [RTMPose](/projects/rtmpose/) - [YOLOX-
+Pose (coming soon)](<>) - [MMPose4AIGC (coming soon)](<>) - Become a
+contributors and make MMPose greater. Start your journey from the [example
+project](/projects/example_project/)
+- 2022-03-15: MMPose [v1.0.0rc1](https://github.com/open-mmlab/mmpose/releases/
+tag/v1.0.0rc1) is released. Major updates include: - Release [RTMPose](/
+projects/rtmpose/), a high-performance real-time pose estimation framework
+based on MMPose - Support [ViTPose](/configs/body_2d_keypoint/topdown_heatmap/
+coco/vitpose_coco.md) (NeurIPS'22), [CID](/configs/body_2d_keypoint/cid/coco/
+hrnet_coco.md) (CVPR'22) and [DEKR](/configs/body_2d_keypoint/dekr/) (CVPR'21)
+- Add [*Inferencer*](/docs/en/user_guides/inference.md#out-of-the-box-
+inferencer), a convenient interface for inference and visualization See the
+full [release note](https://github.com/open-mmlab/mmpose/releases/tag/
+v1.0.0rc1) for more exciting updates brought by MMPose v1.0.0rc1! ##
+Installation Below are quick steps for installation: ```shell conda create -
+n open-mmlab python=3.8 pytorch==1.10.1 torchvision==0.11.2 cudatoolkit=11.3 -
+c pytorch -y conda activate open-mmlab pip install openmim git clone -b 1.x
+https://github.com/open-mmlab/mmpose.git cd mmpose mim install -e . ``` Please
+refer to [installation.md](https://mmpose.readthedocs.io/en/1.x/
+installation.html) for more detailed installation and dataset preparation. ##
+Getting Started We provided a series of tutorials about the basic usage of
+MMPose for new users: - [About Configs](https://mmpose.readthedocs.io/en/1.x/
+user_guides/configs.html) - [Add New Dataset](https://mmpose.readthedocs.io/en/
+1.x/user_guides/prepare_datasets.html) - [Keypoint Encoding & Decoding](https:/
+/mmpose.readthedocs.io/en/1.x/user_guides/codecs.html) - [Inference with
+Existing Models](https://mmpose.readthedocs.io/en/1.x/user_guides/
+inference.html) - [Train and Test](https://mmpose.readthedocs.io/en/1.x/
+user_guides/train_and_test.html) - [Visualization Tools](https://
+mmpose.readthedocs.io/en/1.x/user_guides/visualization.html) - [Other Useful
+Tools](https://mmpose.readthedocs.io/en/1.x/user_guides/useful_tools.html) ##
+Model Zoo Results and models are available in the **README.md** of each
+method's config directory. A summary can be found in the [Model Zoo](https://
+mmpose.readthedocs.io/en/1.x/modelzoo.html) page.  Supported algorithms: - [x]
+[DeepPose](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
+algorithms.html#deeppose-cvpr-2014) (CVPR'2014) - [x] [CPM](https://
+mmpose.readthedocs.io/en/1.x/model_zoo_papers/backbones.html#cpm-cvpr-2016)
+(CVPR'2016) - [x] [Hourglass](https://mmpose.readthedocs.io/en/1.x/
 model_zoo_papers/backbones.html#hourglass-eccv-2016) (ECCV'2016) - [ ]
 [SimpleBaseline3D](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
 algorithms.html#simplebaseline3d-iccv-2017) (ICCV'2017) - [ ] [Associative
 Embedding](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
 algorithms.html#associative-embedding-nips-2017) (NeurIPS'2017) - [x]
 [SimpleBaseline2D](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
 algorithms.html#simplebaseline2d-eccv-2018) (ECCV'2018) - [x] [DSNT](https://
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/aflw.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/zebra.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,83 +1,64 @@
 dataset_info = dict(
-    dataset_name='aflw',
+    dataset_name='zebra',
     paper_info=dict(
-        author='Koestinger, Martin and Wohlhart, Paul and '
-        'Roth, Peter M and Bischof, Horst',
-        title='Annotated facial landmarks in the wild: '
-        'A large-scale, real-world database for facial '
-        'landmark localization',
-        container='2011 IEEE international conference on computer '
-        'vision workshops (ICCV workshops)',
-        year='2011',
-        homepage='https://www.tugraz.at/institute/icg/research/'
-        'team-bischof/lrs/downloads/aflw/',
+        author='Graving, Jacob M and Chae, Daniel and Naik, Hemal and '
+        'Li, Liang and Koger, Benjamin and Costelloe, Blair R and '
+        'Couzin, Iain D',
+        title='DeepPoseKit, a software toolkit for fast and robust '
+        'animal pose estimation using deep learning',
+        container='Elife',
+        year='2019',
+        homepage='https://github.com/jgraving/DeepPoseKit-Data',
     ),
     keypoint_info={
         0:
-        dict(name='kpt-0', id=0, color=[255, 255, 255], type='', swap='kpt-5'),
+        dict(name='snout', id=0, color=[255, 255, 255], type='', swap=''),
         1:
-        dict(name='kpt-1', id=1, color=[255, 255, 255], type='', swap='kpt-4'),
+        dict(name='head', id=1, color=[255, 255, 255], type='', swap=''),
         2:
-        dict(name='kpt-2', id=2, color=[255, 255, 255], type='', swap='kpt-3'),
+        dict(name='neck', id=2, color=[255, 255, 255], type='', swap=''),
         3:
-        dict(name='kpt-3', id=3, color=[255, 255, 255], type='', swap='kpt-2'),
-        4:
-        dict(name='kpt-4', id=4, color=[255, 255, 255], type='', swap='kpt-1'),
-        5:
-        dict(name='kpt-5', id=5, color=[255, 255, 255], type='', swap='kpt-0'),
-        6:
-        dict(
-            name='kpt-6', id=6, color=[255, 255, 255], type='', swap='kpt-11'),
-        7:
-        dict(
-            name='kpt-7', id=7, color=[255, 255, 255], type='', swap='kpt-10'),
-        8:
-        dict(name='kpt-8', id=8, color=[255, 255, 255], type='', swap='kpt-9'),
-        9:
-        dict(name='kpt-9', id=9, color=[255, 255, 255], type='', swap='kpt-8'),
-        10:
-        dict(
-            name='kpt-10', id=10, color=[255, 255, 255], type='',
-            swap='kpt-7'),
-        11:
         dict(
-            name='kpt-11', id=11, color=[255, 255, 255], type='',
-            swap='kpt-6'),
-        12:
-        dict(
-            name='kpt-12',
-            id=12,
+            name='forelegL1',
+            id=3,
             color=[255, 255, 255],
             type='',
-            swap='kpt-14'),
-        13:
-        dict(name='kpt-13', id=13, color=[255, 255, 255], type='', swap=''),
-        14:
+            swap='forelegR1'),
+        4:
         dict(
-            name='kpt-14',
-            id=14,
+            name='forelegR1',
+            id=4,
             color=[255, 255, 255],
             type='',
-            swap='kpt-12'),
-        15:
+            swap='forelegL1'),
+        5:
         dict(
-            name='kpt-15',
-            id=15,
+            name='hindlegL1',
+            id=5,
             color=[255, 255, 255],
             type='',
-            swap='kpt-17'),
-        16:
-        dict(name='kpt-16', id=16, color=[255, 255, 255], type='', swap=''),
-        17:
+            swap='hindlegR1'),
+        6:
         dict(
-            name='kpt-17',
-            id=17,
+            name='hindlegR1',
+            id=6,
             color=[255, 255, 255],
             type='',
-            swap='kpt-15'),
-        18:
-        dict(name='kpt-18', id=18, color=[255, 255, 255], type='', swap='')
+            swap='hindlegL1'),
+        7:
+        dict(name='tailbase', id=7, color=[255, 255, 255], type='', swap=''),
+        8:
+        dict(name='tailtip', id=8, color=[255, 255, 255], type='', swap='')
+    },
+    skeleton_info={
+        0: dict(link=('head', 'snout'), id=0, color=[255, 255, 255]),
+        1: dict(link=('neck', 'head'), id=1, color=[255, 255, 255]),
+        2: dict(link=('forelegL1', 'neck'), id=2, color=[255, 255, 255]),
+        3: dict(link=('forelegR1', 'neck'), id=3, color=[255, 255, 255]),
+        4: dict(link=('hindlegL1', 'tailbase'), id=4, color=[255, 255, 255]),
+        5: dict(link=('hindlegR1', 'tailbase'), id=5, color=[255, 255, 255]),
+        6: dict(link=('tailbase', 'neck'), id=6, color=[255, 255, 255]),
+        7: dict(link=('tailtip', 'tailbase'), id=7, color=[255, 255, 255])
     },
-    skeleton_info={},
-    joint_weights=[1.] * 19,
+    joint_weights=[1.] * 9,
     sigmas=[])
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/aic.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/aic.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/animalpose.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/animalpose.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/ap10k.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/ap10k.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/atrw.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/atrw.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/campus.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/campus.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/coco.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/coco.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/coco_wholebody.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/coco_wholebody.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/coco_wholebody_hand.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/coco_wholebody_hand.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/crowdpose.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/crowdpose.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/deepfashion_full.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/deepfashion_full.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/deepfashion_lower.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/deepfashion_lower.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/deepfashion_upper.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/deepfashion_upper.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/fly.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/fly.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/freihand2d.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/freihand2d.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/h36m.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/h36m.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/halpe.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/halpe.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/horse10.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/horse10.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/interhand2d.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/interhand2d.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/interhand3d.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/interhand3d.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/jhmdb.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/jhmdb.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/locust.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/locust.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/macaque.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/macaque.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/mhp.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/mhp.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/mpi_inf_3dhp.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/mpi_inf_3dhp.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/mpii.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/mpii.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/mpii_trb.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/mpii_trb.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/ochuman.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/ochuman.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/onehand10k.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/onehand10k.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/panoptic_body3d.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/panoptic_body3d.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/panoptic_hand2d.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/panoptic_hand2d.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/posetrack18.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/posetrack18.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/rhd2d.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/rhd2d.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/datasets/shelf.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/datasets/shelf.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/_base_/default_runtime.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/_base_/default_runtime.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 default_scope = 'mmpose'
 
 # hooks
 default_hooks = dict(
     timer=dict(type='IterTimerHook'),
     logger=dict(type='LoggerHook', interval=50),
     param_scheduler=dict(type='ParamSchedulerHook'),
-    checkpoint=dict(type='CheckpointHook', interval=1),
+    checkpoint=dict(type='CheckpointHook', interval=10),
     sampler_seed=dict(type='DistSamplerSeedHook'),
     visualization=dict(type='PoseVisualizationHook', enable=False),
 )
 
 # custom hooks
 custom_hooks = [
     # Synchronize model buffers such as running_mean and running_var in BN
@@ -35,11 +35,11 @@
 log_level = 'INFO'
 load_from = None
 resume = False
 
 # file I/O backend
 file_client_args = dict(backend='disk')
 
-# training/validatin/testing progress
+# training/validation/testing progress
 train_cfg = dict(by_epoch=True)
 val_cfg = dict()
 test_cfg = dict()
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_hrnet-w32_8xb64-210e_animalpose-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_hrnet-w32_8xb64-210e_animalpose-256x256.py`

 * *Files 1% similar despite different names*

```diff
@@ -96,15 +96,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_hrnet-w48_8xb64-210e_animalpose-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_hrnet-w48_8xb64-210e_animalpose-256x256.py`

 * *Files 1% similar despite different names*

```diff
@@ -96,15 +96,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res101_8xb64-210e_animalpose-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res50_8xb64-210e_animalpose-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -39,16 +39,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=20,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res152_8xb32-210e_animalpose-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res152_8xb32-210e_animalpose-256x256.py`

 * *Files 1% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res50_8xb64-210e_animalpose-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res101_8xb64-210e_animalpose-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -39,16 +39,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
+        depth=101,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=20,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_hrnet-w32_8xb64-210e_ap10k-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_hrnet-w32_8xb64-210e_ap10k-256x256.py`

 * *Files 3% similar despite different names*

```diff
@@ -96,25 +96,22 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(
-        type='PackPoseInputs',
-        meta_keys=('id', 'img_id', 'img_path', 'ori_shape', 'img_shape',
-                   'input_size', 'flip_indices', 'category'))
+    dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
     batch_size=64,
     num_workers=4,
     persistent_workers=True,
@@ -156,12 +153,12 @@
         data_prefix=dict(img='data/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 
 # evaluators
 val_evaluator = dict(
-    type='AP10KCocoMetric',
+    type='CocoMetric',
     ann_file=data_root + 'annotations/ap10k-val-split1.json')
 test_evaluator = dict(
-    type='AP10KCocoMetric',
+    type='CocoMetric',
     ann_file=data_root + 'annotations/ap10k-test-split1.json')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_hrnet-w48_8xb64-210e_ap10k-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_hrnet-w48_8xb64-210e_ap10k-256x256.py`

 * *Files 5% similar despite different names*

```diff
@@ -96,25 +96,22 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(
-        type='PackPoseInputs',
-        meta_keys=('id', 'img_id', 'img_path', 'ori_shape', 'img_shape',
-                   'input_size', 'flip_indices', 'category'))
+    dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
     batch_size=64,
     num_workers=4,
     persistent_workers=True,
@@ -156,12 +153,12 @@
         data_prefix=dict(img='data/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 
 # evaluators
 val_evaluator = dict(
-    type='AP10KCocoMetric',
+    type='CocoMetric',
     ann_file=data_root + 'annotations/ap10k-val-split1.json')
 test_evaluator = dict(
-    type='AP10KCocoMetric',
+    type='CocoMetric',
     ann_file=data_root + 'annotations/ap10k-test-split1.json')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_res101_8xb64-210e_ap10k-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_res50_8xb64-210e_ap10k-256x256.py`

 * *Files 3% similar despite different names*

```diff
@@ -39,16 +39,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,25 +67,22 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(
-        type='PackPoseInputs',
-        meta_keys=('id', 'img_id', 'img_path', 'ori_shape', 'img_shape',
-                   'input_size', 'flip_indices', 'category'))
+    dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
     batch_size=64,
     num_workers=4,
     persistent_workers=True,
@@ -127,12 +124,12 @@
         data_prefix=dict(img='data/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 
 # evaluators
 val_evaluator = dict(
-    type='AP10KCocoMetric',
+    type='CocoMetric',
     ann_file=data_root + 'annotations/ap10k-val-split1.json')
 test_evaluator = dict(
-    type='AP10KCocoMetric',
+    type='CocoMetric',
     ann_file=data_root + 'annotations/ap10k-test-split1.json')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_res50_8xb64-210e_ap10k-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_res101_8xb64-210e_ap10k-256x256.py`

 * *Files 6% similar despite different names*

```diff
@@ -39,16 +39,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
+        depth=101,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,25 +67,22 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(
-        type='PackPoseInputs',
-        meta_keys=('id', 'img_id', 'img_path', 'ori_shape', 'img_shape',
-                   'input_size', 'flip_indices', 'category'))
+    dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
     batch_size=64,
     num_workers=4,
     persistent_workers=True,
@@ -127,12 +124,12 @@
         data_prefix=dict(img='data/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 
 # evaluators
 val_evaluator = dict(
-    type='AP10KCocoMetric',
+    type='CocoMetric',
     ann_file=data_root + 'annotations/ap10k-val-split1.json')
 test_evaluator = dict(
-    type='AP10KCocoMetric',
+    type='CocoMetric',
     ann_file=data_root + 'annotations/ap10k-test-split1.json')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res101_8xb64-210e_locust-160x160.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res101_8xb64-210e_locust-160x160.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(160, 160), heatmap_size=(40, 40), sigma=2)
 
 # model settings
 model = dict(
@@ -70,15 +70,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_factor=0.25,
         rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale', padding=0.8),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res152_8xb32-210e_locust-160x160.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res152_8xb32-210e_locust-160x160.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(160, 160), heatmap_size=(40, 40), sigma=2)
 
 # model settings
 model = dict(
@@ -70,15 +70,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_factor=0.25,
         rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale', padding=0.8),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res50_8xb64-210e_locust-160x160.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res50_8xb64-210e_locust-160x160.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(160, 160), heatmap_size=(40, 40), sigma=2)
 
 # model settings
 model = dict(
@@ -70,15 +70,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_factor=0.25,
         rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale', padding=0.8),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res101_8xb64-210e_zebra-160x160.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res50_8xb64-210e_zebra-160x160.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(160, 160), heatmap_size=(40, 40), sigma=2)
 
 # model settings
 model = dict(
@@ -39,16 +39,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=9,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -70,15 +70,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_factor=0.25,
         rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale', padding=0.8),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res152_8xb32-210e_zebra-160x160.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res152_8xb32-210e_zebra-160x160.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(160, 160), heatmap_size=(40, 40), sigma=2)
 
 # model settings
 model = dict(
@@ -70,15 +70,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_factor=0.25,
         rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale', padding=0.8),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res50_8xb64-210e_zebra-160x160.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_res50_8xb32-210e_onehand10k-256x256.py`

 * *Files 4% similar despite different names*

```diff
@@ -23,97 +23,97 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(160, 160), heatmap_size=(40, 40), sigma=2)
+    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
         depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
-    ),
+        init_cfg=dict(
+            type='Pretrained',
+            checkpoint='torchvision://resnet50',
+        )),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
-        out_channels=9,
+        out_channels=21,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'ZebraDataset'
+dataset_type = 'OneHand10KDataset'
 data_mode = 'topdown'
-data_root = 'data/zebra/'
+data_root = 'data/onehand10k/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
-    dict(type='GetBBoxCenterScale', padding=0.8),
+    dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
-        type='RandomBBoxTransform',
-        shift_factor=0.25,
-        rotate_factor=180,
+        type='RandomBBoxTransform', rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
-    dict(type='GetBBoxCenterScale', padding=0.8),
+    dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/zebra_train.json',
-        data_prefix=dict(img='images/'),
+        ann_file='annotations/onehand10k_train.json',
+        data_prefix=dict(img=''),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/zebra_test.json',
-        data_prefix=dict(img='images/'),
+        ann_file='annotations/onehand10k_test.json',
+        data_prefix=dict(img=''),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
 val_evaluator = [
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_8xb64-210e_coco-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_8xb64-210e_coco-256x256.py`

 * *Files 4% similar despite different names*

```diff
@@ -79,18 +79,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(
-        type='GenerateTarget',
-        target_type='heatmap+keypoint_label',
-        encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 test_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_debias-8xb64-210e_coco-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_dsnt-8xb64-210e_coco-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -47,16 +47,14 @@
         depth=50,
     ),
     head=dict(
         type='DSNTHead',
         in_channels=2048,
         in_featuremap_size=(8, 8),
         num_joints=17,
-        debias=True,
-        beta=10.,
         loss=dict(
             type='MultipleLossWrapper',
             losses=[
                 dict(type='SmoothL1Loss', use_target_weight=True),
                 dict(type='JSDiscretLoss', use_target_weight=True)
             ]),
         decoder=codec),
@@ -81,18 +79,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(
-        type='GenerateTarget',
-        target_type='heatmap+keypoint_label',
-        encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 test_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_dsnt-8xb64-210e_coco-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_debias-8xb64-210e_coco-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -47,14 +47,16 @@
         depth=50,
     ),
     head=dict(
         type='DSNTHead',
         in_channels=2048,
         in_featuremap_size=(8, 8),
         num_joints=17,
+        debias=True,
+        beta=10.,
         loss=dict(
             type='MultipleLossWrapper',
             losses=[
                 dict(type='SmoothL1Loss', use_target_weight=True),
                 dict(type='JSDiscretLoss', use_target_weight=True)
             ]),
         decoder=codec),
@@ -79,18 +81,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(
-        type='GenerateTarget',
-        target_type='heatmap+keypoint_label',
-        encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 test_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_mobilenetv2_wo-deconv-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_mobilenetv2_wo-deconv-8xb64-210e_coco-256x192.py`

 * *Files 3% similar despite different names*

```diff
@@ -69,16 +69,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(
-        type='GenerateTarget', target_type='keypoint_xy_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_res50_8xb32-140e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_res50_8xb32-140e_coco-384x288.py`

 * *Files 5% similar despite different names*

```diff
@@ -65,16 +65,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(
-        type='GenerateTarget', target_type='keypoint_xy_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 test_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_res50_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_res50_8xb64-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -59,16 +59,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(
-        type='GenerateTarget', target_type='keypoint_xy_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 test_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_vipnas-mbv3_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_cpm_8xb32-210e_coco-384x288.py`

 * *Files 5% similar despite different names*

```diff
@@ -13,79 +13,85 @@
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
-        end=train_cfg['max_epochs'],
+        end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
+# hooks
+default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+
 # codec settings
 codec = dict(
-    type='SimCCLabel', input_size=(192, 256), sigma=6.0, simcc_split_ratio=2.0)
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(36, 48), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
-    backbone=dict(type='ViPNAS_MobileNetV3'),
+    backbone=dict(
+        type='CPM',
+        in_channels=3,
+        out_channels=17,
+        feat_channels=128,
+        num_stages=6),
     head=dict(
-        type='SimCCHead',
-        in_channels=160,
+        type='CPMHead',
+        in_channels=17,
         out_channels=17,
-        input_size=codec['input_size'],
-        in_featuremap_size=(6, 8),
-        simcc_split_ratio=codec['simcc_split_ratio'],
-        deconv_type='vipnas',
-        deconv_out_channels=(160, 160, 160),
-        deconv_num_groups=(160, 160, 160),
-        loss=dict(type='KLDiscretLoss', use_target_weight=True),
+        num_stages=6,
+        deconv_out_channels=None,
+        has_final_layer=False,
+        loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
-    test_cfg=dict(flip_test=True, ))
+    test_cfg=dict(
+        flip_test=True,
+        flip_mode='heatmap',
+        shift_heatmap=True,
+    ))
 
 # base dataset settings
 dataset_type = 'CocoDataset'
 data_mode = 'topdown'
 data_root = 'data/coco/'
 
-file_client_args = dict(backend='disk')
-
 # pipelines
 train_pipeline = [
-    dict(type='LoadImage', file_client_args=file_client_args),
+    dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(
-        type='GenerateTarget', target_type='keypoint_xy_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
-    dict(type='LoadImage', file_client_args=file_client_args),
+    dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
@@ -100,23 +106,20 @@
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
         ann_file='annotations/person_keypoints_val2017.json',
-        bbox_file=data_root + 'person_detection_results/'
+        bbox_file='data/coco/person_detection_results/'
         'COCO_val2017_detections_AP_H_56_person.json',
         data_prefix=dict(img='val2017/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
-# hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
-
 # evaluators
 val_evaluator = dict(
     type='CocoMetric',
     ann_file=data_root + 'annotations/person_keypoints_val2017.json')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/simcc/mpii/simcc_res50_wo-deconv-8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res50_8xb64-210e_mpii-256x256.py`

 * *Files 5% similar despite different names*

```diff
@@ -13,49 +13,45 @@
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
-        end=train_cfg['max_epochs'],
+        end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # codec settings
-codec = dict(
-    type='SimCCLabel', input_size=(256, 256), sigma=6.0, simcc_split_ratio=2.0)
+codec = dict(type='RegressionLabel', input_size=(256, 256))
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
         depth=50,
         init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
+    neck=dict(type='GlobalAveragePooling'),
     head=dict(
-        type='SimCCHead',
+        type='RegressionHead',
         in_channels=2048,
-        out_channels=16,
-        input_size=codec['input_size'],
-        in_featuremap_size=(8, 8),
-        simcc_split_ratio=codec['simcc_split_ratio'],
-        deconv_out_channels=None,
-        loss=dict(type='KLDiscretLoss', use_target_weight=True),
+        num_joints=16,
+        loss=dict(type='SmoothL1Loss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         shift_coords=True,
     ))
 
 # base dataset settings
@@ -68,16 +64,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(
-        type='GenerateTarget', target_type='keypoint_xy_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -112,12 +107,12 @@
         data_prefix=dict(img='images/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # evaluators
-val_evaluator = dict(type='MpiiPCKAccuracy', norm_item='head')
+val_evaluator = dict(type='MpiiPCKAccuracy')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/aic/td-hm_hrnet-w32_8xb64-210e_aic-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/aic/td-hm_hrnet-w32_8xb64-210e_aic-256x192.py`

 * *Files 4% similar despite different names*

```diff
@@ -96,15 +96,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/aic/td-hm_res101_8xb64-210e_aic-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/aic/td-hm_res101_8xb64-210e_aic-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/hrnet_coco.yml` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/hrnet_coco.yml`

 * *Files 5% similar despite different names*

```diff
@@ -3,14 +3,15 @@
   Paper:
     Title: Deep high-resolution representation learning for human pose estimation
     URL: http://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Deep_High-Resolution_Representation_Learning_for_Human_Pose_Estimation_CVPR_2019_paper.html
   README: https://github.com/open-mmlab/mmpose/blob/1.x/docs/src/papers/backbones/hrnet.md
 Models:
 - Config: configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-256x192.py
   In Collection: HRNet
+  Alias: human
   Metadata:
     Architecture: &id001
     - HRNet
     Training Data: COCO
   Name: td-hm_hrnet-w32_8xb64-210e_coco-256x192
   Results:
   - Dataset: COCO
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/litehrnet_coco.yml` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/litehrnet_coco.yml`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/mspn_coco.yml` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/mspn_coco.yml`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_2xmspn50_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_4xmspn50_8xb32-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -47,44 +47,44 @@
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='MSPN',
         unit_channels=256,
-        num_stages=2,
+        num_stages=4,
         num_units=4,
         num_blocks=[3, 4, 6, 3],
         norm_cfg=dict(type='BN'),
         init_cfg=dict(
             type='Pretrained',
             checkpoint='torchvision://resnet50',
         )),
     head=dict(
         type='MSPNHead',
         out_shape=(64, 48),
         unit_channels=256,
         out_channels=17,
-        num_stages=2,
+        num_stages=4,
         num_units=4,
         norm_cfg=dict(type='BN'),
         # each sub list is for a stage
         # and each element in each list is for a unit
-        level_indices=[0, 1, 2, 3] + [1, 2, 3, 4],
+        level_indices=[0, 1, 2, 3] * 3 + [1, 2, 3, 4],
         loss=([
             dict(
                 type='KeypointMSELoss',
                 use_target_weight=True,
                 loss_weight=0.25)
         ] * 3 + [
             dict(
                 type='KeypointOHKMMSELoss',
                 use_target_weight=True,
                 loss_weight=1.)
-        ]) * 2,
+        ]) * 4,
         decoder=codec[-1]),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=False,
     ))
 
@@ -97,17 +97,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
-    dict(
-        type='GenerateTarget', target_type='multilevel_heatmap',
-        encoder=codec),
+    dict(type='GenerateTarget', multilevel=True, encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_2xrsn50_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_2xrsn50_8xb32-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -95,17 +95,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
-    dict(
-        type='GenerateTarget', target_type='multilevel_heatmap',
-        encoder=codec),
+    dict(type='GenerateTarget', multilevel=True, encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_3xmspn50_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_2xmspn50_8xb32-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -47,44 +47,44 @@
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='MSPN',
         unit_channels=256,
-        num_stages=3,
+        num_stages=2,
         num_units=4,
         num_blocks=[3, 4, 6, 3],
         norm_cfg=dict(type='BN'),
         init_cfg=dict(
             type='Pretrained',
             checkpoint='torchvision://resnet50',
         )),
     head=dict(
         type='MSPNHead',
         out_shape=(64, 48),
         unit_channels=256,
         out_channels=17,
-        num_stages=3,
+        num_stages=2,
         num_units=4,
         norm_cfg=dict(type='BN'),
         # each sub list is for a stage
         # and each element in each list is for a unit
-        level_indices=[0, 1, 2, 3] * 2 + [1, 2, 3, 4],
+        level_indices=[0, 1, 2, 3] + [1, 2, 3, 4],
         loss=([
             dict(
                 type='KeypointMSELoss',
                 use_target_weight=True,
                 loss_weight=0.25)
         ] * 3 + [
             dict(
                 type='KeypointOHKMMSELoss',
                 use_target_weight=True,
                 loss_weight=1.)
-        ]) * 3,
+        ]) * 2,
         decoder=codec[-1]),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=False,
     ))
 
@@ -97,17 +97,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
-    dict(
-        type='GenerateTarget', target_type='multilevel_heatmap',
-        encoder=codec),
+    dict(type='GenerateTarget', multilevel=True, encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_3xrsn50_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_3xrsn50_8xb32-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -95,17 +95,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
-    dict(
-        type='GenerateTarget', target_type='multilevel_heatmap',
-        encoder=codec),
+    dict(type='GenerateTarget', multilevel=True, encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_4xmspn50_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_3xmspn50_8xb32-210e_coco-256x192.py`

 * *Files 6% similar despite different names*

```diff
@@ -47,44 +47,44 @@
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='MSPN',
         unit_channels=256,
-        num_stages=4,
+        num_stages=3,
         num_units=4,
         num_blocks=[3, 4, 6, 3],
         norm_cfg=dict(type='BN'),
         init_cfg=dict(
             type='Pretrained',
             checkpoint='torchvision://resnet50',
         )),
     head=dict(
         type='MSPNHead',
         out_shape=(64, 48),
         unit_channels=256,
         out_channels=17,
-        num_stages=4,
+        num_stages=3,
         num_units=4,
         norm_cfg=dict(type='BN'),
         # each sub list is for a stage
         # and each element in each list is for a unit
-        level_indices=[0, 1, 2, 3] * 3 + [1, 2, 3, 4],
+        level_indices=[0, 1, 2, 3] * 2 + [1, 2, 3, 4],
         loss=([
             dict(
                 type='KeypointMSELoss',
                 use_target_weight=True,
                 loss_weight=0.25)
         ] * 3 + [
             dict(
                 type='KeypointOHKMMSELoss',
                 use_target_weight=True,
                 loss_weight=1.)
-        ]) * 4,
+        ]) * 3,
         decoder=codec[-1]),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=False,
     ))
 
@@ -97,17 +97,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
-    dict(
-        type='GenerateTarget', target_type='multilevel_heatmap',
-        encoder=codec),
+    dict(type='GenerateTarget', multilevel=True, encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_alexnet_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_alexnet_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -63,15 +63,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_cpm_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_cpm_8xb64-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,15 +27,15 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(36, 48), sigma=3)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(24, 32), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -71,27 +71,27 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_cpm_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hourglass52_8xb32-210e_coco-384x384.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,37 +27,34 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(24, 32), sigma=2)
+    type='MSRAHeatmap', input_size=(384, 384), heatmap_size=(96, 96), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='CPM',
-        in_channels=3,
-        out_channels=17,
-        feat_channels=128,
-        num_stages=6),
+        type='HourglassNet',
+        num_stacks=1,
+    ),
     head=dict(
         type='CPMHead',
-        in_channels=17,
+        in_channels=256,
         out_channels=17,
-        num_stages=6,
+        num_stages=1,
         deconv_out_channels=None,
-        has_final_layer=False,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
@@ -71,27 +68,27 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hourglass52_8xb32-210e_coco-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hourglass52_8xb32-210e_coco-256x256.py`

 * *Files 1% similar despite different names*

```diff
@@ -68,15 +68,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hourglass52_8xb32-210e_coco-384x384.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_dark-8xb64-210e_coco-384x288.py`

 * *Files 3% similar despite different names*

```diff
@@ -27,34 +27,37 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(384, 384), heatmap_size=(96, 96), sigma=3)
+    type='MSRAHeatmap',
+    input_size=(288, 384),
+    heatmap_size=(72, 96),
+    sigma=3,
+    unbiased=True)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='HourglassNet',
-        num_stacks=1,
+        type='ResNet',
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
     head=dict(
-        type='CPMHead',
-        in_channels=256,
+        type='HeatmapHead',
+        in_channels=2048,
         out_channels=17,
-        num_stages=1,
-        deconv_out_channels=None,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
@@ -68,27 +71,27 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-base_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-base_8xb32-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,17 +6,17 @@
 # optimizer
 optim_wrapper = dict(
     optimizer=dict(
         type='AdamW',
         lr=5e-4,
         betas=(0.9, 0.999),
         weight_decay=0.01,
-        paramwise_cfg=dict(
-            custom_keys={'relative_position_bias_table': dict(
-                decay_mult=0.)})))
+    ),
+    paramwise_cfg=dict(
+        custom_keys={'relative_position_bias_table': dict(decay_mult=0.)}))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
@@ -116,15 +116,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-base_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-base_8xb32-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,17 +6,17 @@
 # optimizer
 optim_wrapper = dict(
     optimizer=dict(
         type='AdamW',
         lr=5e-4,
         betas=(0.9, 0.999),
         weight_decay=0.01,
-        paramwise_cfg=dict(
-            custom_keys={'relative_position_bias_table': dict(
-                decay_mult=0.)})))
+    ),
+    paramwise_cfg=dict(
+        custom_keys={'relative_position_bias_table': dict(decay_mult=0.)}))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
@@ -116,15 +116,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-small_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-small_8xb32-210e_coco-256x192.py`

 * *Files 0% similar despite different names*

```diff
@@ -6,17 +6,17 @@
 # optimizer
 optim_wrapper = dict(
     optimizer=dict(
         type='AdamW',
         lr=5e-4,
         betas=(0.9, 0.999),
         weight_decay=0.01,
-        paramwise_cfg=dict(
-            custom_keys={'relative_position_bias_table': dict(
-                decay_mult=0.)})))
+    ),
+    paramwise_cfg=dict(
+        custom_keys={'relative_position_bias_table': dict(decay_mult=0.)}))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
@@ -116,15 +116,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-small_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-small_8xb32-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,17 +6,17 @@
 # optimizer
 optim_wrapper = dict(
     optimizer=dict(
         type='AdamW',
         lr=5e-4,
         betas=(0.9, 0.999),
         weight_decay=0.01,
-        paramwise_cfg=dict(
-            custom_keys={'relative_position_bias_table': dict(
-                decay_mult=0.)})))
+    ),
+    paramwise_cfg=dict(
+        custom_keys={'relative_position_bias_table': dict(decay_mult=0.)}))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
@@ -116,15 +116,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -96,15 +96,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -96,15 +96,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_coarsedropout-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_coarsedropout-8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -111,15 +111,15 @@
                 max_height=40,
                 max_width=40,
                 min_holes=1,
                 min_height=10,
                 min_width=10,
                 p=0.5),
         ]),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_dark-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_dark-8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -100,15 +100,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_dark-8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_dark-8xb64-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -100,15 +100,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_gridmask-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_gridmask-8xb64-210e_coco-256x192.py`

 * *Files 0% similar despite different names*

```diff
@@ -108,15 +108,15 @@
             dict(
                 type='GridDropout',
                 unit_size_min=10,
                 unit_size_max=40,
                 random_offset=True,
                 p=0.5),
         ]),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_photometric-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_photometric-8xb64-210e_coco-256x192.py`

 * *Files 0% similar despite different names*

```diff
@@ -99,15 +99,15 @@
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PhotometricDistortion'),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_udp-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_udp-8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -96,15 +96,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size'], use_udp=True),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size'], use_udp=True),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_udp-8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_udp-8xb64-210e_coco-384x288.py`

 * *Files 0% similar despite different names*

```diff
@@ -96,15 +96,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size'], use_udp=True),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size'], use_udp=True),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_udp-regress-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_udp-regress-8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -101,15 +101,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size'], use_udp=True),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size'], use_udp=True),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_dark-8xb32-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -27,15 +27,19 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap',
+    input_size=(192, 256),
+    heatmap_size=(48, 64),
+    sigma=2,
+    unbiased=True)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -96,15 +100,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-384x288.py`

 * *Files 0% similar despite different names*

```diff
@@ -96,15 +96,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_dark-8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,19 +27,15 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap',
-    input_size=(192, 256),
-    heatmap_size=(48, 64),
-    sigma=2,
-    unbiased=True)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -100,15 +96,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_dark-8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_dark-8xb32-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -100,15 +100,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_udp-8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_udp-8xb32-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -96,15 +96,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size'], use_udp=True),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size'], use_udp=True),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_udp-8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_udp-8xb32-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -96,15 +96,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size'], use_udp=True),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size'], use_udp=True),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-18_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-18_8xb32-210e_coco-384x288.py`

 * *Files 5% similar despite different names*

```diff
@@ -86,15 +86,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-18_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-18_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -86,15 +86,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-30_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-30_8xb32-210e_coco-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -86,15 +86,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-30_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_litehrnet-30_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -86,15 +86,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_mobilenetv2_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_mobilenetv2_8xb64-210e_coco-256x192.py`

 * *Files 0% similar despite different names*

```diff
@@ -70,15 +70,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_mobilenetv2_8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_mobilenetv2_8xb64-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -70,15 +70,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_mspn50_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_mspn50_8xb32-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -97,17 +97,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
-    dict(
-        type='GenerateTarget', target_type='multilevel_heatmap',
-        encoder=codec),
+    dict(type='GenerateTarget', multilevel=True, encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_pvt-s_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_pvt-s_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -72,15 +72,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_pvtv2-b2_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_pvtv2-b2_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -73,15 +73,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_8xb32-210e_coco-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=256)
+auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
@@ -39,16 +39,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
+        depth=152,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet152'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_dark-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -27,32 +27,28 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap',
-    input_size=(192, 256),
-    heatmap_size=(48, 64),
-    sigma=2,
-    unbiased=True)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -71,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_dark-8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_dark-8xb64-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -71,15 +71,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_8xb32-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest50_8xb64-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,28 +27,28 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNet',
-        depth=152,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet152'),
+        type='ResNeSt',
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest50'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,27 +67,27 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_dark-8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_dark-8xb32-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=512)
+auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap',
@@ -71,15 +71,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_dark-8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res152_dark-8xb32-210e_coco-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,26 +20,27 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=512)
+auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap',
     input_size=(288, 384),
     heatmap_size=(72, 96),
     sigma=3,
-    unbiased=True)
+    unbiased=True,
+    blur_kernel_size=17)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -71,15 +72,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest101_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -38,17 +38,17 @@
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNet',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
+        type='ResNeSt',
+        depth=101,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest101'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_8xb64-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_dark-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_dark-8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -71,15 +71,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res50_dark-8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest269_8xb32-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -27,32 +27,28 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap',
-    input_size=(288, 384),
-    heatmap_size=(72, 96),
-    sigma=3,
-    unbiased=True)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNet',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
+        type='ResNeSt',
+        depth=269,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest269'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -71,27 +67,27 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest101_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest200_8xb16-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,15 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=256)
+auto_scale_lr = dict(base_batch_size=128)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
@@ -39,16 +39,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNeSt',
-        depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest101'),
+        depth=200,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest200'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,40 +67,40 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=16,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
         ann_file='annotations/person_keypoints_train2017.json',
         data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
-    batch_size=32,
+    batch_size=16,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest101_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest200_8xb64-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -39,16 +39,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNeSt',
-        depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest101'),
+        depth=200,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest200'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest200_8xb16-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d101_8xb32-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,15 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=128)
+auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
@@ -38,17 +38,17 @@
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNeSt',
-        depth=200,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest200'),
+        type='ResNetV1d',
+        depth=101,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet101_v1d'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,40 +67,40 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=16,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
         ann_file='annotations/person_keypoints_train2017.json',
         data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
-    batch_size=16,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest200_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv2_8xb64-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -27,32 +27,32 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNeSt',
-        depth=200,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest200'),
+        type='ShuffleNetV2',
+        widen_factor=1.0,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://shufflenet_v2'),
     ),
     head=dict(
         type='HeatmapHead',
-        in_channels=2048,
+        in_channels=1024,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest269_8xb16-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d152_8xb48-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,15 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=128)
+auto_scale_lr = dict(base_batch_size=384)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
@@ -38,17 +38,17 @@
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNeSt',
-        depth=269,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest269'),
+        type='ResNetV1d',
+        depth=152,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet152_v1d'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,40 +67,40 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=16,
+    batch_size=48,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
         ann_file='annotations/person_keypoints_train2017.json',
         data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
-    batch_size=16,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest269_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d50_8xb64-210e_coco-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,28 +27,28 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNeSt',
-        depth=269,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest269'),
+        type='ResNetV1d',
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet50_v1d'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,27 +67,27 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest50_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest50_8xb64-210e_coco-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,15 +27,15 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest50_8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv2_8xb64-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,32 +27,32 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNeSt',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest50'),
+        type='ShuffleNetV2',
+        widen_factor=1.0,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://shufflenet_v2'),
     ),
     head=dict(
         type='HeatmapHead',
-        in_channels=2048,
+        in_channels=1024,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d101_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d101_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,22 +20,22 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=256)
+auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -67,27 +67,27 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d101_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext50_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -38,17 +38,17 @@
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNetV1d',
-        depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet101_v1d'),
+        type='ResNeXt',
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnext50_32x4d'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d152_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d152_8xb32-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d152_8xb48-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d50_8xb64-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,35 +20,35 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=384)
+auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNetV1d',
-        depth=152,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet152_v1d'),
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet50_v1d'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,27 +67,27 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=48,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d50_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet50_8xb64-210e_coco-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,28 +27,28 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNetV1d',
+        type='SEResNet',
         depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet50_v1d'),
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://se-resnet50'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnetv1d50_8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vipnas-res50_8xb64-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,32 +27,28 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
-    backbone=dict(
-        type='ResNetV1d',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet50_v1d'),
-    ),
+    backbone=dict(type='ViPNAS_ResNet', depth=50),
     head=dict(
-        type='HeatmapHead',
-        in_channels=2048,
+        type='ViPNASHead',
+        in_channels=608,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
@@ -65,17 +61,20 @@
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
-    dict(type='RandomBBoxTransform'),
+    dict(
+        type='RandomBBoxTransform',
+        rotate_factor=60,
+        scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext101_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext152_8xb32-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,36 +20,36 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=256)
+auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNeXt',
-        depth=101,
+        depth=152,
         init_cfg=dict(
-            type='Pretrained', checkpoint='mmcls://resnext101_32x4d'),
+            type='Pretrained', checkpoint='mmcls://resnext152_32x4d'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -68,15 +68,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext101_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext101_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -68,15 +68,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext152_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext152_8xb48-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,22 +20,22 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=512)
+auto_scale_lr = dict(base_batch_size=384)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -68,27 +68,27 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=48,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext152_8xb48-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext101_8xb32-210e_coco-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=384)
+auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
@@ -39,17 +39,17 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNeXt',
-        depth=152,
+        depth=101,
         init_cfg=dict(
-            type='Pretrained', checkpoint='mmcls://resnext152_32x4d'),
+            type='Pretrained', checkpoint='mmcls://resnext101_32x4d'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -68,27 +68,27 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=48,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext50_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext50_8xb64-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -27,15 +27,15 @@
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnext50_8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest269_8xb16-210e_coco-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=512)
+auto_scale_lr = dict(base_batch_size=128)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
@@ -38,17 +38,17 @@
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNeXt',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnext50_32x4d'),
+        type='ResNeSt',
+        depth=269,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest269'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,40 +67,40 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=16,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
         ann_file='annotations/person_keypoints_train2017.json',
         data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
-    batch_size=32,
+    batch_size=16,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_rsn18_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_rsn18_8xb32-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -95,17 +95,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
-    dict(
-        type='GenerateTarget', target_type='multilevel_heatmap',
-        encoder=codec),
+    dict(type='GenerateTarget', multilevel=True, encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_rsn50_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_rsn50_8xb32-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -95,17 +95,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
-    dict(
-        type='GenerateTarget', target_type='multilevel_heatmap',
-        encoder=codec),
+    dict(type='GenerateTarget', multilevel=True, encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec[0]['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet101_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet101_8xb32-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -70,15 +70,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet101_8xb48-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet50_8xb32-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,15 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=512)
+auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
@@ -39,19 +39,19 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='SCNet',
-        depth=101,
+        depth=50,
         init_cfg=dict(
             type='Pretrained',
             checkpoint='https://download.openmmlab.com/mmpose/'
-            'pretrain_models/scnet101-94250a77.pth'),
+            'pretrain_models/scnet50-7ef0a199.pth'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -70,41 +70,41 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=48,
-    num_workers=2,
+    batch_size=32,
+    num_workers=1,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
         ann_file='annotations/person_keypoints_train2017.json',
         data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
-    num_workers=2,
+    num_workers=1,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet50_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet101_8xb48-210e_coco-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=256)
+auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
@@ -39,19 +39,19 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='SCNet',
-        depth=50,
+        depth=101,
         init_cfg=dict(
             type='Pretrained',
             checkpoint='https://download.openmmlab.com/mmpose/'
-            'pretrain_models/scnet50-7ef0a199.pth'),
+            'pretrain_models/scnet101-94250a77.pth'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -70,41 +70,41 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
-    num_workers=1,
+    batch_size=48,
+    num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
         ann_file='annotations/person_keypoints_train2017.json',
         data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
-    num_workers=1,
+    num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet50_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_scnet50_8xb64-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -70,15 +70,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet101_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vipnas-mbv3_8xb64-210e_coco-256x192.py`

 * *Files 4% similar despite different names*

```diff
@@ -20,40 +20,38 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=256)
+auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
-    backbone=dict(
-        type='SEResNet',
-        depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://se-resnet101'),
-    ),
+    backbone=dict(type='ViPNAS_MobileNetV3'),
     head=dict(
-        type='HeatmapHead',
-        in_channels=2048,
+        type='ViPNASHead',
+        in_channels=160,
         out_channels=17,
+        deconv_out_channels=(160, 160, 160),
+        deconv_num_groups=(160, 160, 160),
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
@@ -65,29 +63,32 @@
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
-    dict(type='RandomBBoxTransform'),
+    dict(
+        type='RandomBBoxTransform',
+        rotate_factor=60,
+        scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet101_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet101_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet152_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet152_8xb48-210e_coco-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,22 +20,22 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=512)
+auto_scale_lr = dict(base_batch_size=384)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -66,27 +66,27 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=48,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet152_8xb48-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_resnest101_8xb32-210e_coco-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=384)
+auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
@@ -38,16 +38,17 @@
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='SEResNet',
-        depth=152,
+        type='ResNeSt',
+        depth=101,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnest101'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -66,27 +67,27 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=48,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet50_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet50_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet50_8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res152_8xb64-210e_crowdpose-256x192.py`

 * *Files 6% similar despite different names*

```diff
@@ -23,59 +23,59 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='crowdpose/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='SEResNet',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://se-resnet50'),
+        type='ResNet',
+        depth=152,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet152'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
-        out_channels=17,
+        out_channels=14,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'CocoDataset'
+dataset_type = 'CrowdPoseDataset'
 data_mode = 'topdown'
-data_root = 'data/coco/'
+data_root = 'data/crowdpose/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -87,35 +87,37 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/person_keypoints_train2017.json',
-        data_prefix=dict(img='train2017/'),
+        ann_file='annotations/mmpose_crowdpose_trainval.json',
+        data_prefix=dict(img='images/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/person_keypoints_val2017.json',
-        bbox_file='data/coco/person_detection_results/'
-        'COCO_val2017_detections_AP_H_56_person.json',
-        data_prefix=dict(img='val2017/'),
+        ann_file='annotations/mmpose_crowdpose_test.json',
+        bbox_file='data/crowdpose/annotations/det_for_crowd_test_0.1_0.5.json',
+        data_prefix=dict(img='images/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
 val_evaluator = dict(
     type='CocoMetric',
-    ann_file=data_root + 'annotations/person_keypoints_val2017.json')
+    ann_file=data_root + 'annotations/mmpose_crowdpose_test.json',
+    use_area=False,
+    iou_type='keypoints_crowd',
+    prefix='crowdpose')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv1_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv1_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv1_8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv1_8xb64-210e_coco-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv2_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res152_rle-8xb64-210e_coco-256x192.py`

 * *Files 4% similar despite different names*

```diff
@@ -13,53 +13,49 @@
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
-        end=210,
+        end=train_cfg['max_epochs'],
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
-# hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
-
 # codec settings
-codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+codec = dict(type='RegressionLabel', input_size=(192, 256))
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ShuffleNetV2',
-        widen_factor=1.0,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://shufflenet_v2'),
+        type='ResNet',
+        depth=152,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet152'),
     ),
+    neck=dict(type='GlobalAveragePooling'),
     head=dict(
-        type='HeatmapHead',
-        in_channels=1024,
-        out_channels=17,
-        loss=dict(type='KeypointMSELoss', use_target_weight=True),
+        type='RLEHead',
+        in_channels=2048,
+        num_joints=17,
+        loss=dict(type='RLELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
-        flip_mode='heatmap',
-        shift_heatmap=True,
+        shift_coords=True,
     ))
 
 # base dataset settings
 dataset_type = 'CocoDataset'
 data_mode = 'topdown'
 data_root = 'data/coco/'
 
@@ -67,15 +63,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -102,20 +98,24 @@
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
         ann_file='annotations/person_keypoints_val2017.json',
-        bbox_file='data/coco/person_detection_results/'
+        bbox_file=f'{data_root}person_detection_results/'
         'COCO_val2017_detections_AP_H_56_person.json',
         data_prefix=dict(img='val2017/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
+# hooks
+default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+
 # evaluators
 val_evaluator = dict(
     type='CocoMetric',
-    ann_file=data_root + 'annotations/person_keypoints_val2017.json')
+    ann_file=f'{data_root}annotations/person_keypoints_val2017.json',
+    score_mode='bbox_rle')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_shufflenetv2_8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res152_rle-8xb64-210e_coco-384x288.py`

 * *Files 5% similar despite different names*

```diff
@@ -13,53 +13,49 @@
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
-        end=210,
+        end=train_cfg['max_epochs'],
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
-# hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
-
 # codec settings
-codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
+codec = dict(type='RegressionLabel', input_size=(288, 384))
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ShuffleNetV2',
-        widen_factor=1.0,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://shufflenet_v2'),
+        type='ResNet',
+        depth=152,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet152'),
     ),
+    neck=dict(type='GlobalAveragePooling'),
     head=dict(
-        type='HeatmapHead',
-        in_channels=1024,
-        out_channels=17,
-        loss=dict(type='KeypointMSELoss', use_target_weight=True),
+        type='RLEHead',
+        in_channels=2048,
+        num_joints=17,
+        loss=dict(type='RLELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
-        flip_mode='heatmap',
-        shift_heatmap=True,
+        shift_coords=True,
     ))
 
 # base dataset settings
 dataset_type = 'CocoDataset'
 data_mode = 'topdown'
 data_root = 'data/coco/'
 
@@ -67,15 +63,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -102,20 +98,24 @@
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
         ann_file='annotations/person_keypoints_val2017.json',
-        bbox_file='data/coco/person_detection_results/'
+        bbox_file=f'{data_root}person_detection_results/'
         'COCO_val2017_detections_AP_H_56_person.json',
         data_prefix=dict(img='val2017/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
+# hooks
+default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+
 # evaluators
 val_evaluator = dict(
     type='CocoMetric',
-    ann_file=data_root + 'annotations/person_keypoints_val2017.json')
+    ann_file=f'{data_root}annotations/person_keypoints_val2017.json',
+    score_mode='bbox_rle')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-b-p4-w7_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-b-p4-w7_8xb32-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -84,15 +84,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-b-p4-w7_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-b-p4-w7_8xb32-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -84,15 +84,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-l-p4-w7_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-l-p4-w7_8xb32-210e_coco-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,20 +6,21 @@
 # optimizer
 optim_wrapper = dict(
     optimizer=dict(
         type='AdamW',
         lr=5e-4,
         betas=(0.9, 0.999),
         weight_decay=0.01,
-        paramwise_cfg=dict(
-            custom_keys={
-                'absolute_pos_embed': dict(decay_mult=0.),
-                'relative_position_bias_table': dict(decay_mult=0.),
-                'norm': dict(decay_mult=0.)
-            })))
+    ),
+    paramwise_cfg=dict(
+        custom_keys={
+            'absolute_pos_embed': dict(decay_mult=0.),
+            'relative_position_bias_table': dict(decay_mult=0.),
+            'norm': dict(decay_mult=0.)
+        }))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
@@ -35,15 +36,15 @@
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=2)
 
 # model settings
 norm_cfg = dict(type='SyncBN', requires_grad=True)
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
@@ -65,15 +66,15 @@
         patch_norm=True,
         out_indices=(3, ),
         with_cp=False,
         convert_weights=True,
         init_cfg=dict(
             type='Pretrained',
             checkpoint='https://github.com/SwinTransformer/storage/releases/'
-            'download/v1.0.0/swin_base_patch4_window7_224_22k.pth'),
+            'download/v1.0.0/swin_base_patch4_window12_384_22k.pth'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=1536,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -92,15 +93,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-l-p4-w7_8xb32-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-l-p4-w7_8xb32-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,20 +6,21 @@
 # optimizer
 optim_wrapper = dict(
     optimizer=dict(
         type='AdamW',
         lr=5e-4,
         betas=(0.9, 0.999),
         weight_decay=0.01,
-        paramwise_cfg=dict(
-            custom_keys={
-                'absolute_pos_embed': dict(decay_mult=0.),
-                'relative_position_bias_table': dict(decay_mult=0.),
-                'norm': dict(decay_mult=0.)
-            })))
+    ),
+    paramwise_cfg=dict(
+        custom_keys={
+            'absolute_pos_embed': dict(decay_mult=0.),
+            'relative_position_bias_table': dict(decay_mult=0.),
+            'norm': dict(decay_mult=0.)
+        }))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
@@ -35,15 +36,15 @@
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=2)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 norm_cfg = dict(type='SyncBN', requires_grad=True)
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
@@ -65,15 +66,15 @@
         patch_norm=True,
         out_indices=(3, ),
         with_cp=False,
         convert_weights=True,
         init_cfg=dict(
             type='Pretrained',
             checkpoint='https://github.com/SwinTransformer/storage/releases/'
-            'download/v1.0.0/swin_base_patch4_window12_384_22k.pth'),
+            'download/v1.0.0/swin_base_patch4_window7_224_22k.pth'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=1536,
         out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -92,15 +93,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-t-p4-w7_8xb32-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-t-p4-w7_8xb32-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -84,15 +84,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vgg16-bn_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vgg16-bn_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -68,15 +68,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vipnas-mbv3_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-mbv3_dark-8xb64-210e_coco-wholebody-256x192.py`

 * *Files 4% similar despite different names*

```diff
@@ -23,60 +23,65 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+default_hooks = dict(
+    checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap',
+    input_size=(192, 256),
+    heatmap_size=(48, 64),
+    sigma=2,
+    unbiased=True)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(type='ViPNAS_MobileNetV3'),
     head=dict(
         type='ViPNASHead',
         in_channels=160,
-        out_channels=17,
+        out_channels=133,
         deconv_out_channels=(160, 160, 160),
         deconv_num_groups=(160, 160, 160),
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'CocoDataset'
+dataset_type = 'CocoWholeBodyDataset'
 data_mode = 'topdown'
 data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -88,35 +93,34 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/person_keypoints_train2017.json',
+        ann_file='annotations/coco_wholebody_train_v1.0.json',
         data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/person_keypoints_val2017.json',
-        bbox_file='data/coco/person_detection_results/'
-        'COCO_val2017_detections_AP_H_56_person.json',
+        ann_file='annotations/coco_wholebody_val_v1.0.json',
         data_prefix=dict(img='val2017/'),
         test_mode=True,
+        bbox_file='data/coco/person_detection_results/'
+        'COCO_val2017_detections_AP_H_56_person.json',
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
-# evaluators
 val_evaluator = dict(
-    type='CocoMetric',
-    ann_file=data_root + 'annotations/person_keypoints_val2017.json')
+    type='CocoWholeBodyMetric',
+    ann_file=data_root + 'annotations/coco_wholebody_val_v1.0.json')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vipnas-res50_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub2-256x256.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 _base_ = ['../../../_base_/default_runtime.py']
 
 # runtime
-train_cfg = dict(max_epochs=210, val_interval=10)
+train_cfg = dict(max_epochs=20, val_interval=1)
 
 # optimizer
 optim_wrapper = dict(optimizer=dict(
     type='Adam',
     lr=5e-4,
 ))
 
@@ -13,70 +13,72 @@
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
-        end=210,
-        milestones=[170, 200],
+        end=20,
+        milestones=[8, 15],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+default_hooks = dict(
+    checkpoint=dict(save_best='PCK', rule='greater', interval=1))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
-    backbone=dict(type='ViPNAS_ResNet', depth=50),
+    backbone=dict(type='ResNet', depth=50),
     head=dict(
-        type='ViPNASHead',
-        in_channels=608,
-        out_channels=17,
+        type='HeatmapHead',
+        in_channels=2048,
+        out_channels=15,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
+load_from = 'https://download.openmmlab.com/mmpose/top_down/resnet/res50_mpii_256x256-418ffc88_20200812.pth'  # noqa: E501
 
 # base dataset settings
-dataset_type = 'CocoDataset'
+dataset_type = 'JhmdbDataset'
 data_mode = 'topdown'
-data_root = 'data/coco/'
+data_root = 'data/jhmdb/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(type='RandomHalfBody'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
+
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
@@ -86,35 +88,33 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/person_keypoints_train2017.json',
-        data_prefix=dict(img='train2017/'),
+        ann_file='annotations/Sub2_train.json',
+        data_prefix=dict(img=''),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/person_keypoints_val2017.json',
-        bbox_file='data/coco/person_detection_results/'
-        'COCO_val2017_detections_AP_H_56_person.json',
-        data_prefix=dict(img='val2017/'),
+        ann_file='annotations/Sub2_test.json',
+        data_prefix=dict(img=''),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
-val_evaluator = dict(
-    type='CocoMetric',
-    ann_file=data_root + 'annotations/person_keypoints_val2017.json')
+val_evaluator = [
+    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item=['bbox', 'torso']),
+]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_hrnet-w32_8xb64-210e_crowdpose-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_hrnet-w32_8xb64-210e_crowdpose-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -96,15 +96,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res101_8xb64-210e_crowdpose-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res101_8xb64-210e_crowdpose-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res101_8xb64-210e_crowdpose-320x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res101_8xb64-210e_crowdpose-320x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res152_8xb64-210e_crowdpose-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res50_8xb64-210e_crowdpose-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -39,16 +39,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=152,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet152'),
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=14,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,15 +67,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res50_8xb64-210e_crowdpose-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_mobilenetv2_8xb64-210e_mpii-256x256.py`

 * *Files 6% similar despite different names*

```diff
@@ -23,59 +23,59 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='crowdpose/AP', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNet',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
+        type='MobileNetV2',
+        widen_factor=1.,
+        out_indices=(7, ),
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://mobilenet_v2'),
     ),
     head=dict(
         type='HeatmapHead',
-        in_channels=2048,
-        out_channels=14,
+        in_channels=1280,
+        out_channels=16,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'CrowdPoseDataset'
+dataset_type = 'MpiiDataset'
 data_mode = 'topdown'
-data_root = 'data/crowdpose/'
+data_root = 'data/mpii/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(type='RandomHalfBody'),
-    dict(type='RandomBBoxTransform'),
+    dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -87,37 +87,32 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/mmpose_crowdpose_trainval.json',
+        ann_file='annotations/mpii_train.json',
         data_prefix=dict(img='images/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/mmpose_crowdpose_test.json',
-        bbox_file='data/crowdpose/annotations/det_for_crowd_test_0.1_0.5.json',
+        ann_file='annotations/mpii_val.json',
+        headbox_file='data/mpii/annotations/mpii_gt_val.mat',
         data_prefix=dict(img='images/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
-val_evaluator = dict(
-    type='CocoMetric',
-    ann_file=data_root + 'annotations/mmpose_crowdpose_test.json',
-    use_area=False,
-    iou_type='keypoints_crowd',
-    prefix='crowdpose')
+val_evaluator = dict(type='MpiiPCKAccuracy')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub1-368x368.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub1-368x368.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,16 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/Mean PCK', rule='greater'))
+default_hooks = dict(
+    checkpoint=dict(save_best='PCK', rule='greater', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(368, 368), heatmap_size=(46, 46), sigma=2)
 
 # model settings
 model = dict(
@@ -73,15 +74,15 @@
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
@@ -117,11 +118,10 @@
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
 val_evaluator = [
-    dict(type='JhmdbPCKAccuracy', thr=0.2),
-    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item='torso'),
+    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item=['bbox', 'torso']),
 ]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub2-368x368.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub2-368x368.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,16 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/Mean PCK', rule='greater'))
+default_hooks = dict(
+    checkpoint=dict(save_best='PCK', rule='greater', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(368, 368), heatmap_size=(46, 46), sigma=2)
 
 # model settings
 model = dict(
@@ -73,15 +74,15 @@
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
@@ -117,11 +118,10 @@
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
 val_evaluator = [
-    dict(type='JhmdbPCKAccuracy', thr=0.2),
-    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item='torso'),
+    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item=['bbox', 'torso']),
 ]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub3-368x368.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub3-368x368.py`

 * *Files 3% similar despite different names*

```diff
@@ -23,15 +23,16 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/Mean PCK', rule='greater'))
+default_hooks = dict(
+    checkpoint=dict(save_best='PCK', rule='greater', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(368, 368), heatmap_size=(46, 46), sigma=2)
 
 # model settings
 model = dict(
@@ -73,15 +74,15 @@
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
@@ -117,11 +118,10 @@
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
 val_evaluator = [
-    dict(type='JhmdbPCKAccuracy', thr=0.2),
-    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item='torso'),
+    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item=['bbox', 'torso']),
 ]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub1-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub1-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,16 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/Mean PCK', rule='greater'))
+default_hooks = dict(
+    checkpoint=dict(save_best='PCK', rule='greater', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(32, 32), sigma=2)
 
 # model settings
 model = dict(
@@ -68,15 +69,15 @@
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
@@ -112,11 +113,10 @@
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
 val_evaluator = [
-    dict(type='JhmdbPCKAccuracy', thr=0.2),
-    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item='torso'),
+    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item=['bbox', 'torso']),
 ]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub2-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub2-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,16 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/Mean PCK', rule='greater'))
+default_hooks = dict(
+    checkpoint=dict(save_best='PCK', rule='greater', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(32, 32), sigma=2)
 
 # model settings
 model = dict(
@@ -68,15 +69,15 @@
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
@@ -112,11 +113,10 @@
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
 val_evaluator = [
-    dict(type='JhmdbPCKAccuracy', thr=0.2),
-    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item='torso'),
+    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item=['bbox', 'torso']),
 ]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub3-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub3-256x256.py`

 * *Files 3% similar despite different names*

```diff
@@ -23,15 +23,16 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/Mean PCK', rule='greater'))
+default_hooks = dict(
+    checkpoint=dict(save_best='PCK', rule='greater', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(32, 32), sigma=2)
 
 # model settings
 model = dict(
@@ -68,15 +69,15 @@
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
@@ -112,11 +113,10 @@
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
 val_evaluator = [
-    dict(type='JhmdbPCKAccuracy', thr=0.2),
-    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item='torso'),
+    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item=['bbox', 'torso']),
 ]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub1-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub1-256x256.py`

 * *Files 6% similar despite different names*

```diff
@@ -23,15 +23,16 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/Mean PCK', rule='greater'))
+default_hooks = dict(
+    checkpoint=dict(save_best='PCK', rule='greater', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -66,15 +67,15 @@
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
@@ -110,11 +111,10 @@
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
 val_evaluator = [
-    dict(type='JhmdbPCKAccuracy', thr=0.2),
-    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item='torso'),
+    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item=['bbox', 'torso']),
 ]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub2-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub3-256x256.py`

 * *Files 6% similar despite different names*

```diff
@@ -23,15 +23,16 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/Mean PCK', rule='greater'))
+default_hooks = dict(
+    checkpoint=dict(save_best='PCK', rule='greater', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -66,15 +67,15 @@
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
@@ -87,34 +88,33 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/Sub2_train.json',
+        ann_file='annotations/Sub3_train.json',
         data_prefix=dict(img=''),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/Sub2_test.json',
+        ann_file='annotations/Sub3_test.json',
         data_prefix=dict(img=''),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
 val_evaluator = [
-    dict(type='JhmdbPCKAccuracy', thr=0.2),
-    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item='torso'),
+    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item=['bbox', 'torso']),
 ]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub3-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_rle-pretrained-8xb64-210e_coco-256x192.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,85 +1,87 @@
 _base_ = ['../../../_base_/default_runtime.py']
 
 # runtime
-train_cfg = dict(max_epochs=20, val_interval=1)
+train_cfg = dict(max_epochs=210, val_interval=10)
 
 # optimizer
 optim_wrapper = dict(optimizer=dict(
     type='Adam',
-    lr=5e-4,
+    lr=1e-3,
 ))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
-        end=20,
-        milestones=[8, 15],
+        end=train_cfg['max_epochs'],
+        milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
-# hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/Mean PCK', rule='greater'))
-
 # codec settings
-codec = dict(
-    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+codec = dict(type='RegressionLabel', input_size=(192, 256))
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
-    backbone=dict(type='ResNet', depth=50),
+    backbone=dict(
+        type='ResNet',
+        depth=50,
+        init_cfg=dict(
+            type='Pretrained',
+            prefix='backbone.',
+            checkpoint='https://download.openmmlab.com/mmpose/'
+            'pretrain_models/td-hm_res50_8xb64-210e_coco-256x192.pth'),
+    ),
+    neck=dict(type='GlobalAveragePooling'),
     head=dict(
-        type='HeatmapHead',
+        type='RLEHead',
         in_channels=2048,
-        out_channels=15,
-        loss=dict(type='KeypointMSELoss', use_target_weight=True),
+        num_joints=17,
+        loss=dict(type='RLELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
-        flip_mode='heatmap',
-        shift_heatmap=True,
+        shift_coords=True,
     ))
-load_from = 'https://download.openmmlab.com/mmpose/top_down/resnet/res50_mpii_256x256-418ffc88_20200812.pth'  # noqa: E501
 
 # base dataset settings
-dataset_type = 'JhmdbDataset'
+dataset_type = 'CocoDataset'
 data_mode = 'topdown'
-data_root = 'data/jhmdb/'
+data_root = 'data/coco/'
+
+file_client_args = dict(backend='disk')
 
 # pipelines
 train_pipeline = [
-    dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
+    dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(
-        type='RandomBBoxTransform',
-        rotate_factor=60,
-        scale_factor=(0.75, 1.25)),
+    dict(type='RandomHalfBody'),
+    dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
-
-val_pipeline = [
-    dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
+test_pipeline = [
+    dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
@@ -87,34 +89,39 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/Sub3_train.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/person_keypoints_train2017.json',
+        data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/Sub3_test.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/person_keypoints_val2017.json',
+        bbox_file=f'{data_root}person_detection_results/'
+        'COCO_val2017_detections_AP_H_56_person.json',
+        data_prefix=dict(img='val2017/'),
         test_mode=True,
-        pipeline=val_pipeline,
+        pipeline=test_pipeline,
     ))
 test_dataloader = val_dataloader
 
+# hooks
+default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+
 # evaluators
-val_evaluator = [
-    dict(type='JhmdbPCKAccuracy', thr=0.2),
-    dict(type='JhmdbPCKAccuracy', thr=0.2, norm_item='torso'),
-]
+val_evaluator = dict(
+    type='CocoMetric',
+    ann_file=f'{data_root}annotations/person_keypoints_val2017.json',
+    score_mode='bbox_rle')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_cpm_8xb64-210e_mpii-368x368.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_cpm_8xb64-210e_mpii-368x368.py`

 * *Files 4% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(368, 368), heatmap_size=(46, 46), sigma=2)
 
 # model settings
 model = dict(
@@ -74,15 +74,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_prob=0,
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hourglass52_8xb32-210e_mpii-384x384.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hourglass52_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,19 +23,19 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(384, 384), heatmap_size=(96, 96), sigma=2)
+    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -67,27 +67,27 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hourglass52_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hourglass52_8xb32-210e_mpii-384x384.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,19 +23,19 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(384, 384), heatmap_size=(96, 96), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -67,27 +67,27 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w32_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w32_dark-8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,19 +23,23 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+    type='MSRAHeatmap',
+    input_size=(256, 256),
+    heatmap_size=(64, 64),
+    sigma=2,
+    unbiased=True)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -95,15 +99,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w32_dark-8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w32_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,23 +23,19 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap',
-    input_size=(256, 256),
-    heatmap_size=(64, 64),
-    sigma=2,
-    unbiased=True)
+    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -99,40 +95,40 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=16,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
         ann_file='annotations/mpii_train.json',
         data_prefix=dict(img='images/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
-    batch_size=32,
+    batch_size=16,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w48_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w48_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -95,15 +95,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w48_dark-8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w48_dark-8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap',
     input_size=(256, 256),
     heatmap_size=(64, 64),
     sigma=2,
@@ -99,15 +99,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_litehrnet-18_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_litehrnet-18_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -86,15 +86,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_prob=0,
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_litehrnet-30_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_litehrnet-30_8xb64-210e_mpii-256x256.py`

 * *Files 3% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -86,15 +86,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_prob=0,
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_mobilenetv2_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_shufflenetv1_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,37 +23,36 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='MobileNetV2',
-        widen_factor=1.,
-        out_indices=(7, ),
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://mobilenet_v2'),
+        type='ShuffleNetV1',
+        groups=3,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://shufflenet_v1'),
     ),
     head=dict(
         type='HeatmapHead',
-        in_channels=1280,
+        in_channels=960,
         out_channels=16,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
@@ -67,15 +66,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_res101_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_seresnet101_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,32 +23,32 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNet',
+        type='SEResNet',
         depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://se-resnet101'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=16,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -66,15 +66,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_res152_8xb32-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_res152_8xb32-210e_mpii-256x256.py`

 * *Files 1% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -66,15 +66,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_res50_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_seresnet50_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,32 +23,32 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNet',
+        type='SEResNet',
         depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://se-resnet50'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=16,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -66,15 +66,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnetv1d101_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnetv1d50_8xb64-210e_mpii-256x256.py`

 * *Files 1% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -39,16 +39,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNetV1d',
-        depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet101_v1d'),
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet50_v1d'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=16,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -66,15 +66,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnetv1d152_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_res50_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,32 +23,32 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNetV1d',
-        depth=152,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet152_v1d'),
+        type='ResNet',
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=16,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -66,15 +66,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnetv1d50_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_shufflenetv2_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,36 +23,36 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNetV1d',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet50_v1d'),
+        type='ShuffleNetV2',
+        widen_factor=1.0,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://shufflenet_v2'),
     ),
     head=dict(
         type='HeatmapHead',
-        in_channels=2048,
+        in_channels=1024,
         out_channels=16,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
@@ -66,15 +66,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnext152_8xb32-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnetv1d101_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,36 +20,35 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=256)
+auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNeXt',
-        depth=152,
-        init_cfg=dict(
-            type='Pretrained', checkpoint='mmcls://resnext152_32x4d'),
+        type='ResNetV1d',
+        depth=101,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet101_v1d'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=16,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -67,27 +66,27 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_scnet101_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_scnet101_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -69,15 +69,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_scnet50_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_scnet50_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -69,15 +69,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_seresnet101_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_res101_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,32 +23,32 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='SEResNet',
+        type='ResNet',
         depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://se-resnet101'),
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=16,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -66,15 +66,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_seresnet152_8xb32-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_seresnet152_8xb32-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -65,15 +65,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_seresnet50_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnetv1d152_8xb64-210e_mpii-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,32 +23,32 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='SEResNet',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://se-resnet50'),
+        type='ResNetV1d',
+        depth=152,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://resnet152_v1d'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=16,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -66,15 +66,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_shufflenetv1_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_mobilenetv2_8xb64-210e_onehand10k-256x256.py`

 * *Files 4% similar despite different names*

```diff
@@ -23,58 +23,63 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ShuffleNetV1',
-        groups=3,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://shufflenet_v1'),
-    ),
+        type='MobileNetV2',
+        widen_factor=1.,
+        out_indices=(7, ),
+        init_cfg=dict(
+            type='Pretrained',
+            checkpoint='mmcls://mobilenet_v2',
+        )),
     head=dict(
         type='HeatmapHead',
-        in_channels=960,
-        out_channels=16,
+        in_channels=1280,
+        out_channels=21,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'MpiiDataset'
+dataset_type = 'OneHand10KDataset'
 data_mode = 'topdown'
-data_root = 'data/mpii/'
+data_root = 'data/onehand10k/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(type='RandomBBoxTransform', shift_prob=0),
+    dict(
+        type='RandomBBoxTransform', rotate_factor=180,
+        scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -86,32 +91,35 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/mpii_train.json',
-        data_prefix=dict(img='images/'),
+        ann_file='annotations/onehand10k_train.json',
+        data_prefix=dict(img=''),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/mpii_val.json',
-        headbox_file='data/mpii/annotations/mpii_gt_val.mat',
-        data_prefix=dict(img='images/'),
+        ann_file='annotations/onehand10k_test.json',
+        data_prefix=dict(img=''),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
-val_evaluator = dict(type='MpiiPCKAccuracy')
+val_evaluator = [
+    dict(type='PCKAccuracy', thr=0.2),
+    dict(type='AUC'),
+    dict(type='EPE'),
+]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_shufflenetv2_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_res50_8xb64-210e_rhd2d-256x256.py`

 * *Files 6% similar despite different names*

```diff
@@ -23,58 +23,62 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ShuffleNetV2',
-        widen_factor=1.0,
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://shufflenet_v2'),
-    ),
+        type='ResNet',
+        depth=50,
+        init_cfg=dict(
+            type='Pretrained',
+            checkpoint='torchvision://resnet50',
+        )),
     head=dict(
         type='HeatmapHead',
-        in_channels=1024,
-        out_channels=16,
+        in_channels=2048,
+        out_channels=21,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'MpiiDataset'
+dataset_type = 'Rhd2DDataset'
 data_mode = 'topdown'
-data_root = 'data/mpii/'
+data_root = 'data/rhd/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(type='RandomBBoxTransform', shift_prob=0),
+    dict(
+        type='RandomBBoxTransform', rotate_factor=180,
+        scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -86,32 +90,35 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/mpii_train.json',
-        data_prefix=dict(img='images/'),
+        ann_file='annotations/rhd_train.json',
+        data_prefix=dict(img=''),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/mpii_val.json',
-        headbox_file='data/mpii/annotations/mpii_gt_val.mat',
-        data_prefix=dict(img='images/'),
+        ann_file='annotations/rhd_test.json',
+        data_prefix=dict(img=''),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
-val_evaluator = dict(type='MpiiPCKAccuracy')
+val_evaluator = [
+    dict(type='PCKAccuracy', thr=0.2),
+    dict(type='AUC'),
+    dict(type='EPE'),
+]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w32_8xb64-20e_posetrack18-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w32_8xb64-20e_posetrack18-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -24,15 +24,16 @@
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(
-    checkpoint=dict(save_best='posetrack18/Total AP', rule='greater'))
+    checkpoint=dict(
+        save_best='posetrack18/Total AP', rule='greater', interval=1))
 
 # load from the pretrained model
 load_from = 'https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-256x192-81c58e40_20220909.pth'  # noqa: E501
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
@@ -97,15 +98,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w32_8xb64-20e_posetrack18-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w32_8xb64-20e_posetrack18-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -24,15 +24,16 @@
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(
-    checkpoint=dict(save_best='posetrack18/Total AP', rule='greater'))
+    checkpoint=dict(
+        save_best='posetrack18/Total AP', rule='greater', interval=1))
 
 # load from the pretrained model
 load_from = 'https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-384x288-ca5956af_20220909.pth'  # noqa: E501
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
@@ -97,15 +98,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w48_8xb64-20e_posetrack18-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w48_8xb64-20e_posetrack18-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -24,15 +24,16 @@
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(
-    checkpoint=dict(save_best='posetrack18/Total AP', rule='greater'))
+    checkpoint=dict(
+        save_best='posetrack18/Total AP', rule='greater', interval=1))
 
 # load from the pretrained model
 load_from = 'https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-256x192-0e67c616_20220913.pth'  # noqa: E501
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
@@ -97,15 +98,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w48_8xb64-20e_posetrack18-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_hrnet-w48_8xb64-20e_posetrack18-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -24,15 +24,16 @@
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(
-    checkpoint=dict(save_best='posetrack18/Total AP', rule='greater'))
+    checkpoint=dict(
+        save_best='posetrack18/Total AP', rule='greater', interval=1))
 
 # load from the pretrained model
 load_from = 'https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-384x288-c161b7de_20220915.pth'  # noqa: E501
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
@@ -97,15 +98,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_res50_8xb64-20e_posetrack18-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/posetrack18/td-hm_res50_8xb64-20e_posetrack18-256x192.py`

 * *Files 4% similar despite different names*

```diff
@@ -24,15 +24,16 @@
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(
-    checkpoint=dict(save_best='posetrack18/Total AP', rule='greater'))
+    checkpoint=dict(
+        save_best='posetrack18/Total AP', rule='greater', interval=1))
 
 # load from the pretrained model
 load_from = 'https://download.openmmlab.com/mmpose/top_down/resnet/res50_coco_256x192-ec54d7f3_20200709.pth'  # noqa: E501
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
@@ -72,15 +73,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_mobilenetv2_rle-pretrained-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_vipnas-mbv3_8xb64-210e_coco-256x192.py`

 * *Files 5% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 
 # runtime
 train_cfg = dict(max_epochs=210, val_interval=10)
 
 # optimizer
 optim_wrapper = dict(optimizer=dict(
     type='Adam',
-    lr=1e-3,
+    lr=5e-4,
 ))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
@@ -23,45 +23,39 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # codec settings
-codec = dict(type='RegressionLabel', input_size=(192, 256))
+codec = dict(
+    type='SimCCLabel', input_size=(192, 256), sigma=6.0, simcc_split_ratio=2.0)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
-    backbone=dict(
-        type='MobileNetV2',
-        widen_factor=1.,
-        out_indices=(7, ),
-        init_cfg=dict(
-            type='Pretrained',
-            prefix='backbone.',
-            checkpoint='https://download.openmmlab.com/mmpose/top_down/'
-            'mobilenetv2/mobilenetv2_coco_256x192-d1e58e7b_20200727.pth')),
-    neck=dict(type='GlobalAveragePooling'),
+    backbone=dict(type='ViPNAS_MobileNetV3'),
     head=dict(
-        type='RLEHead',
-        in_channels=1280,
-        num_joints=17,
-        loss=dict(type='RLELoss', use_target_weight=True),
+        type='SimCCHead',
+        in_channels=160,
+        out_channels=17,
+        input_size=codec['input_size'],
+        in_featuremap_size=(6, 8),
+        simcc_split_ratio=codec['simcc_split_ratio'],
+        deconv_type='vipnas',
+        deconv_out_channels=(160, 160, 160),
+        deconv_num_groups=(160, 160, 160),
+        loss=dict(type='KLDiscretLoss', use_target_weight=True),
         decoder=codec),
-    test_cfg=dict(
-        flip_test=True,
-        shift_coords=True,
-    ),
-)
+    test_cfg=dict(flip_test=True, ))
 
 # base dataset settings
 dataset_type = 'CocoDataset'
 data_mode = 'topdown'
 data_root = 'data/coco/'
 
 file_client_args = dict(backend='disk')
@@ -70,15 +64,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -105,24 +99,23 @@
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
         ann_file='annotations/person_keypoints_val2017.json',
-        bbox_file=f'{data_root}person_detection_results/'
+        bbox_file=data_root + 'person_detection_results/'
         'COCO_val2017_detections_AP_H_56_person.json',
         data_prefix=dict(img='val2017/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # evaluators
 val_evaluator = dict(
     type='CocoMetric',
-    ann_file=f'{data_root}annotations/person_keypoints_val2017.json',
-    score_mode='bbox_rle')
+    ann_file=data_root + 'annotations/person_keypoints_val2017.json')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res101_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res101_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -63,15 +63,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res101_rle-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res101_rle-8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -63,15 +63,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res152_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res152_8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -63,15 +63,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res152_rle-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_rle-8xb64-210e_coco-256x192.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 
 # runtime
 train_cfg = dict(max_epochs=210, val_interval=10)
 
 # optimizer
 optim_wrapper = dict(optimizer=dict(
     type='Adam',
-    lr=5e-4,
+    lr=1e-3,
 ))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
@@ -35,16 +35,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=152,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet152'),
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
     neck=dict(type='GlobalAveragePooling'),
     head=dict(
         type='RLEHead',
         in_channels=2048,
         num_joints=17,
         loss=dict(type='RLELoss', use_target_weight=True),
@@ -63,15 +63,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res152_rle-8xb64-210e_coco-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_8xb64-210e_coco-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,35 +23,35 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # codec settings
-codec = dict(type='RegressionLabel', input_size=(288, 384))
+codec = dict(type='RegressionLabel', input_size=(192, 256))
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=152,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet152'),
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
     neck=dict(type='GlobalAveragePooling'),
     head=dict(
-        type='RLEHead',
+        type='RegressionHead',
         in_channels=2048,
         num_joints=17,
-        loss=dict(type='RLELoss', use_target_weight=True),
+        loss=dict(type='SmoothL1Loss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         shift_coords=True,
     ))
 
 # base dataset settings
@@ -63,15 +63,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -112,10 +112,9 @@
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # evaluators
 val_evaluator = dict(
     type='CocoMetric',
-    ann_file=f'{data_root}annotations/person_keypoints_val2017.json',
-    score_mode='bbox_rle')
+    ann_file=f'{data_root}annotations/person_keypoints_val2017.json')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-mbv3_8xb64-210e_coco-wholebody-256x192.py`

 * *Files 6% similar despite different names*

```diff
@@ -13,65 +13,71 @@
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
-        end=train_cfg['max_epochs'],
+        end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
+# hooks
+default_hooks = dict(
+    checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
+
 # codec settings
-codec = dict(type='RegressionLabel', input_size=(192, 256))
+codec = dict(
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
-    backbone=dict(
-        type='ResNet',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
-    ),
-    neck=dict(type='GlobalAveragePooling'),
+    backbone=dict(type='ViPNAS_MobileNetV3'),
     head=dict(
-        type='RegressionHead',
-        in_channels=2048,
-        num_joints=17,
-        loss=dict(type='SmoothL1Loss', use_target_weight=True),
+        type='ViPNASHead',
+        in_channels=160,
+        out_channels=133,
+        deconv_out_channels=(160, 160, 160),
+        deconv_num_groups=(160, 160, 160),
+        loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
-        shift_coords=True,
+        flip_mode='heatmap',
+        shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'CocoDataset'
+dataset_type = 'CocoWholeBodyDataset'
 data_mode = 'topdown'
 data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
-    dict(type='RandomBBoxTransform'),
+    dict(
+        type='RandomBBoxTransform',
+        rotate_factor=60,
+        scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -83,38 +89,34 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/person_keypoints_train2017.json',
+        ann_file='annotations/coco_wholebody_train_v1.0.json',
         data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/person_keypoints_val2017.json',
-        bbox_file=f'{data_root}person_detection_results/'
-        'COCO_val2017_detections_AP_H_56_person.json',
+        ann_file='annotations/coco_wholebody_val_v1.0.json',
         data_prefix=dict(img='val2017/'),
         test_mode=True,
+        bbox_file='data/coco/person_detection_results/'
+        'COCO_val2017_detections_AP_H_56_person.json',
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
-# hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
-
-# evaluators
 val_evaluator = dict(
-    type='CocoMetric',
-    ann_file=f'{data_root}annotations/person_keypoints_val2017.json')
+    type='CocoWholeBodyMetric',
+    ann_file=data_root + 'annotations/coco_wholebody_val_v1.0.json')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_rle-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hourglass52_8xb32-60e_coco-wholebody-face-256x256.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,121 +1,123 @@
 _base_ = ['../../../_base_/default_runtime.py']
 
 # runtime
-train_cfg = dict(max_epochs=210, val_interval=10)
+train_cfg = dict(max_epochs=60, val_interval=1)
 
 # optimizer
 optim_wrapper = dict(optimizer=dict(
     type='Adam',
-    lr=1e-3,
+    lr=2e-3,
 ))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
-        end=train_cfg['max_epochs'],
-        milestones=[170, 200],
+        end=210,
+        milestones=[40, 55],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=512)
+auto_scale_lr = dict(base_batch_size=256)
+
+# hooks
+default_hooks = dict(checkpoint=dict(save_best='NME', rule='less', interval=1))
 
 # codec settings
-codec = dict(type='RegressionLabel', input_size=(192, 256))
+codec = dict(
+    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNet',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
+        type='HourglassNet',
+        num_stacks=1,
     ),
-    neck=dict(type='GlobalAveragePooling'),
     head=dict(
-        type='RLEHead',
-        in_channels=2048,
-        num_joints=17,
-        loss=dict(type='RLELoss', use_target_weight=True),
+        type='CPMHead',
+        in_channels=256,
+        out_channels=68,
+        num_stages=1,
+        deconv_out_channels=None,
+        loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
-        shift_coords=True,
+        flip_mode='heatmap',
+        shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'CocoDataset'
+dataset_type = 'CocoWholeBodyFaceDataset'
 data_mode = 'topdown'
 data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(type='RandomHalfBody'),
-    dict(type='RandomBBoxTransform'),
+    dict(
+        type='RandomBBoxTransform',
+        rotate_factor=60,
+        scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/person_keypoints_train2017.json',
+        ann_file='annotations/coco_wholebody_train_v1.0.json',
         data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/person_keypoints_val2017.json',
-        bbox_file=f'{data_root}person_detection_results/'
-        'COCO_val2017_detections_AP_H_56_person.json',
+        ann_file='annotations/coco_wholebody_val_v1.0.json',
         data_prefix=dict(img='val2017/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
-# hooks
-default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
-
 # evaluators
 val_evaluator = dict(
-    type='CocoMetric',
-    ann_file=f'{data_root}annotations/person_keypoints_val2017.json',
-    score_mode='bbox_rle')
+    type='NME',
+    norm_mode='keypoint_distance',
+)
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_rle-pretrained-8xb64-210e_coco-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_mobilenetv2_rle-pretrained-8xb64-210e_coco-256x192.py`

 * *Files 10% similar despite different names*

```diff
@@ -34,33 +34,34 @@
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNet',
-        depth=50,
+        type='MobileNetV2',
+        widen_factor=1.,
+        out_indices=(7, ),
         init_cfg=dict(
             type='Pretrained',
             prefix='backbone.',
-            checkpoint='https://download.openmmlab.com/mmpose/'
-            'pretrain_models/td-hm_res50_8xb64-210e_coco-256x192.pth'),
-    ),
+            checkpoint='https://download.openmmlab.com/mmpose/top_down/'
+            'mobilenetv2/mobilenetv2_coco_256x192-d1e58e7b_20200727.pth')),
     neck=dict(type='GlobalAveragePooling'),
     head=dict(
         type='RLEHead',
-        in_channels=2048,
+        in_channels=1280,
         num_joints=17,
         loss=dict(type='RLELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         shift_coords=True,
-    ))
+    ),
+)
 
 # base dataset settings
 dataset_type = 'CocoDataset'
 data_mode = 'topdown'
 data_root = 'data/coco/'
 
 file_client_args = dict(backend='disk')
@@ -69,18 +70,18 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
-test_pipeline = [
+val_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
@@ -108,15 +109,15 @@
         data_root=data_root,
         data_mode=data_mode,
         ann_file='annotations/person_keypoints_val2017.json',
         bbox_file=f'{data_root}person_detection_results/'
         'COCO_val2017_detections_AP_H_56_person.json',
         data_prefix=dict(img='val2017/'),
         test_mode=True,
-        pipeline=test_pipeline,
+        pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # hooks
 default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # evaluators
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res101_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res152_8xb64-210e_mpii-256x256.py`

 * *Files 3% similar despite different names*

```diff
@@ -35,16 +35,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
+        depth=152,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet152'),
     ),
     neck=dict(type='GlobalAveragePooling'),
     head=dict(
         type='RegressionHead',
         in_channels=2048,
         num_joints=16,
         loss=dict(type='SmoothL1Loss', use_target_weight=True),
@@ -64,15 +64,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -107,12 +107,12 @@
         data_prefix=dict(img='images/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # evaluators
-val_evaluator = dict(type='MpiiPCKAccuracy', norm_item='head')
+val_evaluator = dict(type='MpiiPCKAccuracy')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res152_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hourglass52_8xb32-210e_coco-wholebody-hand-256x256.py`

 * *Files 6% similar despite different names*

```diff
@@ -20,99 +20,104 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=512)
+auto_scale_lr = dict(base_batch_size=256)
+
+# hooks
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
-codec = dict(type='RegressionLabel', input_size=(256, 256))
+codec = dict(
+    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNet',
-        depth=152,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet152'),
+        type='HourglassNet',
+        num_stacks=1,
     ),
-    neck=dict(type='GlobalAveragePooling'),
     head=dict(
-        type='RegressionHead',
-        in_channels=2048,
-        num_joints=16,
-        loss=dict(type='SmoothL1Loss', use_target_weight=True),
+        type='CPMHead',
+        in_channels=256,
+        out_channels=21,
+        num_stages=1,
+        deconv_out_channels=None,
+        loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
-        shift_coords=True,
+        flip_mode='heatmap',
+        shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'MpiiDataset'
+dataset_type = 'CocoWholeBodyHandDataset'
 data_mode = 'topdown'
-data_root = 'data/mpii/'
-
-file_client_args = dict(backend='disk')
+data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
-    dict(type='LoadImage', file_client_args=file_client_args),
+    dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(type='RandomBBoxTransform', shift_prob=0),
+    dict(
+        type='RandomBBoxTransform',
+        rotate_factor=180.0,
+        scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
-    dict(type='LoadImage', file_client_args=file_client_args),
+    dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/mpii_train.json',
-        data_prefix=dict(img='images/'),
+        ann_file='annotations/coco_wholebody_train_v1.0.json',
+        data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/mpii_val.json',
-        headbox_file=f'{data_root}/annotations/mpii_gt_val.mat',
-        data_prefix=dict(img='images/'),
+        ann_file='annotations/coco_wholebody_val_v1.0.json',
+        data_prefix=dict(img='val2017/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
-# hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
-
-# evaluators
-val_evaluator = dict(type='MpiiPCKAccuracy', norm_item='head')
+val_evaluator = [
+    dict(type='PCKAccuracy', thr=0.2),
+    dict(type='AUC'),
+    dict(type='EPE')
+]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res50_8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res101_8xb64-210e_mpii-256x256.py`

 * *Files 6% similar despite different names*

```diff
@@ -35,16 +35,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
+        depth=101,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
     ),
     neck=dict(type='GlobalAveragePooling'),
     head=dict(
         type='RegressionHead',
         in_channels=2048,
         num_joints=16,
         loss=dict(type='SmoothL1Loss', use_target_weight=True),
@@ -64,15 +64,15 @@
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -107,12 +107,12 @@
         data_prefix=dict(img='images/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # evaluators
-val_evaluator = dict(type='MpiiPCKAccuracy', norm_item='head')
+val_evaluator = dict(type='MpiiPCKAccuracy')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res50_rle-8xb64-210e_mpii-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-res50_dark-8xb64-210e_coco-wholebody-256x192.py`

 * *Files 8% similar despite different names*

```diff
@@ -22,61 +22,71 @@
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
+# hooks
+default_hooks = dict(
+    checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
+
 # codec settings
-codec = dict(type='RegressionLabel', input_size=(256, 256))
+codec = dict(
+    type='MSRAHeatmap',
+    input_size=(192, 256),
+    heatmap_size=(48, 64),
+    sigma=2,
+    unbiased=True)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNet',
+        type='ViPNAS_ResNet',
         depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
-    neck=dict(type='GlobalAveragePooling'),
     head=dict(
-        type='RLEHead',
-        in_channels=2048,
-        num_joints=16,
-        loss=dict(type='RLELoss', use_target_weight=True),
+        type='ViPNASHead',
+        in_channels=608,
+        out_channels=133,
+        loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
-        shift_coords=True,
+        flip_mode='heatmap',
+        shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'MpiiDataset'
+dataset_type = 'CocoWholeBodyDataset'
 data_mode = 'topdown'
-data_root = 'data/mpii/'
-
-file_client_args = dict(backend='disk')
+data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
-    dict(type='LoadImage', file_client_args=file_client_args),
+    dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(type='RandomBBoxTransform', shift_prob=0),
+    dict(type='RandomHalfBody'),
+    dict(
+        type='RandomBBoxTransform',
+        rotate_factor=60,
+        scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
-    dict(type='LoadImage', file_client_args=file_client_args),
+    dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
@@ -84,35 +94,34 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/mpii_train.json',
-        data_prefix=dict(img='images/'),
+        ann_file='annotations/coco_wholebody_train_v1.0.json',
+        data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/mpii_val.json',
-        headbox_file=f'{data_root}/annotations/mpii_gt_val.mat',
-        data_prefix=dict(img='images/'),
+        ann_file='annotations/coco_wholebody_val_v1.0.json',
+        data_prefix=dict(img='val2017/'),
         test_mode=True,
+        bbox_file='data/coco/person_detection_results/'
+        'COCO_val2017_detections_AP_H_56_person.json',
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
-# hooks
-default_hooks = dict(checkpoint=dict(save_best='pck/PCKh', rule='greater'))
-
-# evaluators
-val_evaluator = dict(type='MpiiPCKAccuracy', norm_item='head')
+val_evaluator = dict(
+    type='CocoWholeBodyMetric',
+    ann_file=data_root + 'annotations/coco_wholebody_val_v1.0.json')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/300w/td-hm_hrnetv2-w18_8xb64-60e_300w-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/aflw/td-hm_hrnetv2-w18_8xb64-60e_aflw-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,23 +23,19 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='nme/@[36, 45]', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='NME', rule='less', interval=1))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap',
-    input_size=(256, 256),
-    heatmap_size=(64, 64),
-    sigma=1.5)
+    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -79,43 +75,43 @@
             type='Pretrained', checkpoint='open-mmlab://msra/hrnetv2_w18'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=(18, 36, 72, 144),
         input_index=(0, 1, 2, 3),
         input_transform='resize_concat',
-        out_channels=68,
+        out_channels=19,
         deconv_out_channels=None,
         conv_out_channels=(270, ),
         conv_kernel_sizes=(1, ),
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'Face300WDataset'
+dataset_type = 'AFLWDataset'
 data_mode = 'topdown'
-data_root = 'data/300w/'
+data_root = 'data/aflw/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_prob=0,
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -127,34 +123,32 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/face_landmarks_300w_train.json',
+        ann_file='annotations/face_landmarks_aflw_train.json',
         data_prefix=dict(img='images/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/face_landmarks_300w_valid.json',
+        ann_file='annotations/face_landmarks_aflw_test.json',
         data_prefix=dict(img='images/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
 val_evaluator = dict(
-    type='NME',
-    norm_mode='keypoint_distance',
-)
+    type='NME', norm_mode='use_norm_item', norm_item='bbox_size')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/aflw/td-hm_hrnetv2-w18_8xb64-60e_aflw-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/aflw/td-hm_hrnetv2-w18_dark-8xb64-60e_aflw-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,20 +23,23 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='nme/@bbox_size', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='NME', rule='less', interval=1))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+    type='MSRAHeatmap',
+    input_size=(256, 256),
+    heatmap_size=(64, 64),
+    sigma=2,
+    unbiased=True)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -104,15 +107,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_prob=0,
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/aflw/td-hm_hrnetv2-w18_dark-8xb64-60e_aflw-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_udp-8xb64-210e_onehand10k-256x256.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,46 +1,41 @@
 _base_ = ['../../../_base_/default_runtime.py']
 
 # runtime
-train_cfg = dict(max_epochs=60, val_interval=1)
+train_cfg = dict(max_epochs=210, val_interval=10)
 
 # optimizer
 optim_wrapper = dict(optimizer=dict(
     type='Adam',
-    lr=2e-3,
+    lr=5e-4,
 ))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
-        end=60,
-        milestones=[40, 55],
+        end=210,
+        milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='nme/@bbox_size', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap',
-    input_size=(256, 256),
-    heatmap_size=(64, 64),
-    sigma=2,
-    unbiased=True)
+    type='UDPHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -73,50 +68,49 @@
                 num_branches=4,
                 block='BASIC',
                 num_blocks=(4, 4, 4, 4),
                 num_channels=(18, 36, 72, 144),
                 multiscale_output=True),
             upsample=dict(mode='bilinear', align_corners=False)),
         init_cfg=dict(
-            type='Pretrained', checkpoint='open-mmlab://msra/hrnetv2_w18'),
-    ),
+            type='Pretrained',
+            checkpoint='open-mmlab://msra/hrnetv2_w18',
+        )),
     head=dict(
         type='HeatmapHead',
-        in_channels=(18, 36, 72, 144),
+        in_channels=[18, 36, 72, 144],
         input_index=(0, 1, 2, 3),
         input_transform='resize_concat',
-        out_channels=19,
+        out_channels=21,
         deconv_out_channels=None,
         conv_out_channels=(270, ),
         conv_kernel_sizes=(1, ),
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
-        shift_heatmap=True,
+        shift_heatmap=False,
     ))
 
 # base dataset settings
-dataset_type = 'AFLWDataset'
+dataset_type = 'OneHand10KDataset'
 data_mode = 'topdown'
-data_root = 'data/aflw/'
+data_root = 'data/onehand10k/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
-        type='RandomBBoxTransform',
-        shift_prob=0,
-        rotate_factor=60,
-        scale_factor=(0.75, 1.25)),
+        type='RandomBBoxTransform', rotate_factor=180,
+        scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -128,32 +122,35 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/face_landmarks_aflw_train.json',
-        data_prefix=dict(img='images/'),
+        ann_file='annotations/onehand10k_train.json',
+        data_prefix=dict(img=''),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/face_landmarks_aflw_test.json',
-        data_prefix=dict(img='images/'),
+        ann_file='annotations/onehand10k_test.json',
+        data_prefix=dict(img=''),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
-val_evaluator = dict(
-    type='NME', norm_mode='use_norm_item', norm_item='bbox_size')
+val_evaluator = [
+    dict(type='PCKAccuracy', thr=0.2),
+    dict(type='AUC'),
+    dict(type='EPE'),
+]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hourglass52_8xb32-60e_coco-wholebody-face-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_mobilenetv2_8xb32-60e_coco-wholebody-face-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,39 +23,37 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='nme/@[36, 45]', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='NME', rule='less', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='HourglassNet',
-        num_stacks=1,
-    ),
+        type='MobileNetV2',
+        widen_factor=1.,
+        out_indices=(7, ),
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://mobilenet_v2')),
     head=dict(
-        type='CPMHead',
-        in_channels=256,
+        type='HeatmapHead',
+        in_channels=1280,
         out_channels=68,
-        num_stages=1,
-        deconv_out_channels=None,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
@@ -71,15 +69,15 @@
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hrnetv2-w18_8xb32-60e_coco-wholebody-face-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hrnetv2-w18_8xb32-210e_coco-wholebody-hand-256x256.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,39 +1,37 @@
 _base_ = ['../../../_base_/default_runtime.py']
 
 # runtime
-train_cfg = dict(max_epochs=60, val_interval=1)
+train_cfg = dict(max_epochs=210, val_interval=10)
 
 # optimizer
 optim_wrapper = dict(optimizer=dict(
     type='Adam',
-    lr=2e-3,
+    lr=5e-4,
 ))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
         end=210,
-        milestones=[40, 55],
+        milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='nme/@[36, 45]', rule='greater'))
-
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
@@ -75,42 +73,41 @@
         init_cfg=dict(
             type='Pretrained', checkpoint='open-mmlab://msra/hrnetv2_w18')),
     head=dict(
         type='HeatmapHead',
         in_channels=[18, 36, 72, 144],
         input_index=(0, 1, 2, 3),
         input_transform='resize_concat',
-        out_channels=68,
+        out_channels=21,
         deconv_out_channels=None,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         conv_out_channels=(270, ),
         conv_kernel_sizes=(1, ),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'CocoWholeBodyFaceDataset'
+dataset_type = 'CocoWholeBodyHandDataset'
 data_mode = 'topdown'
 data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
-        type='RandomBBoxTransform',
-        rotate_factor=60,
-        scale_factor=(0.75, 1.25)),
+        type='RandomBBoxTransform', rotate_factor=180,
+        scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -143,13 +140,13 @@
         ann_file='annotations/coco_wholebody_val_v1.0.json',
         data_prefix=dict(img='val2017/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
-# evaluators
-val_evaluator = dict(
-    type='NME',
-    norm_mode='keypoint_distance',
-)
+val_evaluator = [
+    dict(type='PCKAccuracy', thr=0.2),
+    dict(type='AUC'),
+    dict(type='EPE')
+]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hrnetv2-w18_dark-8xb32-60e_coco-wholebody-face-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hrnetv2-w18_dark-8xb32-60e_coco-wholebody-face-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,16 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='nme/@[36, 45]', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='NME', rule='less', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap',
     input_size=(256, 256),
     heatmap_size=(64, 64),
     sigma=2,
@@ -106,15 +105,15 @@
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_mobilenetv2_8xb32-60e_coco-wholebody-face-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_mobilenetv2_8xb32-210e_coco-wholebody-hand-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,39 +1,37 @@
 _base_ = ['../../../_base_/default_runtime.py']
 
 # runtime
-train_cfg = dict(max_epochs=60, val_interval=1)
+train_cfg = dict(max_epochs=210, val_interval=10)
 
 # optimizer
 optim_wrapper = dict(optimizer=dict(
     type='Adam',
-    lr=2e-3,
+    lr=5e-4,
 ))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
         end=210,
-        milestones=[40, 55],
+        milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='nme/@[36, 45]', rule='greater'))
-
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
@@ -46,39 +44,38 @@
         type='MobileNetV2',
         widen_factor=1.,
         out_indices=(7, ),
         init_cfg=dict(type='Pretrained', checkpoint='mmcls://mobilenet_v2')),
     head=dict(
         type='HeatmapHead',
         in_channels=1280,
-        out_channels=68,
+        out_channels=21,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'CocoWholeBodyFaceDataset'
+dataset_type = 'CocoWholeBodyHandDataset'
 data_mode = 'topdown'
 data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
-    dict(type='RandomFlip', direction='horizontal'),
     dict(
-        type='RandomBBoxTransform',
-        rotate_factor=60,
-        scale_factor=(0.75, 1.25)),
+        type='RandomBBoxTransform', rotate_factor=180,
+        scale_factor=(0.7, 1.3)),
+    dict(type='RandomFlip', direction='horizontal'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -111,13 +108,13 @@
         ann_file='annotations/coco_wholebody_val_v1.0.json',
         data_prefix=dict(img='val2017/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
-# evaluators
-val_evaluator = dict(
-    type='NME',
-    norm_mode='keypoint_distance',
-)
+val_evaluator = [
+    dict(type='PCKAccuracy', thr=0.2),
+    dict(type='AUC'),
+    dict(type='EPE')
+]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_res50_8xb32-60e_coco-wholebody-face-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_res50_8xb32-60e_coco-wholebody-face-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,16 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='nme/@[36, 45]', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='NME', rule='less', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -69,15 +68,15 @@
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_scnet50_8xb32-60e_coco-wholebody-face-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_scnet50_8xb32-60e_coco-wholebody-face-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,16 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='nme/@[36, 45]', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='NME', rule='less', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -72,15 +71,15 @@
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/cofw/td-hm_hrnetv2-w18_8xb64-60e_cofw-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/cofw/td-hm_hrnetv2-w18_8xb64-60e_cofw-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='nme/@[8, 9]', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='NME', rule='less', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap',
     input_size=(256, 256),
     heatmap_size=(64, 64),
     sigma=1.5)
@@ -106,15 +106,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_prob=0,
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_8xb64-60e_wflw-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_8xb64-60e_wflw-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,16 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='nme/@[60, 72]', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='NME', rule='less', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -104,15 +103,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_prob=0,
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_awing-8xb64-60e_wflw-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_awing-8xb64-60e_wflw-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,16 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='nme/@[60, 72]', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='NME', rule='less', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
@@ -104,15 +103,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_prob=0,
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_dark-8xb64-60e_wflw-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_dark-8xb64-60e_wflw-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,16 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='nme/@[60, 72]', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='NME', rule='less', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap',
     input_size=(256, 256),
     heatmap_size=(64, 64),
     sigma=2,
@@ -108,15 +107,15 @@
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform',
         shift_prob=0,
         rotate_factor=60,
         scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hourglass52_8xb32-210e_coco-wholebody-hand-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_mobilenetv2_8xb64-210e_rhd2d-256x256.py`

 * *Files 4% similar despite different names*

```diff
@@ -20,104 +20,106 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=256)
+auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='HourglassNet',
-        num_stacks=1,
-    ),
+        type='MobileNetV2',
+        widen_factor=1.,
+        out_indices=(7, ),
+        init_cfg=dict(
+            type='Pretrained',
+            checkpoint='mmcls://mobilenet_v2',
+        )),
     head=dict(
-        type='CPMHead',
-        in_channels=256,
+        type='HeatmapHead',
+        in_channels=1280,
         out_channels=21,
-        num_stages=1,
-        deconv_out_channels=None,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'CocoWholeBodyHandDataset'
+dataset_type = 'Rhd2DDataset'
 data_mode = 'topdown'
-data_root = 'data/coco/'
+data_root = 'data/rhd/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
-        type='RandomBBoxTransform',
-        rotate_factor=180.0,
+        type='RandomBBoxTransform', rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/coco_wholebody_train_v1.0.json',
-        data_prefix=dict(img='train2017/'),
+        ann_file='annotations/rhd_train.json',
+        data_prefix=dict(img=''),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/coco_wholebody_val_v1.0.json',
-        data_prefix=dict(img='val2017/'),
+        ann_file='annotations/rhd_test.json',
+        data_prefix=dict(img=''),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
+# evaluators
 val_evaluator = [
     dict(type='PCKAccuracy', thr=0.2),
     dict(type='AUC'),
-    dict(type='EPE')
+    dict(type='EPE'),
 ]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hrnetv2-w18_8xb32-210e_coco-wholebody-hand-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hrnetv2-w18_dark-8xb32-210e_coco-wholebody-hand-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,18 +23,22 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+    type='MSRAHeatmap',
+    input_size=(256, 256),
+    heatmap_size=(64, 64),
+    sigma=2,
+    unbiased=True)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -94,20 +98,20 @@
 data_mode = 'topdown'
 data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
-    dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform', rotate_factor=180,
         scale_factor=(0.7, 1.3)),
+    dict(type='RandomFlip', direction='horizontal'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hrnetv2-w18_dark-8xb32-210e_coco-wholebody-hand-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_dark-8xb64-210e_onehand10k-256x256.py`

 * *Files 3% similar despite different names*

```diff
@@ -20,18 +20,19 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=256)
+auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
+
 # codec settings
 codec = dict(
     type='MSRAHeatmap',
     input_size=(256, 256),
     heatmap_size=(64, 64),
     sigma=2,
     unbiased=True)
@@ -71,86 +72,89 @@
                 num_branches=4,
                 block='BASIC',
                 num_blocks=(4, 4, 4, 4),
                 num_channels=(18, 36, 72, 144),
                 multiscale_output=True),
             upsample=dict(mode='bilinear', align_corners=False)),
         init_cfg=dict(
-            type='Pretrained', checkpoint='open-mmlab://msra/hrnetv2_w18')),
+            type='Pretrained',
+            checkpoint='open-mmlab://msra/hrnetv2_w18',
+        )),
     head=dict(
         type='HeatmapHead',
         in_channels=[18, 36, 72, 144],
         input_index=(0, 1, 2, 3),
         input_transform='resize_concat',
         out_channels=21,
         deconv_out_channels=None,
-        loss=dict(type='KeypointMSELoss', use_target_weight=True),
         conv_out_channels=(270, ),
         conv_kernel_sizes=(1, ),
+        loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'CocoWholeBodyHandDataset'
+dataset_type = 'OneHand10KDataset'
 data_mode = 'topdown'
-data_root = 'data/coco/'
+data_root = 'data/onehand10k/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
+    dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform', rotate_factor=180,
         scale_factor=(0.7, 1.3)),
-    dict(type='RandomFlip', direction='horizontal'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/coco_wholebody_train_v1.0.json',
-        data_prefix=dict(img='train2017/'),
+        ann_file='annotations/onehand10k_train.json',
+        data_prefix=dict(img=''),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/coco_wholebody_val_v1.0.json',
-        data_prefix=dict(img='val2017/'),
+        ann_file='annotations/onehand10k_test.json',
+        data_prefix=dict(img=''),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
+# evaluators
 val_evaluator = [
     dict(type='PCKAccuracy', thr=0.2),
     dict(type='AUC'),
-    dict(type='EPE')
+    dict(type='EPE'),
 ]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_litehrnet-w18_8xb32-210e_coco-wholebody-hand-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_litehrnet-w18_8xb32-210e_coco-wholebody-hand-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
@@ -83,15 +83,15 @@
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(
         type='RandomBBoxTransform', rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_mobilenetv2_8xb32-210e_coco-wholebody-hand-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet101_8xb32-210e_coco-384x288.py`

 * *Files 5% similar despite different names*

```diff
@@ -23,59 +23,59 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
+
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='MobileNetV2',
-        widen_factor=1.,
-        out_indices=(7, ),
-        init_cfg=dict(type='Pretrained', checkpoint='mmcls://mobilenet_v2')),
+        type='SEResNet',
+        depth=101,
+        init_cfg=dict(type='Pretrained', checkpoint='mmcls://se-resnet101'),
+    ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
-        out_channels=21,
+        out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'CocoWholeBodyHandDataset'
+dataset_type = 'CocoDataset'
 data_mode = 'topdown'
 data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
-    dict(
-        type='RandomBBoxTransform', rotate_factor=180,
-        scale_factor=(0.7, 1.3)),
     dict(type='RandomFlip', direction='horizontal'),
+    dict(type='RandomHalfBody'),
+    dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -87,34 +87,35 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/coco_wholebody_train_v1.0.json',
+        ann_file='annotations/person_keypoints_train2017.json',
         data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/coco_wholebody_val_v1.0.json',
+        ann_file='annotations/person_keypoints_val2017.json',
+        bbox_file='data/coco/person_detection_results/'
+        'COCO_val2017_detections_AP_H_56_person.json',
         data_prefix=dict(img='val2017/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
-val_evaluator = [
-    dict(type='PCKAccuracy', thr=0.2),
-    dict(type='AUC'),
-    dict(type='EPE')
-]
+# evaluators
+val_evaluator = dict(
+    type='CocoMetric',
+    ann_file=data_root + 'annotations/person_keypoints_val2017.json')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_res50_8xb32-210e_coco-wholebody-hand-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_res50_8xb32-210e_coco-wholebody-hand-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
@@ -66,15 +66,15 @@
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(
         type='RandomBBoxTransform', rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_scnet50_8xb32-210e_coco-wholebody-hand-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_scnet50_8xb32-210e_coco-wholebody-hand-256x256.py`

 * *Files 4% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 # codec settings
 codec = dict(
     type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
@@ -69,15 +69,15 @@
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(
         type='RandomBBoxTransform', rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/freihand2d/td-hm_res50_8xb64-100e_freihand2d-224x224.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_resnext152_8xb32-210e_mpii-256x256.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 _base_ = ['../../../_base_/default_runtime.py']
 
 # runtime
-train_cfg = dict(max_epochs=100, val_interval=1)
+train_cfg = dict(max_epochs=210, val_interval=10)
 
 # optimizer
 optim_wrapper = dict(optimizer=dict(
     type='Adam',
     lr=5e-4,
 ))
 
@@ -13,125 +13,106 @@
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
-        end=100,
-        milestones=[50, 70],
+        end=210,
+        milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=512)
+auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(224, 224), heatmap_size=(56, 56), sigma=2)
+    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNet',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),
+        type='ResNeXt',
+        depth=152,
+        init_cfg=dict(
+            type='Pretrained', checkpoint='mmcls://resnext152_32x4d'),
+    ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
-        out_channels=21,
+        out_channels=16,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'FreiHandDataset'
+dataset_type = 'MpiiDataset'
 data_mode = 'topdown'
-data_root = 'data/freihand/'
+data_root = 'data/mpii/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
-    dict(type='GetBBoxCenterScale', padding=0.8),
+    dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(
-        type='RandomBBoxTransform',
-        shift_factor=0.25,
-        rotate_factor=180,
-        scale_factor=(0.7, 1.3)),
+    dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
-    dict(type='GetBBoxCenterScale', padding=0.8),
+    dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/freihand_train.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/mpii_train.json',
+        data_prefix=dict(img='images/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/freihand_val.json',
-        data_prefix=dict(img=''),
-        test_mode=True,
-        pipeline=val_pipeline,
-    ))
-test_dataloader = dict(
-    batch_size=32,
-    num_workers=2,
-    persistent_workers=True,
-    drop_last=False,
-    sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
-    dataset=dict(
-        type=dataset_type,
-        data_root=data_root,
-        data_mode=data_mode,
-        ann_file='annotations/freihand_test.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/mpii_val.json',
+        headbox_file='data/mpii/annotations/mpii_gt_val.mat',
+        data_prefix=dict(img='images/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
+test_dataloader = val_dataloader
 
 # evaluators
-val_evaluator = [
-    dict(type='PCKAccuracy', thr=0.2),
-    dict(type='AUC'),
-    dict(type='EPE'),
-]
+val_evaluator = dict(type='MpiiPCKAccuracy')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_8xb64-210e_onehand10k-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_udp-8xb64-210e_rhd2d-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,19 +23,19 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+    type='UDPHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -85,32 +85,32 @@
         conv_out_channels=(270, ),
         conv_kernel_sizes=(1, ),
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
-        shift_heatmap=True,
+        shift_heatmap=False,
     ))
 
 # base dataset settings
-dataset_type = 'OneHand10KDataset'
+dataset_type = 'Rhd2DDataset'
 data_mode = 'topdown'
-data_root = 'data/onehand10k/'
+data_root = 'data/rhd/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform', rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -122,29 +122,29 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/onehand10k_train.json',
+        ann_file='annotations/rhd_train.json',
         data_prefix=dict(img=''),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/onehand10k_test.json',
+        ann_file='annotations/rhd_test.json',
         data_prefix=dict(img=''),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_dark-8xb64-210e_onehand10k-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_8xb64-210e_onehand10k-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,23 +23,19 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap',
-    input_size=(256, 256),
-    heatmap_size=(64, 64),
-    sigma=2,
-    unbiased=True)
+    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -106,15 +102,15 @@
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform', rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_udp-8xb64-210e_onehand10k-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_8xb64-210e_rhd2d-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,19 +23,19 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='UDPHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -85,32 +85,32 @@
         conv_out_channels=(270, ),
         conv_kernel_sizes=(1, ),
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
-        shift_heatmap=False,
+        shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'OneHand10KDataset'
+dataset_type = 'Rhd2DDataset'
 data_mode = 'topdown'
-data_root = 'data/onehand10k/'
+data_root = 'data/rhd/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform', rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -122,29 +122,29 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/onehand10k_train.json',
+        ann_file='annotations/rhd_train.json',
         data_prefix=dict(img=''),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/onehand10k_test.json',
+        ann_file='annotations/rhd_test.json',
         data_prefix=dict(img=''),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_mobilenetv2_8xb64-210e_onehand10k-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/rhd2d/td-reg_res50_8xb64-210e_rhd2d-256x256.py`

 * *Files 4% similar despite different names*

```diff
@@ -23,63 +23,60 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
-codec = dict(
-    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+codec = dict(type='RegressionLabel', input_size=(256, 256))
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='MobileNetV2',
-        widen_factor=1.,
-        out_indices=(7, ),
-        init_cfg=dict(
-            type='Pretrained',
-            checkpoint='mmcls://mobilenet_v2',
-        )),
+        type='ResNet',
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
+    ),
+    neck=dict(type='GlobalAveragePooling'),
     head=dict(
-        type='HeatmapHead',
-        in_channels=1280,
-        out_channels=21,
-        loss=dict(type='KeypointMSELoss', use_target_weight=True),
+        type='RegressionHead',
+        in_channels=2048,
+        num_joints=21,
+        loss=dict(type='SmoothL1Loss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'OneHand10KDataset'
+dataset_type = 'Rhd2DDataset'
 data_mode = 'topdown'
-data_root = 'data/onehand10k/'
+data_root = 'data/rhd/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform', rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -91,29 +88,29 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/onehand10k_train.json',
+        ann_file='annotations/rhd_train.json',
         data_prefix=dict(img=''),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/onehand10k_test.json',
+        ann_file='annotations/rhd_test.json',
         data_prefix=dict(img=''),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_res50_8xb32-210e_onehand10k-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res101_8xb64-210e_zebra-160x160.py`

 * *Files 4% similar despite different names*

```diff
@@ -23,97 +23,97 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(160, 160), heatmap_size=(40, 40), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=50,
-        init_cfg=dict(
-            type='Pretrained',
-            checkpoint='torchvision://resnet50',
-        )),
+        depth=101,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
+    ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
-        out_channels=21,
+        out_channels=9,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'OneHand10KDataset'
+dataset_type = 'ZebraDataset'
 data_mode = 'topdown'
-data_root = 'data/onehand10k/'
+data_root = 'data/zebra/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
-    dict(type='GetBBoxCenterScale'),
+    dict(type='GetBBoxCenterScale', padding=0.8),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
-        type='RandomBBoxTransform', rotate_factor=180,
+        type='RandomBBoxTransform',
+        shift_factor=0.25,
+        rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
-    dict(type='GetBBoxCenterScale'),
+    dict(type='GetBBoxCenterScale', padding=0.8),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/onehand10k_train.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/zebra_train.json',
+        data_prefix=dict(img='images/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/onehand10k_test.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/zebra_test.json',
+        data_prefix=dict(img='images/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
 val_evaluator = [
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_8xb64-210e_rhd2d-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_dark-8xb64-210e_rhd2d-256x256.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,19 +23,23 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+    type='MSRAHeatmap',
+    input_size=(256, 256),
+    heatmap_size=(64, 64),
+    sigma=2,
+    unbiased=True)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -102,15 +106,15 @@
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
         type='RandomBBoxTransform', rotate_factor=180,
         scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_dark-8xb64-210e_rhd2d-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/300w/td-hm_hrnetv2-w18_8xb64-60e_300w-256x256.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,45 +1,44 @@
 _base_ = ['../../../_base_/default_runtime.py']
 
 # runtime
-train_cfg = dict(max_epochs=210, val_interval=10)
+train_cfg = dict(max_epochs=60, val_interval=1)
 
 # optimizer
 optim_wrapper = dict(optimizer=dict(
     type='Adam',
-    lr=5e-4,
+    lr=2e-3,
 ))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
-        end=210,
-        milestones=[170, 200],
+        end=60,
+        milestones=[40, 55],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='NME', rule='less', interval=1))
 
 # codec settings
 codec = dict(
     type='MSRAHeatmap',
     input_size=(256, 256),
     heatmap_size=(64, 64),
-    sigma=2,
-    unbiased=True)
+    sigma=1.5)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -72,49 +71,50 @@
                 num_branches=4,
                 block='BASIC',
                 num_blocks=(4, 4, 4, 4),
                 num_channels=(18, 36, 72, 144),
                 multiscale_output=True),
             upsample=dict(mode='bilinear', align_corners=False)),
         init_cfg=dict(
-            type='Pretrained',
-            checkpoint='open-mmlab://msra/hrnetv2_w18',
-        )),
+            type='Pretrained', checkpoint='open-mmlab://msra/hrnetv2_w18'),
+    ),
     head=dict(
         type='HeatmapHead',
-        in_channels=[18, 36, 72, 144],
+        in_channels=(18, 36, 72, 144),
         input_index=(0, 1, 2, 3),
         input_transform='resize_concat',
-        out_channels=21,
+        out_channels=68,
         deconv_out_channels=None,
         conv_out_channels=(270, ),
         conv_kernel_sizes=(1, ),
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'Rhd2DDataset'
+dataset_type = 'Face300WDataset'
 data_mode = 'topdown'
-data_root = 'data/rhd/'
+data_root = 'data/300w/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(
-        type='RandomBBoxTransform', rotate_factor=180,
-        scale_factor=(0.7, 1.3)),
+        type='RandomBBoxTransform',
+        shift_prob=0,
+        rotate_factor=60,
+        scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -126,35 +126,34 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/rhd_train.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/face_landmarks_300w_train.json',
+        data_prefix=dict(img='images/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/rhd_test.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/face_landmarks_300w_valid.json',
+        data_prefix=dict(img='images/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
-val_evaluator = [
-    dict(type='PCKAccuracy', thr=0.2),
-    dict(type='AUC'),
-    dict(type='EPE'),
-]
+val_evaluator = dict(
+    type='NME',
+    norm_mode='keypoint_distance',
+)
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_udp-8xb64-210e_rhd2d-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_8xb64-210e_coco-wholebody-256x192.py`

 * *Files 8% similar despite different names*

```diff
@@ -23,19 +23,20 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(
+    checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='UDPHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -52,65 +53,59 @@
                 num_blocks=(4, ),
                 num_channels=(64, )),
             stage2=dict(
                 num_modules=1,
                 num_branches=2,
                 block='BASIC',
                 num_blocks=(4, 4),
-                num_channels=(18, 36)),
+                num_channels=(32, 64)),
             stage3=dict(
                 num_modules=4,
                 num_branches=3,
                 block='BASIC',
                 num_blocks=(4, 4, 4),
-                num_channels=(18, 36, 72)),
+                num_channels=(32, 64, 128)),
             stage4=dict(
                 num_modules=3,
                 num_branches=4,
                 block='BASIC',
                 num_blocks=(4, 4, 4, 4),
-                num_channels=(18, 36, 72, 144),
-                multiscale_output=True),
-            upsample=dict(mode='bilinear', align_corners=False)),
+                num_channels=(32, 64, 128, 256))),
         init_cfg=dict(
             type='Pretrained',
-            checkpoint='open-mmlab://msra/hrnetv2_w18',
-        )),
+            checkpoint='https://download.openmmlab.com/mmpose/'
+            'pretrain_models/hrnet_w32-36af842e.pth'),
+    ),
     head=dict(
         type='HeatmapHead',
-        in_channels=[18, 36, 72, 144],
-        input_index=(0, 1, 2, 3),
-        input_transform='resize_concat',
-        out_channels=21,
+        in_channels=32,
+        out_channels=133,
         deconv_out_channels=None,
-        conv_out_channels=(270, ),
-        conv_kernel_sizes=(1, ),
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
-        shift_heatmap=False,
+        shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'Rhd2DDataset'
+dataset_type = 'CocoWholeBodyDataset'
 data_mode = 'topdown'
-data_root = 'data/rhd/'
+data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(
-        type='RandomBBoxTransform', rotate_factor=180,
-        scale_factor=(0.7, 1.3)),
+    dict(type='RandomHalfBody'),
+    dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -122,35 +117,34 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/rhd_train.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/coco_wholebody_train_v1.0.json',
+        data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/rhd_test.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/coco_wholebody_val_v1.0.json',
+        data_prefix=dict(img='val2017/'),
         test_mode=True,
+        bbox_file='data/coco/person_detection_results/'
+        'COCO_val2017_detections_AP_H_56_person.json',
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
-# evaluators
-val_evaluator = [
-    dict(type='PCKAccuracy', thr=0.2),
-    dict(type='AUC'),
-    dict(type='EPE'),
-]
+val_evaluator = dict(
+    type='CocoWholeBodyMetric',
+    ann_file=data_root + 'annotations/coco_wholebody_val_v1.0.json')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_mobilenetv2_8xb64-210e_rhd2d-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_dark-8xb64-210e_coco-256x192.py`

 * *Files 5% similar despite different names*

```diff
@@ -23,63 +23,63 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+    type='MSRAHeatmap',
+    input_size=(192, 256),
+    heatmap_size=(48, 64),
+    sigma=2,
+    unbiased=True)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='MobileNetV2',
-        widen_factor=1.,
-        out_indices=(7, ),
-        init_cfg=dict(
-            type='Pretrained',
-            checkpoint='mmcls://mobilenet_v2',
-        )),
+        type='ResNet',
+        depth=101,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
+    ),
     head=dict(
         type='HeatmapHead',
-        in_channels=1280,
-        out_channels=21,
+        in_channels=2048,
+        out_channels=17,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'Rhd2DDataset'
+dataset_type = 'CocoDataset'
 data_mode = 'topdown'
-data_root = 'data/rhd/'
+data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(
-        type='RandomBBoxTransform', rotate_factor=180,
-        scale_factor=(0.7, 1.3)),
+    dict(type='RandomHalfBody'),
+    dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -91,35 +91,35 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/rhd_train.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/person_keypoints_train2017.json',
+        data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/rhd_test.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/person_keypoints_val2017.json',
+        bbox_file='data/coco/person_detection_results/'
+        'COCO_val2017_detections_AP_H_56_person.json',
+        data_prefix=dict(img='val2017/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
-val_evaluator = [
-    dict(type='PCKAccuracy', thr=0.2),
-    dict(type='AUC'),
-    dict(type='EPE'),
-]
+val_evaluator = dict(
+    type='CocoMetric',
+    ann_file=data_root + 'annotations/person_keypoints_val2017.json')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_res50_8xb64-210e_rhd2d-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res50_rle-8xb64-210e_mpii-256x256.py`

 * *Files 7% similar despite different names*

```diff
@@ -22,67 +22,61 @@
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
-# hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
-
 # codec settings
-codec = dict(
-    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
+codec = dict(type='RegressionLabel', input_size=(256, 256))
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
         depth=50,
-        init_cfg=dict(
-            type='Pretrained',
-            checkpoint='torchvision://resnet50',
-        )),
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
+    ),
+    neck=dict(type='GlobalAveragePooling'),
     head=dict(
-        type='HeatmapHead',
+        type='RLEHead',
         in_channels=2048,
-        out_channels=21,
-        loss=dict(type='KeypointMSELoss', use_target_weight=True),
+        num_joints=16,
+        loss=dict(type='RLELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
-        flip_mode='heatmap',
-        shift_heatmap=True,
+        shift_coords=True,
     ))
 
 # base dataset settings
-dataset_type = 'Rhd2DDataset'
+dataset_type = 'MpiiDataset'
 data_mode = 'topdown'
-data_root = 'data/rhd/'
+data_root = 'data/mpii/'
+
+file_client_args = dict(backend='disk')
 
 # pipelines
 train_pipeline = [
-    dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
+    dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(
-        type='RandomBBoxTransform', rotate_factor=180,
-        scale_factor=(0.7, 1.3)),
+    dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
-    dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
+    dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
@@ -90,35 +84,35 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/rhd_train.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/mpii_train.json',
+        data_prefix=dict(img='images/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/rhd_test.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/mpii_val.json',
+        headbox_file=f'{data_root}/annotations/mpii_gt_val.mat',
+        data_prefix=dict(img='images/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
+# hooks
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
+
 # evaluators
-val_evaluator = [
-    dict(type='PCKAccuracy', thr=0.2),
-    dict(type='AUC'),
-    dict(type='EPE'),
-]
+val_evaluator = dict(type='MpiiPCKAccuracy')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/onehand10k/td-reg_res50_8xb64-210e_onehand10k-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_res101_8xb32-210e_coco-384x288.py`

 * *Files 5% similar despite different names*

```diff
@@ -20,103 +20,102 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=512)
+auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
-codec = dict(type='RegressionLabel', input_size=(256, 256))
+codec = dict(
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
+        depth=101,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
     ),
-    neck=dict(type='GlobalAveragePooling'),
     head=dict(
-        type='RegressionHead',
+        type='HeatmapHead',
         in_channels=2048,
-        num_joints=21,
-        loss=dict(type='SmoothL1Loss', use_target_weight=True),
+        out_channels=17,
+        loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'OneHand10KDataset'
+dataset_type = 'CocoDataset'
 data_mode = 'topdown'
-data_root = 'data/onehand10k/'
+data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(
-        type='RandomBBoxTransform', rotate_factor=180,
-        scale_factor=(0.7, 1.3)),
+    dict(type='RandomHalfBody'),
+    dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/onehand10k_train.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/person_keypoints_train2017.json',
+        data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
-    batch_size=32,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/onehand10k_test.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/person_keypoints_val2017.json',
+        bbox_file='data/coco/person_detection_results/'
+        'COCO_val2017_detections_AP_H_56_person.json',
+        data_prefix=dict(img='val2017/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
-val_evaluator = [
-    dict(type='PCKAccuracy', thr=0.2),
-    dict(type='AUC'),
-    dict(type='EPE'),
-]
+val_evaluator = dict(
+    type='CocoMetric',
+    ann_file=data_root + 'annotations/person_keypoints_val2017.json')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/rhd2d/td-reg_res50_8xb64-210e_rhd2d-256x256.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_seresnet152_8xb32-210e_coco-256x192.py`

 * *Files 5% similar despite different names*

```diff
@@ -23,100 +23,98 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(checkpoint=dict(save_best='auc/@20thrs', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='coco/AP', rule='greater'))
 
 # codec settings
-codec = dict(type='RegressionLabel', input_size=(256, 256))
+codec = dict(
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNet',
-        depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
+        type='SEResNet',
+        depth=152,
     ),
-    neck=dict(type='GlobalAveragePooling'),
     head=dict(
-        type='RegressionHead',
+        type='HeatmapHead',
         in_channels=2048,
-        num_joints=21,
-        loss=dict(type='SmoothL1Loss', use_target_weight=True),
+        out_channels=17,
+        loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'Rhd2DDataset'
+dataset_type = 'CocoDataset'
 data_mode = 'topdown'
-data_root = 'data/rhd/'
+data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(
-        type='RandomBBoxTransform', rotate_factor=180,
-        scale_factor=(0.7, 1.3)),
+    dict(type='RandomHalfBody'),
+    dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='keypoint_label', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/rhd_train.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/person_keypoints_train2017.json',
+        data_prefix=dict(img='train2017/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/rhd_test.json',
-        data_prefix=dict(img=''),
+        ann_file='annotations/person_keypoints_val2017.json',
+        bbox_file='data/coco/person_detection_results/'
+        'COCO_val2017_detections_AP_H_56_person.json',
+        data_prefix=dict(img='val2017/'),
         test_mode=True,
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
 # evaluators
-val_evaluator = [
-    dict(type='PCKAccuracy', thr=0.2),
-    dict(type='AUC'),
-    dict(type='EPE'),
-]
+val_evaluator = dict(
+    type='CocoMetric',
+    ann_file=data_root + 'annotations/person_keypoints_val2017.json')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_8xb64-210e_coco-wholebody-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_8xb64-210e_coco-wholebody-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -28,15 +28,15 @@
 
 # hooks
 default_hooks = dict(
     checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -97,15 +97,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_8xb64-210e_coco-wholebody-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_dark-8xb64-210e_coco-wholebody-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -28,15 +28,19 @@
 
 # hooks
 default_hooks = dict(
     checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
+    type='MSRAHeatmap',
+    input_size=(192, 256),
+    heatmap_size=(48, 64),
+    sigma=2,
+    unbiased=True)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -97,15 +101,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_dark-8xb64-210e_coco-wholebody-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hrnetv2-w18_8xb32-60e_coco-wholebody-face-256x256.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,46 +1,41 @@
 _base_ = ['../../../_base_/default_runtime.py']
 
 # runtime
-train_cfg = dict(max_epochs=210, val_interval=10)
+train_cfg = dict(max_epochs=60, val_interval=1)
 
 # optimizer
 optim_wrapper = dict(optimizer=dict(
     type='Adam',
-    lr=5e-4,
+    lr=2e-3,
 ))
 
 # learning policy
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
         end=210,
-        milestones=[170, 200],
+        milestones=[40, 55],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=512)
+auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='NME', rule='less', interval=1))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap',
-    input_size=(192, 256),
-    heatmap_size=(48, 64),
-    sigma=2,
-    unbiased=True)
+    type='MSRAHeatmap', input_size=(256, 256), heatmap_size=(64, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -57,71 +52,76 @@
                 num_blocks=(4, ),
                 num_channels=(64, )),
             stage2=dict(
                 num_modules=1,
                 num_branches=2,
                 block='BASIC',
                 num_blocks=(4, 4),
-                num_channels=(32, 64)),
+                num_channels=(18, 36)),
             stage3=dict(
                 num_modules=4,
                 num_branches=3,
                 block='BASIC',
                 num_blocks=(4, 4, 4),
-                num_channels=(32, 64, 128)),
+                num_channels=(18, 36, 72)),
             stage4=dict(
                 num_modules=3,
                 num_branches=4,
                 block='BASIC',
                 num_blocks=(4, 4, 4, 4),
-                num_channels=(32, 64, 128, 256))),
+                num_channels=(18, 36, 72, 144),
+                multiscale_output=True),
+            upsample=dict(mode='bilinear', align_corners=False)),
         init_cfg=dict(
-            type='Pretrained',
-            checkpoint='https://download.openmmlab.com/mmpose/'
-            'pretrain_models/hrnet_w32-36af842e.pth'),
-    ),
+            type='Pretrained', checkpoint='open-mmlab://msra/hrnetv2_w18')),
     head=dict(
         type='HeatmapHead',
-        in_channels=32,
-        out_channels=133,
+        in_channels=[18, 36, 72, 144],
+        input_index=(0, 1, 2, 3),
+        input_transform='resize_concat',
+        out_channels=68,
         deconv_out_channels=None,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
+        conv_out_channels=(270, ),
+        conv_kernel_sizes=(1, ),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'CocoWholeBodyDataset'
+dataset_type = 'CocoWholeBodyFaceDataset'
 data_mode = 'topdown'
 data_root = 'data/coco/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(type='RandomHalfBody'),
-    dict(type='RandomBBoxTransform'),
+    dict(
+        type='RandomBBoxTransform',
+        rotate_factor=60,
+        scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
@@ -138,17 +138,17 @@
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
         ann_file='annotations/coco_wholebody_val_v1.0.json',
         data_prefix=dict(img='val2017/'),
         test_mode=True,
-        bbox_file='data/coco/person_detection_results/'
-        'COCO_val2017_detections_AP_H_56_person.json',
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
+# evaluators
 val_evaluator = dict(
-    type='CocoWholeBodyMetric',
-    ann_file=data_root + 'annotations/coco_wholebody_val_v1.0.json')
+    type='NME',
+    norm_mode='keypoint_distance',
+)
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_8xb32-210e_coco-wholebody-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_8xb32-210e_coco-wholebody-256x192.py`

 * *Files 8% similar despite different names*

```diff
@@ -97,15 +97,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_8xb32-210e_coco-wholebody-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_8xb32-210e_coco-wholebody-384x288.py`

 * *Files 8% similar despite different names*

```diff
@@ -97,15 +97,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_dark-8xb32-210e_coco-wholebody-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_dark-8xb32-210e_coco-wholebody-384x288.py`

 * *Files 8% similar despite different names*

```diff
@@ -101,15 +101,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res101_8xb32-210e_coco-wholebody-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res101_8xb32-210e_coco-wholebody-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -28,15 +28,15 @@
 
 # hooks
 default_hooks = dict(
     checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -68,15 +68,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res101_8xb32-210e_coco-wholebody-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res152_8xb32-210e_coco-wholebody-384x288.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=256)
+auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(
     checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
 
 # codec settings
 codec = dict(
@@ -40,16 +40,16 @@
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=101,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
+        depth=152,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet152'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=133,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -68,15 +68,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res152_8xb32-210e_coco-wholebody-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res152_8xb32-210e_coco-wholebody-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -68,15 +68,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res152_8xb32-210e_coco-wholebody-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res50_8xb64-210e_coco-wholebody-256x192.py`

 * *Files 2% similar despite different names*

```diff
@@ -28,28 +28,28 @@
 
 # hooks
 default_hooks = dict(
     checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
         type='ResNet',
-        depth=152,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet152'),
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
     head=dict(
         type='HeatmapHead',
         in_channels=2048,
         out_channels=133,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
@@ -68,27 +68,27 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=32,
+    batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res50_8xb64-210e_coco-wholebody-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res50_8xb64-210e_coco-wholebody-384x288.py`

 * *Files 1% similar despite different names*

```diff
@@ -28,15 +28,15 @@
 
 # hooks
 default_hooks = dict(
     checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
@@ -68,15 +68,15 @@
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
     dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res50_8xb64-210e_coco-wholebody-384x288.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-res50_8xb64-210e_coco-wholebody-256x192.py`

 * *Files 6% similar despite different names*

```diff
@@ -28,32 +28,31 @@
 
 # hooks
 default_hooks = dict(
     checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(288, 384), heatmap_size=(72, 96), sigma=3)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ResNet',
+        type='ViPNAS_ResNet',
         depth=50,
-        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
     head=dict(
-        type='HeatmapHead',
-        in_channels=2048,
+        type='ViPNASHead',
+        in_channels=608,
         out_channels=133,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
@@ -66,17 +65,20 @@
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
-    dict(type='RandomBBoxTransform'),
+    dict(
+        type='RandomBBoxTransform',
+        rotate_factor=60,
+        scale_factor=(0.75, 1.25)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-mbv3_8xb64-210e_coco-wholebody-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/body_2d_keypoint/simcc/mpii/simcc_res50_wo-deconv-8xb64-210e_mpii-256x256.py`

 * *Files 11% similar despite different names*

```diff
@@ -13,75 +13,74 @@
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
-        end=210,
+        end=train_cfg['max_epochs'],
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
-# hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
-
 # codec settings
 codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+    type='SimCCLabel', input_size=(256, 256), sigma=6.0, simcc_split_ratio=2.0)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
-    backbone=dict(type='ViPNAS_MobileNetV3'),
+    backbone=dict(
+        type='ResNet',
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
+    ),
     head=dict(
-        type='ViPNASHead',
-        in_channels=160,
-        out_channels=133,
-        deconv_out_channels=(160, 160, 160),
-        deconv_num_groups=(160, 160, 160),
-        loss=dict(type='KeypointMSELoss', use_target_weight=True),
+        type='SimCCHead',
+        in_channels=2048,
+        out_channels=16,
+        input_size=codec['input_size'],
+        in_featuremap_size=(8, 8),
+        simcc_split_ratio=codec['simcc_split_ratio'],
+        deconv_out_channels=None,
+        loss=dict(type='KLDiscretLoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
-        flip_mode='heatmap',
-        shift_heatmap=True,
+        shift_coords=True,
     ))
 
 # base dataset settings
-dataset_type = 'CocoWholeBodyDataset'
+dataset_type = 'MpiiDataset'
 data_mode = 'topdown'
-data_root = 'data/coco/'
+data_root = 'data/mpii/'
+
+file_client_args = dict(backend='disk')
 
 # pipelines
 train_pipeline = [
-    dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
+    dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(type='RandomHalfBody'),
-    dict(
-        type='RandomBBoxTransform',
-        rotate_factor=60,
-        scale_factor=(0.75, 1.25)),
+    dict(type='RandomBBoxTransform', shift_prob=0),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
-    dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
+    dict(type='LoadImage', file_client_args=file_client_args),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
@@ -89,34 +88,35 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/coco_wholebody_train_v1.0.json',
-        data_prefix=dict(img='train2017/'),
+        ann_file='annotations/mpii_train.json',
+        data_prefix=dict(img='images/'),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/coco_wholebody_val_v1.0.json',
-        data_prefix=dict(img='val2017/'),
+        ann_file='annotations/mpii_val.json',
+        headbox_file=f'{data_root}/annotations/mpii_gt_val.mat',
+        data_prefix=dict(img='images/'),
         test_mode=True,
-        bbox_file='data/coco/person_detection_results/'
-        'COCO_val2017_detections_AP_H_56_person.json',
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
-val_evaluator = dict(
-    type='CocoWholeBodyMetric',
-    ann_file=data_root + 'annotations/coco_wholebody_val_v1.0.json')
+# hooks
+default_hooks = dict(checkpoint=dict(save_best='PCK', rule='greater'))
+
+# evaluators
+val_evaluator = dict(type='MpiiPCKAccuracy')
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-mbv3_dark-8xb64-210e_coco-wholebody-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/freihand2d/td-hm_res50_8xb64-100e_freihand2d-224x224.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 _base_ = ['../../../_base_/default_runtime.py']
 
 # runtime
-train_cfg = dict(max_epochs=210, val_interval=10)
+train_cfg = dict(max_epochs=100, val_interval=1)
 
 # optimizer
 optim_wrapper = dict(optimizer=dict(
     type='Adam',
     lr=5e-4,
 ))
 
@@ -13,114 +13,126 @@
 param_scheduler = [
     dict(
         type='LinearLR', begin=0, end=500, start_factor=0.001,
         by_epoch=False),  # warm-up
     dict(
         type='MultiStepLR',
         begin=0,
-        end=210,
-        milestones=[170, 200],
+        end=100,
+        milestones=[50, 70],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
 default_hooks = dict(
-    checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
+    checkpoint=dict(save_best='AUC', rule='greater', interval=1))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap',
-    input_size=(192, 256),
-    heatmap_size=(48, 64),
-    sigma=2,
-    unbiased=True)
+    type='MSRAHeatmap', input_size=(224, 224), heatmap_size=(56, 56), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
-    backbone=dict(type='ViPNAS_MobileNetV3'),
+    backbone=dict(
+        type='ResNet',
+        depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),
     head=dict(
-        type='ViPNASHead',
-        in_channels=160,
-        out_channels=133,
-        deconv_out_channels=(160, 160, 160),
-        deconv_num_groups=(160, 160, 160),
+        type='HeatmapHead',
+        in_channels=2048,
+        out_channels=21,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'CocoWholeBodyDataset'
+dataset_type = 'FreiHandDataset'
 data_mode = 'topdown'
-data_root = 'data/coco/'
+data_root = 'data/freihand/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
-    dict(type='GetBBoxCenterScale'),
+    dict(type='GetBBoxCenterScale', padding=0.8),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(type='RandomHalfBody'),
     dict(
         type='RandomBBoxTransform',
-        rotate_factor=60,
-        scale_factor=(0.75, 1.25)),
+        shift_factor=0.25,
+        rotate_factor=180,
+        scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
-    dict(type='GetBBoxCenterScale'),
+    dict(type='GetBBoxCenterScale', padding=0.8),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
     batch_size=64,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/coco_wholebody_train_v1.0.json',
-        data_prefix=dict(img='train2017/'),
+        ann_file='annotations/freihand_train.json',
+        data_prefix=dict(img=''),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/coco_wholebody_val_v1.0.json',
-        data_prefix=dict(img='val2017/'),
+        ann_file='annotations/freihand_val.json',
+        data_prefix=dict(img=''),
+        test_mode=True,
+        pipeline=val_pipeline,
+    ))
+test_dataloader = dict(
+    batch_size=32,
+    num_workers=2,
+    persistent_workers=True,
+    drop_last=False,
+    sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
+    dataset=dict(
+        type=dataset_type,
+        data_root=data_root,
+        data_mode=data_mode,
+        ann_file='annotations/freihand_test.json',
+        data_prefix=dict(img=''),
         test_mode=True,
-        bbox_file='data/coco/person_detection_results/'
-        'COCO_val2017_detections_AP_H_56_person.json',
         pipeline=val_pipeline,
     ))
-test_dataloader = val_dataloader
 
-val_evaluator = dict(
-    type='CocoWholeBodyMetric',
-    ann_file=data_root + 'annotations/coco_wholebody_val_v1.0.json')
+# evaluators
+val_evaluator = [
+    dict(type='PCKAccuracy', thr=0.2),
+    dict(type='AUC'),
+    dict(type='EPE'),
+]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-res50_8xb64-210e_coco-wholebody-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/onehand10k/td-reg_res50_8xb64-210e_onehand10k-256x256.py`

 * *Files 14% similar despite different names*

```diff
@@ -23,62 +23,60 @@
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
 auto_scale_lr = dict(base_batch_size=512)
 
 # hooks
-default_hooks = dict(
-    checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
+default_hooks = dict(checkpoint=dict(save_best='AUC', rule='greater'))
 
 # codec settings
-codec = dict(
-    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
+codec = dict(type='RegressionLabel', input_size=(256, 256))
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ViPNAS_ResNet',
+        type='ResNet',
         depth=50,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
     ),
+    neck=dict(type='GlobalAveragePooling'),
     head=dict(
-        type='ViPNASHead',
-        in_channels=608,
-        out_channels=133,
-        loss=dict(type='KeypointMSELoss', use_target_weight=True),
+        type='RegressionHead',
+        in_channels=2048,
+        num_joints=21,
+        loss=dict(type='SmoothL1Loss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
     ))
 
 # base dataset settings
-dataset_type = 'CocoWholeBodyDataset'
+dataset_type = 'OneHand10KDataset'
 data_mode = 'topdown'
-data_root = 'data/coco/'
+data_root = 'data/onehand10k/'
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
-    dict(type='RandomHalfBody'),
     dict(
-        type='RandomBBoxTransform',
-        rotate_factor=60,
-        scale_factor=(0.75, 1.25)),
+        type='RandomBBoxTransform', rotate_factor=180,
+        scale_factor=(0.7, 1.3)),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
@@ -90,34 +88,35 @@
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/coco_wholebody_train_v1.0.json',
-        data_prefix=dict(img='train2017/'),
+        ann_file='annotations/onehand10k_train.json',
+        data_prefix=dict(img=''),
         pipeline=train_pipeline,
     ))
 val_dataloader = dict(
     batch_size=32,
     num_workers=2,
     persistent_workers=True,
     drop_last=False,
     sampler=dict(type='DefaultSampler', shuffle=False, round_up=False),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
-        ann_file='annotations/coco_wholebody_val_v1.0.json',
-        data_prefix=dict(img='val2017/'),
+        ann_file='annotations/onehand10k_test.json',
+        data_prefix=dict(img=''),
         test_mode=True,
-        bbox_file='data/coco/person_detection_results/'
-        'COCO_val2017_detections_AP_H_56_person.json',
         pipeline=val_pipeline,
     ))
 test_dataloader = val_dataloader
 
-val_evaluator = dict(
-    type='CocoWholeBodyMetric',
-    ann_file=data_root + 'annotations/coco_wholebody_val_v1.0.json')
+# evaluators
+val_evaluator = [
+    dict(type='PCKAccuracy', thr=0.2),
+    dict(type='AUC'),
+    dict(type='EPE'),
+]
 test_evaluator = val_evaluator
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-res50_dark-8xb64-210e_coco-wholebody-256x192.py` & `mmpose-1.0.0rc1/mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res101_8xb32-210e_coco-wholebody-256x192.py`

 * *Files 18% similar despite different names*

```diff
@@ -20,43 +20,40 @@
         end=210,
         milestones=[170, 200],
         gamma=0.1,
         by_epoch=True)
 ]
 
 # automatically scaling LR based on the actual training batch size
-auto_scale_lr = dict(base_batch_size=512)
+auto_scale_lr = dict(base_batch_size=256)
 
 # hooks
 default_hooks = dict(
     checkpoint=dict(save_best='coco-wholebody/AP', rule='greater'))
 
 # codec settings
 codec = dict(
-    type='MSRAHeatmap',
-    input_size=(192, 256),
-    heatmap_size=(48, 64),
-    sigma=2,
-    unbiased=True)
+    type='MSRAHeatmap', input_size=(192, 256), heatmap_size=(48, 64), sigma=2)
 
 # model settings
 model = dict(
     type='TopdownPoseEstimator',
     data_preprocessor=dict(
         type='PoseDataPreprocessor',
         mean=[123.675, 116.28, 103.53],
         std=[58.395, 57.12, 57.375],
         bgr_to_rgb=True),
     backbone=dict(
-        type='ViPNAS_ResNet',
-        depth=50,
+        type='ResNet',
+        depth=101,
+        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
     ),
     head=dict(
-        type='ViPNASHead',
-        in_channels=608,
+        type='HeatmapHead',
+        in_channels=2048,
         out_channels=133,
         loss=dict(type='KeypointMSELoss', use_target_weight=True),
         decoder=codec),
     test_cfg=dict(
         flip_test=True,
         flip_mode='heatmap',
         shift_heatmap=True,
@@ -69,32 +66,29 @@
 
 # pipelines
 train_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='RandomFlip', direction='horizontal'),
     dict(type='RandomHalfBody'),
-    dict(
-        type='RandomBBoxTransform',
-        rotate_factor=60,
-        scale_factor=(0.75, 1.25)),
+    dict(type='RandomBBoxTransform'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
-    dict(type='GenerateTarget', target_type='heatmap', encoder=codec),
+    dict(type='GenerateTarget', encoder=codec),
     dict(type='PackPoseInputs')
 ]
 val_pipeline = [
     dict(type='LoadImage', file_client_args={{_base_.file_client_args}}),
     dict(type='GetBBoxCenterScale'),
     dict(type='TopdownAffine', input_size=codec['input_size']),
     dict(type='PackPoseInputs')
 ]
 
 # data loaders
 train_dataloader = dict(
-    batch_size=64,
+    batch_size=32,
     num_workers=2,
     persistent_workers=True,
     sampler=dict(type='DefaultSampler', shuffle=True),
     dataset=dict(
         type=dataset_type,
         data_root=data_root,
         data_mode=data_mode,
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/image_demo.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/image_demo.py`

 * *Files 15% similar despite different names*

```diff
@@ -2,36 +2,44 @@
 from argparse import ArgumentParser
 
 from mmcv.image import imread
 
 from mmpose.apis import inference_topdown, init_model
 from mmpose.registry import VISUALIZERS
 from mmpose.structures import merge_data_samples
-from mmpose.utils import register_all_modules
 
 
 def parse_args():
     parser = ArgumentParser()
     parser.add_argument('img', help='Image file')
     parser.add_argument('config', help='Config file')
     parser.add_argument('checkpoint', help='Checkpoint file')
     parser.add_argument('--out-file', default=None, help='Path to output file')
     parser.add_argument(
         '--device', default='cuda:0', help='Device used for inference')
     parser.add_argument(
         '--draw-heatmap',
         action='store_true',
         help='Visualize the predicted heatmap')
+    parser.add_argument(
+        '--show-kpt-idx',
+        action='store_true',
+        default=False,
+        help='Whether to show the index of keypoints')
+    parser.add_argument(
+        '--show',
+        action='store_true',
+        default=False,
+        help='whether to show img')
     args = parser.parse_args()
     return args
 
 
-def main(args):
-    # register all modules in mmpose into the registries
-    register_all_modules()
+def main():
+    args = parse_args()
 
     # build the model from a config file and a checkpoint file
     if args.draw_heatmap:
         cfg_options = dict(model=dict(test_cfg=dict(output_heatmaps=True)))
     else:
         cfg_options = None
 
@@ -42,26 +50,26 @@
         cfg_options=cfg_options)
 
     # init visualizer
     visualizer = VISUALIZERS.build(model.cfg.visualizer)
     visualizer.set_dataset_meta(model.dataset_meta)
 
     # inference a single image
-    results = inference_topdown(model, args.img)
-    results = merge_data_samples(results)
+    batch_results = inference_topdown(model, args.img)
+    results = merge_data_samples(batch_results)
 
     # show the results
     img = imread(args.img, channel_order='rgb')
     visualizer.add_datasample(
         'result',
         img,
         data_sample=results,
         draw_gt=False,
         draw_bbox=True,
         draw_heatmap=args.draw_heatmap,
-        show=True,
+        show_kpt_idx=args.show_kpt_idx,
+        show=args.show,
         out_file=args.out_file)
 
 
 if __name__ == '__main__':
-    args = parse_args()
-    main(args)
+    main()
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/cascade_rcnn_x101_64x4d_fpn_1class.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/cascade_rcnn_x101_64x4d_fpn_1class.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/cascade_rcnn_x101_64x4d_fpn_coco.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/cascade_rcnn_x101_64x4d_fpn_coco.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/faster_rcnn_r50_fpn_1class.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/faster_rcnn_r50_fpn_1class.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/mask_rcnn_r50_fpn_2x_coco.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/mask_rcnn_r50_fpn_2x_coco.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/ssdlite_mobilenetv2-scratch_8xb24-600e_coco.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/ssdlite_mobilenetv2-scratch_8xb24-600e_coco.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/mmdetection_cfg/yolov3_d53_320_273e_coco.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/mmdetection_cfg/yolov3_d53_320_273e_coco.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/mmtracking_cfg/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/mmtracking_cfg/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/mmtracking_cfg/tracktor_faster-rcnn_r50_fpn_4e_mot17-private.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/mmtracking_cfg/tracktor_faster-rcnn_r50_fpn_4e_mot17-private.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/topdown_demo_with_mmdet.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/topdown_demo_with_mmdet.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,71 +1,72 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 import mimetypes
 import os
 import tempfile
 from argparse import ArgumentParser
 
+import json_tricks as json
 import mmcv
 import mmengine
 import numpy as np
 
 from mmpose.apis import inference_topdown
 from mmpose.apis import init_model as init_pose_estimator
 from mmpose.evaluation.functional import nms
 from mmpose.registry import VISUALIZERS
-from mmpose.structures import merge_data_samples
-from mmpose.utils import register_all_modules as register_mmpose_modules
+from mmpose.structures import merge_data_samples, split_instances
+from mmpose.utils import adapt_mmdet_pipeline
 
 try:
     from mmdet.apis import inference_detector, init_detector
-    from mmdet.utils import register_all_modules as register_mmdet_modules
     has_mmdet = True
 except (ImportError, ModuleNotFoundError):
     has_mmdet = False
 
 
-def visualize_img(args, img_path, detector, pose_estimator, visualizer,
-                  show_interval):
+def process_one_image(args, img_path, detector, pose_estimator, visualizer,
+                      show_interval):
     """Visualize predicted keypoints (and heatmaps) of one image."""
 
     # predict bbox
-    register_mmdet_modules()
-    detect_result = inference_detector(detector, img_path)
-    pred_instance = detect_result.pred_instances.cpu().numpy()
+    det_result = inference_detector(detector, img_path)
+    pred_instance = det_result.pred_instances.cpu().numpy()
     bboxes = np.concatenate(
         (pred_instance.bboxes, pred_instance.scores[:, None]), axis=1)
     bboxes = bboxes[np.logical_and(pred_instance.labels == args.det_cat_id,
                                    pred_instance.scores > args.bbox_thr)]
-    bboxes = bboxes[nms(bboxes, args.nms_thr)][:, :4]
+    bboxes = bboxes[nms(bboxes, args.nms_thr), :4]
 
     # predict keypoints
-    register_mmpose_modules()
     pose_results = inference_topdown(pose_estimator, img_path, bboxes)
     data_samples = merge_data_samples(pose_results)
 
     # show the results
-    img = mmcv.imread(img_path)
-    img = mmcv.imconvert(img, 'bgr', 'rgb')
+    img = mmcv.imread(img_path, channel_order='rgb')
 
     out_file = None
     if args.output_root:
         out_file = f'{args.output_root}/{os.path.basename(img_path)}'
 
     visualizer.add_datasample(
         'result',
         img,
         data_sample=data_samples,
         draw_gt=False,
         draw_heatmap=args.draw_heatmap,
-        draw_bbox=False,
+        draw_bbox=args.draw_bbox,
+        show_kpt_idx=args.show_kpt_idx,
         show=args.show,
         wait_time=show_interval,
         out_file=out_file,
         kpt_score_thr=args.kpt_thr)
 
+    # if there is no instance detected, return None
+    return data_samples.get('pred_instances', None)
+
 
 def main():
     """Visualize the demo images.
 
     Using mmdet to detect the human.
     """
     parser = ArgumentParser()
@@ -83,14 +84,19 @@
     parser.add_argument(
         '--output-root',
         type=str,
         default='',
         help='root of the output img file. '
         'Default not saving the visualization images.')
     parser.add_argument(
+        '--save-predictions',
+        action='store_true',
+        default=False,
+        help='whether to save predicted results')
+    parser.add_argument(
         '--device', default='cuda:0', help='Device used for inference')
     parser.add_argument(
         '--det-cat-id',
         type=int,
         default=0,
         help='Category id for bounding box detection model')
     parser.add_argument(
@@ -105,44 +111,54 @@
         help='IoU threshold for bounding box NMS')
     parser.add_argument(
         '--kpt-thr', type=float, default=0.3, help='Keypoint score threshold')
     parser.add_argument(
         '--draw-heatmap',
         action='store_true',
         default=False,
-        help='Whether to draw output heatmap')
+        help='Draw heatmap predicted by the model')
+    parser.add_argument(
+        '--show-kpt-idx',
+        action='store_true',
+        default=False,
+        help='Whether to show the index of keypoints')
     parser.add_argument(
         '--radius',
         type=int,
         default=3,
         help='Keypoint radius for visualization')
     parser.add_argument(
         '--thickness',
         type=int,
         default=1,
         help='Link thickness for visualization')
+    parser.add_argument(
+        '--draw-bbox', action='store_true', help='Draw bboxes of instances')
 
     assert has_mmdet, 'Please install mmdet to run the demo.'
 
     args = parser.parse_args()
 
     assert args.show or (args.output_root != '')
     assert args.input != ''
     assert args.det_config is not None
     assert args.det_checkpoint is not None
     if args.output_root:
         mmengine.mkdir_or_exist(args.output_root)
+    if args.save_predictions:
+        assert args.output_root != ''
+        args.pred_save_path = f'{args.output_root}/results_' \
+            f'{os.path.splitext(os.path.basename(args.input))[0]}.json'
 
     # build detector
-    register_mmdet_modules()
     detector = init_detector(
         args.det_config, args.det_checkpoint, device=args.device)
+    detector.cfg = adapt_mmdet_pipeline(detector.cfg)
 
     # build pose estimator
-    register_mmpose_modules()
     pose_estimator = init_pose_estimator(
         args.pose_config,
         args.pose_checkpoint,
         device=args.device,
         cfg_options=dict(
             model=dict(test_cfg=dict(output_heatmaps=args.draw_heatmap))))
 
@@ -152,45 +168,67 @@
     visualizer = VISUALIZERS.build(pose_estimator.cfg.visualizer)
     # the dataset_meta is loaded from the checkpoint and
     # then pass to the model in init_pose_estimator
     visualizer.set_dataset_meta(pose_estimator.dataset_meta)
 
     input_type = mimetypes.guess_type(args.input)[0].split('/')[0]
     if input_type == 'image':
-        visualize_img(
+        pred_instances = process_one_image(
             args,
             args.input,
             detector,
             pose_estimator,
             visualizer,
             show_interval=0)
+        pred_instances_list = split_instances(pred_instances)
+
     elif input_type == 'video':
         tmp_folder = tempfile.TemporaryDirectory()
         video = mmcv.VideoReader(args.input)
         progressbar = mmengine.ProgressBar(len(video))
         video.cvt2frames(tmp_folder.name, show_progress=False)
         output_root = args.output_root
         args.output_root = tmp_folder.name
-        for img_fname in os.listdir(tmp_folder.name):
-            visualize_img(
+        pred_instances_list = []
+
+        for frame_id, img_fname in enumerate(os.listdir(tmp_folder.name)):
+            pred_instances = process_one_image(
                 args,
                 f'{tmp_folder.name}/{img_fname}',
                 detector,
                 pose_estimator,
                 visualizer,
                 show_interval=1)
+
             progressbar.update()
+            pred_instances_list.append(
+                dict(
+                    frame_id=frame_id,
+                    instances=split_instances(pred_instances)))
+
         if output_root:
             mmcv.frames2video(
                 tmp_folder.name,
                 f'{output_root}/{os.path.basename(args.input)}',
                 fps=video.fps,
                 fourcc='mp4v',
                 show_progress=False)
         tmp_folder.cleanup()
+
     else:
+        args.save_predictions = False
         raise ValueError(
             f'file {os.path.basename(args.input)} has invalid format.')
 
+    if args.save_predictions:
+        with open(args.pred_save_path, 'w') as f:
+            json.dump(
+                dict(
+                    meta_info=pose_estimator.dataset_meta,
+                    instance_info=pred_instances_list),
+                f,
+                indent='\t')
+        print(f'predictions have been saved at {args.pred_save_path}')
+
 
 if __name__ == '__main__':
     main()
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/topdown_face_demo.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/bottomup_demo.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,185 +1,179 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 import mimetypes
 import os
 import tempfile
 from argparse import ArgumentParser
 
+import json_tricks as json
 import mmcv
 import mmengine
-import numpy as np
 
-from mmpose.apis import inference_topdown
-from mmpose.apis import init_model as init_pose_estimator
-from mmpose.evaluation.functional import nms
+from mmpose.apis import inference_bottomup, init_model
 from mmpose.registry import VISUALIZERS
-from mmpose.structures import merge_data_samples
-from mmpose.utils import register_all_modules as register_mmpose_modules
+from mmpose.structures import split_instances
 
-try:
-    import face_recognition
-    has_face_det = True
-except (ImportError, ModuleNotFoundError):
-    has_face_det = False
 
-
-def process_face_det_results(face_det_results):
-    """Process det results, and return a list of bboxes.
-
-    :param face_det_results: (top, right, bottom and left)
-    :return: a list of detected bounding boxes (x,y,x,y)-format
-    """
-
-    person_results = []
-    for bbox in face_det_results:
-        # left, top, right, bottom
-        person_results.append([bbox[3], bbox[0], bbox[1], bbox[2]])
-    person_results = np.array(person_results)
-
-    return person_results
-
-
-def visualize_img(args, img_path, pose_estimator, visualizer, show_interval):
+def process_one_image(args, img_path, pose_estimator, visualizer,
+                      show_interval):
     """Visualize predicted keypoints (and heatmaps) of one image."""
 
-    # predict bbox
-    image = face_recognition.load_image_file(img_path)
-    face_det_results = face_recognition.face_locations(image)
-    bboxes = process_face_det_results(face_det_results)
-
-    bboxes = np.concatenate((bboxes, np.ones((bboxes.shape[0], 1))), axis=1)
-    bboxes = bboxes[nms(bboxes, args.nms_thr)][:, :4]
-
-    # predict keypoints
-    pose_results = inference_topdown(pose_estimator, img_path, bboxes)
-    data_samples = merge_data_samples(pose_results)
+    # inference a single image
+    batch_results = inference_bottomup(pose_estimator, img_path)
+    results = batch_results[0]
 
     # show the results
-    img = mmcv.imread(img_path)
-    img = mmcv.imconvert(img, 'bgr', 'rgb')
+    img = mmcv.imread(img_path, channel_order='rgb')
 
     out_file = None
     if args.output_root:
         out_file = f'{args.output_root}/{os.path.basename(img_path)}'
 
     visualizer.add_datasample(
         'result',
         img,
-        data_sample=data_samples,
+        data_sample=results,
         draw_gt=False,
-        draw_heatmap=args.draw_heatmap,
         draw_bbox=False,
+        draw_heatmap=args.draw_heatmap,
+        show_kpt_idx=args.show_kpt_idx,
         show=args.show,
         wait_time=show_interval,
         out_file=out_file,
         kpt_score_thr=args.kpt_thr)
 
+    return results.pred_instances
 
-def main():
-    """Visualize the demo images.
 
-    Use `face_recognition` to detect the face.
-    """
+def parse_args():
     parser = ArgumentParser()
-    parser.add_argument('pose_config', help='Config file for pose')
-    parser.add_argument('pose_checkpoint', help='Checkpoint file for pose')
+    parser.add_argument('config', help='Config file')
+    parser.add_argument('checkpoint', help='Checkpoint file')
     parser.add_argument(
         '--input', type=str, default='', help='Image/Video file')
     parser.add_argument(
         '--show',
         action='store_true',
         default=False,
         help='whether to show img')
     parser.add_argument(
         '--output-root',
         type=str,
         default='',
         help='root of the output img file. '
         'Default not saving the visualization images.')
     parser.add_argument(
-        '--device', default='cuda:0', help='Device used for inference')
-    parser.add_argument(
-        '--nms-thr',
-        type=float,
-        default=0.3,
-        help='IoU threshold for bounding box NMS')
+        '--save-predictions',
+        action='store_true',
+        default=False,
+        help='whether to save predicted results')
     parser.add_argument(
-        '--kpt-thr', type=float, default=0.3, help='Keypoint score threshold')
+        '--device', default='cuda:0', help='Device used for inference')
     parser.add_argument(
         '--draw-heatmap',
         action='store_true',
+        help='Visualize the predicted heatmap')
+    parser.add_argument(
+        '--show-kpt-idx',
+        action='store_true',
         default=False,
-        help='Whether to draw output heatmap')
+        help='Whether to show the index of keypoints')
+    parser.add_argument(
+        '--kpt-thr', type=float, default=0.3, help='Keypoint score threshold')
     parser.add_argument(
         '--radius',
         type=int,
-        default=2,
+        default=3,
         help='Keypoint radius for visualization')
     parser.add_argument(
         '--thickness',
         type=int,
         default=1,
         help='Link thickness for visualization')
-
-    assert has_face_det, 'Please install face_recognition to run the demo. ' \
-                         '"pip install face_recognition", For more details, ' \
-                         'see https://github.com/ageitgey/face_recognition'
-
     args = parser.parse_args()
+    return args
+
 
+def main():
+    args = parse_args()
     assert args.show or (args.output_root != '')
     assert args.input != ''
     if args.output_root:
         mmengine.mkdir_or_exist(args.output_root)
+    if args.save_predictions:
+        assert args.output_root != ''
+        args.pred_save_path = f'{args.output_root}/results_' \
+            f'{os.path.splitext(os.path.basename(args.input))[0]}.json'
+
+    # build the model from a config file and a checkpoint file
+    if args.draw_heatmap:
+        cfg_options = dict(model=dict(test_cfg=dict(output_heatmaps=True)))
+    else:
+        cfg_options = None
 
-    # build pose estimator
-    register_mmpose_modules()
-    pose_estimator = init_pose_estimator(
-        args.pose_config,
-        args.pose_checkpoint,
+    model = init_model(
+        args.config,
+        args.checkpoint,
         device=args.device,
-        cfg_options=dict(
-            model=dict(test_cfg=dict(output_heatmaps=args.draw_heatmap))))
+        cfg_options=cfg_options)
 
     # init visualizer
-    pose_estimator.cfg.visualizer.radius = args.radius
-    pose_estimator.cfg.visualizer.line_width = args.thickness
-    visualizer = VISUALIZERS.build(pose_estimator.cfg.visualizer)
-    # the dataset_meta is loaded from the checkpoint and
-    # then pass to the model in init_pose_estimator
-    visualizer.set_dataset_meta(pose_estimator.dataset_meta)
-    visualizer.kpt_color = 'red'
+    model.cfg.visualizer.radius = args.radius
+    model.cfg.visualizer.line_width = args.thickness
+    visualizer = VISUALIZERS.build(model.cfg.visualizer)
+    visualizer.set_dataset_meta(model.dataset_meta)
 
     input_type = mimetypes.guess_type(args.input)[0].split('/')[0]
     if input_type == 'image':
-        visualize_img(
-            args, args.input, pose_estimator, visualizer, show_interval=0)
+        pred_instances = process_one_image(
+            args, args.input, model, visualizer, show_interval=0)
+        pred_instances_list = split_instances(pred_instances)
+
     elif input_type == 'video':
         tmp_folder = tempfile.TemporaryDirectory()
         video = mmcv.VideoReader(args.input)
         progressbar = mmengine.ProgressBar(len(video))
         video.cvt2frames(tmp_folder.name, show_progress=False)
         output_root = args.output_root
         args.output_root = tmp_folder.name
-        for img_fname in os.listdir(tmp_folder.name):
-            visualize_img(
+        pred_instances_list = []
+
+        for frame_id, img_fname in enumerate(os.listdir(tmp_folder.name)):
+            pred_instances = process_one_image(
                 args,
                 f'{tmp_folder.name}/{img_fname}',
-                pose_estimator,
+                model,
                 visualizer,
                 show_interval=1)
             progressbar.update()
+            pred_instances_list.append(
+                dict(
+                    frame_id=frame_id,
+                    instances=split_instances(pred_instances)))
+
         if output_root:
             mmcv.frames2video(
                 tmp_folder.name,
                 f'{output_root}/{os.path.basename(args.input)}',
                 fps=video.fps,
                 fourcc='mp4v',
                 show_progress=False)
         tmp_folder.cleanup()
+
     else:
+        args.save_predictions = False
         raise ValueError(
             f'file {os.path.basename(args.input)} has invalid format.')
 
+    if args.save_predictions:
+        with open(args.pred_save_path, 'w') as f:
+            json.dump(
+                dict(
+                    meta_info=model.dataset_meta,
+                    instance_info=pred_instances_list),
+                f,
+                indent='\t')
+        print(f'predictions have been saved at {args.pred_save_path}')
+
 
 if __name__ == '__main__':
     main()
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/webcam_cfg/pose_estimation.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/webcam_cfg/pose_estimation.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,31 +23,31 @@
             'ssdlite_mobilenetv2-scratch_8xb24-600e_coco.py',
             model_checkpoint='https://download.openmmlab.com'
             '/mmdetection/v2.0/ssd/'
             'ssdlite_mobilenetv2_scratch_600e_coco/ssdlite_mobilenetv2_'
             'scratch_600e_coco_20210629_110627-974d9307.pth',
             input_buffer='_input_',  # `_input_` is an executor-reserved buffer
             output_buffer='det_result'),
-        # 'TopDownPoseEstimatorNode':
+        # 'TopdownPoseEstimatorNode':
         # This node performs keypoint detection from the frame image using an
         # MMPose top-down model. Detection results is needed.
         dict(
-            type='TopDownPoseEstimatorNode',
+            type='TopdownPoseEstimatorNode',
             name='human pose estimator',
             model_config='configs/wholebody_2d_keypoint/'
             'topdown_heatmap/coco-wholebody/'
             'td-hm_vipnas-mbv3_dark-8xb64-210e_coco-wholebody-256x192.py',
             model_checkpoint='https://download.openmmlab.com/mmpose/'
             'top_down/vipnas/vipnas_mbv3_coco_wholebody_256x192_dark'
             '-e2158108_20211205.pth',
             labels=['person'],
             input_buffer='det_result',
             output_buffer='human_pose'),
         dict(
-            type='TopDownPoseEstimatorNode',
+            type='TopdownPoseEstimatorNode',
             name='animal pose estimator',
             model_config='configs/animal_2d_keypoint/topdown_heatmap/'
             'animalpose/td-hm_hrnet-w32_8xb64-210e_animalpose-256x256.py',
             model_checkpoint='https://download.openmmlab.com/mmpose/animal/'
             'hrnet/hrnet_w32_animalpose_256x256-1aa7f075_20210426.pth',
             labels=['cat', 'dog', 'horse', 'sheep', 'cow'],
             input_buffer='human_pose',
@@ -81,17 +81,17 @@
         dict(
             type='SunglassesEffectNode',
             name='sunglasses',
             enable_key='s',
             enable=False,
             input_buffer='vis',
             output_buffer='vis_sunglasses'),
-        # # 'BigeyeEffectNode':
-        # # This node draw the big-eye effetc in the frame image.
-        # # Pose results is needed.
+        # 'BigeyeEffectNode':
+        # This node draw the big-eye effetc in the frame image.
+        # Pose results is needed.
         dict(
             type='BigeyeEffectNode',
             name='big-eye',
             enable_key='b',
             enable=False,
             input_buffer='vis_sunglasses',
             output_buffer='vis_bigeye'),
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/webcam_cfg/test_camera.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/webcam_cfg/test_camera.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/demo/webcam_demo.py` & `mmpose-1.0.0rc1/mmpose/.mim/demo/webcam_demo.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/analysis_tools/analyze_logs.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/analysis_tools/analyze_logs.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/analysis_tools/get_flops.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/analysis_tools/get_flops.py`

 * *Files 6% similar despite different names*

```diff
@@ -2,15 +2,14 @@
 import argparse
 from functools import partial
 
 import torch
 from mmengine.config import DictAction
 
 from mmpose.apis.inference import init_model
-from mmpose.utils import register_all_modules as register_mmpose_modules
 
 try:
     from mmcv.cnn import get_model_complexity_info
 except ImportError:
     raise ImportError('Please upgrade mmcv to >0.6.2')
 
 
@@ -66,15 +65,14 @@
         device=next(flops_model.parameters()).device)
 
     batch['inputs'] = inputs
     return batch
 
 
 def main():
-    register_mmpose_modules()
 
     args = parse_args()
 
     if len(args.shape) == 1:
         input_shape = (3, args.shape[0], args.shape[0])
     elif len(args.shape) == 2:
         input_shape = (3, ) + tuple(args.shape)
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/analysis_tools/print_config.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/analysis_tools/print_config.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/h36m_to_coco.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/h36m_to_coco.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/mat2json.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/mat2json.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/parse_animalpose_dataset.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/parse_animalpose_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/parse_cofw_dataset.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/parse_cofw_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/parse_deepposekit_dataset.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/parse_deepposekit_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/parse_macaquepose_dataset.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/parse_macaquepose_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/preprocess_h36m.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/preprocess_h36m.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/dataset_converters/preprocess_mpi_inf_3dhp.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/dataset_converters/preprocess_mpi_inf_3dhp.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/deployment/mmpose2torchserve.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/torchserve/mmpose2torchserve.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/deployment/mmpose_handler.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/torchserve/mmpose_handler.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/deployment/test_torchserver.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/torchserve/test_torchserver.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/dist_test.sh` & `mmpose-1.0.0rc1/mmpose/.mim/tools/dist_test.sh`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/misc/browse_dataset.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/misc/browse_dataset.py`

 * *Files 5% similar despite different names*

```diff
@@ -3,20 +3,19 @@
 import os
 import os.path as osp
 
 import mmcv
 import mmengine
 import numpy as np
 from mmengine import Config, DictAction
-from mmengine.registry import build_from_cfg
+from mmengine.registry import build_from_cfg, init_default_scope
 from mmengine.structures import InstanceData
 
 from mmpose.registry import DATASETS, VISUALIZERS
 from mmpose.structures import PoseDataSample
-from mmpose.utils import register_all_modules
 
 
 def parse_args():
     parser = argparse.ArgumentParser(description='Browse a dataset')
     parser.add_argument('config', help='train config file path')
     parser.add_argument(
         '--output-dir',
@@ -80,15 +79,15 @@
     cfg = Config.fromfile(args.config)
     if args.cfg_options is not None:
         cfg.merge_from_dict(args.cfg_options)
     file_client_args = cfg.get('file_client_args', dict(backend='disk'))
     file_client = mmengine.FileClient(**file_client_args)
 
     # register all modules in mmpose into the registries
-    register_all_modules()
+    init_default_scope(cfg.get('default_scope', 'mmpose'))
 
     if args.mode == 'original':
         cfg[f'{args.phase}_dataloader'].dataset.pipeline = []
     else:
         # pack transformed keypoints for visualization
         cfg[f'{args.phase}_dataloader'].dataset.pipeline[
             -1].pack_transformed = True
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/misc/keypoints2coco_without_mmdet.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/misc/keypoints2coco_without_mmdet.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/slurm_test.sh` & `mmpose-1.0.0rc1/mmpose/.mim/tools/slurm_test.sh`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/slurm_train.sh` & `mmpose-1.0.0rc1/mmpose/.mim/tools/slurm_train.sh`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/test.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/test.py`

 * *Files 14% similar despite different names*

```diff
@@ -4,16 +4,14 @@
 import os.path as osp
 
 import mmengine
 from mmengine.config import Config, DictAction
 from mmengine.hooks import Hook
 from mmengine.runner import Runner
 
-from mmpose.utils import register_all_modules
-
 
 def parse_args():
     parser = argparse.ArgumentParser(
         description='MMPose test (and eval) model')
     parser.add_argument('config', help='test config file path')
     parser.add_argument('checkpoint', help='checkpoint file')
     parser.add_argument(
@@ -88,18 +86,14 @@
 
     return cfg
 
 
 def main():
     args = parse_args()
 
-    # register all modules in mmpose into the registries
-    # do not init the default scope here because it will be init in the runner
-    register_all_modules(init_default_scope=False)
-
     # load config
     cfg = Config.fromfile(args.config)
     cfg = merge_args(cfg, args)
     cfg.launcher = args.launcher
     if args.cfg_options is not None:
         cfg.merge_from_dict(args.cfg_options)
```

### Comparing `mmpose-1.0.0rc0/mmpose/.mim/tools/train.py` & `mmpose-1.0.0rc1/mmpose/.mim/tools/train.py`

 * *Files 7% similar despite different names*

```diff
@@ -2,16 +2,14 @@
 import argparse
 import os
 import os.path as osp
 
 from mmengine.config import Config, DictAction
 from mmengine.runner import Runner
 
-from mmpose.utils import register_all_modules
-
 
 def parse_args():
     parser = argparse.ArgumentParser(description='Train a pose model')
     parser.add_argument('config', help='train config file path')
     parser.add_argument('--work-dir', help='the dir to save logs and models')
     parser.add_argument(
         '--resume',
@@ -133,26 +131,24 @@
 
     return cfg
 
 
 def main():
     args = parse_args()
 
-    # register all modules in mmpose into the registries
-    # do not init the default scope here because it will be init in the runner
-    register_all_modules(init_default_scope=False)
-
     # load config
     cfg = Config.fromfile(args.config)
 
     # merge CLI arguments to config
     cfg = merge_args(cfg, args)
 
     # set preprocess configs to model
-    cfg.model.setdefault('data_preprocessor', cfg.get('preprocess_cfg', {}))
+    if 'preprocess_cfg' in cfg:
+        cfg.model.setdefault('data_preprocessor',
+                             cfg.get('preprocess_cfg', {}))
 
     # build the runner from config
     runner = Runner.from_cfg(cfg)
 
     # start training
     runner.train()
```

### Comparing `mmpose-1.0.0rc0/mmpose/__init__.py` & `mmpose-1.0.0rc1/mmpose/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 import mmcv
 import mmengine
 from mmengine.utils import digit_version
 
 from .version import __version__, short_version
 
-mmcv_minimum_version = '2.0.0rc0'
+mmcv_minimum_version = '2.0.0rc4'
 mmcv_maximum_version = '2.1.0'
 mmcv_version = digit_version(mmcv.__version__)
 
-mmengine_minimum_version = '0.1.0'
+mmengine_minimum_version = '0.6.0'
 mmengine_maximum_version = '1.0.0'
 mmengine_version = digit_version(mmengine.__version__)
 
 assert (mmcv_version >= digit_version(mmcv_minimum_version)
         and mmcv_version <= digit_version(mmcv_maximum_version)), \
     f'MMCV=={mmcv.__version__} is used but incompatible. ' \
     f'Please install mmcv>={mmcv_minimum_version}, <={mmcv_maximum_version}.'
```

### Comparing `mmpose-1.0.0rc0/mmpose/apis/inference.py` & `mmpose-1.0.0rc1/mmpose/apis/inference.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,22 +1,24 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 import warnings
 from pathlib import Path
-from typing import Optional, Union
+from typing import List, Optional, Union
 
 import numpy as np
 import torch
 import torch.nn as nn
 from mmengine.config import Config
-from mmengine.dataset import Compose
+from mmengine.dataset import Compose, pseudo_collate
+from mmengine.registry import init_default_scope
 from mmengine.runner import load_checkpoint
 from PIL import Image
 
 from mmpose.datasets.datasets.utils import parse_pose_metainfo
 from mmpose.models.builder import build_pose_estimator
+from mmpose.structures import PoseDataSample
 from mmpose.structures.bbox import bbox_xywh2xyxy
 
 
 def dataset_meta_from_config(config: Config,
                              dataset_mode: str = 'train') -> Optional[dict]:
     """Get dataset metainfo from the model config.
 
@@ -88,27 +90,30 @@
                         f'but got {type(config)}')
     if cfg_options is not None:
         config.merge_from_dict(cfg_options)
     elif 'init_cfg' in config.model.backbone:
         config.model.backbone.init_cfg = None
     config.model.train_cfg = None
 
+    # register all modules in mmpose into the registries
+    init_default_scope(config.get('default_scope', 'mmpose'))
+
     model = build_pose_estimator(config.model)
     # get dataset_meta in this priority: checkpoint > config > default (COCO)
     dataset_meta = None
 
     if checkpoint is not None:
         ckpt = load_checkpoint(model, checkpoint, map_location='cpu')
 
         if 'dataset_meta' in ckpt.get('meta', {}):
             # checkpoint from mmpose 1.x
             dataset_meta = ckpt['meta']['dataset_meta']
 
     if dataset_meta is None:
-        dataset_meta = dataset_meta_from_config(config, dataset_mode='test')
+        dataset_meta = dataset_meta_from_config(config, dataset_mode='train')
 
     if dataset_meta is None:
         warnings.simplefilter('once')
         warnings.warn('Can not load dataset_meta from the checkpoint or the '
                       'model config. Use COCO metainfo by default.')
         dataset_meta = parse_pose_metainfo(
             dict(from_file='configs/_base_/datasets/coco.py'))
@@ -119,66 +124,100 @@
     model.to(device)
     model.eval()
     return model
 
 
 def inference_topdown(model: nn.Module,
                       img: Union[np.ndarray, str],
-                      bboxes: Optional[np.ndarray] = None,
-                      bbox_format: str = 'xyxy'):
-    """Inference image with the top-down pose estimator.
+                      bboxes: Optional[Union[List, np.ndarray]] = None,
+                      bbox_format: str = 'xyxy') -> List[PoseDataSample]:
+    """Inference image with a top-down pose estimator.
 
     Args:
         model (nn.Module): The top-down pose estimator
         img (np.ndarray | str): The loaded image or image file to inference
         bboxes (np.ndarray, optional): The bboxes in shape (N, 4), each row
             represents a bbox. If not given, the entire image will be regarded
             as a single bbox area. Defaults to ``None``
         bbox_format (str): The bbox format indicator. Options are ``'xywh'``
             and ``'xyxy'``. Defaults to ``'xyxy'``
 
     Returns:
-        :obj:`PoseDataSample`: The inference results. Specifically, the
+        List[:obj:`PoseDataSample`]: The inference results. Specifically, the
         predicted keypoints and scores are saved at
-        ``data_samples.pred_instances.keypoints`` and
-        ``data_samples.pred_instances.keypoint_scores``.
+        ``data_sample.pred_instances.keypoints`` and
+        ``data_sample.pred_instances.keypoint_scores``.
     """
-    cfg = model.cfg
-    pipeline = Compose(cfg.test_dataloader.dataset.pipeline)
+    init_default_scope(model.cfg.get('default_scope', 'mmpose'))
+    pipeline = Compose(model.cfg.test_dataloader.dataset.pipeline)
 
     if bboxes is None:
         # get bbox from the image size
         if isinstance(img, str):
             w, h = Image.open(img).size
         else:
             h, w = img.shape[:2]
 
         bboxes = np.array([[0, 0, w, h]], dtype=np.float32)
     else:
+        if isinstance(bboxes, list):
+            bboxes = np.array(bboxes)
+
         assert bbox_format in {'xyxy', 'xywh'}, \
             f'Invalid bbox_format "{bbox_format}".'
 
         if bbox_format == 'xywh':
             bboxes = bbox_xywh2xyxy(bboxes)
 
     # construct batch data samples
-    data = []
+    data_list = []
     for bbox in bboxes:
-
         if isinstance(img, str):
-            _data = dict(img_path=img)
+            data_info = dict(img_path=img)
         else:
-            _data = dict(img=img)
+            data_info = dict(img=img)
+        data_info['bbox'] = bbox[None]  # shape (1, 4)
+        data_info['bbox_score'] = np.ones(1, dtype=np.float32)  # shape (1,)
+        data_info.update(model.dataset_meta)
+        data_list.append(pipeline(data_info))
+
+    if data_list:
+        # collate data list into a batch, which is a dict with following keys:
+        # batch['inputs']: a list of input images
+        # batch['data_samples']: a list of :obj:`PoseDataSample`
+        batch = pseudo_collate(data_list)
+        with torch.no_grad():
+            results = model.test_step(batch)
+    else:
+        results = []
+
+    return results
+
+
+def inference_bottomup(model: nn.Module, img: Union[np.ndarray, str]):
+    """Inference image with a bottom-up pose estimator.
 
-        _data['bbox'] = bbox[None]  # shape (1, 4)
-        _data['bbox_score'] = np.ones(1, dtype=np.float32)  # shape (1,)
-        _data.update(model.dataset_meta)
-        data.append(pipeline(_data))
-
-    data_ = dict()
-    data_['inputs'] = [_data['inputs'] for _data in data]
-    data_['data_samples'] = [_data['data_samples'] for _data in data]
+    Args:
+        model (nn.Module): The bottom-up pose estimator
+        img (np.ndarray | str): The loaded image or image file to inference
+
+    Returns:
+        List[:obj:`PoseDataSample`]: The inference results. Specifically, the
+        predicted keypoints and scores are saved at
+        ``data_sample.pred_instances.keypoints`` and
+        ``data_sample.pred_instances.keypoint_scores``.
+    """
+    pipeline = Compose(model.cfg.test_dataloader.dataset.pipeline)
+
+    # prepare data batch
+    if isinstance(img, str):
+        data_info = dict(img_path=img)
+    else:
+        data_info = dict(img=img)
+    data_info.update(model.dataset_meta)
+    data = pipeline(data_info)
+    batch = pseudo_collate([data])
 
     with torch.no_grad():
-        results = model.test_step(data_)
+        results = model.test_step(batch)
 
     return results
```

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/__init__.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from .base_visualizer_node import BaseVisualizerNode
 from .helper_nodes import MonitorNode, ObjectAssignerNode, RecorderNode
-from .model_nodes import DetectorNode, TopDownPoseEstimatorNode
+from .model_nodes import DetectorNode, TopdownPoseEstimatorNode
 from .node import Node
 from .registry import NODES
 from .visualizer_nodes import (BigeyeEffectNode, NoticeBoardNode,
                                ObjectVisualizerNode, SunglassesEffectNode)
 
 __all__ = [
     'BaseVisualizerNode', 'NODES', 'MonitorNode', 'ObjectAssignerNode',
-    'RecorderNode', 'DetectorNode', 'TopDownPoseEstimatorNode', 'Node',
+    'RecorderNode', 'DetectorNode', 'TopdownPoseEstimatorNode', 'Node',
     'BigeyeEffectNode', 'NoticeBoardNode', 'ObjectVisualizerNode',
     'ObjectAssignerNode', 'SunglassesEffectNode'
 ]
```

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/base_visualizer_node.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/base_visualizer_node.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/helper_nodes/monitor_node.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/helper_nodes/monitor_node.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/helper_nodes/object_assigner_node.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/helper_nodes/object_assigner_node.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/helper_nodes/recorder_node.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/helper_nodes/recorder_node.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/model_nodes/detector_node.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/model_nodes/detector_node.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from typing import Dict, List, Optional, Union
 
 import numpy as np
 
+from mmpose.utils import adapt_mmdet_pipeline
 from ...utils import get_config_path
 from ..node import Node
 from ..registry import NODES
 
 try:
     from mmdet.apis import inference_detector, init_detector
-    from mmdet.utils import register_all_modules
     has_mmdet = True
 except (ImportError, ModuleNotFoundError):
     has_mmdet = False
 
 
 @NODES.register_module()
 class DetectorNode(Node):
@@ -86,17 +86,17 @@
 
         self.model_config = get_config_path(model_config, 'mmdet')
         self.model_checkpoint = model_checkpoint
         self.device = device.lower()
         self.bbox_thr = bbox_thr
 
         # Init model
-        register_all_modules()
         self.model = init_detector(
             self.model_config, self.model_checkpoint, device=self.device)
+        self.model.cfg = adapt_mmdet_pipeline(self.model.cfg)
 
         # Register buffers
         self.register_input_buffer(input_buffer, 'input', trigger=True)
         self.register_output_buffer(output_buffer)
 
     def bypass(self, input_msgs):
         return input_msgs['input']
@@ -106,29 +106,28 @@
 
         if self.multi_input:
             imgs = [frame.get_image() for frame in input_msg]
             input_msg = input_msg[-1]
 
         img = input_msg.get_image()
 
-        register_all_modules()
         preds = inference_detector(self.model, img)
         objects = self._post_process(preds)
         input_msg.update_objects(objects)
 
         if self.multi_input:
             input_msg.set_image(np.stack(imgs, axis=0))
 
         return input_msg
 
     def _post_process(self, preds) -> List[Dict]:
         """Post-process the predictions of MMDetection model."""
         instances = preds.pred_instances.cpu().numpy()
 
-        classes = self.model.dataset_meta['CLASSES']
+        classes = self.model.dataset_meta['classes']
         if isinstance(classes, str):
             classes = (classes, )
 
         objects = []
         for i in range(len(instances)):
             if instances.scores[i] < self.bbox_thr:
                 continue
```

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/model_nodes/pose_estimator_node.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/model_nodes/pose_estimator_node.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,29 +1,28 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from dataclasses import dataclass
 from typing import List, Optional, Union
 
 import numpy as np
 
 from mmpose.apis import inference_topdown, init_model
-from mmpose.utils import register_all_modules
 from ...utils import get_config_path
 from ..node import Node
 from ..registry import NODES
 
 
 @dataclass
 class TrackInfo:
     """Dataclass for object tracking information."""
     next_id: int = 0
     last_objects: List = None
 
 
 @NODES.register_module()
-class TopDownPoseEstimatorNode(Node):
+class TopdownPoseEstimatorNode(Node):
     """Perform top-down pose estimation using MMPose model.
 
     The node should be placed after an object detection node.
 
     Parameters:
         name (str): The node name (also thread name)
         model_cfg (str): The model config file
@@ -47,15 +46,15 @@
         labels (list[str], optional): Specify the object category names to
             apply pose estimation. See also ``class_ids``. Default: ``None``
         bbox_thr (float): Set a threshold to filter out objects with low bbox
             scores. Default: 0.5
 
     Example::
         >>> cfg = dict(
-        ...     type='TopDownPoseEstimatorNode',
+        ...     type='TopdownPoseEstimatorNode',
         ...     name='human pose estimator',
         ...     model_config='configs/wholebody/2d_kpt_sview_rgb_img/'
         ...     'topdown_heatmap/coco-wholebody/'
         ...     'vipnas_mbv3_coco_wholebody_256x192_dark.py',
         ...     model_checkpoint='https://download.openmmlab.com/mmpose/'
         ...     'top_down/vipnas/vipnas_mbv3_coco_wholebody_256x192_dark'
         ...     '-e2158108_20211205.pth',
@@ -87,15 +86,14 @@
         self.device = device.lower()
 
         self.class_ids = class_ids
         self.labels = labels
         self.bbox_thr = bbox_thr
 
         # Init model
-        register_all_modules()
         self.model = init_model(
             self.model_config, self.model_checkpoint, device=self.device)
 
         # Register buffers
         self.register_input_buffer(input_buffer, 'input', trigger=True)
         self.register_output_buffer(output_buffer)
 
@@ -115,24 +113,23 @@
                 lambda x: x.get('label') in self.labels)
         else:
             objects = input_msg.get_objects()
 
         if len(objects) > 0:
             # Inference pose
             bboxes = np.stack([object['bbox'] for object in objects])
-            register_all_modules()
             pose_results = inference_topdown(self.model, img, bboxes)
 
             # Update objects
             for pose_result, object in zip(pose_results, objects):
                 pred_instances = pose_result.pred_instances
                 object['keypoints'] = pred_instances.keypoints[0]
                 object['keypoint_scores'] = pred_instances.keypoint_scores[0]
 
-                dataset_meta = object.get('dataset_meta', dict())
-                dataset_meta.update(self.model.dataset_meta)
+                dataset_meta = self.model.dataset_meta.copy()
+                dataset_meta.update(object.get('dataset_meta', dict()))
                 object['dataset_meta'] = dataset_meta
                 object['pose_model_cfg'] = self.model.cfg
 
         input_msg.update_objects(objects)
 
         return input_msg
```

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/node.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/node.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/visualizer_nodes/bigeye_effect_node.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/visualizer_nodes/bigeye_effect_node.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/visualizer_nodes/notice_board_node.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/visualizer_nodes/notice_board_node.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/visualizer_nodes/object_visualizer_node.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/visualizer_nodes/object_visualizer_node.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/nodes/visualizer_nodes/sunglasses_effect_node.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/nodes/visualizer_nodes/sunglasses_effect_node.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/utils/__init__.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/utils/buffer.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/utils/buffer.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/utils/event.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/utils/event.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/utils/image_capture.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/utils/image_capture.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/utils/message.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/utils/message.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/utils/misc.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/utils/misc.py`

 * *Files 1% similar despite different names*

```diff
@@ -78,46 +78,44 @@
         return image
     else:
         image = cv2.imread(filename, readFlag)
         return image
 
 
 def get_cached_file_path(url: str,
-                         save_dir: Optional[str] = None,
+                         save_dir: str,
                          progress: bool = True,
                          check_hash: bool = False,
                          file_name: Optional[str] = None) -> str:
     r"""Loads the Torch serialized object at the given URL.
 
     If downloaded file is a zip file, it will be automatically decompressed
 
     If the object is already present in `model_dir`, it's deserialized and
     returned.
     The default value of ``model_dir`` is ``<hub_dir>/checkpoints`` where
     ``hub_dir`` is the directory returned by :func:`~torch.hub.get_dir`.
 
     Args:
         url (str): URL of the object to download
-        save_dir (str, optional): directory in which to save the object
+        save_dir (str): directory in which to save the object
         progress (bool): whether or not to display a progress bar
             to stderr. Default: ``True``
         check_hash(bool): If True, the filename part of the URL
             should follow the naming convention ``filename-<sha256>.ext``
             where ``<sha256>`` is the first eight or more digits of the
             SHA256 hash of the contents of the file. The hash is used to
             ensure unique names and to verify the contents of the file.
             Default: ``False``
         file_name (str, optional): name for the downloaded file. Filename
             from ``url`` will be used if not set. Default: ``None``.
 
     Returns:
         str: The path to the cached file.
     """
-    if save_dir is None:
-        save_dir = os.path.join('webcam_resources')
 
     mkdir_or_exist(save_dir)
 
     parts = urlparse(url)
     filename = os.path.basename(parts.path)
     if file_name is not None:
         filename = file_name
```

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/utils/pose.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/utils/pose.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/apis/webcam/webcam_executor.py` & `mmpose-1.0.0rc1/mmpose/apis/webcam/webcam_executor.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/codecs/__init__.py` & `mmpose-1.0.0rc1/mmpose/codecs/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,13 +1,16 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from .associative_embedding import AssociativeEmbedding
+from .decoupled_heatmap import DecoupledHeatmap
 from .integral_regression_label import IntegralRegressionLabel
 from .megvii_heatmap import MegviiHeatmap
 from .msra_heatmap import MSRAHeatmap
 from .regression_label import RegressionLabel
 from .simcc_label import SimCCLabel
+from .spr import SPR
 from .udp_heatmap import UDPHeatmap
 
 __all__ = [
     'MSRAHeatmap', 'MegviiHeatmap', 'UDPHeatmap', 'RegressionLabel',
-    'SimCCLabel', 'IntegralRegressionLabel', 'AssociativeEmbedding'
+    'SimCCLabel', 'IntegralRegressionLabel', 'AssociativeEmbedding', 'SPR',
+    'DecoupledHeatmap'
 ]
```

### Comparing `mmpose-1.0.0rc0/mmpose/codecs/associative_embedding.py` & `mmpose-1.0.0rc1/mmpose/codecs/associative_embedding.py`

 * *Files 4% similar despite different names*

```diff
@@ -17,16 +17,16 @@
 
 
 def _group_keypoints_by_tags(vals: np.ndarray,
                              tags: np.ndarray,
                              locs: np.ndarray,
                              keypoint_order: List[int],
                              val_thr: float,
-                             tag_dist_thr: float = 1.0,
-                             max_groups: Optional[int] = None):
+                             tag_thr: float = 1.0,
+                             max_groups: Optional[int] = None) -> np.ndarray:
     """Group the keypoints by tags using Munkres algorithm.
 
     Note:
 
         - keypoint number: K
         - candidate number: M
         - tag dimenssion: L
@@ -40,26 +40,23 @@
             (K, M, L)
         locs (np.ndarray): The locations of the keypoint candidates in shape
             (K, M, D)
         keypoint_order (List[int]): The grouping order of the keypoints.
             The groupping usually starts from a keypoints around the head and
             torso, and gruadually moves out to the limbs
         val_thr (float): The threshold of the keypoint response value
-        tag_dist_thr (float): The maximum allowed tag distance when matching a
+        tag_thr (float): The maximum allowed tag distance when matching a
             keypoint to a group. A keypoint with larger tag distance to any
             of the existing groups will initializes a new group
         max_groups (int, optional): The maximum group number. ``None`` means
             no limitation. Defaults to ``None``
 
     Returns:
-        tuple:
-        - grouped_keypoints (np.ndarray): The grouped keypoints in shape
-            (G, K, D)
-        - grouped_keypoint_scores (np.ndarray): The grouped keypoint scores
-             in shape (G, K)
+        np.ndarray: grouped keypoints in shape (G, K, D+1), where the last
+        dimenssion is the concatenated keypoint coordinates and scores.
     """
     K, M, D = locs.shape
     assert vals.shape == tags.shape[:2] == (K, M)
     assert len(keypoint_order) == K
 
     # Build Munkres instance
     munkres = Munkres()
@@ -105,74 +102,90 @@
             # of the i-th keypoint
             # Shape: (M', 1, L) , (1, G, L) -> (M', G, L)
             diff = tags_i[:, None] - np.array(group_tags)[None]
             dists = np.linalg.norm(diff, ord=2, axis=2)
             num_kpts, num_groups = dists.shape[:2]
 
             # Experimental cost function for keypoint-group matching
-            costs = np.round(dists) * 100 - vals_i
+            costs = np.round(dists) * 100 - vals_i[..., None]
             if num_kpts > num_groups:
                 padding = np.full((num_kpts, num_kpts - num_groups),
                                   1e10,
                                   dtype=np.float32)
                 costs = np.concatenate((costs, padding), axis=1)
 
             # Match keypoints and groups by Munkres algorithm
             matches = munkres.compute(costs)
             for kpt_idx, group_idx in matches:
                 if group_idx < num_groups and dists[kpt_idx,
-                                                    group_idx] < tag_dist_thr:
+                                                    group_idx] < tag_thr:
                     # Add the keypoint to the matched group
                     group = groups[group_idx]
                 else:
                     # Initialize a new group with unmatched keypoint
                     group = _init_group()
                     groups.append(group)
 
                 group.kpts[i] = locs_i[kpt_idx]
                 group.scores[i] = vals_i[kpt_idx]
                 group.tag_list.append(tags_i[kpt_idx])
 
     groups = groups[:max_groups]
-    grouped_keypoints = np.stack((g.kpts for g in groups))  # (G, K, D)
-    grouped_keypoint_scores = np.stack((g.scores for g in groups))  # (G, K)
+    if groups:
+        grouped_keypoints = np.stack(
+            [np.r_['1', g.kpts, g.scores[:, None]] for g in groups])
+    else:
+        grouped_keypoints = np.empty((0, K, D + 1))
 
-    return grouped_keypoints, grouped_keypoint_scores
+    return grouped_keypoints
 
 
 @KEYPOINT_CODECS.register_module()
 class AssociativeEmbedding(BaseKeypointCodec):
     """Encode/decode keypoints with the method introduced in "Associative
     Embedding". This is an asymmetric codec, where the keypoints are
     represented as gaussian heatmaps and position indices during encoding, and
-    reostred from predicted heatmaps and group tags.
+    restored from predicted heatmaps and group tags.
 
     See the paper `Associative Embedding: End-to-End Learning for Joint
     Detection and Grouping`_ by Newell et al (2017) for details
 
     Note:
 
         - instance number: N
         - keypoint number: K
         - keypoint dimension: D
         - embedding tag dimension: L
         - image size: [w, h]
         - heatmap size: [W, H]
 
+    Encoded:
+
+        - heatmaps (np.ndarray): The generated heatmap in shape (K, H, W)
+            where [W, H] is the `heatmap_size`
+        - keypoint_indices (np.ndarray): The keypoint position indices in shape
+            (N, K, 2). Each keypoint's index is [i, v], where i is the position
+            index in the heatmap (:math:`i=y*w+x`) and v is the visibility
+        - keypoint_weights (np.ndarray): The target weights in shape (N, K)
+
     Args:
         input_size (tuple): Image size in [w, h]
         heatmap_size (tuple): Heatmap size in [W, H]
         sigma (float): The sigma value of the Gaussian heatmap
         use_udp (bool): Whether use unbiased data processing. See
             `UDP (CVPR 2020)`_ for details. Defaults to ``False``
         decode_keypoint_order (List[int]): The grouping order of the
             keypoint indices. The groupping usually starts from a keypoints
             around the head and torso, and gruadually moves out to the limbs
-        decode_thr (float): The threshold of keypoint response value in
-            heatmaps. Defaults to 0.1
+        decode_keypoint_thr (float): The threshold of keypoint response value
+            in heatmaps. Defaults to 0.1
+        decode_tag_thr (float): The maximum allowed tag distance when matching
+            a keypoint to a group. A keypoint with larger tag distance to any
+            of the existing groups will initializes a new group. Defaults to
+            1.0
         decode_nms_kernel (int): The kernel size of the NMS during decoding,
             which should be an odd integer. Defaults to 5
         decode_gaussian_kernel (int): The kernel size of the Gaussian blur
             during decoding, which should be an odd integer. It is only used
             when ``self.use_udp==True``. Defaults to 3
         decode_topk (int): The number top-k candidates of each keypoints that
             will be retrieved from the heatmaps during dedocding. Defaults to
@@ -182,115 +195,107 @@
             Defaults to ``None``
 
     .. _`Associative Embedding: End-to-End Learning for Joint Detection and
     Grouping`: https://arxiv.org/abs/1611.05424
     .. _`UDP (CVPR 2020)`: https://arxiv.org/abs/1911.07524
     """
 
-    def __init__(self,
-                 input_size: Tuple[int, int],
-                 heatmap_size: Tuple[int, int],
-                 sigma: Optional[float] = None,
-                 use_udp: bool = False,
-                 decode_keypoint_order: List[int] = [],
-                 decode_nms_kernel: int = 5,
-                 decode_gaussian_kernel: int = 3,
-                 decode_thr: float = 0.1,
-                 decode_topk: int = 20,
-                 decode_max_instances: Optional[int] = None,
-                 tag_per_keypoint: bool = True) -> None:
+    def __init__(
+        self,
+        input_size: Tuple[int, int],
+        heatmap_size: Tuple[int, int],
+        sigma: Optional[float] = None,
+        use_udp: bool = False,
+        decode_keypoint_order: List[int] = [],
+        decode_nms_kernel: int = 5,
+        decode_gaussian_kernel: int = 3,
+        decode_keypoint_thr: float = 0.1,
+        decode_tag_thr: float = 1.0,
+        decode_topk: int = 20,
+        decode_max_instances: Optional[int] = None,
+    ) -> None:
         super().__init__()
         self.input_size = input_size
         self.heatmap_size = heatmap_size
         self.use_udp = use_udp
         self.decode_nms_kernel = decode_nms_kernel
         self.decode_gaussian_kernel = decode_gaussian_kernel
-        self.decode_thr = decode_thr
+        self.decode_keypoint_thr = decode_keypoint_thr
+        self.decode_tag_thr = decode_tag_thr
         self.decode_topk = decode_topk
         self.decode_max_instances = decode_max_instances
-        self.tag_per_keypoint = tag_per_keypoint
         self.dedecode_keypoint_order = decode_keypoint_order.copy()
 
+        if self.use_udp:
+            self.scale_factor = ((np.array(input_size) - 1) /
+                                 (np.array(heatmap_size) - 1)).astype(
+                                     np.float32)
+        else:
+            self.scale_factor = (np.array(input_size) /
+                                 heatmap_size).astype(np.float32)
+
         if sigma is None:
             sigma = (heatmap_size[0] * heatmap_size[1])**0.5 / 64
         self.sigma = sigma
 
-    def _get_scale_factor(self, input_size: Tuple[int, int],
-                          heatmap_size: Tuple[int, int]) -> np.ndarray:
-        """Calculate scale factors from the input size and the heatmap size.
-
-        Args:
-            input_size (tuple): Image size in [w, h]
-            heatmap_size (tuple): Heatmap size in [W, H]
-
-        Returns:
-            np.ndarray: scale factors in [fx, fy] where :math:`fx=w/W` and
-            :math:`fy=h/H`.
-        """
-        if self.use_udp:
-            scale_factor = ((np.array(input_size) - 1) /
-                            (np.array(heatmap_size) - 1)).astype(np.float32)
-        else:
-            scale_factor = (np.array(input_size) /
-                            heatmap_size).astype(np.float32)
-        return scale_factor
-
     def encode(
         self,
         keypoints: np.ndarray,
         keypoints_visible: Optional[np.ndarray] = None
     ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
         """Encode keypoints into heatmaps and position indices. Note that the
         original keypoint coordinates should be in the input image space.
 
         Args:
             keypoints (np.ndarray): Keypoint coordinates in shape (N, K, D)
             keypoints_visible (np.ndarray): Keypoint visibilities in shape
                 (N, K)
 
         Returns:
-            tuple:
+            dict:
             - heatmaps (np.ndarray): The generated heatmap in shape
                 (K, H, W) where [W, H] is the `heatmap_size`
             - keypoint_indices (np.ndarray): The keypoint position indices
                 in shape (N, K, 2). Each keypoint's index is [i, v], where i
                 is the position index in the heatmap (:math:`i=y*w+x`) and v
                 is the visibility
             - keypoint_weights (np.ndarray): The target weights in shape
                 (N, K)
         """
 
-        scale_factor = self._get_scale_factor(self.input_size,
-                                              self.heatmap_size)
-
         if keypoints_visible is None:
             keypoints_visible = np.ones(keypoints.shape[:2], dtype=np.float32)
 
         # keypoint coordinates in heatmap
-        _keypoints = keypoints / scale_factor
+        _keypoints = keypoints / self.scale_factor
 
         if self.use_udp:
-            heatmaps, keypoints_weights = generate_udp_gaussian_heatmaps(
+            heatmaps, keypoint_weights = generate_udp_gaussian_heatmaps(
                 heatmap_size=self.heatmap_size,
                 keypoints=_keypoints,
                 keypoints_visible=keypoints_visible,
                 sigma=self.sigma)
         else:
-            heatmaps, keypoints_weights = generate_gaussian_heatmaps(
+            heatmaps, keypoint_weights = generate_gaussian_heatmaps(
                 heatmap_size=self.heatmap_size,
                 keypoints=_keypoints,
                 keypoints_visible=keypoints_visible,
                 sigma=self.sigma)
 
         keypoint_indices = self._encode_keypoint_indices(
             heatmap_size=self.heatmap_size,
             keypoints=_keypoints,
             keypoints_visible=keypoints_visible)
 
-        return heatmaps, keypoint_indices, keypoints_weights
+        encoded = dict(
+            heatmaps=heatmaps,
+            keypoint_indices=keypoint_indices,
+            keypoint_weights=keypoint_weights)
+
+        return encoded
 
     def _encode_keypoint_indices(self, heatmap_size: Tuple[int, int],
                                  keypoints: np.ndarray,
                                  keypoints_visible: np.ndarray) -> np.ndarray:
         w, h = heatmap_size
         N, K, _ = keypoints.shape
         keypoint_indices = np.zeros((N, K, 2), dtype=np.int64)
@@ -333,15 +338,15 @@
 
         # shape of topk_val, top_indices: (B, K, TopK)
         topk_vals, topk_indices = batch_heatmaps.flatten(-2, -1).topk(
             k, dim=-1)
 
         topk_tags_per_kpts = [
             torch.gather(_tag, dim=2, index=topk_indices)
-            for _tag in torch.unbind(batch_tags.view(B, K, L, H * W), dim=2)
+            for _tag in torch.unbind(batch_tags.view(B, L, K, H * W), dim=1)
         ]
 
         topk_tags = torch.stack(topk_tags_per_kpts, dim=-1)  # (B, K, TopK, L)
         topk_locs = torch.stack([topk_indices % W, topk_indices // W],
                                 dim=-1)  # (B, K, TopK, 2)
 
         return topk_vals, topk_tags, topk_locs
@@ -355,27 +360,29 @@
                 candidates in shape (B, K, Topk)
             batch_tags (Tensor): Tags of keypoint candidates in shape
                 (B, K, Topk, L)
             batch_locs (Tensor): Locations of keypoint candidates in shape
                 (B, K, Topk, 2)
 
         Returns:
-            List[Tuple[np.ndarray, np.ndarray]]: Grouping results of a batch,
-            eath element is a tuple of keypoints (in shape [N, K, D]) and
-            keypoint scores (in shape [N, K]) decoded from one image.
+            List[np.ndarray]: Grouping results of a batch, each element is a
+            np.ndarray (in shape [N, K, D+1]) that contains the groups
+            detected in an image, including both keypoint coordinates and
+            scores.
         """
 
         def _group_func(inputs: Tuple):
             vals, tags, locs = inputs
             return _group_keypoints_by_tags(
                 vals,
                 tags,
                 locs,
                 keypoint_order=self.dedecode_keypoint_order,
-                val_thr=self.decode_thr,
+                val_thr=self.decode_keypoint_thr,
+                tag_thr=self.decode_tag_thr,
                 max_groups=self.decode_max_instances)
 
         _results = map(_group_func, zip(batch_vals, batch_tags, batch_locs))
         results = list(_results)
         return results
 
     def _fill_missing_keypoints(self, keypoints: np.ndarray,
@@ -386,136 +393,120 @@
         Args:
             keypoints (np.ndarray): Keypoint predictions in shape (N, K, D)
             keypoint_scores (np.ndarray): Keypint score predictions in shape
                 (N, K), in which 0 means the corresponding keypoint is
                 missing in the initial prediction
             heatmaps (np.ndarry): Heatmaps in shape (K, H, W)
             tags (np.ndarray): Tagging heatmaps in shape (C, H, W) where
-                C=K*L
+                C=L*K
 
         Returns:
             tuple:
             - keypoints (np.ndarray): Keypoint predictions with missing
                 ones filled
             - keypoint_scores (np.ndarray): Keypoint score predictions with
                 missing ones filled
         """
 
         N, K = keypoints.shape[:2]
         H, W = heatmaps.shape[1:]
-        keypoint_tags = np.split(tags, K, axis=0)
+        L = tags.shape[0] // K
+        keypoint_tags = [tags[k::K] for k in range(K)]
 
         for n in range(N):
             # Calculate the instance tag (mean tag of detected keypoints)
             _tag = []
             for k in range(K):
                 if keypoint_scores[n, k] > 0:
                     x, y = keypoints[n, k, :2].astype(np.int64)
                     x = np.clip(x, 0, W - 1)
                     y = np.clip(y, 0, H - 1)
                     _tag.append(keypoint_tags[k][:, y, x])
-            tag = np.mean(_tag, axis=0)
 
+            tag = np.mean(_tag, axis=0)
+            tag = tag.reshape(L, 1, 1)
             # Search maximum response of the missing keypoints
             for k in range(K):
                 if keypoint_scores[n, k] > 0:
                     continue
-                dist_map = np.linalg.norm(keypoint_tags - tag, ord=2, axis=0)
+                dist_map = np.linalg.norm(
+                    keypoint_tags[k] - tag, ord=2, axis=0)
                 cost_map = np.round(dist_map) * 100 - heatmaps[k]  # H, W
                 y, x = np.unravel_index(np.argmin(cost_map), shape=(H, W))
                 keypoints[n, k] = [x, y]
                 keypoint_scores[n, k] = heatmaps[k, y, x]
 
         return keypoints, keypoint_scores
 
-    def batch_decode(
-        self,
-        batch_heatmaps: Tensor,
-        batch_tags: Tensor,
-        input_sizes: Optional[Tuple[int, int]] = None
-    ) -> Tuple[List[np.ndarray], List[np.ndarray]]:
+    def batch_decode(self, batch_heatmaps: Tensor, batch_tags: Tensor
+                     ) -> Tuple[List[np.ndarray], List[np.ndarray]]:
         """Decode the keypoint coordinates from a batch of heatmaps and tagging
         heatmaps. The decoded keypoint coordinates are in the input image
         space.
 
         Args:
             batch_heatmaps (Tensor): Keypoint detection heatmaps in shape
                 (B, K, H, W)
             batch_tags (Tensor): Tagging heatmaps in shape (B, C, H, W), where
-                :math:`C=L` if `tag_per_keypoint==False`, or
-                :math:`C=L*K` otherwise
-            input_sizes (List[Tuple[int, int]], optional): Manually set the
-                input size [w, h] of each sample for decoding. This is useful
-                when inference a model on images with arbitrary sizes. If not
-                given, the value `self.input_size` set at initialization will
-                be used for all samples. Defaults to ``None``
+                :math:`C=L*K`
 
         Returns:
             tuple:
             - batch_keypoints (List[np.ndarray]): Decoded keypoint coordinates
                 of the batch, each is in shape (N, K, D)
             - batch_scores (List[np.ndarray]): Decoded keypoint scores of the
                 batch, each is in shape (N, K). It usually represents the
                 confidience of the keypoint prediction
         """
-        B, K, H, W = batch_heatmaps.shape
+        B, _, H, W = batch_heatmaps.shape
         assert batch_tags.shape[0] == B and batch_tags.shape[2:4] == (H, W), (
-            f'Unmatched shapes of heatmap ({batch_heatmaps.shape}) and '
+            f'Mismatched shapes of heatmap ({batch_heatmaps.shape}) and '
             f'tagging map ({batch_tags.shape})')
 
-        if not self.tag_per_keypoint:
-            batch_tags = batch_tags.repeat((1, K, 1, 1))
-
         # Heatmap NMS
         batch_heatmaps = batch_heatmap_nms(batch_heatmaps,
                                            self.decode_nms_kernel)
 
         # Get top-k in each heatmap and and convert to numpy
         batch_topk_vals, batch_topk_tags, batch_topk_locs = to_numpy(
             self._get_batch_topk(
                 batch_heatmaps, batch_tags, k=self.decode_topk))
 
         # Group keypoint candidates into groups (instances)
         batch_groups = self._group_keypoints(batch_topk_vals, batch_topk_tags,
                                              batch_topk_locs)
 
-        batch_keypoints, batch_keypoint_scores = map(list, zip(*batch_groups))
-
         # Convert to numpy
         batch_heatmaps_np = to_numpy(batch_heatmaps)
         batch_tags_np = to_numpy(batch_tags)
 
         # Refine the keypoint prediction
-        for i, (keypoints, scores, heatmaps, tags) in enumerate(
-                zip(batch_keypoints, batch_keypoint_scores, batch_heatmaps_np,
-                    batch_tags_np)):
-
-            # identify missing keypoints
-            keypoints, scores = self._fill_missing_keypoints(
-                keypoints, scores, heatmaps, tags)
-
-            # refine keypoint coordinates according to heatmap distribution
-            if self.use_udp:
-                keypoints = refine_keypoints_dark_udp(
-                    keypoints,
-                    heatmaps,
-                    blur_kernel_size=self.decode_gaussian_kernel)
-            else:
-                keypoints = refine_keypoints(keypoints, heatmaps)
+        batch_keypoints = []
+        batch_keypoint_scores = []
+        for i, (groups, heatmaps, tags) in enumerate(
+                zip(batch_groups, batch_heatmaps_np, batch_tags_np)):
+
+            keypoints, scores = groups[..., :-1], groups[..., -1]
+
+            if keypoints.size > 0:
+                # identify missing keypoints
+                keypoints, scores = self._fill_missing_keypoints(
+                    keypoints, scores, heatmaps, tags)
+
+                # refine keypoint coordinates according to heatmap distribution
+                if self.use_udp:
+                    keypoints = refine_keypoints_dark_udp(
+                        keypoints,
+                        heatmaps,
+                        blur_kernel_size=self.decode_gaussian_kernel)
+                else:
+                    keypoints = refine_keypoints(keypoints, heatmaps)
 
-            batch_keypoints[i] = keypoints
-            batch_keypoint_scores[i] = scores
+            batch_keypoints.append(keypoints)
+            batch_keypoint_scores.append(scores)
 
         # restore keypoint scale
-        if input_sizes is None:
-            input_sizes = [self.input_size] * B
-        else:
-            assert len(input_sizes) == B
-
-        heatmap_size = (W, H)
-
         batch_keypoints = [
-            kpts * self._get_scale_factor(input_size, heatmap_size)
-            for kpts, input_size in zip(batch_keypoints, input_sizes)
+            kpts * self.scale_factor for kpts in batch_keypoints
         ]
 
         return batch_keypoints, batch_keypoint_scores
```

### Comparing `mmpose-1.0.0rc0/mmpose/codecs/base.py` & `mmpose-1.0.0rc1/mmpose/codecs/base.py`

 * *Files 7% similar despite different names*

```diff
@@ -10,30 +10,37 @@
     """The base class of the keypoint codec.
 
     A keypoint codec is a module to encode keypoint coordinates to specific
     representation (e.g. heatmap) and vice versa. A subclass should implement
     the methods :meth:`encode` and :meth:`decode`.
     """
 
+    # pass additional encoding arguments to the `encode` method, beyond the
+    # mandatory `keypoints` and `keypoints_visible` arguments.
+    auxiliary_encode_keys = set()
+
     @abstractmethod
     def encode(self,
                keypoints: np.ndarray,
-               keypoints_visible: Optional[np.ndarray] = None) -> Any:
+               keypoints_visible: Optional[np.ndarray] = None) -> dict:
         """Encode keypoints.
 
         Note:
 
             - instance number: N
             - keypoint number: K
             - keypoint dimension: D
 
         Args:
             keypoints (np.ndarray): Keypoint coordinates in shape (N, K, D)
             keypoints_visible (np.ndarray): Keypoint visibility in shape
                 (N, K, D)
+
+        Returns:
+            dict: Encoded items.
         """
 
     @abstractmethod
     def decode(self, encoded: Any) -> Tuple[np.ndarray, np.ndarray]:
         """Decode keypoints.
 
         Args:
```

### Comparing `mmpose-1.0.0rc0/mmpose/codecs/integral_regression_label.py` & `mmpose-1.0.0rc1/mmpose/codecs/integral_regression_label.py`

 * *Files 13% similar despite different names*

```diff
@@ -13,15 +13,26 @@
 @KEYPOINT_CODECS.register_module()
 class IntegralRegressionLabel(BaseKeypointCodec):
     """Generate keypoint coordinates and normalized heatmaps. See the paper:
     `DSNT`_ by Nibali et al(2018).
 
     Note:
 
-        - input image size: [w, h]
+        - instance number: N
+        - keypoint number: K
+        - keypoint dimension: D
+        - image size: [w, h]
+
+    Encoded:
+
+        - keypoint_labels (np.ndarray): The normalized regression labels in
+            shape (N, K, D) where D is 2 for 2d coordinates
+        - heatmaps (np.ndarray): The generated heatmap in shape (K, H, W) where
+            [W, H] is the `heatmap_size`
+        - keypoint_weights (np.ndarray): The target weights in shape (N, K)
 
     Args:
         input_size (tuple): Input image size in [w, h]
         heatmap_size (tuple): Heatmap size in [W, H]
         sigma (float): The sigma value of the Gaussian heatmap
         unbiased (bool): Whether use unbiased method (DarkPose) in ``'msra'``
             encoding. See `Dark Pose`_ for details. Defaults to ``False``
@@ -44,45 +55,50 @@
         super().__init__()
 
         self.heatmap_codec = MSRAHeatmap(input_size, heatmap_size, sigma,
                                          unbiased, blur_kernel_size)
         self.keypoint_codec = RegressionLabel(input_size)
         self.normalize = normalize
 
-    def encode(
-        self,
-        keypoints: np.ndarray,
-        keypoints_visible: Optional[np.ndarray] = None
-    ) -> Tuple[np.ndarray, np.ndarray]:
+    def encode(self,
+               keypoints: np.ndarray,
+               keypoints_visible: Optional[np.ndarray] = None) -> dict:
         """Encoding keypoints to regression labels and heatmaps.
 
         Args:
             keypoints (np.ndarray): Keypoint coordinates in shape (N, K, D)
             keypoints_visible (np.ndarray): Keypoint visibilities in shape
                 (N, K)
 
         Returns:
-            tuple:
-            - reg_labels (np.ndarray): The normalized regression labels in
+            dict:
+            - keypoint_labels (np.ndarray): The normalized regression labels in
                 shape (N, K, D) where D is 2 for 2d coordinates
             - heatmaps (np.ndarray): The generated heatmap in shape
                 (K, H, W) where [W, H] is the `heatmap_size`
             - keypoint_weights (np.ndarray): The target weights in shape
                 (N, K)
         """
-        heatmaps, keypoint_weights = self.heatmap_codec.encode(
-            keypoints, keypoints_visible)
-        reg_labels, keypoint_weights = self.keypoint_codec.encode(
-            keypoints, keypoint_weights)
+        encoded_hm = self.heatmap_codec.encode(keypoints, keypoints_visible)
+        encoded_kp = self.keypoint_codec.encode(keypoints, keypoints_visible)
+
+        heatmaps = encoded_hm['heatmaps']
+        keypoint_labels = encoded_kp['keypoint_labels']
+        keypoint_weights = encoded_kp['keypoint_weights']
 
         if self.normalize:
             val_sum = heatmaps.sum(axis=(-1, -2)).reshape(-1, 1, 1) + 1e-24
             heatmaps = heatmaps / val_sum
 
-        return heatmaps, reg_labels, keypoint_weights
+        encoded = dict(
+            keypoint_labels=keypoint_labels,
+            heatmaps=heatmaps,
+            keypoint_weights=keypoint_weights)
+
+        return encoded
 
     def decode(self, encoded: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
         """Decode keypoint coordinates from normalized space to input image
         space.
 
         Args:
             encoded (np.ndarray): Coordinates in shape (N, K, D)
```

### Comparing `mmpose-1.0.0rc0/mmpose/codecs/megvii_heatmap.py` & `mmpose-1.0.0rc1/mmpose/codecs/megvii_heatmap.py`

 * *Files 12% similar despite different names*

```diff
@@ -19,14 +19,20 @@
 
         - instance number: N
         - keypoint number: K
         - keypoint dimension: D
         - image size: [w, h]
         - heatmap size: [W, H]
 
+    Encoded:
+
+        - heatmaps (np.ndarray): The generated heatmap in shape (K, H, W)
+            where [W, H] is the `heatmap_size`
+        - keypoint_weights (np.ndarray): The target weights in shape (N, K)
+
     Args:
         input_size (tuple): Image size in [w, h]
         heatmap_size (tuple): Heatmap size in [W, H]
         kernel_size (tuple): The kernel size of the heatmap gaussian in
             [ks_x, ks_y]
 
     .. _`MSPN`: https://arxiv.org/abs/1901.00148
@@ -43,29 +49,27 @@
         super().__init__()
         self.input_size = input_size
         self.heatmap_size = heatmap_size
         self.kernel_size = kernel_size
         self.scale_factor = (np.array(input_size) /
                              heatmap_size).astype(np.float32)
 
-    def encode(
-        self,
-        keypoints: np.ndarray,
-        keypoints_visible: Optional[np.ndarray] = None
-    ) -> Tuple[np.ndarray, np.ndarray]:
+    def encode(self,
+               keypoints: np.ndarray,
+               keypoints_visible: Optional[np.ndarray] = None) -> dict:
         """Encode keypoints into heatmaps. Note that the original keypoint
         coordinates should be in the input image space.
 
         Args:
             keypoints (np.ndarray): Keypoint coordinates in shape (N, K, D)
             keypoints_visible (np.ndarray): Keypoint visibilities in shape
                 (N, K)
 
         Returns:
-            tuple:
+            dict:
             - heatmaps (np.ndarray): The generated heatmap in shape
                 (K, H, W) where [W, H] is the `heatmap_size`
             - keypoint_weights (np.ndarray): The target weights in shape
                 (N, K)
         """
 
         N, K, _ = keypoints.shape
@@ -92,15 +96,17 @@
             heatmaps[k, ky, kx] = 1.
             kernel_size = (self.kernel_size, self.kernel_size)
             heatmaps[k] = cv2.GaussianBlur(heatmaps[k], kernel_size, 0)
 
             # normalize the heatmap
             heatmaps[k] = heatmaps[k] / heatmaps[k, ky, kx] * 255.
 
-        return heatmaps, keypoint_weights
+        encoded = dict(heatmaps=heatmaps, keypoint_weights=keypoint_weights)
+
+        return encoded
 
     def decode(self, encoded: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
         """Decode keypoint coordinates from heatmaps. The decoded keypoint
         coordinates are in the input image space.
 
         Args:
             encoded (np.ndarray): Heatmaps in shape (K, H, W)
```

### Comparing `mmpose-1.0.0rc0/mmpose/codecs/msra_heatmap.py` & `mmpose-1.0.0rc1/mmpose/codecs/msra_heatmap.py`

 * *Files 9% similar despite different names*

```diff
@@ -21,14 +21,20 @@
 
         - instance number: N
         - keypoint number: K
         - keypoint dimension: D
         - image size: [w, h]
         - heatmap size: [W, H]
 
+    Encoded:
+
+        - heatmaps (np.ndarray): The generated heatmap in shape (K, H, W)
+            where [W, H] is the `heatmap_size`
+        - keypoint_weights (np.ndarray): The target weights in shape (N, K)
+
     Args:
         input_size (tuple): Image size in [w, h]
         heatmap_size (tuple): Heatmap size in [W, H]
         sigma (float): The sigma value of the Gaussian heatmap
         unbiased (bool): Whether use unbiased method (DarkPose) in ``'msra'``
             encoding. See `Dark Pose`_ for details. Defaults to ``False``
         blur_kernel_size (int): The Gaussian blur kernel size of the heatmap
@@ -61,29 +67,27 @@
         #   sigma=2 if ks=11;
         #   sigma~=1.5 if ks=7;
         #   sigma~=1 if ks=3;
         self.blur_kernel_size = blur_kernel_size
         self.scale_factor = (np.array(input_size) /
                              heatmap_size).astype(np.float32)
 
-    def encode(
-        self,
-        keypoints: np.ndarray,
-        keypoints_visible: Optional[np.ndarray] = None
-    ) -> Tuple[np.ndarray, np.ndarray]:
+    def encode(self,
+               keypoints: np.ndarray,
+               keypoints_visible: Optional[np.ndarray] = None) -> dict:
         """Encode keypoints into heatmaps. Note that the original keypoint
         coordinates should be in the input image space.
 
         Args:
             keypoints (np.ndarray): Keypoint coordinates in shape (N, K, D)
             keypoints_visible (np.ndarray): Keypoint visibilities in shape
                 (N, K)
 
         Returns:
-            tuple:
+            dict:
             - heatmaps (np.ndarray): The generated heatmap in shape
                 (K, H, W) where [W, H] is the `heatmap_size`
             - keypoint_weights (np.ndarray): The target weights in shape
                 (N, K)
         """
 
         assert keypoints.shape[0] == 1, (
@@ -102,15 +106,17 @@
         else:
             heatmaps, keypoint_weights = generate_gaussian_heatmaps(
                 heatmap_size=self.heatmap_size,
                 keypoints=keypoints / self.scale_factor,
                 keypoints_visible=keypoints_visible,
                 sigma=self.sigma)
 
-        return heatmaps, keypoint_weights
+        encoded = dict(heatmaps=heatmaps, keypoint_weights=keypoint_weights)
+
+        return encoded
 
     def decode(self, encoded: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
         """Decode keypoint coordinates from heatmaps. The decoded keypoint
         coordinates are in the input image space.
 
         Args:
             encoded (np.ndarray): Heatmaps in shape (K, H, W)
```

### Comparing `mmpose-1.0.0rc0/mmpose/codecs/regression_label.py` & `mmpose-1.0.0rc1/mmpose/codecs/regression_label.py`

 * *Files 19% similar despite different names*

```diff
@@ -10,57 +10,67 @@
 
 @KEYPOINT_CODECS.register_module()
 class RegressionLabel(BaseKeypointCodec):
     r"""Generate keypoint coordinates.
 
     Note:
 
-        - input image size: [w, h]
+        - instance number: N
+        - keypoint number: K
+        - keypoint dimension: D
+        - image size: [w, h]
+
+    Encoded:
+
+        - keypoint_labels (np.ndarray): The normalized regression labels in
+            shape (N, K, D) where D is 2 for 2d coordinates
+        - keypoint_weights (np.ndarray): The target weights in shape (N, K)
 
     Args:
         input_size (tuple): Input image size in [w, h]
 
     """
 
     def __init__(self, input_size: Tuple[int, int]) -> None:
         super().__init__()
 
         self.input_size = input_size
 
-    def encode(
-        self,
-        keypoints: np.ndarray,
-        keypoints_visible: Optional[np.ndarray] = None
-    ) -> Tuple[np.ndarray, np.ndarray]:
+    def encode(self,
+               keypoints: np.ndarray,
+               keypoints_visible: Optional[np.ndarray] = None) -> dict:
         """Encoding keypoints from input image space to normalized space.
 
         Args:
             keypoints (np.ndarray): Keypoint coordinates in shape (N, K, D)
             keypoints_visible (np.ndarray): Keypoint visibilities in shape
                 (N, K)
 
         Returns:
-            tuple:
-            - reg_labels (np.ndarray): The normalized regression labels in
+            dict:
+            - keypoint_labels (np.ndarray): The normalized regression labels in
                 shape (N, K, D) where D is 2 for 2d coordinates
             - keypoint_weights (np.ndarray): The target weights in shape
                 (N, K)
         """
         if keypoints_visible is None:
             keypoints_visible = np.ones(keypoints.shape[:2], dtype=np.float32)
 
         w, h = self.input_size
         valid = ((keypoints >= 0) &
                  (keypoints <= [w - 1, h - 1])).all(axis=-1) & (
                      keypoints_visible > 0.5)
 
-        reg_labels = (keypoints / np.array([w, h])).astype(np.float32)
+        keypoint_labels = (keypoints / np.array([w, h])).astype(np.float32)
         keypoint_weights = np.where(valid, 1., 0.).astype(np.float32)
 
-        return reg_labels, keypoint_weights
+        encoded = dict(
+            keypoint_labels=keypoint_labels, keypoint_weights=keypoint_weights)
+
+        return encoded
 
     def decode(self, encoded: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
         """Decode keypoint coordinates from normalized space to input image
         space.
 
         Args:
             encoded (np.ndarray): Coordinates in shape (N, K, D)
```

### Comparing `mmpose-1.0.0rc0/mmpose/codecs/simcc_label.py` & `mmpose-1.0.0rc1/mmpose/codecs/simcc_label.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,141 +1,181 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from itertools import product
 from typing import Optional, Tuple, Union
 
 import numpy as np
 
 from mmpose.codecs.utils import get_simcc_maximum
+from mmpose.codecs.utils.refinement import refine_simcc_dark
 from mmpose.registry import KEYPOINT_CODECS
 from .base import BaseKeypointCodec
 
 
 @KEYPOINT_CODECS.register_module()
 class SimCCLabel(BaseKeypointCodec):
     r"""Generate keypoint representation via "SimCC" approach.
     See the paper: `SimCC: a Simple Coordinate Classification Perspective for
     Human Pose Estimation`_ by Li et al (2022) for more details.
     Old name: SimDR
 
     Note:
 
-        - input image size: [w, h]
+        - instance number: N
+        - keypoint number: K
+        - keypoint dimension: D
+        - image size: [w, h]
+
+    Encoded:
+
+        - keypoint_x_labels (np.ndarray): The generated SimCC label for x-axis.
+            The label shape is (N, K, Wx) if ``smoothing_type=='gaussian'``
+            and (N, K) if `smoothing_type=='standard'``, where
+            :math:`Wx=w*simcc_split_ratio`
+        - keypoint_y_labels (np.ndarray): The generated SimCC label for y-axis.
+            The label shape is (N, K, Wy) if ``smoothing_type=='gaussian'``
+            and (N, K) if `smoothing_type=='standard'``, where
+            :math:`Wy=h*simcc_split_ratio`
+        - keypoint_weights (np.ndarray): The target weights in shape (N, K)
 
     Args:
         input_size (tuple): Input image size in [w, h]
         smoothing_type (str): The SimCC label smoothing strategy. Options are
-        ``'gaussian'`` and ``'standard'``. Defaults to ``'gaussian'``
-        sigma (str): The sigma value in the Gaussian SimCC label. Defaults to
-            6.0
+            ``'gaussian'`` and ``'standard'``. Defaults to ``'gaussian'``
+        sigma (float | int | tuple): The sigma value in the Gaussian SimCC
+            label. Defaults to 6.0
         simcc_split_ratio (float): The ratio of the label size to the input
             size. For example, if the input width is ``w``, the x label size
             will be :math:`w*simcc_split_ratio`. Defaults to 2.0
         label_smooth_weight (float): Label Smoothing weight. Defaults to 0.0
         normalize (bool): Whether to normalize the heatmaps. Defaults to True.
 
     .. _`SimCC: a Simple Coordinate Classification Perspective for Human Pose
     Estimation`: https://arxiv.org/abs/2107.03332
     """
 
     def __init__(self,
                  input_size: Tuple[int, int],
                  smoothing_type: str = 'gaussian',
-                 sigma: float = 6.0,
+                 sigma: Union[float, int, Tuple[float]] = 6.0,
                  simcc_split_ratio: float = 2.0,
                  label_smooth_weight: float = 0.0,
-                 normalize: bool = True) -> None:
+                 normalize: bool = True,
+                 use_dark: bool = False) -> None:
         super().__init__()
 
         self.input_size = input_size
         self.smoothing_type = smoothing_type
-        self.sigma = sigma
         self.simcc_split_ratio = simcc_split_ratio
         self.label_smooth_weight = label_smooth_weight
         self.normalize = normalize
+        self.use_dark = use_dark
+
+        if isinstance(sigma, (float, int)):
+            self.sigma = np.array([sigma, sigma])
+        else:
+            self.sigma = np.array(sigma)
 
         if self.smoothing_type not in {'gaussian', 'standard'}:
             raise ValueError(
                 f'{self.__class__.__name__} got invalid `smoothing_type` value'
                 f'{self.smoothing_type}. Should be one of '
                 '{"gaussian", "standard"}')
 
         if self.smoothing_type == 'gaussian' and self.label_smooth_weight > 0:
             raise ValueError('Attribute `label_smooth_weight` is only '
                              'used for `standard` mode.')
 
         if self.label_smooth_weight < 0.0 or self.label_smooth_weight > 1.0:
             raise ValueError('`label_smooth_weight` should be in range [0, 1]')
 
-    def encode(
-        self,
-        keypoints: np.ndarray,
-        keypoints_visible: Optional[np.ndarray] = None
-    ) -> Union[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray,
-                                                    np.ndarray]]:
+    def encode(self,
+               keypoints: np.ndarray,
+               keypoints_visible: Optional[np.ndarray] = None) -> dict:
         """Encoding keypoints into SimCC labels. Note that the original
         keypoint coordinates should be in the input image space.
 
         Args:
             keypoints (np.ndarray): Keypoint coordinates in shape (N, K, D)
             keypoints_visible (np.ndarray): Keypoint visibilities in shape
                 (N, K)
 
         Returns:
-            tuple:
-            - simcc_x (np.ndarray): The generated SimCC label for x-axis.
+            dict:
+            - keypoint_x_labels (np.ndarray): The generated SimCC label for
+                x-axis.
                 The label shape is (N, K, Wx) if ``smoothing_type=='gaussian'``
                 and (N, K) if `smoothing_type=='standard'``, where
                 :math:`Wx=w*simcc_split_ratio`
-            - simcc_y (np.ndarray): The generated SimCC label for y-axis.
+            - keypoint_y_labels (np.ndarray): The generated SimCC label for
+                y-axis.
                 The label shape is (N, K, Wy) if ``smoothing_type=='gaussian'``
                 and (N, K) if `smoothing_type=='standard'``, where
                 :math:`Wy=h*simcc_split_ratio`
             - keypoint_weights (np.ndarray): The target weights in shape
                 (N, K)
         """
         if keypoints_visible is None:
             keypoints_visible = np.ones(keypoints.shape[:2], dtype=np.float32)
 
         if self.smoothing_type == 'gaussian':
-            return self._generate_gaussian(keypoints, keypoints_visible)
+            x_labels, y_labels, keypoint_weights = self._generate_gaussian(
+                keypoints, keypoints_visible)
         elif self.smoothing_type == 'standard':
-            return self._generate_standard(keypoints, keypoints_visible)
+            x_labels, y_labels, keypoint_weights = self._generate_standard(
+                keypoints, keypoints_visible)
         else:
             raise ValueError(
                 f'{self.__class__.__name__} got invalid `smoothing_type` value'
                 f'{self.smoothing_type}. Should be one of '
                 '{"gaussian", "standard"}')
 
-    def decode(self,
-               encoded: Tuple[np.ndarray,
-                              np.ndarray]) -> Tuple[np.ndarray, np.ndarray]:
+        encoded = dict(
+            keypoint_x_labels=x_labels,
+            keypoint_y_labels=y_labels,
+            keypoint_weights=keypoint_weights)
+
+        return encoded
+
+    def decode(self, simcc_x: np.ndarray,
+               simcc_y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
         """Decode keypoint coordinates from SimCC representations. The decoded
         coordinates are in the input image space.
 
         Args:
             encoded (Tuple[np.ndarray, np.ndarray]): SimCC labels for x-axis
                 and y-axis
+            simcc_x (np.ndarray): SimCC label for x-axis
+            simcc_y (np.ndarray): SimCC label for y-axis
 
         Returns:
             tuple:
             - keypoints (np.ndarray): Decoded coordinates in shape (N, K, D)
             - socres (np.ndarray): The keypoint scores in shape (N, K).
                 It usually represents the confidence of the keypoint prediction
         """
 
-        simcc_x, simcc_y = encoded
         keypoints, scores = get_simcc_maximum(simcc_x, simcc_y)
 
-        keypoints /= self.simcc_split_ratio
-
         # Unsqueeze the instance dimension for single-instance results
-        if len(keypoints) == 2:
+        if keypoints.ndim == 2:
             keypoints = keypoints[None, :]
             scores = scores[None, :]
 
+        if self.use_dark:
+            x_blur = int((self.sigma[0] * 20 - 7) // 3)
+            y_blur = int((self.sigma[1] * 20 - 7) // 3)
+            x_blur -= int((x_blur % 2) == 0)
+            y_blur -= int((y_blur % 2) == 0)
+            keypoints[:, :, 0] = refine_simcc_dark(keypoints[:, :, 0], simcc_x,
+                                                   x_blur)
+            keypoints[:, :, 1] = refine_simcc_dark(keypoints[:, :, 1], simcc_y,
+                                                   y_blur)
+
+        keypoints /= self.simcc_split_ratio
+
         return keypoints, scores
 
     def _map_coordinates(
         self,
         keypoints: np.ndarray,
         keypoints_visible: Optional[np.ndarray] = None
     ) -> Tuple[np.ndarray, np.ndarray]:
@@ -231,16 +271,16 @@
 
             if left >= W or top >= H or right < 0 or bottom < 0:
                 keypoint_weights[n, k] = 0
                 continue
 
             mu_x, mu_y = mu
 
-            target_x[n, k] = np.exp(-((x - mu_x)**2) / (2 * self.sigma**2))
-            target_y[n, k] = np.exp(-((y - mu_y)**2) / (2 * self.sigma**2))
+            target_x[n, k] = np.exp(-((x - mu_x)**2) / (2 * self.sigma[0]**2))
+            target_y[n, k] = np.exp(-((y - mu_y)**2) / (2 * self.sigma[1]**2))
 
         if self.normalize:
             norm_value = self.sigma * np.sqrt(np.pi * 2)
-            target_x /= norm_value
-            target_y /= norm_value
+            target_x /= norm_value[0]
+            target_y /= norm_value[1]
 
         return target_x, target_y, keypoint_weights
```

### Comparing `mmpose-1.0.0rc0/mmpose/codecs/udp_heatmap.py` & `mmpose-1.0.0rc1/mmpose/codecs/udp_heatmap.py`

 * *Files 4% similar despite different names*

```diff
@@ -20,14 +20,24 @@
 
         - instance number: N
         - keypoint number: K
         - keypoint dimension: D
         - image size: [w, h]
         - heatmap size: [W, H]
 
+    Encoded:
+
+        - heatmap (np.ndarray): The generated heatmap in shape (C_out, H, W)
+            where [W, H] is the `heatmap_size`, and the C_out is the output
+            channel number which depends on the `heatmap_type`. If
+            `heatmap_type=='gaussian'`, C_out equals to keypoint number K;
+            if `heatmap_type=='combined'`, C_out equals to K*3
+            (x_offset, y_offset and class label)
+        - keypoint_weights (np.ndarray): The target weights in shape (K,)
+
     Args:
         input_size (tuple): Image size in [w, h]
         heatmap_size (tuple): Heatmap size in [W, H]
         heatmap_type (str): The heatmap type to encode the keypoitns. Options
             are:
 
             - ``'gaussian'``: Gaussian heatmap
@@ -66,29 +76,27 @@
 
         if self.heatmap_type not in {'gaussian', 'combined'}:
             raise ValueError(
                 f'{self.__class__.__name__} got invalid `heatmap_type` value'
                 f'{self.heatmap_type}. Should be one of '
                 '{"gaussian", "combined"}')
 
-    def encode(
-        self,
-        keypoints: np.ndarray,
-        keypoints_visible: Optional[np.ndarray] = None
-    ) -> Tuple[np.ndarray, np.ndarray]:
+    def encode(self,
+               keypoints: np.ndarray,
+               keypoints_visible: Optional[np.ndarray] = None) -> dict:
         """Encode keypoints into heatmaps. Note that the original keypoint
         coordinates should be in the input image space.
 
         Args:
             keypoints (np.ndarray): Keypoint coordinates in shape (N, K, D)
             keypoints_visible (np.ndarray): Keypoint visibilities in shape
                 (N, K)
 
         Returns:
-            tuple:
+            dict:
             - heatmap (np.ndarray): The generated heatmap in shape
                 (C_out, H, W) where [W, H] is the `heatmap_size`, and the
                 C_out is the output channel number which depends on the
                 `heatmap_type`. If `heatmap_type=='gaussian'`, C_out equals to
                 keypoint number K; if `heatmap_type=='combined'`, C_out
                 equals to K*3 (x_offset, y_offset and class label)
             - keypoint_weights (np.ndarray): The target weights in shape
@@ -115,15 +123,17 @@
                 radius_factor=self.radius_factor)
         else:
             raise ValueError(
                 f'{self.__class__.__name__} got invalid `heatmap_type` value'
                 f'{self.heatmap_type}. Should be one of '
                 '{"gaussian", "combined"}')
 
-        return heatmaps, keypoint_weights
+        encoded = dict(heatmaps=heatmaps, keypoint_weights=keypoint_weights)
+
+        return encoded
 
     def decode(self, encoded: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
         """Decode keypoint coordinates from heatmaps. The decoded keypoint
         coordinates are in the input image space.
 
         Args:
             encoded (np.ndarray): Heatmaps in shape (K, H, W)
@@ -145,22 +155,19 @@
 
             keypoints = refine_keypoints_dark_udp(
                 keypoints, heatmaps, blur_kernel_size=self.blur_kernel_size)
 
         elif self.heatmap_type == 'combined':
             _K, H, W = heatmaps.shape
             K = _K // 3
-            for k in range(_K):
-                if k % 3 == 0:
-                    # for classification map
-                    ks = 2 * self.blur_kernel_size + 1
-                else:
-                    # for offset map
-                    ks = self.blur_kernel_size
-                cv2.GaussianBlur(heatmaps[k], (ks, ks), 0, heatmaps[k])
+
+            for cls_heatmap in heatmaps[::3]:
+                # Apply Gaussian blur on classification maps
+                ks = 2 * self.blur_kernel_size + 1
+                cv2.GaussianBlur(cls_heatmap, (ks, ks), 0, cls_heatmap)
 
             # valid radius
             radius = self.radius_factor * max(W, H)
 
             x_offset = heatmaps[1::3].flatten() * radius
             y_offset = heatmaps[2::3].flatten() * radius
             keypoints, scores = get_heatmap_maximum(heatmaps=heatmaps[::3])
```

### Comparing `mmpose-1.0.0rc0/mmpose/codecs/utils/__init__.py` & `mmpose-1.0.0rc1/mmpose/codecs/utils/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,17 +1,23 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from .gaussian_heatmap import (generate_gaussian_heatmaps,
                                generate_udp_gaussian_heatmaps,
                                generate_unbiased_gaussian_heatmaps)
-from .offset_heatmap import generate_offset_heatmap
+from .instance_property import (get_diagonal_lengths, get_instance_bbox,
+                                get_instance_root)
+from .offset_heatmap import (generate_displacement_heatmap,
+                             generate_offset_heatmap)
 from .post_processing import (batch_heatmap_nms, gaussian_blur,
-                              get_heatmap_maximum, get_simcc_maximum)
+                              gaussian_blur1d, get_heatmap_maximum,
+                              get_simcc_maximum)
 from .refinement import (refine_keypoints, refine_keypoints_dark,
-                         refine_keypoints_dark_udp)
+                         refine_keypoints_dark_udp, refine_simcc_dark)
 
 __all__ = [
     'generate_gaussian_heatmaps', 'generate_udp_gaussian_heatmaps',
     'generate_unbiased_gaussian_heatmaps', 'gaussian_blur',
     'get_heatmap_maximum', 'get_simcc_maximum', 'generate_offset_heatmap',
     'batch_heatmap_nms', 'refine_keypoints', 'refine_keypoints_dark',
-    'refine_keypoints_dark_udp'
+    'refine_keypoints_dark_udp', 'generate_displacement_heatmap',
+    'refine_simcc_dark', 'gaussian_blur1d', 'get_diagonal_lengths',
+    'get_instance_root', 'get_instance_bbox'
 ]
```

### Comparing `mmpose-1.0.0rc0/mmpose/codecs/utils/gaussian_heatmap.py` & `mmpose-1.0.0rc1/mmpose/codecs/utils/gaussian_heatmap.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,28 +1,30 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from itertools import product
-from typing import Tuple
+from typing import Tuple, Union
 
 import numpy as np
 
 
 def generate_gaussian_heatmaps(
     heatmap_size: Tuple[int, int],
     keypoints: np.ndarray,
     keypoints_visible: np.ndarray,
-    sigma: float,
+    sigma: Union[float, Tuple[float], np.ndarray],
 ) -> Tuple[np.ndarray, np.ndarray]:
     """Generate gaussian heatmaps of keypoints.
 
     Args:
         heatmap_size (Tuple[int, int]): Heatmap size in [W, H]
         keypoints (np.ndarray): Keypoint coordinates in shape (N, K, D)
         keypoints_visible (np.ndarray): Keypoint visibilities in shape
             (N, K)
-        sigma (float): The sigma value of the Gaussian heatmap
+        sigma (float or List[float]): A list of sigma values of the Gaussian
+            heatmap for each instance. If sigma is given as a single float
+            value, it will be expanded into a tuple
 
     Returns:
         tuple:
         - heatmaps (np.ndarray): The generated heatmap in shape
             (K, H, W) where [W, H] is the `heatmap_size`
         - keypoint_weights (np.ndarray): The target weights in shape
             (N, K)
@@ -30,59 +32,64 @@
 
     N, K, _ = keypoints.shape
     W, H = heatmap_size
 
     heatmaps = np.zeros((K, H, W), dtype=np.float32)
     keypoint_weights = keypoints_visible.copy()
 
-    # 3-sigma rule
-    radius = sigma * 3
+    if isinstance(sigma, (int, float)):
+        sigma = (sigma, ) * N
 
-    # xy grid
-    gaussian_size = 2 * radius + 1
-    x = np.arange(0, gaussian_size, 1, dtype=np.float32)
-    y = x[:, None]
-    x0 = y0 = gaussian_size // 2
-
-    for n, k in product(range(N), range(K)):
-        # skip unlabled keypoints
-        if keypoints_visible[n, k] < 0.5:
-            continue
-
-        # get gaussian center coordinates
-        mu = (keypoints[n, k] + 0.5).astype(np.int64)
-
-        # check that the gaussian has in-bounds part
-        left, top = (mu - radius).astype(np.int64)
-        right, bottom = (mu + radius + 1).astype(np.int64)
-
-        if left >= W or top >= H or right < 0 or bottom < 0:
-            keypoint_weights[n, k] = 0
-            continue
-
-        # The gaussian is not normalized,
-        # we want the center value to equal 1
-        gaussian = np.exp(-((x - x0)**2 + (y - y0)**2) / (2 * sigma**2))
-
-        # valid range in gaussian
-        g_x1 = max(0, -left)
-        g_x2 = min(W, right) - left
-        g_y1 = max(0, -top)
-        g_y2 = min(H, bottom) - top
-
-        # valid range in heatmap
-        h_x1 = max(0, left)
-        h_x2 = min(W, right)
-        h_y1 = max(0, top)
-        h_y2 = min(H, bottom)
+    for n in range(N):
+        # 3-sigma rule
+        radius = sigma[n] * 3
+
+        # xy grid
+        gaussian_size = 2 * radius + 1
+        x = np.arange(0, gaussian_size, 1, dtype=np.float32)
+        y = x[:, None]
+        x0 = y0 = gaussian_size // 2
+
+        for k in range(K):
+            # skip unlabled keypoints
+            if keypoints_visible[n, k] < 0.5:
+                continue
+
+            # get gaussian center coordinates
+            mu = (keypoints[n, k] + 0.5).astype(np.int64)
+
+            # check that the gaussian has in-bounds part
+            left, top = (mu - radius).astype(np.int64)
+            right, bottom = (mu + radius + 1).astype(np.int64)
+
+            if left >= W or top >= H or right < 0 or bottom < 0:
+                keypoint_weights[n, k] = 0
+                continue
+
+            # The gaussian is not normalized,
+            # we want the center value to equal 1
+            gaussian = np.exp(-((x - x0)**2 + (y - y0)**2) / (2 * sigma[n]**2))
+
+            # valid range in gaussian
+            g_x1 = max(0, -left)
+            g_x2 = min(W, right) - left
+            g_y1 = max(0, -top)
+            g_y2 = min(H, bottom) - top
+
+            # valid range in heatmap
+            h_x1 = max(0, left)
+            h_x2 = min(W, right)
+            h_y1 = max(0, top)
+            h_y2 = min(H, bottom)
 
-        heatmap_region = heatmaps[k, h_y1:h_y2, h_x1:h_x2]
-        gaussian_regsion = gaussian[g_y1:g_y2, g_x1:g_x2]
+            heatmap_region = heatmaps[k, h_y1:h_y2, h_x1:h_x2]
+            gaussian_regsion = gaussian[g_y1:g_y2, g_x1:g_x2]
 
-        _ = np.maximum(heatmap_region, gaussian_regsion, out=heatmap_region)
+            _ = np.maximum(
+                heatmap_region, gaussian_regsion, out=heatmap_region)
 
     return heatmaps, keypoint_weights
 
 
 def generate_unbiased_gaussian_heatmaps(
     heatmap_size: Tuple[int, int],
     keypoints: np.ndarray,
```

### Comparing `mmpose-1.0.0rc0/mmpose/codecs/utils/post_processing.py` & `mmpose-1.0.0rc1/mmpose/codecs/utils/post_processing.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,9 @@
 # Copyright (c) OpenMMLab. All rights reserved.
+from itertools import product
 from typing import Tuple
 
 import cv2
 import numpy as np
 import torch
 import torch.nn.functional as F
 from torch import Tensor
@@ -137,14 +138,45 @@
         dr[border:-border, border:-border] = heatmaps[k].copy()
         dr = cv2.GaussianBlur(dr, (kernel, kernel), 0)
         heatmaps[k] = dr[border:-border, border:-border].copy()
         heatmaps[k] *= origin_max / np.max(heatmaps[k])
     return heatmaps
 
 
+def gaussian_blur1d(simcc: np.ndarray, kernel: int = 11) -> np.ndarray:
+    """Modulate simcc distribution with Gaussian.
+
+    Note:
+        - num_keypoints: K
+        - simcc length: Wx
+
+    Args:
+        simcc (np.ndarray[K, Wx]): model predicted simcc.
+        kernel (int): Gaussian kernel size (K) for modulation, which should
+            match the simcc gaussian sigma when training.
+            K=17 for sigma=3 and k=11 for sigma=2.
+
+    Returns:
+        np.ndarray ([K, Wx]): Modulated simcc distribution.
+    """
+    assert kernel % 2 == 1
+
+    border = (kernel - 1) // 2
+    N, K, Wx = simcc.shape
+
+    for n, k in product(range(N), range(K)):
+        origin_max = np.max(simcc[n, k])
+        dr = np.zeros((1, Wx + 2 * border), dtype=np.float32)
+        dr[0, border:-border] = simcc[n, k].copy()
+        dr = cv2.GaussianBlur(dr, (kernel, 1), 0)
+        simcc[n, k] = dr[0, border:-border].copy()
+        simcc[n, k] *= origin_max / np.max(simcc[n, k])
+    return simcc
+
+
 def batch_heatmap_nms(batch_heatmaps: Tensor, kernel_size: int = 5):
     """Apply NMS on a batch of heatmaps.
 
     Args:
         batch_heatmaps (Tensor): batch heatmaps in shape (B, K, H, W)
         kernel_size (int): The kernel size of the NMS which should be
             a odd integer. Defaults to 5
```

### Comparing `mmpose-1.0.0rc0/mmpose/codecs/utils/refinement.py` & `mmpose-1.0.0rc1/mmpose/codecs/utils/refinement.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from itertools import product
 
 import numpy as np
 
-from .post_processing import gaussian_blur
+from .post_processing import gaussian_blur, gaussian_blur1d
 
 
 def refine_keypoints(keypoints: np.ndarray,
                      heatmaps: np.ndarray) -> np.ndarray:
     """Refine keypoint predictions by moving from the maximum towards the
     second maximum by 0.25 pixel. The operation is in-place.
 
@@ -159,7 +159,57 @@
         hessian = np.concatenate([dxx, dxy, dxy, dyy], axis=1)
         hessian = hessian.reshape(K, 2, 2)
         hessian = np.linalg.inv(hessian + np.finfo(np.float32).eps * np.eye(2))
         keypoints[n] -= np.einsum('imn,ink->imk', hessian,
                                   derivative).squeeze()
 
     return keypoints
+
+
+def refine_simcc_dark(keypoints: np.ndarray, simcc: np.ndarray,
+                      blur_kernel_size: int) -> np.ndarray:
+    """SimCC version. Refine keypoint predictions using distribution aware
+    coordinate decoding for UDP. See `UDP`_ for details. The operation is in-
+    place.
+
+    Note:
+
+        - instance number: N
+        - keypoint number: K
+        - keypoint dimension: D
+
+    Args:
+        keypoints (np.ndarray): The keypoint coordinates in shape (N, K, D)
+        simcc (np.ndarray): The heatmaps in shape (N, K, Wx)
+        blur_kernel_size (int): The Gaussian blur kernel size of the heatmap
+            modulation
+
+    Returns:
+        np.ndarray: Refine keypoint coordinates in shape (N, K, D)
+
+    .. _`UDP`: https://arxiv.org/abs/1911.07524
+    """
+    N = simcc.shape[0]
+
+    # modulate simcc
+    simcc = gaussian_blur1d(simcc, blur_kernel_size)
+    np.clip(simcc, 1e-3, 50., simcc)
+    np.log(simcc, simcc)
+
+    simcc = np.pad(simcc, ((0, 0), (0, 0), (2, 2)), 'edge')
+
+    for n in range(N):
+        px = (keypoints[n] + 2.5).astype(np.int64).reshape(-1, 1)  # K, 1
+
+        dx0 = np.take_along_axis(simcc[n], px, axis=1)  # K, 1
+        dx1 = np.take_along_axis(simcc[n], px + 1, axis=1)
+        dx_1 = np.take_along_axis(simcc[n], px - 1, axis=1)
+        dx2 = np.take_along_axis(simcc[n], px + 2, axis=1)
+        dx_2 = np.take_along_axis(simcc[n], px - 2, axis=1)
+
+        dx = 0.5 * (dx1 - dx_1)
+        dxx = 1e-9 + 0.25 * (dx2 - 2 * dx0 + dx_2)
+
+        offset = dx / dxx
+        keypoints[n] -= offset.reshape(-1)
+
+    return keypoints
```

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/builder.py` & `mmpose-1.0.0rc1/mmpose/datasets/builder.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 import copy
 import platform
 import random
 
 import numpy as np
 import torch
 from mmengine import build_from_cfg, is_seq_of
-from torch.utils.data.dataset import ConcatDataset
+from mmengine.dataset import ConcatDataset, RepeatDataset
 
 from mmpose.registry import DATASETS
 
 if platform.system() != 'Windows':
     # https://github.com/pytorch/pytorch/issues/973
     import resource
     rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)
@@ -60,15 +60,14 @@
         cfg (dict): Config dict. It should at least contain the key "type".
         default_args (dict, optional): Default initialization arguments.
             Default: None.
 
     Returns:
         Dataset: The constructed dataset.
     """
-    from .dataset_wrappers import RepeatDataset
 
     if isinstance(cfg, (list, tuple)):
         dataset = ConcatDataset([build_dataset(c, default_args) for c in cfg])
     elif cfg['type'] == 'ConcatDataset':
         dataset = ConcatDataset(
             [build_dataset(c, default_args) for c in cfg['datasets']])
     elif cfg['type'] == 'RepeatDataset':
```

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/__init__.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/__init__.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/animalpose_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/animalpose_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/ap10k_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/zebra_dataset.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,41 +5,33 @@
 import numpy as np
 
 from mmpose.registry import DATASETS
 from ..base import BaseCocoStyleDataset
 
 
 @DATASETS.register_module()
-class AP10KDataset(BaseCocoStyleDataset):
-    """AP-10K dataset for animal pose estimation.
+class ZebraDataset(BaseCocoStyleDataset):
+    """ZebraDataset for animal pose estimation.
 
-    "AP-10K: A Benchmark for Animal Pose Estimation in the Wild"
-    Neurips Dataset Track'2021.
+    "DeepPoseKit, a software toolkit for fast and robust animal
+    pose estimation using deep learning" Elife'2019.
     More details can be found in the `paper
-    <https://arxiv.org/abs/2108.12617>`__ .
+    <https://elifesciences.org/articles/47994>`__ .
 
-    AP-10K keypoints::
+    Zebra keypoints::
 
-        0: 'L_Eye',
-        1: 'R_Eye',
-        2: 'Nose',
-        3: 'Neck',
-        4: 'root of tail',
-        5: 'L_Shoulder',
-        6: 'L_Elbow',
-        7: 'L_F_Paw',
-        8: 'R_Shoulder',
-        9: 'R_Elbow',
-        10: 'R_F_Paw,
-        11: 'L_Hip',
-        12: 'L_Knee',
-        13: 'L_B_Paw',
-        14: 'R_Hip',
-        15: 'R_Knee',
-        16: 'R_B_Paw'
+        0: "snout",
+        1: "head",
+        2: "neck",
+        3: "forelegL1",
+        4: "forelegR1",
+        5: "hindlegL1",
+        6: "hindlegR1",
+        7: "tailbase",
+        8: "tailtip"
 
     Args:
         ann_file (str): Annotation file path. Default: ''.
         bbox_file (str, optional): Detection result file path. If
             ``bbox_file`` is set, detected bboxes loaded from this file will
             be used instead of ground-truth bboxes. This setting is only for
             evaluation, i.e., ignored when ``test_mode`` is ``False``.
@@ -71,70 +63,54 @@
             load annotation file. ``Basedataset`` can skip load annotations to
             save time by set ``lazy_init=False``. Default: ``False``.
         max_refetch (int, optional): If ``Basedataset.prepare_data`` get a
             None img. The maximum extra number of cycles to get a valid
             image. Default: 1000.
     """
 
-    METAINFO: dict = dict(from_file='configs/_base_/datasets/ap10k.py')
+    METAINFO: dict = dict(from_file='configs/_base_/datasets/zebra.py')
 
     def parse_data_info(self, raw_data_info: dict) -> Optional[dict]:
-        """Parse raw AP-10K annotation of an instance.
+        """Parse raw Zebra annotation of an instance.
 
         Args:
             raw_data_info (dict): Raw data information loaded from
                 ``ann_file``. It should have following contents:
 
                 - ``'raw_ann_info'``: Raw annotation of an instance
                 - ``'raw_img_info'``: Raw information of the image that
                     contains the instance
 
         Returns:
-            dict | None: Parsed instance annotation
+            dict: Parsed instance annotation
         """
 
         ann = raw_data_info['raw_ann_info']
         img = raw_data_info['raw_img_info']
 
-        # filter invalid instance
-        if 'bbox' not in ann or 'keypoints' not in ann or max(
-                ann['keypoints']) == 0:
-            return None
-
         img_path = osp.join(self.data_prefix['img'], img['file_name'])
-        img_w, img_h = img['width'], img['height']
 
         # get bbox in shape [1, 4], formatted as xywh
-        x, y, w, h = ann['bbox']
-        x1 = np.clip(x, 0, img_w - 1)
-        y1 = np.clip(y, 0, img_h - 1)
-        x2 = np.clip(x + w, 0, img_w - 1)
-        y2 = np.clip(y + h, 0, img_h - 1)
-
-        bbox = np.array([x1, y1, x2, y2], dtype=np.float32).reshape(1, 4)
+        # use the entire image which is 160x160
+        bbox = np.array([0, 0, 160, 160], dtype=np.float32).reshape(1, 4)
 
         # keypoints in shape [1, K, 2] and keypoints_visible in [1, K]
         _keypoints = np.array(
             ann['keypoints'], dtype=np.float32).reshape(1, -1, 3)
         keypoints = _keypoints[..., :2]
         keypoints_visible = np.minimum(1, _keypoints[..., 2])
 
-        if 'num_keypoints' in ann:
-            num_keypoints = ann['num_keypoints']
-        else:
-            num_keypoints = np.count_nonzero(keypoints.max(axis=2))
+        num_keypoints = ann['num_keypoints']
 
         data_info = {
             'img_id': ann['image_id'],
             'img_path': img_path,
             'bbox': bbox,
             'bbox_score': np.ones(1, dtype=np.float32),
             'num_keypoints': num_keypoints,
             'keypoints': keypoints,
             'keypoints_visible': keypoints_visible,
-            'iscrowd': ann.get('iscrowd', 0),
-            'segmentation': ann.get('segmentation', None),
+            'iscrowd': ann['iscrowd'],
             'id': ann['id'],
-            'category': ann['category_id'],
         }
 
         return data_info
```

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/atrw_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/atrw_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/fly_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/fly_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/horse10_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/horse10_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/locust_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/locust_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/macaque_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/animal/macaque_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/animal/zebra_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/body/jhmdb_dataset.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,33 +5,39 @@
 import numpy as np
 
 from mmpose.registry import DATASETS
 from ..base import BaseCocoStyleDataset
 
 
 @DATASETS.register_module()
-class ZebraDataset(BaseCocoStyleDataset):
-    """ZebraDataset for animal pose estimation.
+class JhmdbDataset(BaseCocoStyleDataset):
+    """JhmdbDataset dataset for pose estimation.
 
-    "DeepPoseKit, a software toolkit for fast and robust animal
-    pose estimation using deep learning" Elife'2019.
+    "Towards understanding action recognition", ICCV'2013.
     More details can be found in the `paper
-    <https://elifesciences.org/articles/47994>`__ .
+    <https://openaccess.thecvf.com/content_iccv_2013/papers/\
+    Jhuang_Towards_Understanding_Action_2013_ICCV_paper.pdf>`__
 
-    Zebra keypoints::
+    sub-JHMDB keypoints::
 
-        0: "snout",
-        1: "head",
-        2: "neck",
-        3: "forelegL1",
-        4: "forelegR1",
-        5: "hindlegL1",
-        6: "hindlegR1",
-        7: "tailbase",
-        8: "tailtip"
+        0: "neck",
+        1: "belly",
+        2: "head",
+        3: "right_shoulder",
+        4: "left_shoulder",
+        5: "right_hip",
+        6: "left_hip",
+        7: "right_elbow",
+        8: "left_elbow",
+        9: "right_knee",
+        10: "left_knee",
+        11: "right_wrist",
+        12: "left_wrist",
+        13: "right_ankle",
+        14: "left_ankle"
 
     Args:
         ann_file (str): Annotation file path. Default: ''.
         bbox_file (str, optional): Detection result file path. If
             ``bbox_file`` is set, detected bboxes loaded from this file will
             be used instead of ground-truth bboxes. This setting is only for
             evaluation, i.e., ignored when ``test_mode`` is ``False``.
@@ -63,18 +69,18 @@
             load annotation file. ``Basedataset`` can skip load annotations to
             save time by set ``lazy_init=False``. Default: ``False``.
         max_refetch (int, optional): If ``Basedataset.prepare_data`` get a
             None img. The maximum extra number of cycles to get a valid
             image. Default: 1000.
     """
 
-    METAINFO: dict = dict(from_file='configs/_base_/datasets/zebra.py')
+    METAINFO: dict = dict(from_file='configs/_base_/datasets/jhmdb.py')
 
     def parse_data_info(self, raw_data_info: dict) -> Optional[dict]:
-        """Parse raw Zebra annotation of an instance.
+        """Parse raw COCO annotation of an instance.
 
         Args:
             raw_data_info (dict): Raw data information loaded from
                 ``ann_file``. It should have following contents:
 
                 - ``'raw_ann_info'``: Raw annotation of an instance
                 - ``'raw_img_info'``: Raw information of the image that
@@ -84,33 +90,46 @@
             dict: Parsed instance annotation
         """
 
         ann = raw_data_info['raw_ann_info']
         img = raw_data_info['raw_img_info']
 
         img_path = osp.join(self.data_prefix['img'], img['file_name'])
+        img_w, img_h = img['width'], img['height']
 
         # get bbox in shape [1, 4], formatted as xywh
-        # use the entire image which is 160x160
-        bbox = np.array([0, 0, 160, 160], dtype=np.float32).reshape(1, 4)
+        x, y, w, h = ann['bbox']
+        # JHMDB uses matlab format, index is 1-based,
+        # we should first convert to 0-based index
+        x -= 1
+        y -= 1
+        x1 = np.clip(x, 0, img_w - 1)
+        y1 = np.clip(y, 0, img_h - 1)
+        x2 = np.clip(x + w, 0, img_w - 1)
+        y2 = np.clip(y + h, 0, img_h - 1)
+
+        bbox = np.array([x1, y1, x2, y2], dtype=np.float32).reshape(1, 4)
 
         # keypoints in shape [1, K, 2] and keypoints_visible in [1, K]
         _keypoints = np.array(
             ann['keypoints'], dtype=np.float32).reshape(1, -1, 3)
-        keypoints = _keypoints[..., :2]
+        # JHMDB uses matlab format, index is 1-based,
+        # we should first convert to 0-based index
+        keypoints = _keypoints[..., :2] - 1
         keypoints_visible = np.minimum(1, _keypoints[..., 2])
 
-        num_keypoints = ann['num_keypoints']
+        num_keypoints = np.count_nonzero(keypoints.max(axis=2))
 
         data_info = {
             'img_id': ann['image_id'],
             'img_path': img_path,
             'bbox': bbox,
             'bbox_score': np.ones(1, dtype=np.float32),
             'num_keypoints': num_keypoints,
             'keypoints': keypoints,
             'keypoints_visible': keypoints_visible,
-            'iscrowd': ann['iscrowd'],
+            'iscrowd': ann.get('iscrowd', 0),
+            'segmentation': ann.get('segmentation', None),
             'id': ann['id'],
         }
 
         return data_info
```

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/base/base_coco_style_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/base/base_coco_style_dataset.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 # Copyright (c) OpenMMLab. All rights reserved.
+import copy
 import os.path as osp
 from copy import deepcopy
 from itertools import filterfalse, groupby
-from typing import (Any, Callable, Dict, Iterable, List, Optional, Sequence,
-                    Union)
+from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union
 
 import numpy as np
 from mmengine.dataset import BaseDataset, force_full_init
 from mmengine.fileio import load
 from mmengine.utils import check_file_exist, is_list_of
 from xtcocotools.coco import COCO
 
@@ -143,68 +143,94 @@
             idx (int): The index of ``data_info``.
 
         Returns:
             Any: Depends on ``self.pipeline``.
         """
         data_info = self.get_data_info(idx)
 
+        return self.pipeline(data_info)
+
+    def get_data_info(self, idx: int) -> dict:
+        """Get data info by index.
+
+        Args:
+            idx (int): Index of data info.
+
+        Returns:
+            dict: Data info.
+        """
+        data_info = super().get_data_info(idx)
+
         # Add metainfo items that are required in the pipeline and the model
         metainfo_keys = [
             'upper_body_ids', 'lower_body_ids', 'flip_pairs',
-            'dataset_keypoint_weights', 'flip_indices'
+            'dataset_keypoint_weights', 'flip_indices', 'skeleton_links'
         ]
 
         for key in metainfo_keys:
             assert key not in data_info, (
                 f'"{key}" is a reserved key for `metainfo`, but already '
                 'exists in the `data_info`.')
 
             data_info[key] = deepcopy(self._metainfo[key])
 
-        return self.pipeline(data_info)
+        return data_info
 
     def load_data_list(self) -> List[dict]:
         """Load data list from COCO annotation file or person detection result
         file."""
 
         if self.bbox_file:
             data_list = self._load_detection_results()
         else:
-            data_list = self._load_annotations()
+            instance_list, image_list = self._load_annotations()
 
             if self.data_mode == 'topdown':
-                data_list = self._get_topdown_data_infos(data_list)
+                data_list = self._get_topdown_data_infos(instance_list)
             else:
-                data_list = self._get_bottomup_data_infos(data_list)
+                data_list = self._get_bottomup_data_infos(
+                    instance_list, image_list)
 
         return data_list
 
-    def _load_annotations(self):
+    def _load_annotations(self) -> Tuple[List[dict], List[dict]]:
         """Load data from annotations in COCO format."""
 
         check_file_exist(self.ann_file)
 
         coco = COCO(self.ann_file)
-        data_list = []
+        # set the metainfo about categories, which is a list of dict
+        # and each dict contains the 'id', 'name', etc. about this category
+        self._metainfo['CLASSES'] = coco.loadCats(coco.getCatIds())
+
+        instance_list = []
+        image_list = []
 
         for img_id in coco.getImgIds():
             img = coco.loadImgs(img_id)[0]
-            ann_ids = coco.getAnnIds(imgIds=img_id, iscrowd=False)
+            img.update({
+                'img_id':
+                img_id,
+                'img_path':
+                osp.join(self.data_prefix['img'], img['file_name']),
+            })
+            image_list.append(img)
+
+            ann_ids = coco.getAnnIds(imgIds=img_id)
             for ann in coco.loadAnns(ann_ids):
 
-                data_info = self.parse_data_info(
+                instance_info = self.parse_data_info(
                     dict(raw_ann_info=ann, raw_img_info=img))
 
                 # skip invalid instance annotation.
-                if not data_info:
+                if not instance_info:
                     continue
 
-                data_list.append(data_info)
-
-        return data_list
+                instance_list.append(instance_info)
+        return instance_list, image_list
 
     def parse_data_info(self, raw_data_info: dict) -> Optional[dict]:
         """Parse raw COCO annotation of an instance.
 
         Args:
             raw_data_info (dict): Raw data information loaded from
                 ``ann_file``. It should have following contents:
@@ -217,19 +243,17 @@
             dict | None: Parsed instance annotation
         """
 
         ann = raw_data_info['raw_ann_info']
         img = raw_data_info['raw_img_info']
 
         # filter invalid instance
-        if 'bbox' not in ann or 'keypoints' not in ann or max(
-                ann['keypoints']) == 0:
+        if 'bbox' not in ann or 'keypoints' not in ann:
             return None
 
-        img_path = osp.join(self.data_prefix['img'], img['file_name'])
         img_w, img_h = img['width'], img['height']
 
         # get bbox in shape [1, 4], formatted as xywh
         x, y, w, h = ann['bbox']
         x1 = np.clip(x, 0, img_w - 1)
         y1 = np.clip(y, 0, img_h - 1)
         x2 = np.clip(x + w, 0, img_w - 1)
@@ -246,25 +270,32 @@
         if 'num_keypoints' in ann:
             num_keypoints = ann['num_keypoints']
         else:
             num_keypoints = np.count_nonzero(keypoints.max(axis=2))
 
         data_info = {
             'img_id': ann['image_id'],
-            'img_path': img_path,
+            'img_path': img['img_path'],
             'bbox': bbox,
             'bbox_score': np.ones(1, dtype=np.float32),
             'num_keypoints': num_keypoints,
             'keypoints': keypoints,
             'keypoints_visible': keypoints_visible,
             'iscrowd': ann.get('iscrowd', 0),
             'segmentation': ann.get('segmentation', None),
             'id': ann['id'],
+            'category_id': ann['category_id'],
+            # store the raw annotation of the instance
+            # it is useful for evaluation without providing ann_file
+            'raw_ann_info': copy.deepcopy(ann),
         }
 
+        if 'crowdIndex' in img:
+            data_info['crowd_index'] = img['crowdIndex']
+
         return data_info
 
     @staticmethod
     def _is_valid_instance(data_info: Dict) -> bool:
         """Check a data info is an instance with valid bbox and keypoint
         annotations."""
         # crowd annotation
@@ -275,82 +306,96 @@
             return False
         # invalid bbox
         if 'bbox' in data_info:
             bbox = data_info['bbox'][0]
             w, h = bbox[2:4] - bbox[:2]
             if w <= 0 or h <= 0:
                 return False
+        # invalid keypoints
+        if 'keypoints' in data_info:
+            if np.max(data_info['keypoints']) <= 0:
+                return False
         return True
 
-    def _get_topdown_data_infos(self, data_list: List[Dict]) -> List[Dict]:
+    def _get_topdown_data_infos(self, instance_list: List[Dict]) -> List[Dict]:
         """Organize the data list in top-down mode."""
         # sanitize data samples
-        data_list_tp = list(filter(self._is_valid_instance, data_list))
+        data_list_tp = list(filter(self._is_valid_instance, instance_list))
 
         return data_list_tp
 
-    def _get_bottomup_data_infos(self, data_list):
+    def _get_bottomup_data_infos(self, instance_list: List[Dict],
+                                 image_list: List[Dict]) -> List[Dict]:
         """Organize the data list in bottom-up mode."""
 
-        def _concat(seq: Iterable, key: Any, axis=0):
-            seq = [x[key] for x in seq]
-            if isinstance(seq[0], np.ndarray):
-                seq = np.concatenate(seq, axis=axis)
-            return seq
-
         # bottom-up data list
         data_list_bu = []
 
+        used_img_ids = set()
+
         # group instances by img_id
-        for img_id, data_infos in groupby(data_list, lambda x: x['img_id']):
+        for img_id, data_infos in groupby(instance_list,
+                                          lambda x: x['img_id']):
+            used_img_ids.add(img_id)
             data_infos = list(data_infos)
 
-            # get valid instances for keypoint annotations
-            data_infos_valid = list(
-                filter(self._is_valid_instance, data_infos))
-            if not data_infos_valid:
-                continue
-
-            img_path = data_infos_valid[0]['img_path']
-
             # image data
+            img_path = data_infos[0]['img_path']
             data_info_bu = {
                 'img_id': img_id,
                 'img_path': img_path,
             }
-            # instance data
-            for key in data_infos_valid[0].keys():
+
+            for key in data_infos[0].keys():
                 if key not in data_info_bu:
-                    data_info_bu[key] = _concat(data_infos_valid, key)
+                    seq = [d[key] for d in data_infos]
+                    if isinstance(seq[0], np.ndarray):
+                        seq = np.concatenate(seq, axis=0)
+                    data_info_bu[key] = seq
 
             # The segmentation annotation of invalid objects will be used
             # to generate valid region mask in the pipeline.
             invalid_segs = []
             for data_info_invalid in filterfalse(self._is_valid_instance,
                                                  data_infos):
-                if 'segementation' in data_info_invalid:
+                if 'segmentation' in data_info_invalid:
                     invalid_segs.append(data_info_invalid['segmentation'])
             data_info_bu['invalid_segs'] = invalid_segs
 
             data_list_bu.append(data_info_bu)
 
+        # add images without instance for evaluation
+        if self.test_mode:
+            for img_info in image_list:
+                if img_info['img_id'] not in used_img_ids:
+                    data_info_bu = {
+                        'img_id': img_info['img_id'],
+                        'img_path': img_info['img_path'],
+                        'id': list(),
+                        'raw_ann_info': None,
+                    }
+                    data_list_bu.append(data_info_bu)
+
         return data_list_bu
 
     def _load_detection_results(self) -> List[dict]:
         """Load data from detection results with dummy keypoint annotations."""
 
         check_file_exist(self.ann_file)
         check_file_exist(self.bbox_file)
 
         # load detection results
         det_results = load(self.bbox_file)
         assert is_list_of(det_results, dict)
 
         # load coco annotations to build image id-to-name index
         coco = COCO(self.ann_file)
+        # set the metainfo about categories, which is a list of dict
+        # and each dict contains the 'id', 'name', etc. about this category
+        self._metainfo['CLASSES'] = coco.loadCats(coco.getCatIds())
 
         num_keypoints = self.metainfo['num_keypoints']
         data_list = []
         id_ = 0
         for det in det_results:
             # remove non-human instances
             if det['category_id'] != 1:
```

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/body/__init__.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/body/__init__.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/body/aic_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/body/aic_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/body/coco_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/body/coco_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/body/crowdpose_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/body/crowdpose_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/body/jhmdb_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/wholebody/coco_wholebody_dataset.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,43 +1,34 @@
 # Copyright (c) OpenMMLab. All rights reserved.
+import copy
 import os.path as osp
 from typing import Optional
 
 import numpy as np
 
 from mmpose.registry import DATASETS
 from ..base import BaseCocoStyleDataset
 
 
 @DATASETS.register_module()
-class JhmdbDataset(BaseCocoStyleDataset):
-    """JhmdbDataset dataset for pose estimation.
+class CocoWholeBodyDataset(BaseCocoStyleDataset):
+    """CocoWholeBody dataset for pose estimation.
 
-    "Towards understanding action recognition", ICCV'2013.
+    "Whole-Body Human Pose Estimation in the Wild", ECCV'2020.
     More details can be found in the `paper
-    <https://openaccess.thecvf.com/content_iccv_2013/papers/\
-    Jhuang_Towards_Understanding_Action_2013_ICCV_paper.pdf>`__
+    <https://arxiv.org/abs/2007.11858>`__ .
 
-    sub-JHMDB keypoints::
+    COCO-WholeBody keypoints::
 
-        0: "neck",
-        1: "belly",
-        2: "head",
-        3: "right_shoulder",
-        4: "left_shoulder",
-        5: "right_hip",
-        6: "left_hip",
-        7: "right_elbow",
-        8: "left_elbow",
-        9: "right_knee",
-        10: "left_knee",
-        11: "right_wrist",
-        12: "left_wrist",
-        13: "right_ankle",
-        14: "left_ankle"
+        0-16: 17 body keypoints,
+        17-22: 6 foot keypoints,
+        23-90: 68 face keypoints,
+        91-132: 42 hand keypoints
+
+        In total, we have 133 keypoints for wholebody pose estimation.
 
     Args:
         ann_file (str): Annotation file path. Default: ''.
         bbox_file (str, optional): Detection result file path. If
             ``bbox_file`` is set, detected bboxes loaded from this file will
             be used instead of ground-truth bboxes. This setting is only for
             evaluation, i.e., ignored when ``test_mode`` is ``False``.
@@ -69,15 +60,16 @@
             load annotation file. ``Basedataset`` can skip load annotations to
             save time by set ``lazy_init=False``. Default: ``False``.
         max_refetch (int, optional): If ``Basedataset.prepare_data`` get a
             None img. The maximum extra number of cycles to get a valid
             image. Default: 1000.
     """
 
-    METAINFO: dict = dict(from_file='configs/_base_/datasets/jhmdb.py')
+    METAINFO: dict = dict(
+        from_file='configs/_base_/datasets/coco_wholebody.py')
 
     def parse_data_info(self, raw_data_info: dict) -> Optional[dict]:
         """Parse raw COCO annotation of an instance.
 
         Args:
             raw_data_info (dict): Raw data information loaded from
                 ``ann_file``. It should have following contents:
@@ -94,42 +86,42 @@
         img = raw_data_info['raw_img_info']
 
         img_path = osp.join(self.data_prefix['img'], img['file_name'])
         img_w, img_h = img['width'], img['height']
 
         # get bbox in shape [1, 4], formatted as xywh
         x, y, w, h = ann['bbox']
-        # JHMDB uses matlab format, index is 1-based,
-        # we should first convert to 0-based index
-        x -= 1
-        y -= 1
         x1 = np.clip(x, 0, img_w - 1)
         y1 = np.clip(y, 0, img_h - 1)
         x2 = np.clip(x + w, 0, img_w - 1)
         y2 = np.clip(y + h, 0, img_h - 1)
 
         bbox = np.array([x1, y1, x2, y2], dtype=np.float32).reshape(1, 4)
 
         # keypoints in shape [1, K, 2] and keypoints_visible in [1, K]
-        _keypoints = np.array(
-            ann['keypoints'], dtype=np.float32).reshape(1, -1, 3)
-        # JHMDB uses matlab format, index is 1-based,
-        # we should first convert to 0-based index
-        keypoints = _keypoints[..., :2] - 1
-        keypoints_visible = np.minimum(1, _keypoints[..., 2])
+        # COCO-Wholebody: consisting of body, foot, face and hand keypoints
+        _keypoints = np.array(ann['keypoints'] + ann['foot_kpts'] +
+                              ann['face_kpts'] + ann['lefthand_kpts'] +
+                              ann['righthand_kpts']).reshape(1, -1, 3)
+        keypoints = _keypoints[..., :2]
+        keypoints_visible = np.minimum(1, _keypoints[..., 2] > 0)
 
-        num_keypoints = np.count_nonzero(keypoints.max(axis=2))
+        num_keypoints = ann['num_keypoints']
 
         data_info = {
             'img_id': ann['image_id'],
             'img_path': img_path,
             'bbox': bbox,
             'bbox_score': np.ones(1, dtype=np.float32),
             'num_keypoints': num_keypoints,
             'keypoints': keypoints,
             'keypoints_visible': keypoints_visible,
-            'iscrowd': ann.get('iscrowd', 0),
-            'segmentation': ann.get('segmentation', None),
+            'iscrowd': ann['iscrowd'],
+            'segmentation': ann['segmentation'],
             'id': ann['id'],
+            'category_id': ann['category_id'],
+            # store the raw annotation of the instance
+            # it is useful for evaluation without providing ann_file
+            'raw_ann_info': copy.deepcopy(ann),
         }
 
         return data_info
```

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/body/mhp_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/body/mhp_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/body/mpii_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/body/mpii_dataset.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 import json
 import os.path as osp
-from typing import Callable, List, Optional, Sequence, Union
+from typing import Callable, List, Optional, Sequence, Tuple, Union
 
 import numpy as np
 from mmengine.utils import check_file_exist
 from scipy.io import loadmat
 
 from mmpose.registry import DATASETS
 from mmpose.structures.bbox import bbox_cs2xyxy
@@ -130,29 +130,31 @@
             indices=indices,
             serialize_data=serialize_data,
             pipeline=pipeline,
             test_mode=test_mode,
             lazy_init=lazy_init,
             max_refetch=max_refetch)
 
-    def _load_annotations(self) -> List[dict]:
+    def _load_annotations(self) -> Tuple[List[dict], List[dict]]:
         """Load data from annotations in MPII format."""
 
         check_file_exist(self.ann_file)
         with open(self.ann_file) as anno_file:
             anns = json.load(anno_file)
 
         if self.headbox_file:
             check_file_exist(self.headbox_file)
             headbox_dict = loadmat(self.headbox_file)
             headboxes_src = np.transpose(headbox_dict['headboxes_src'],
                                          [2, 0, 1])
             SC_BIAS = 0.6
 
-        data_list = []
+        instance_list = []
+        image_list = []
+        used_img_ids = set()
         ann_id = 0
 
         # mpii bbox scales are normalized with factor 200.
         pixel_std = 200.
 
         for idx, ann in enumerate(anns):
             center = np.array(ann['center'], dtype=np.float32)
@@ -172,15 +174,15 @@
             scale = scale.reshape(1, -1)
             bbox = bbox_cs2xyxy(center, scale)
 
             # load keypoints in shape [1, K, 2] and keypoints_visible in [1, K]
             keypoints = np.array(ann['joints']).reshape(1, -1, 2)
             keypoints_visible = np.array(ann['joints_vis']).reshape(1, -1)
 
-            data_info = {
+            instance_info = {
                 'id': ann_id,
                 'img_id': int(ann['image'].split('.')[0]),
                 'img_path': osp.join(self.data_prefix['img'], ann['image']),
                 'bbox_center': center,
                 'bbox_scale': scale,
                 'bbox': bbox,
                 'bbox_score': np.ones(1, dtype=np.float32),
@@ -189,13 +191,20 @@
             }
 
             if self.headbox_file:
                 # calculate the diagonal length of head box as norm_factor
                 headbox = headboxes_src[idx]
                 head_size = np.linalg.norm(headbox[1] - headbox[0], axis=0)
                 head_size *= SC_BIAS
-                data_info['head_size'] = head_size.reshape(1, -1)
+                instance_info['head_size'] = head_size.reshape(1, -1)
 
-            data_list.append(data_info)
+            if instance_info['img_id'] not in used_img_ids:
+                used_img_ids.add(instance_info['img_id'])
+                image_list.append({
+                    'img_id': instance_info['img_id'],
+                    'img_path': instance_info['img_path'],
+                })
+
+            instance_list.append(instance_info)
             ann_id = ann_id + 1
 
-        return data_list
+        return instance_list, image_list
```

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/body/mpii_trb_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/body/mpii_trb_dataset.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 import json
 import os.path as osp
-from typing import List
+from typing import List, Tuple
 
 import numpy as np
 from mmengine.utils import check_file_exist
 
 from mmpose.registry import DATASETS
 from mmpose.structures.bbox import bbox_cs2xyxy
 from ..base import BaseCocoStyleDataset
@@ -99,24 +99,26 @@
         max_refetch (int, optional): If ``Basedataset.prepare_data`` get a
             None img. The maximum extra number of cycles to get a valid
             image. Default: 1000.
     """
 
     METAINFO: dict = dict(from_file='configs/_base_/datasets/mpii_trb.py')
 
-    def _load_annotations(self) -> List[dict]:
+    def _load_annotations(self) -> Tuple[List[dict], List[dict]]:
         """Load data from annotations in MPII-TRB format."""
 
         check_file_exist(self.ann_file)
         with open(self.ann_file) as anno_file:
             data = json.load(anno_file)
 
         imgid2info = {img['id']: img for img in data['images']}
 
-        data_list = []
+        instance_list = []
+        image_list = []
+        used_img_ids = set()
 
         # mpii-trb bbox scales are normalized with factor 200.
         pixel_std = 200.
 
         for ann in data['annotations']:
             img_id = ann['image_id']
 
@@ -131,15 +133,15 @@
                 ann['keypoints'], dtype=np.float32).reshape(1, -1, 3)
             keypoints = _keypoints[..., :2]
             keypoints_visible = np.minimum(1, _keypoints[..., 2])
 
             img_path = osp.join(self.data_prefix['img'],
                                 imgid2info[img_id]['file_name'])
 
-            data_info = {
+            instance_info = {
                 'id': ann['id'],
                 'img_id': img_id,
                 'img_path': img_path,
                 'bbox_center': center,
                 'bbox_scale': scale,
                 'bbox': bbox,
                 'bbox_score': np.ones(1, dtype=np.float32),
@@ -147,14 +149,20 @@
                 'keypoints': keypoints,
                 'keypoints_visible': keypoints_visible,
                 'iscrowd': ann['iscrowd'],
             }
 
             # val set
             if 'headbox' in ann:
-                data_info['headbox'] = np.array(
+                instance_info['headbox'] = np.array(
                     ann['headbox'], dtype=np.float32)
 
-            data_list.append(data_info)
+            instance_list.append(instance_info)
+            if instance_info['img_id'] not in used_img_ids:
+                used_img_ids.add(instance_info['img_id'])
+                image_list.append({
+                    'img_id': instance_info['img_id'],
+                    'img_path': instance_info['img_path'],
+                })
 
-        data_list = sorted(data_list, key=lambda x: x['id'])
-        return data_list
+        instance_list = sorted(instance_list, key=lambda x: x['id'])
+        return instance_list, image_list
```

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/body/ochuman_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/body/ochuman_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/body/posetrack18_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/body/posetrack18_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/body/posetrack18_video_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/body/posetrack18_video_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/face/aflw_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/face/aflw_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/face/coco_wholebody_face_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/face/coco_wholebody_face_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/face/cofw_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/face/cofw_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/face/face_300w_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/face/face_300w_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/face/wflw_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/face/wflw_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/fashion/deepfashion_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/fashion/deepfashion_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/hand/coco_wholebody_hand_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/hand/coco_wholebody_hand_dataset.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 import os.path as osp
-from typing import List
+from typing import List, Tuple
 
 import numpy as np
 from mmengine.utils import check_file_exist
 from xtcocotools.coco import COCO
 
 from mmpose.registry import DATASETS
 from mmpose.structures.bbox import bbox_xywh2xyxy
@@ -80,35 +80,43 @@
             None img. The maximum extra number of cycles to get a valid
             image. Default: 1000.
     """
 
     METAINFO: dict = dict(
         from_file='configs/_base_/datasets/coco_wholebody_hand.py')
 
-    def _load_annotations(self) -> List[dict]:
+    def _load_annotations(self) -> Tuple[List[dict], List[dict]]:
         """Load data from annotations in COCO format."""
 
         check_file_exist(self.ann_file)
 
         coco = COCO(self.ann_file)
-        data_list = []
+        instance_list = []
+        image_list = []
         id = 0
 
         for img_id in coco.getImgIds():
             img = coco.loadImgs(img_id)[0]
+
+            img.update({
+                'img_id':
+                img_id,
+                'img_path':
+                osp.join(self.data_prefix['img'], img['file_name']),
+            })
+            image_list.append(img)
+
             ann_ids = coco.getAnnIds(imgIds=img_id, iscrowd=False)
             anns = coco.loadAnns(ann_ids)
             for ann in anns:
                 for type in ['left', 'right']:
                     # filter invalid hand annotations, there might be two
                     # valid instances (left and right hand) in one image
                     if ann[f'{type}hand_valid'] and max(
                             ann[f'{type}hand_kpts']) > 0:
-                        img_path = osp.join(self.data_prefix['img'],
-                                            img['file_name'])
 
                         bbox_xywh = np.array(
                             ann[f'{type}hand_box'],
                             dtype=np.float32).reshape(1, 4)
 
                         bbox = bbox_xywh2xyxy(bbox_xywh)
 
@@ -116,24 +124,24 @@
                             ann[f'{type}hand_kpts'],
                             dtype=np.float32).reshape(1, -1, 3)
                         keypoints = _keypoints[..., :2]
                         keypoints_visible = np.minimum(1, _keypoints[..., 2])
 
                         num_keypoints = np.count_nonzero(keypoints.max(axis=2))
 
-                        data_info = {
+                        instance_info = {
                             'img_id': ann['image_id'],
-                            'img_path': img_path,
+                            'img_path': img['img_path'],
                             'bbox': bbox,
                             'bbox_score': np.ones(1, dtype=np.float32),
                             'num_keypoints': num_keypoints,
                             'keypoints': keypoints,
                             'keypoints_visible': keypoints_visible,
                             'iscrowd': ann['iscrowd'],
                             'segmentation': ann['segmentation'],
                             'id': id,
                         }
-                        data_list.append(data_info)
+                        instance_list.append(instance_info)
                         id = id + 1
 
-        data_list = sorted(data_list, key=lambda x: x['id'])
-        return data_list
+        instance_list = sorted(instance_list, key=lambda x: x['id'])
+        return instance_list, image_list
```

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/hand/freihand_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/hand/freihand_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/hand/onehand10k_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/hand/onehand10k_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/hand/panoptic_hand2d_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/hand/panoptic_hand2d_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/hand/rhd2d_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/hand/rhd2d_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/utils.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/utils.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/datasets/wholebody/halpe_dataset.py` & `mmpose-1.0.0rc1/mmpose/datasets/datasets/wholebody/halpe_dataset.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/transforms/__init__.py` & `mmpose-1.0.0rc1/mmpose/datasets/transforms/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,18 +1,19 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from .bottomup_transforms import (BottomupGetHeatmapMask, BottomupRandomAffine,
                                   BottomupResize)
 from .common_transforms import (Albumentation, GenerateTarget,
                                 GetBBoxCenterScale, PhotometricDistortion,
                                 RandomBBoxTransform, RandomFlip,
                                 RandomHalfBody)
+from .converting import KeypointConverter
 from .formatting import PackPoseInputs
 from .loading import LoadImage
 from .topdown_transforms import TopdownAffine
 
 __all__ = [
     'GetBBoxCenterScale', 'RandomBBoxTransform', 'RandomFlip',
     'RandomHalfBody', 'TopdownAffine', 'Albumentation',
     'PhotometricDistortion', 'PackPoseInputs', 'LoadImage',
     'BottomupGetHeatmapMask', 'BottomupRandomAffine', 'BottomupResize',
-    'GenerateTarget'
+    'GenerateTarget', 'KeypointConverter'
 ]
```

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/transforms/bottomup_transforms.py` & `mmpose-1.0.0rc1/mmpose/datasets/transforms/bottomup_transforms.py`

 * *Files 8% similar despite different names*

```diff
@@ -160,14 +160,16 @@
         shift_prob (float): Probability of applying random shift. Defaults to
             1.0
         scale_factor (Tuple[float, float]): Randomly resize the image in range
             :math:`[scale_factor[0], scale_factor[1]]`. Defaults to
             (0.75, 1.5)
         scale_prob (float): Probability of applying random resizing. Defaults
             to 1.0
+        scale_type (str): wrt ``long`` or ``short`` length of the image.
+            Defaults to ``short``
         rotate_factor (float): Randomly rotate the bbox in
             :math:`[-rotate_factor, rotate_factor]` in degrees. Defaults
             to 40.0
         use_udp (bool): Whether use unbiased data processing. See
             `UDP (CVPR 2020)`_ for details. Defaults to ``False``
 
     .. _`UDP (CVPR 2020)`: https://arxiv.org/abs/1911.07524
@@ -175,52 +177,62 @@
 
     def __init__(self,
                  input_size: Tuple[int, int],
                  shift_factor: float = 0.2,
                  shift_prob: float = 1.,
                  scale_factor: Tuple[float, float] = (0.75, 1.5),
                  scale_prob: float = 1.,
+                 scale_type: str = 'short',
                  rotate_factor: float = 30.,
                  rotate_prob: float = 1,
                  use_udp: bool = False) -> None:
         super().__init__()
 
         self.input_size = input_size
         self.shift_factor = shift_factor
         self.shift_prob = shift_prob
         self.scale_factor = scale_factor
         self.scale_prob = scale_prob
+        self.scale_type = scale_type
         self.rotate_factor = rotate_factor
         self.rotate_prob = rotate_prob
         self.use_udp = use_udp
 
     @staticmethod
     def _truncnorm(low: float = -1.,
                    high: float = 1.,
                    size: tuple = ()) -> np.ndarray:
         """Sample from a truncated normal distribution."""
         return truncnorm.rvs(low, high, size=size).astype(np.float32)
 
-    @staticmethod
-    def _fix_aspect_ratio(scale: np.ndarray, aspect_ratio: float):
+    def _fix_aspect_ratio(self, scale: np.ndarray, aspect_ratio: float):
         """Extend the scale to match the given aspect ratio.
 
         Args:
             scale (np.ndarray): The image scale (w, h) in shape (2, )
             aspect_ratio (float): The ratio of ``w/h``
 
         Returns:
             np.ndarray: The reshaped image scale in (2, )
         """
         w, h = scale
         if w > h * aspect_ratio:
-            _w, _h = w, w / aspect_ratio
+            if self.scale_type == 'long':
+                _w, _h = w, w / aspect_ratio
+            elif self.scale_type == 'short':
+                _w, _h = h * aspect_ratio, h
+            else:
+                raise ValueError(f'Unknown scale type: {self.scale_type}')
         else:
-            _w, _h = h * aspect_ratio, h
-
+            if self.scale_type == 'short':
+                _w, _h = w, w / aspect_ratio
+            elif self.scale_type == 'long':
+                _w, _h = h * aspect_ratio, h
+            else:
+                raise ValueError(f'Unknown scale type: {self.scale_type}')
         return np.array([_w, _h], dtype=scale.dtype)
 
     @cache_randomness
     def _get_transform_params(self) -> Tuple:
         """Get random transform parameters.
 
         Returns:
@@ -234,16 +246,16 @@
             offset = self._truncnorm(size=(2, )) * self.shift_factor
         else:
             offset = np.zeros((2, ), dtype=np.float32)
 
         # get scale
         if np.random.rand() < self.scale_prob:
             scale_min, scale_max = self.scale_factor
-            scale = scale_min + (scale_max -
-                                 scale_min) * self._truncnorm(size=(1, ))
+            scale = scale_min + (scale_max - scale_min) * (
+                self._truncnorm(size=(1, )) + 1) / 2
         else:
             scale = np.ones(1, dtype=np.float32)
 
         # get rotation
         if np.random.rand() < self.rotate_prob:
             rotate = self._truncnorm() * self.rotate_factor
         else:
@@ -295,14 +307,20 @@
             results['img'], warp_mat, (int(w), int(h)), flags=cv2.INTER_LINEAR)
 
         if 'keypoints' in results:
             # Only transform (x, y) coordinates
             results['keypoints'][..., :2] = cv2.transform(
                 results['keypoints'][..., :2], warp_mat)
 
+        if 'bbox' in results:
+            bbox = np.tile(results['bbox'], 2).reshape(-1, 4, 2)
+            # corner order: left_top, left_bottom, right_top, right_bottom
+            bbox[:, 1:3, 0] = bbox[:, 0:2, 0]
+            results['bbox'] = cv2.transform(bbox, warp_mat).reshape(-1, 8)
+
         results['input_size'] = self.input_size
         results['warp_mat'] = warp_mat
 
         return results
 
 
 @TRANSFORMS.register_module()
@@ -310,38 +328,40 @@
     """Resize the image to the input size of the model. Optionally, the image
     can be resized to multiple sizes to build a image pyramid for multi-scale
     inference.
 
     Required Keys:
 
         - img
-        - img_shape
+        - ori_shape
 
     Modified Keys:
 
         - img
+        - img_shape
 
     Added Keys:
 
         - input_size
-
+        - warp_mat
+        - aug_scale
 
     Args:
         input_size (Tuple[int, int]): The input size of the model in [w, h].
             Note that the actually size of the resized image will be affected
             by ``resize_mode`` and ``size_factor``, thus may not exactly equals
             to the ``input_size``
-        aux_scales (List[float], optional): The auxiliary input scales for
+        aug_scales (List[float], optional): The extra input scales for
             multi-scale testing. If given, the input image will be resized
             to different scales to build a image pyramid. And heatmaps from
             all scales will be aggregated to make final prediction. Defaults
             to ``None``
         size_factor (int): The actual input size will be ceiled to
                 a multiple of the `size_factor` value at both sides.
-                Defaults to 8
+                Defaults to 16
         resize_mode (str): The method to resize the image to the input size.
             Options are:
 
                 - ``'fit'``: The image will be resized according to the
                     relatively longer side with the aspect ratio kept. The
                     resized image will entirely fits into the range of the
                     input size
@@ -353,79 +373,81 @@
             `UDP (CVPR 2020)`_ for details. Defaults to ``False``
 
     .. _`UDP (CVPR 2020)`: https://arxiv.org/abs/1911.07524
     """
 
     def __init__(self,
                  input_size: Tuple[int, int],
-                 aux_scales: Optional[List[float]] = None,
-                 size_factor: int = 8,
+                 aug_scales: Optional[List[float]] = None,
+                 size_factor: int = 32,
                  resize_mode: str = 'fit',
                  use_udp: bool = False):
         super().__init__()
 
         self.input_size = input_size
-        self.aux_scales = aux_scales
+        self.aug_scales = aug_scales
         self.resize_mode = resize_mode
         self.size_factor = size_factor
         self.use_udp = use_udp
 
     @staticmethod
     def _ceil_to_multiple(size: Tuple[int, int], base: int):
         """Ceil the given size (tuple of [w, h]) to a multiple of the base."""
         return tuple(int(np.ceil(s / base) * base) for s in size)
 
-    def _get_actual_size(self, img_size: Tuple[int, int],
-                         input_size: Tuple[int, int]) -> Tuple:
-        """Calculate the actual input size and the size of the resized image.
+    def _get_input_size(self, img_size: Tuple[int, int],
+                        input_size: Tuple[int, int]) -> Tuple:
+        """Calculate the actual input size (which the original image will be
+        resized to) and the padded input size (which the resized image will be
+        padded to, or which is the size of the model input).
 
         Args:
             img_size (Tuple[int, int]): The original image size in [w, h]
             input_size (Tuple[int, int]): The expected input size in [w, h]
 
         Returns:
             tuple:
-            - actual_input_size (Tuple[int, int]): The target size to generate
+            - actual_input_size (Tuple[int, int]): The target size to resize
+                the image
+            - padded_input_size (Tuple[int, int]): The target size to generate
                 the model input which will contain the resized image
-            - actual_img_size (Tuple[int, int]): The target size to resize the
-                image
         """
         img_w, img_h = img_size
         ratio = img_w / img_h
 
         if self.resize_mode == 'fit':
-            actual_input_size = self._ceil_to_multiple(input_size,
+            padded_input_size = self._ceil_to_multiple(input_size,
                                                        self.size_factor)
-            if actual_input_size != input_size:
+            if padded_input_size != input_size:
                 raise ValueError(
                     'When ``resize_mode==\'fit\', the input size (height and'
                     ' width) should be mulitples of the size_factor('
                     f'{self.size_factor}) at all scales. Got invalid input '
                     f'size {input_size}.')
 
-            tgt_w, tgt_h = actual_input_size
-            rsz_w = min(tgt_w, tgt_h * ratio)
-            rsz_h = min(tgt_h, tgt_w / ratio)
-            actual_img_size = (rsz_w, rsz_h)
+            pad_w, pad_h = padded_input_size
+            rsz_w = min(pad_w, pad_h * ratio)
+            rsz_h = min(pad_h, pad_w / ratio)
+            actual_input_size = (rsz_w, rsz_h)
 
         elif self.resize_mode == 'expand':
-            _actual_input_size = self._ceil_to_multiple(
+            _padded_input_size = self._ceil_to_multiple(
                 input_size, self.size_factor)
-            tgt_w, tgt_h = _actual_input_size
-            rsz_w = max(tgt_w, tgt_h * ratio)
-            rsz_h = max(tgt_h, tgt_w / ratio)
+            pad_w, pad_h = _padded_input_size
+            rsz_w = max(pad_w, pad_h * ratio)
+            rsz_h = max(pad_h, pad_w / ratio)
 
-            actual_img_size = (rsz_w, rsz_h)
-            actual_input_size = self._ceil_to_multiple(actual_img_size,
+            actual_input_size = (rsz_w, rsz_h)
+            padded_input_size = self._ceil_to_multiple(actual_input_size,
                                                        self.size_factor)
 
         else:
             raise ValueError(f'Invalid resize mode {self.resize_mode}')
 
-        return actual_input_size, actual_img_size
+        return actual_input_size, padded_input_size
 
     def transform(self, results: Dict) -> Optional[dict]:
         """The transform function of :class:`BottomupResize` to perform
         photometric distortion on images.
 
         See ``transform()`` method of :class:`BaseTransform` for details.
 
@@ -434,61 +456,62 @@
             results (dict): Result dict from the data pipeline.
 
         Returns:
             dict: Result dict with images distorted.
         """
 
         img = results['img']
-        img_h, img_w = results['img_shape']
+        img_h, img_w = results['ori_shape']
         w, h = self.input_size
 
         input_sizes = [(w, h)]
-        if self.aux_scales:
-            input_sizes += [(int(w * s), int(h * s)) for s in self.aux_scales]
+        if self.aug_scales:
+            input_sizes += [(int(w * s), int(h * s)) for s in self.aug_scales]
 
         imgs = []
-        warp_mats = []
-        actual_input_sizes = []
-        actual_img_sizes = []
-
-        for _w, _h in input_sizes:
+        for i, (_w, _h) in enumerate(input_sizes):
 
-            actual_input_size, actual_img_size = self._get_actual_size(
+            actual_input_size, padded_input_size = self._get_input_size(
                 img_size=(img_w, img_h), input_size=(_w, _h))
 
             if self.use_udp:
                 center = np.array([(img_w - 1.0) / 2, (img_h - 1.0) / 2],
                                   dtype=np.float32)
                 scale = np.array([img_w, img_h], dtype=np.float32)
                 warp_mat = get_udp_warp_matrix(
                     center=center,
                     scale=scale,
                     rot=0,
-                    output_size=actual_img_size)
+                    output_size=actual_input_size)
             else:
                 center = np.array([img_w / 2, img_h / 2], dtype=np.float32)
-                scale = np.array([img_w, img_h], dtype=np.float32)
+                scale = np.array([
+                    img_w * padded_input_size[0] / actual_input_size[0],
+                    img_h * padded_input_size[1] / actual_input_size[1]
+                ],
+                                 dtype=np.float32)
                 warp_mat = get_warp_matrix(
                     center=center,
                     scale=scale,
                     rot=0,
-                    output_size=actual_img_size)
+                    output_size=padded_input_size)
 
             _img = cv2.warpAffine(
-                img, warp_mat, actual_input_size, flags=cv2.INTER_LINEAR)
+                img, warp_mat, padded_input_size, flags=cv2.INTER_LINEAR)
 
             imgs.append(_img)
-            warp_mats.append(warp_mat)
-            actual_input_sizes.append(actual_input_size)
-            actual_img_sizes.append(actual_img_size)
 
-        if self.aux_scales:
+            # Store the transform information w.r.t. the main input size
+            if i == 0:
+                results['img_shape'] = padded_input_size[::-1]
+                results['input_center'] = center
+                results['input_scale'] = scale
+                results['input_size'] = padded_input_size
+
+        if self.aug_scales:
             results['img'] = imgs
+            results['aug_scales'] = self.aug_scales
         else:
             results['img'] = imgs[0]
-
-        # Store the transform information w.r.t. the main input size
-        results['warp_mat'] = warp_mats[0]
-        results['input_size'] = actual_input_sizes[0]
-        results['img_size'] = actual_img_sizes[0]
+            results['aug_scale'] = None
 
         return results
```

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/transforms/common_transforms.py` & `mmpose-1.0.0rc1/mmpose/datasets/transforms/common_transforms.py`

 * *Files 6% similar despite different names*

```diff
@@ -6,14 +6,15 @@
 import mmcv
 import mmengine
 import numpy as np
 from mmcv.image import imflip
 from mmcv.transforms import BaseTransform
 from mmcv.transforms.utils import avoid_cache_randomness, cache_randomness
 from mmengine import is_list_of
+from mmengine.dist import get_dist_info
 from scipy.stats import truncnorm
 
 from mmpose.codecs import *  # noqa: F401, F403
 from mmpose.registry import KEYPOINT_CODECS, TRANSFORMS
 from mmpose.structures.bbox import bbox_xyxy2cs, flip_bbox
 from mmpose.structures.keypoint import flip_keypoints
 from mmpose.utils.typing import MultiConfig
@@ -92,14 +93,15 @@
     """Randomly flip the image, bbox and keypoints.
 
     Required Keys:
 
         - img
         - img_shape
         - flip_indices
+        - input_size (optional)
         - bbox (optional)
         - bbox_center (optional)
         - keypoints (optional)
         - keypoints_visible (optional)
         - img_mask (optional)
 
     Modified Keys:
@@ -197,15 +199,15 @@
         if flip_dir is None:
             results['flip'] = False
             results['flip_direction'] = None
         else:
             results['flip'] = True
             results['flip_direction'] = flip_dir
 
-            h, w = results['img_shape']
+            h, w = results.get('input_size', results['img_shape'])
             # flip image and mask
             if isinstance(results['img'], list):
                 results['img'] = [
                     imflip(img, direction=flip_dir) for img in results['img']
                 ]
             else:
                 results['img'] = imflip(results['img'], direction=flip_dir)
@@ -614,15 +616,14 @@
 
         if not keymap:
             self.keymap_to_albu = {
                 'img': 'image',
             }
         else:
             self.keymap_to_albu = keymap
-        self.keymap_back = {v: k for k, v in self.keymap_to_albu.items()}
 
     def albu_builder(self, cfg: dict) -> albumentations:
         """Import a module from albumentations.
 
         It resembles some of :func:`build_from_cfg` logic.
 
         Args:
@@ -635,64 +636,57 @@
         assert isinstance(cfg, dict) and 'type' in cfg
         args = cfg.copy()
 
         obj_type = args.pop('type')
         if mmengine.is_str(obj_type):
             if albumentations is None:
                 raise RuntimeError('albumentations is not installed')
-            if not hasattr(albumentations.augmentations.transforms, obj_type):
-                warnings.warn('{obj_type} is not pixel-level transformations. '
-                              'Please use with caution.')
+            rank, _ = get_dist_info()
+            if rank == 0 and not hasattr(
+                    albumentations.augmentations.transforms, obj_type):
+                warnings.warn(
+                    f'{obj_type} is not pixel-level transformations. '
+                    'Please use with caution.')
             obj_cls = getattr(albumentations, obj_type)
         else:
             raise TypeError(f'type must be a str, but got {type(obj_type)}')
 
         if 'transforms' in args:
             args['transforms'] = [
                 self.albu_builder(transform)
                 for transform in args['transforms']
             ]
 
         return obj_cls(**args)
 
-    @staticmethod
-    def mapper(d: dict, keymap: dict) -> dict:
-        """Dictionary mapper.
-
-        Renames keys according to keymap provided.
-
-        Args:
-            d (dict): old dict
-            keymap (dict): key mapping like {'old_key': 'new_key'}.
-
-        Returns:
-            dict: new dict.
-        """
-
-        updated_dict = {keymap.get(k, k): v for k, v in d.items()}
-        return updated_dict
-
     def transform(self, results: dict) -> dict:
         """The transform function of :class:`Albumentation` to apply
         albumentations transforms.
 
         See ``transform()`` method of :class:`BaseTransform` for details.
 
         Args:
             results (dict): Result dict from the data pipeline.
 
         Return:
             dict: updated result dict.
         """
         # map result dict to albumentations format
-        results = self.mapper(results, self.keymap_to_albu)
+        results_albu = {}
+        for k, v in self.keymap_to_albu.items():
+            assert k in results, \
+                f'The `{k}` is required to perform albumentations transforms'
+            results_albu[v] = results[k]
+
         # Apply albumentations transforms
-        results = self.aug(**results)
-        # map result dict back to the original format
-        results = self.mapper(results, self.keymap_back)
+        results_albu = self.aug(**results_albu)
+
+        # map the albu results back to the original format
+        for k, v in self.keymap_to_albu.items():
+            results[k] = results_albu[v]
 
         return results
 
     def __repr__(self) -> str:
         """print the basic information of the transform.
 
         Returns:
@@ -880,138 +874,166 @@
 
     Required Keys:
 
         - keypoints
         - keypoints_visible
         - dataset_keypoint_weights
 
-    Added Keys (depends on the args):
-        - heatmaps
-        - keypoint_labels
-        - keypoint_x_labels
-        - keypoint_y_labels
-        - keypoint_weights
+    Added Keys:
+
+        - The keys of the encoded items from the codec will be updated into
+            the results, e.g. ``'heatmaps'`` or ``'keypoint_weights'``. See
+            the specific codec for more details.
 
     Args:
-        encoder (dict | list[dict]): The codec config for keypoint encoding
-        target_type (str): The type of the encoded form of the keypoints.
-            Should be one of the following options:
-
-            - ``'heatmap'``: The encoded should be instance-irrelevant
-                heatmaps and will be stored in ``results['heatmaps']``
-            - ``'multilevel_heatmap'`` The encoded should be a list of
-                heatmaps and will be stored in ``results['heatmaps']``.
-                Note that in this case, ``self.encoder`` should also be
-                a list, and each encoder encodes a single-level heatmaps.
-            - ``'keypoint_label'``: The encoded should be instance-level
-                labels and will be stored in ``results['keypoint_label']``
-            - ``'keypoint_xy_label'``: The encoed should be instance-level
-                labels in x-axis and y-axis respectively. They will be stored
-                in ``results['keypoint_x_label']`` and
-                ``results['keypoint_y_label']``
-            - ``'heatmap+keypoint_label'``: The encoded should be heatmaps and
-                keypoint_labels, will be stored in ``results['heatmaps']``
-                and ``results['keypoint_label']``
+        encoder (dict | list[dict]): The codec config for keypoint encoding.
+            Both single encoder and multiple encoders (given as a list) are
+            supported
+        multilevel (bool): Determine the method to handle multiple encoders.
+            If ``multilevel==True``, generate multilevel targets from a group
+            of encoders of the same type (e.g. multiple :class:`MSRAHeatmap`
+            encoders with different sigma values); If ``multilevel==False``,
+            generate combined targets from a group of different encoders. This
+            argument will have no effect in case of single encoder. Defaults
+            to ``False``
         use_dataset_keypoint_weights (bool): Whether use the keypoint weights
             from the dataset meta information. Defaults to ``False``
+        target_type (str, deprecated): This argument is deprecated and has no
+            effect. Defaults to ``None``
     """
 
     def __init__(self,
                  encoder: MultiConfig,
-                 target_type: str,
+                 target_type: Optional[str] = None,
+                 multilevel: bool = False,
                  use_dataset_keypoint_weights: bool = False) -> None:
         super().__init__()
+
+        if target_type is not None:
+            warnings.warn(
+                'The argument `target_type` is deprecated in GenerateTarget. '
+                'The target type and encoded keys will be determined by '
+                'encoder(s).', DeprecationWarning)
+
         self.encoder_cfg = deepcopy(encoder)
-        self.target_type = target_type
+        self.multilevel = multilevel
         self.use_dataset_keypoint_weights = use_dataset_keypoint_weights
 
-        if self.target_type == 'multilevel_heatmap':
-            if not isinstance(self.encoder_cfg, list):
-                raise ValueError(
-                    'The encoder should be a list if target type is '
-                    '"multilevel_heatmap"')
+        if isinstance(self.encoder_cfg, list):
             self.encoder = [
                 KEYPOINT_CODECS.build(cfg) for cfg in self.encoder_cfg
             ]
         else:
+            assert not self.multilevel, (
+                'Need multiple encoder configs if ``multilevel==True``')
             self.encoder = KEYPOINT_CODECS.build(self.encoder_cfg)
 
     def transform(self, results: Dict) -> Optional[dict]:
+        """The transform function of :class:`GenerateTarget`.
+
+        See ``transform()`` method of :class:`BaseTransform` for details.
+        """
 
         if results.get('transformed_keypoints', None) is not None:
             # use keypoints transformed by TopdownAffine
             keypoints = results['transformed_keypoints']
         elif results.get('keypoints', None) is not None:
             # use original keypoints
             keypoints = results['keypoints']
         else:
             raise ValueError(
                 'GenerateTarget requires \'transformed_keypoints\' or'
                 ' \'keypoints\' in the results.')
 
         keypoints_visible = results['keypoints_visible']
 
-        if self.target_type == 'heatmap':
-            heatmaps, keypoint_weights = self.encoder.encode(
-                keypoints=keypoints, keypoints_visible=keypoints_visible)
-
-            results['heatmaps'] = heatmaps
-            results['keypoint_weights'] = keypoint_weights
-
-        elif self.target_type == 'keypoint_label':
-            keypoint_labels, keypoint_weights = self.encoder.encode(
-                keypoints=keypoints, keypoints_visible=keypoints_visible)
-
-            results['keypoint_labels'] = keypoint_labels
-            results['keypoint_weights'] = keypoint_weights
-
-        elif self.target_type == 'keypoint_xy_label':
-            x_labels, y_labels, keypoint_weights = self.encoder.encode(
-                keypoints=keypoints, keypoints_visible=keypoints_visible)
-
-            results['keypoint_x_labels'] = x_labels
-            results['keypoint_y_labels'] = y_labels
-            results['keypoint_weights'] = keypoint_weights
-
-        elif self.target_type == 'heatmap+keypoint_label':
-            heatmaps, keypoint_labels, keypoint_weights = self.encoder.encode(
-                keypoints=keypoints, keypoints_visible=keypoints_visible)
-
-            results['heatmaps'] = heatmaps
-            results['keypoint_labels'] = keypoint_labels
-            results['keypoint_weights'] = keypoint_weights
-
-        elif self.target_type == 'multilevel_heatmap':
-            heatmaps = []
-            keypoint_weights = []
-
-            for encoder in self.encoder:
-                _heatmaps, _keypoint_weights = encoder.encode(
-                    keypoints=keypoints, keypoints_visible=keypoints_visible)
-                heatmaps.append(_heatmaps)
-                keypoint_weights.append(_keypoint_weights)
-
-            results['heatmaps'] = heatmaps
-            # keypoint_weights.shape: [N, K] -> [N, n, K]
-            results['keypoint_weights'] = np.stack(keypoint_weights, axis=1)
+        # Encoded items from the encoder(s) will be updated into the results.
+        # Please refer to the document of the specific codec for details about
+        # encoded items.
+        if not isinstance(self.encoder, list):
+            # For single encoding, the encoded items will be directly added
+            # into results.
+            auxiliary_encode_kwargs = {
+                key: results[key]
+                for key in self.encoder.auxiliary_encode_keys
+            }
+            encoded = self.encoder.encode(
+                keypoints=keypoints,
+                keypoints_visible=keypoints_visible,
+                **auxiliary_encode_kwargs)
 
         else:
-            raise ValueError(f'Invalid target type {self.target_type}')
+            encoded_list = []
+            for _encoder in self.encoder:
+                auxiliary_encode_kwargs = {
+                    key: results[key]
+                    for key in _encoder.auxiliary_encode_keys
+                }
+                encoded_list.append(
+                    _encoder.encode(
+                        keypoints=keypoints,
+                        keypoints_visible=keypoints_visible,
+                        **auxiliary_encode_kwargs))
+
+            if self.multilevel:
+                # For multilevel encoding, the encoded items from each encoder
+                # should have the same keys.
+
+                keys = encoded_list[0].keys()
+                if not all(_encoded.keys() == keys
+                           for _encoded in encoded_list):
+                    raise ValueError(
+                        'Encoded items from all encoders must have the same '
+                        'keys if ``multilevel==True``.')
+
+                encoded = {
+                    k: [_encoded[k] for _encoded in encoded_list]
+                    for k in keys
+                }
+
+            else:
+                # For combined encoding, the encoded items from different
+                # encoders should have no overlapping items, except for
+                # `keypoint_weights`. If multiple `keypoint_weights` are given,
+                # they will be multiplied as the final `keypoint_weights`.
+
+                encoded = dict()
+                keypoint_weights = []
+
+                for _encoded in encoded_list:
+                    for key, value in _encoded.items():
+                        if key == 'keypoint_weights':
+                            keypoint_weights.append(value)
+                        elif key not in encoded:
+                            encoded[key] = value
+                        else:
+                            raise ValueError(
+                                f'Overlapping item "{key}" from multiple '
+                                'encoders, which is not supported when '
+                                '``multilevel==False``')
+
+                if keypoint_weights:
+                    encoded['keypoint_weights'] = keypoint_weights
+
+        if self.use_dataset_keypoint_weights and 'keypoint_weights' in encoded:
+            if isinstance(encoded['keypoint_weights'], list):
+                for w in encoded['keypoint_weights']:
+                    w *= results['dataset_keypoint_weights']
+            else:
+                encoded['keypoint_weights'] *= results[
+                    'dataset_keypoint_weights']
 
-        # multiply meta keypoint weight
-        if self.use_dataset_keypoint_weights:
-            results['keypoint_weights'] *= results['dataset_keypoint_weights']
+        results.update(encoded)
 
         return results
 
     def __repr__(self) -> str:
         """print the basic information of the transform.
 
         Returns:
             str: Formatted string.
         """
         repr_str = self.__class__.__name__
         repr_str += (f'(encoder={str(self.encoder_cfg)}, ')
-        repr_str += (f'(target_type={str(self.target_type)}, ')
         repr_str += ('use_dataset_keypoint_weights='
                      f'{self.use_dataset_keypoint_weights})')
         return repr_str
```

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/transforms/formatting.py` & `mmpose-1.0.0rc1/mmpose/datasets/transforms/formatting.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from typing import Sequence, Union
 
 import numpy as np
 import torch
-from mmcv.transforms import BaseTransform, to_tensor
+from mmcv.transforms import BaseTransform
 from mmengine.structures import InstanceData, PixelData
 from mmengine.utils import is_seq_of
 
 from mmpose.registry import TRANSFORMS
 from mmpose.structures import MultilevelPixelData, PoseDataSample
 
 
@@ -23,16 +23,16 @@
     Returns:
         torch.Tensor: The output tensor.
     """
 
     if isinstance(img, np.ndarray):
         if len(img.shape) < 3:
             img = np.expand_dims(img, -1)
-        img = np.ascontiguousarray(img.transpose(2, 0, 1))
-        tensor = to_tensor(img)
+
+        tensor = torch.from_numpy(img).permute(2, 0, 1).contiguous()
     else:
         assert is_seq_of(img, np.ndarray)
         tensor = torch.stack([image_to_tensor(_img) for _img in img])
 
     return tensor
 
 
@@ -43,64 +43,86 @@
     The ``img_meta`` item is always populated. The contents of the
     ``img_meta`` dictionary depends on ``meta_keys``. By default it includes:
 
         - ``id``: id of the data sample
 
         - ``img_id``: id of the image
 
+        - ``'category_id'``: the id of the instance category
+
         - ``img_path``: path to the image file
 
+        - ``crowd_index`` (optional): measure the crowding level of an image,
+            defined in CrowdPose dataset
+
         - ``ori_shape``: original shape of the image as a tuple (h, w, c)
 
         - ``img_shape``: shape of the image input to the network as a tuple \
             (h, w).  Note that images may be zero padded on the \
             bottom/right if the batch tensor is larger than this shape.
 
         - ``input_size``: the input size to the network
 
         - ``flip``: a boolean indicating if image flip transform was used
 
         - ``flip_direction``: the flipping direction
 
         - ``flip_indices``: the indices of each keypoint's symmetric keypoint
 
+        - ``raw_ann_info`` (optional): raw annotation of the instance(s)
+
     Args:
         meta_keys (Sequence[str], optional): Meta keys which will be stored in
             :obj: `PoseDataSample` as meta info. Defaults to ``('id',
-            'img_id', 'img_path', 'ori_shape', 'img_shape', 'input_size',
-            'flip', 'flip_direction', 'flip_indices)``
+            'img_id', 'img_path', 'category_id', 'crowd_index, 'ori_shape',
+            'img_shape',, 'input_size', 'input_center', 'input_scale', 'flip',
+            'flip_direction', 'flip_indices', 'raw_ann_info')``
     """
 
     # items in `instance_mapping_table` will be directly packed into
-    # PoseDataSample without converting to Tensor
+    # PoseDataSample.gt_instances without converting to Tensor
     instance_mapping_table = {
         'bbox': 'bboxes',
         'head_size': 'head_size',
         'bbox_center': 'bbox_centers',
         'bbox_scale': 'bbox_scales',
         'bbox_score': 'bbox_scores',
         'keypoints': 'keypoints',
-        'keypoints_visible': 'keypoints_visible'
+        'keypoints_visible': 'keypoints_visible',
     }
 
+    # items in `label_mapping_table` will be packed into
+    # PoseDataSample.gt_instance_labels and converted to Tensor. These items
+    # will be used for computing losses
     label_mapping_table = {
         'keypoint_labels': 'keypoint_labels',
         'keypoint_x_labels': 'keypoint_x_labels',
         'keypoint_y_labels': 'keypoint_y_labels',
-        'keypoint_weights': 'keypoint_weights'
+        'keypoint_weights': 'keypoint_weights',
+        'instance_coords': 'instance_coords'
     }
 
+    # items in `field_mapping_table` will be packed into
+    # PoseDataSample.gt_fields and converted to Tensor. These items will be
+    # used for computing losses
     field_mapping_table = {
         'heatmaps': 'heatmaps',
+        'instance_heatmaps': 'instance_heatmaps',
+        'heatmap_mask': 'heatmap_mask',
+        'heatmap_weights': 'heatmap_weights',
+        'displacements': 'displacements',
+        'displacement_weights': 'displacement_weights',
     }
 
     def __init__(self,
-                 meta_keys=('id', 'img_id', 'img_path', 'ori_shape',
-                            'img_shape', 'input_size', 'flip',
-                            'flip_direction', 'flip_indices'),
+                 meta_keys=('id', 'img_id', 'img_path', 'category_id',
+                            'crowd_index', 'ori_shape', 'img_shape',
+                            'input_size', 'input_center', 'input_scale',
+                            'flip', 'flip_direction', 'flip_indices',
+                            'raw_ann_info'),
                  pack_transformed=False):
         self.meta_keys = meta_keys
         self.pack_transformed = pack_transformed
 
     def transform(self, results: dict) -> dict:
         """Method to pack the input data.
 
@@ -135,15 +157,24 @@
 
         data_sample.gt_instances = gt_instances
 
         # pack instance labels
         gt_instance_labels = InstanceData()
         for key, packed_key in self.label_mapping_table.items():
             if key in results:
-                gt_instance_labels.set_field(results[key], packed_key)
+                if isinstance(results[key], list):
+                    # A list of labels is usually generated by combined
+                    # multiple encoders (See ``GenerateTarget`` in
+                    # mmpose/datasets/transforms/common_transforms.py)
+                    # In this case, labels in list should have the same
+                    # shape and will be stacked.
+                    _labels = np.stack(results[key])
+                    gt_instance_labels.set_field(_labels, packed_key)
+                else:
+                    gt_instance_labels.set_field(results[key], packed_key)
         data_sample.gt_instance_labels = gt_instance_labels.to_tensor()
 
         # pack fields
         gt_fields = None
         for key, packed_key in self.field_mapping_table.items():
             if key in results:
                 if isinstance(results[key], list):
```

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/transforms/loading.py` & `mmpose-1.0.0rc1/mmpose/datasets/transforms/loading.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/datasets/transforms/topdown_transforms.py` & `mmpose-1.0.0rc1/mmpose/datasets/transforms/topdown_transforms.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/engine/hooks/visualization_hook.py` & `mmpose-1.0.0rc1/mmpose/engine/hooks/visualization_hook.py`

 * *Files 3% similar despite different names*

```diff
@@ -92,19 +92,22 @@
         self._visualizer.set_dataset_meta(runner.val_evaluator.dataset_meta)
 
         # There is no guarantee that the same batch of images
         # is visualized for each evaluation.
         total_curr_iter = runner.iter + batch_idx
 
         # Visualize only the first data
-        img_path = data_batch[0]['data_sample'].get('img_path')
+        img_path = data_batch['data_samples'][0].get('img_path')
         img_bytes = self.file_client.get(img_path)
         img = mmcv.imfrombytes(img_bytes, channel_order='rgb')
-
         data_sample = outputs[0]
+
+        # revert the heatmap on the original image
+        data_sample = merge_data_samples([data_sample])
+
         if total_curr_iter % self.interval == 0:
             self._visualizer.add_datasample(
                 os.path.basename(img_path) if self.show else 'val_img',
                 img,
                 data_sample=data_sample,
                 draw_gt=False,
                 draw_bbox=True,
@@ -143,15 +146,16 @@
             img_path = data_sample.get('img_path')
             img_bytes = self.file_client.get(img_path)
             img = mmcv.imfrombytes(img_bytes, channel_order='rgb')
             data_sample = merge_data_samples([data_sample])
 
             out_file = None
             if self.out_dir is not None:
-                out_file_name, postfix = os.path.basename(img_path).split('.')
+                out_file_name, postfix = os.path.basename(img_path).rsplit(
+                    '.', 1)
                 index = len([
                     fname for fname in os.listdir(self.out_dir)
                     if fname.startswith(out_file_name)
                 ])
                 out_file = f'{out_file_name}_{index}.{postfix}'
                 out_file = os.path.join(self.out_dir, out_file)
```

### Comparing `mmpose-1.0.0rc0/mmpose/evaluation/functional/__init__.py` & `mmpose-1.0.0rc1/mmpose/evaluation/functional/__init__.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/evaluation/functional/keypoint_eval.py` & `mmpose-1.0.0rc1/mmpose/evaluation/functional/keypoint_eval.py`

 * *Files 1% similar despite different names*

```diff
@@ -270,15 +270,15 @@
         - int: Number of valid keypoints.
     """
     pred_x, pred_y = output
     gt_x, gt_y = target
 
     N, _, Wx = pred_x.shape
     _, _, Wy = pred_y.shape
-    H, W = int(Wx / simcc_split_ratio), int(Wy / simcc_split_ratio)
+    W, H = int(Wx / simcc_split_ratio), int(Wy / simcc_split_ratio)
 
     if normalize is None:
         normalize = np.tile(np.array([[H, W]]), (N, 1))
 
     pred_coords, _ = get_simcc_maximum(pred_x, pred_y)
     pred_coords /= simcc_split_ratio
     gt_coords, _ = get_simcc_maximum(gt_x, gt_y)
```

### Comparing `mmpose-1.0.0rc0/mmpose/evaluation/metrics/coco_metric.py` & `mmpose-1.0.0rc1/mmpose/evaluation/metrics/coco_metric.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,9 @@
 # Copyright (c) OpenMMLab. All rights reserved.
+import datetime
 import os.path as osp
 import tempfile
 from collections import OrderedDict, defaultdict
 from typing import Dict, Optional, Sequence
 
 import numpy as np
 from mmengine.evaluator import BaseMetric
@@ -13,31 +14,33 @@
 
 from mmpose.registry import METRICS
 from ..functional import oks_nms, soft_oks_nms
 
 
 @METRICS.register_module()
 class CocoMetric(BaseMetric):
-    """COCO evaluation metric.
+    """COCO pose estimation task evaluation metric.
 
     Evaluate AR, AP, and mAP for keypoint detection tasks. Support COCO
     dataset and other datasets in COCO format. Please refer to
     `COCO keypoint evaluation <https://cocodataset.org/#keypoints-eval>`__
     for more details.
 
     Args:
-        ann_file (str): Path to the coco format annotation file.
+        ann_file (str, optional): Path to the coco format annotation file.
+            If not specified, ground truth annotations from the dataset will
+            be converted to coco format. Defaults to None
         use_area (bool): Whether to use ``'area'`` message in the annotations.
             If the ground truth annotations (e.g. CrowdPose, AIC) do not have
             the field ``'area'``, please set ``use_area=False``.
-            Default: ``True``.
+            Defaults to ``True``
         iou_type (str): The same parameter as `iouType` in
             :class:`xtcocotools.COCOeval`, which can be ``'keypoints'``, or
             ``'keypoints_crowd'`` (used in CrowdPose dataset).
-            Defaults to ``'keypoints'``.
+            Defaults to ``'keypoints'``
         score_mode (str): The mode to score the prediction results which
             should be one of the following options:
 
                 - ``'bbox'``: Take the score of bbox as the score of the
                     prediction results.
                 - ``'bbox_keypoint'``: Use keypoint score to rescore the
                     prediction results.
@@ -64,49 +67,53 @@
             used in NMS when ``nms_mode`` is ``'oks_nms'`` or
             ``'soft_oks_nms'``. Will retain the prediction results with OKS
             lower than ``nms_thr``. Defaults to ``0.9``
         format_only (bool): Whether only format the output results without
             doing quantitative evaluation. This is designed for the need of
             test submission when the ground truth annotations are absent. If
             set to ``True``, ``outfile_prefix`` should specify the path to
-            store the output results. Default: ``False``.
+            store the output results. Defaults to ``False``
         outfile_prefix (str | None): The prefix of json files. It includes
             the file path and the prefix of filename, e.g., ``'a/b/prefix'``.
-            If not specified, a temp file will be created. Default: ``None``.
+            If not specified, a temp file will be created. Defaults to ``None``
         collect_device (str): Device name used for collecting results from
             different ranks during distributed training. Must be ``'cpu'`` or
-            ``'gpu'``. Default: ``'cpu'``.
+            ``'gpu'``. Defaults to ``'cpu'``
         prefix (str, optional): The prefix that will be added in the metric
             names to disambiguate homonymous metrics of different evaluators.
             If prefix is not provided in the argument, ``self.default_prefix``
-            will be used instead. Default: ``None``.
+            will be used instead. Defaults to ``None``
     """
     default_prefix: Optional[str] = 'coco'
 
     def __init__(self,
-                 ann_file: str,
+                 ann_file: Optional[str] = None,
                  use_area: bool = True,
                  iou_type: str = 'keypoints',
                  score_mode: str = 'bbox_keypoint',
                  keypoint_score_thr: float = 0.2,
                  nms_mode: str = 'oks_nms',
                  nms_thr: float = 0.9,
                  format_only: bool = False,
                  outfile_prefix: Optional[str] = None,
                  collect_device: str = 'cpu',
                  prefix: Optional[str] = None) -> None:
         super().__init__(collect_device=collect_device, prefix=prefix)
-        # initialize coco helper with the annotation json file
         self.ann_file = ann_file
-        self.coco = COCO(ann_file)
+        # initialize coco helper with the annotation json file
+        # if ann_file is not specified, initialize with the converted dataset
+        if ann_file is not None:
+            self.coco = COCO(ann_file)
+        else:
+            self.coco = None
 
         self.use_area = use_area
         self.iou_type = iou_type
 
-        allowed_score_modes = ['bbox', 'bbox_keypoint', 'bbox_rle']
+        allowed_score_modes = ['bbox', 'bbox_keypoint', 'bbox_rle', 'keypoint']
         if score_mode not in allowed_score_modes:
             raise ValueError(
                 "`score_mode` should be one of 'bbox', 'bbox_keypoint', "
                 f"'bbox_rle', but got {score_mode}")
         self.score_mode = score_mode
         self.keypoint_score_thr = keypoint_score_thr
 
@@ -119,21 +126,21 @@
         self.nms_thr = nms_thr
 
         if format_only:
             assert outfile_prefix is not None, '`outfile_prefix` can not be '\
                 'None when `format_only` is True, otherwise the result file '\
                 'will be saved to a temp directory which will be cleaned up '\
                 'in the end.'
-        else:
+        elif ann_file is not None:
             # do evaluation only if the ground truth annotations exist
             assert 'annotations' in load(ann_file), \
                 'Ground truth annotations are required for evaluation '\
                 'when `format_only` is False.'
-        self.format_only = format_only
 
+        self.format_only = format_only
         self.outfile_prefix = outfile_prefix
 
     def process(self, data_batch: Sequence[dict],
                 data_samples: Sequence[dict]) -> None:
         """Process one batch of data samples and predictions. The processed
         results should be stored in ``self.results``, which will be used to
         compute the metrics when all batches have been processed.
@@ -159,66 +166,207 @@
             # for topdown-style output, N is usually 1, while for
             # bottomup-style output, N is the number of instances in the image
             keypoints = data_sample['pred_instances']['keypoints']
             # [N, K], the scores for all keypoints of all instances
             keypoint_scores = data_sample['pred_instances']['keypoint_scores']
             assert keypoint_scores.shape == keypoints.shape[:2]
 
-            result = dict()
-            result['id'] = data_sample['id']
-            result['img_id'] = data_sample['img_id']
-            result['keypoints'] = keypoints
-            result['keypoint_scores'] = keypoint_scores
-            result['bbox_scores'] = data_sample['gt_instances']['bbox_scores']
+            # parse prediction results
+            pred = dict()
+            pred['id'] = data_sample['id']
+            pred['img_id'] = data_sample['img_id']
+            pred['keypoints'] = keypoints
+            pred['keypoint_scores'] = keypoint_scores
+            pred['category_id'] = data_sample.get('category_id', 1)
+
+            if ('bbox_scores' not in data_sample['gt_instances']
+                    or len(data_sample['gt_instances']['bbox_scores']) !=
+                    len(keypoints)):
+                # bottom-up models might output different number of
+                # instances from annotation
+                bbox_scores = np.ones(len(keypoints))
+            else:
+                bbox_scores = data_sample['gt_instances']['bbox_scores']
+            pred['bbox_scores'] = bbox_scores
 
             # get area information
             if 'bbox_scales' in data_sample['gt_instances']:
-                result['areas'] = np.prod(
+                pred['areas'] = np.prod(
                     data_sample['gt_instances']['bbox_scales'], axis=1)
+
+            # parse gt
+            gt = dict()
+            if self.coco is None:
+                gt['width'] = data_sample['ori_shape'][1]
+                gt['height'] = data_sample['ori_shape'][0]
+                gt['img_id'] = data_sample['img_id']
+                if self.iou_type == 'keypoints_crowd':
+                    assert 'crowd_index' in data_sample, \
+                        '`crowd_index` is required when `self.iou_type` is ' \
+                        '`keypoints_crowd`'
+                    gt['crowd_index'] = data_sample['crowd_index']
+                assert 'raw_ann_info' in data_sample, \
+                    'The row ground truth annotations are required for ' \
+                    'evaluation when `ann_file` is not provided'
+                anns = data_sample['raw_ann_info']
+                gt['raw_ann_info'] = anns if isinstance(anns, list) else [anns]
+
             # add converted result to the results list
-            self.results.append(result)
+            self.results.append((pred, gt))
+
+    def gt_to_coco_json(self, gt_dicts: Sequence[dict],
+                        outfile_prefix: str) -> str:
+        """Convert ground truth to coco format json file.
+
+        Args:
+            gt_dicts (Sequence[dict]): Ground truth of the dataset. Each dict
+                contains the ground truth information about the data sample.
+                Required keys of the each `gt_dict` in `gt_dicts`:
+                    - `img_id`: image id of the data sample
+                    - `width`: original image width
+                    - `height`: original image height
+                    - `raw_ann_info`: the raw annotation information
+                Optional keys:
+                    - `crowd_index`: measure the crowding level of an image,
+                        defined in CrowdPose dataset
+                It is worth mentioning that, in order to compute `CocoMetric`,
+                there are some required keys in the `raw_ann_info`:
+                    - `id`: the id to distinguish different annotations
+                    - `image_id`: the image id of this annotation
+                    - `category_id`: the category of the instance.
+                    - `bbox`: the object bounding box
+                    - `keypoints`: the keypoints cooridinates along with their
+                        visibilities. Note that it need to be aligned
+                        with the official COCO format, e.g., a list with length
+                        N * 3, in which N is the number of keypoints. And each
+                        triplet represent the [x, y, visible] of the keypoint.
+                    - `iscrowd`: indicating whether the annotation is a crowd.
+                        It is useful when matching the detection results to
+                        the ground truth.
+                There are some optional keys as well:
+                    - `area`: it is necessary when `self.use_area` is `True`
+                    - `num_keypoints`: it is necessary when `self.iou_type`
+                        is set as `keypoints_crowd`.
+            outfile_prefix (str): The filename prefix of the json files. If the
+                prefix is "somepath/xxx", the json file will be named
+                "somepath/xxx.gt.json".
+        Returns:
+            str: The filename of the json file.
+        """
+        image_infos = []
+        annotations = []
+        img_ids = []
+        ann_ids = []
+
+        for gt_dict in gt_dicts:
+            # filter duplicate image_info
+            if gt_dict['img_id'] not in img_ids:
+                image_info = dict(
+                    id=gt_dict['img_id'],
+                    width=gt_dict['width'],
+                    height=gt_dict['height'],
+                )
+                if self.iou_type == 'keypoints_crowd':
+                    image_info['crowdIndex'] = gt_dict['crowd_index']
+
+                image_infos.append(image_info)
+                img_ids.append(gt_dict['img_id'])
+
+            # filter duplicate annotations
+            for ann in gt_dict['raw_ann_info']:
+                if ann is None:
+                    # during evaluation on bottom-up datasets, some images
+                    # do not have instance annotation
+                    continue
+
+                annotation = dict(
+                    id=ann['id'],
+                    image_id=ann['image_id'],
+                    category_id=ann['category_id'],
+                    bbox=ann['bbox'],
+                    keypoints=ann['keypoints'],
+                    iscrowd=ann['iscrowd'],
+                )
+                if self.use_area:
+                    assert 'area' in ann, \
+                        '`area` is required when `self.use_area` is `True`'
+                    annotation['area'] = ann['area']
+
+                if self.iou_type == 'keypoints_crowd':
+                    assert 'num_keypoints' in ann, \
+                        '`num_keypoints` is required when `self.iou_type` ' \
+                        'is `keypoints_crowd`'
+                    annotation['num_keypoints'] = ann['num_keypoints']
+
+                annotations.append(annotation)
+                ann_ids.append(ann['id'])
+
+        info = dict(
+            date_created=str(datetime.datetime.now()),
+            description='Coco json file converted by mmpose CocoMetric.')
+        coco_json = dict(
+            info=info,
+            images=image_infos,
+            categories=self.dataset_meta['CLASSES'],
+            licenses=None,
+            annotations=annotations,
+        )
+        converted_json_path = f'{outfile_prefix}.gt.json'
+        dump(coco_json, converted_json_path, sort_keys=True, indent=4)
+        return converted_json_path
 
     def compute_metrics(self, results: list) -> Dict[str, float]:
         """Compute the metrics from processed results.
 
         Args:
             results (list): The processed results of each batch.
 
         Returns:
             Dict[str, float]: The computed metrics. The keys are the names of
             the metrics, and the values are corresponding results.
         """
         logger: MMLogger = MMLogger.get_current_instance()
 
+        # split prediction and gt list
+        preds, gts = zip(*results)
+
         tmp_dir = None
         if self.outfile_prefix is None:
             tmp_dir = tempfile.TemporaryDirectory()
             outfile_prefix = osp.join(tmp_dir.name, 'results')
         else:
             outfile_prefix = self.outfile_prefix
 
+        if self.coco is None:
+            # use converted gt json file to initialize coco helper
+            logger.info('Converting ground truth to coco format...')
+            coco_json_path = self.gt_to_coco_json(
+                gt_dicts=gts, outfile_prefix=outfile_prefix)
+            self.coco = COCO(coco_json_path)
+
         kpts = defaultdict(list)
 
-        # group the results by img_id
-        for result in results:
-            img_id = result['img_id']
-            for idx in range(len(result['bbox_scores'])):
+        # group the preds by img_id
+        for pred in preds:
+            img_id = pred['img_id']
+            for idx in range(len(pred['keypoints'])):
                 instance = {
-                    'id': result['id'],
-                    'img_id': result['img_id'],
-                    'keypoints': result['keypoints'][idx],
-                    'keypoint_scores': result['keypoint_scores'][idx],
-                    'bbox_score': result['bbox_scores'][idx],
+                    'id': pred['id'],
+                    'img_id': pred['img_id'],
+                    'category_id': pred['category_id'],
+                    'keypoints': pred['keypoints'][idx],
+                    'keypoint_scores': pred['keypoint_scores'][idx],
+                    'bbox_score': pred['bbox_scores'][idx],
                 }
 
-                if 'areas' in result:
-                    instance['area'] = result['areas'][idx]
+                if 'areas' in pred:
+                    instance['area'] = pred['areas'][idx]
                 else:
                     # use keypoint to calculate bbox and get area
-                    keypoints = result['keypoints'][idx]
+                    keypoints = pred['keypoints'][idx]
                     area = (
                         np.max(keypoints[:, 0]) - np.min(keypoints[:, 0])) * (
                             np.max(keypoints[:, 1]) - np.min(keypoints[:, 1]))
                     instance['area'] = area
 
                 kpts[img_id].append(instance)
 
@@ -234,14 +382,16 @@
                 # concatenate the keypoint coordinates and scores
                 instance['keypoints'] = np.concatenate([
                     instance['keypoints'], instance['keypoint_scores'][:, None]
                 ],
                                                        axis=-1)
                 if self.score_mode == 'bbox':
                     instance['score'] = instance['bbox_score']
+                elif self.score_mode == 'keypoint':
+                    instance['score'] = np.mean(instance['keypoint_scores'])
                 else:
                     bbox_score = instance['bbox_score']
                     if self.score_mode == 'bbox_rle':
                         keypoint_scores = instance['keypoint_scores']
                         instance['score'] = float(bbox_score +
                                                   np.mean(keypoint_scores) +
                                                   np.max(keypoint_scores))
@@ -299,27 +449,26 @@
                 prefix is "somepath/xxx", the json files will be named
                 "somepath/xxx.keypoints.json",
 
         Returns:
             str: The json file name of keypoint results.
         """
         # the results with category_id
-        cat_id = 1
         cat_results = []
 
         for _, img_kpts in keypoints.items():
             _keypoints = np.array(
                 [img_kpt['keypoints'] for img_kpt in img_kpts])
             num_keypoints = self.dataset_meta['num_keypoints']
             # collect all the person keypoints in current image
             _keypoints = _keypoints.reshape(-1, num_keypoints * 3)
 
             result = [{
                 'image_id': img_kpt['img_id'],
-                'category_id': cat_id,
+                'category_id': img_kpt['category_id'],
                 'keypoints': keypoint.tolist(),
                 'score': float(img_kpt['score']),
             } for img_kpt, keypoint in zip(img_kpts, _keypoints)]
 
             cat_results.extend(result)
 
         res_file = f'{outfile_prefix}.keypoints.json'
@@ -343,18 +492,24 @@
         coco_eval = COCOeval(self.coco, coco_det, self.iou_type, sigmas,
                              self.use_area)
         coco_eval.params.useSegm = None
         coco_eval.evaluate()
         coco_eval.accumulate()
         coco_eval.summarize()
 
-        stats_names = [
-            'AP', 'AP .5', 'AP .75', 'AP (M)', 'AP (L)', 'AR', 'AR .5',
-            'AR .75', 'AR (M)', 'AR (L)'
-        ]
+        if self.iou_type == 'keypoints_crowd':
+            stats_names = [
+                'AP', 'AP .5', 'AP .75', 'AR', 'AR .5', 'AR .75', 'AP(E)',
+                'AP(M)', 'AP(H)'
+            ]
+        else:
+            stats_names = [
+                'AP', 'AP .5', 'AP .75', 'AP (M)', 'AP (L)', 'AR', 'AR .5',
+                'AR .75', 'AR (M)', 'AR (L)'
+            ]
 
         info_str = list(zip(stats_names, coco_eval.stats))
 
         return info_str
 
     def _sort_and_unique_bboxes(self,
                                 kpts: Dict[int, list],
@@ -382,268 +537,7 @@
             num = len(persons)
             kpts[img_id] = sorted(kpts[img_id], key=lambda x: x[key])
             for i in range(num - 1, 0, -1):
                 if kpts[img_id][i][key] == kpts[img_id][i - 1][key]:
                     del kpts[img_id][i]
 
         return kpts
-
-
-@METRICS.register_module()
-class AP10KCocoMetric(CocoMetric):
-    """AP-10K evaluation metric.
-
-    Evaluate AR, AP, and mAP for keypoint detection tasks. Support AP-10K
-    dataset with annotations in COCO format. Please refer to
-    `COCO keypoint evaluation <https://cocodataset.org/#keypoints-eval>`__
-    for more details.
-
-    Args:
-        ann_file (str): Path to the coco format annotation file.
-        use_area (bool): Whether to use ``'area'`` message in the annotations.
-            If the ground truth annotations (e.g. CrowdPose, AIC) do not have
-            the field ``'area'``, please set ``use_area=False``.
-            Default: ``True``.
-        iou_type (str): The same parameter as `iouType` in
-            :class:`xtcocotools.COCOeval`, which can be ``'keypoints'``, or
-            ``'keypoints_crowd'`` (used in CrowdPose dataset).
-            Defaults to ``'keypoints'``.
-        score_mode (str): The mode to score the prediction results which
-            should be one of the following options:
-
-                - ``'bbox'``: Take the score of bbox as the score of the
-                    prediction results.
-                - ``'bbox_keypoint'``: Use keypoint score to rescore the
-                    prediction results.
-                - ``'bbox_rle'``: Use rle_score to rescore the
-                    prediction results.
-
-            Defaults to ``'bbox_keypoint'`
-        keypoint_score_thr (float): The threshold of keypoint score. The
-            keypoints with score lower than it will not be included to
-            rescore the prediction results. Valid only when ``score_mode`` is
-            ``bbox_keypoint``. Defaults to ``0.2``
-        nms_mode (str): The mode to perform Non-Maximum Suppression (NMS),
-            which should be one of the following options:
-
-                - ``'oks_nms'``: Use Object Keypoint Similarity (OKS) to
-                    perform NMS.
-                - ``'soft_oks_nms'``: Use Object Keypoint Similarity (OKS)
-                    to perform soft NMS.
-                - ``'none'``: Do not perform NMS. Typically for bottomup mode
-                    output.
-
-            Defaults to ``'oks_nms'`
-        nms_thr (float): The Object Keypoint Similarity (OKS) threshold
-            used in NMS when ``nms_mode`` is ``'oks_nms'`` or
-            ``'soft_oks_nms'``. Will retain the prediction results with OKS
-            lower than ``nms_thr``. Defaults to ``0.9``
-        format_only (bool): Whether only format the output results without
-            doing quantitative evaluation. This is designed for the need of
-            test submission when the ground truth annotations are absent. If
-            set to ``True``, ``outfile_prefix`` should specify the path to
-            store the output results. Default: ``False``.
-        outfile_prefix (str | None): The prefix of json files. It includes
-            the file path and the prefix of filename, e.g., ``'a/b/prefix'``.
-            If not specified, a temp file will be created. Default: ``None``.
-        collect_device (str): Device name used for collecting results from
-            different ranks during distributed training. Must be ``'cpu'`` or
-            ``'gpu'``. Default: ``'cpu'``.
-        prefix (str, optional): The prefix that will be added in the metric
-            names to disambiguate homonymous metrics of different evaluators.
-            If prefix is not provided in the argument, ``self.default_prefix``
-            will be used instead. Default: ``None``.
-    """
-
-    def process(self, data_batch: Sequence[dict],
-                predictions: Sequence[dict]) -> None:
-        """Process one batch of data samples and predictions. The processed
-        results should be stored in ``self.results``, which will be used to
-        compute the metrics when all batches have been processed.
-
-        Args:
-            data_batch (Sequence[dict]): A batch of data
-                from the dataloader.
-            predictions (Sequence[dict]): A batch of outputs from
-                the model, each of which has the following keys:
-
-                - 'id': The id of the sample
-                - 'img_id': The image_id of the sample
-                - 'category': The category of instance(s)
-                - 'pred_instances': The prediction results of instance(s)
-        """
-        for _, pred in zip(data_batch, predictions):
-            if 'pred_instances' not in pred:
-                raise ValueError(
-                    '`pred_instances` are required to process the '
-                    f'predictions results in {self.__class__.__name__}. ')
-
-            # keypoints.shape: [N, K, 2],
-            # N: number of instances, K: number of keypoints
-            # for topdown-style output, N is usually 1, while for
-            # bottomup-style output, N is the number of instances in the image
-            keypoints = pred['pred_instances']['keypoints']
-            # [N, K], the scores for all keypoints of all instances
-            keypoint_scores = pred['pred_instances']['keypoint_scores']
-            assert keypoint_scores.shape == keypoints.shape[:2]
-
-            result = dict()
-            result['id'] = pred['id']
-            result['img_id'] = pred['img_id']
-            result['keypoints'] = keypoints
-            result['keypoint_scores'] = keypoint_scores
-            result['bbox_scores'] = pred['pred_instances']['bbox_scores']
-            result['category'] = pred['category']
-
-            # get area information
-            if 'bbox_scales' in pred['gt_instances']:
-                result['areas'] = np.prod(
-                    pred['gt_instances']['bbox_scales'], axis=1)
-            # add converted result to the results list
-            self.results.append(result)
-
-    def compute_metrics(self, results: list) -> Dict[str, float]:
-        """Compute the metrics from processed results.
-
-        Args:
-            results (list): The processed results of each batch.
-
-        Returns:
-            Dict[str, float]: The computed metrics. The keys are the names of
-            the metrics, and the values are corresponding results.
-        """
-        logger: MMLogger = MMLogger.get_current_instance()
-
-        tmp_dir = None
-        if self.outfile_prefix is None:
-            tmp_dir = tempfile.TemporaryDirectory()
-            outfile_prefix = osp.join(tmp_dir.name, 'results')
-        else:
-            outfile_prefix = self.outfile_prefix
-
-        kpts = defaultdict(list)
-
-        # group the results by img_id
-        for result in results:
-            img_id = result['img_id']
-            for idx in range(len(result['bbox_scores'])):
-                instance = {
-                    'id': result['id'],
-                    'img_id': result['img_id'],
-                    'keypoints': result['keypoints'][idx],
-                    'keypoint_scores': result['keypoint_scores'][idx],
-                    'bbox_score': result['bbox_scores'][idx],
-                    'category': result['category'],
-                }
-
-                if 'areas' in result:
-                    instance['area'] = result['areas'][idx]
-                else:
-                    # use keypoint to calculate bbox and get area
-                    keypoints = result['keypoints'][idx]
-                    area = (
-                        np.max(keypoints[:, 0]) - np.min(keypoints[:, 0])) * (
-                            np.max(keypoints[:, 1]) - np.min(keypoints[:, 1]))
-                    instance['area'] = area
-
-                kpts[img_id].append(instance)
-
-        # sort keypoint results according to id and remove duplicate ones
-        kpts = self._sort_and_unique_bboxes(kpts, key='id')
-
-        # score the prediction results according to `score_mode`
-        # and perform NMS according to `nms_mode`
-        valid_kpts = defaultdict(list)
-        num_keypoints = self.dataset_meta['num_keypoints']
-        for img_id, instances in kpts.items():
-            for instance in instances:
-                # concatenate the keypoint coordinates and scores
-                instance['keypoints'] = np.concatenate([
-                    instance['keypoints'], instance['keypoint_scores'][:, None]
-                ],
-                                                       axis=-1)
-                if self.score_mode == 'bbox':
-                    instance['score'] = instance['bbox_score']
-                else:
-                    bbox_score = instance['bbox_score']
-                    if self.score_mode == 'bbox_rle':
-                        keypoint_scores = instance['keypoint_scores']
-                        instance['score'] = float(bbox_score +
-                                                  np.mean(keypoint_scores) +
-                                                  np.max(keypoint_scores))
-
-                    else:  # self.score_mode == 'bbox_keypoint':
-                        mean_kpt_score = 0
-                        valid_num = 0
-                        for kpt_idx in range(num_keypoints):
-                            kpt_score = instance['keypoint_scores'][kpt_idx]
-                            if kpt_score > self.keypoint_score_thr:
-                                mean_kpt_score += kpt_score
-                                valid_num += 1
-                        if valid_num != 0:
-                            mean_kpt_score /= valid_num
-                        instance['score'] = bbox_score * mean_kpt_score
-            # perform nms
-            if self.nms_mode == 'none':
-                valid_kpts[img_id] = instances
-            else:
-                nms = oks_nms if self.nms_mode == 'oks_nms' else soft_oks_nms
-                keep = nms(
-                    instances,
-                    self.nms_thr,
-                    sigmas=self.dataset_meta['sigmas'])
-                valid_kpts[img_id] = [instances[_keep] for _keep in keep]
-
-        # convert results to coco style and dump into a json file
-        self.results2json(valid_kpts, outfile_prefix=outfile_prefix)
-
-        # only format the results without doing quantitative evaluation
-        if self.format_only:
-            logger.info('results are saved in '
-                        f'{osp.dirname(outfile_prefix)}')
-            return {}
-
-        # evaluation results
-        eval_results = OrderedDict()
-        logger.info(f'Evaluating {self.__class__.__name__}...')
-        info_str = self._do_python_keypoint_eval(outfile_prefix)
-        name_value = OrderedDict(info_str)
-        eval_results.update(name_value)
-
-        if tmp_dir is not None:
-            tmp_dir.cleanup()
-        return eval_results
-
-    def results2json(self, keypoints: Dict[int, list],
-                     outfile_prefix: str) -> str:
-        """Dump the keypoint detection results to a COCO style json file.
-
-        Args:
-            keypoints (Dict[int, list]): Keypoint detection results
-                of the dataset.
-            outfile_prefix (str): The filename prefix of the json files. If the
-                prefix is "somepath/xxx", the json files will be named
-                "somepath/xxx.keypoints.json",
-
-        Returns:
-            str: The json file name of keypoint results.
-        """
-        cat_results = []
-
-        for _, img_kpts in keypoints.items():
-            _keypoints = np.array(
-                [img_kpt['keypoints'] for img_kpt in img_kpts])
-            num_keypoints = self.dataset_meta['num_keypoints']
-            # collect all the person keypoints in current image
-            _keypoints = _keypoints.reshape(-1, num_keypoints * 3)
-
-            result = [{
-                'image_id': img_kpt['img_id'],
-                'category_id': img_kpt['category'],
-                'keypoints': keypoint.tolist(),
-                'score': float(img_kpt['score']),
-            } for img_kpt, keypoint in zip(img_kpts, _keypoints)]
-
-            cat_results.extend(result)
-
-        res_file = f'{outfile_prefix}.keypoints.json'
-        dump(cat_results, res_file, sort_keys=True, indent=4)
```

### Comparing `mmpose-1.0.0rc0/mmpose/evaluation/metrics/keypoint_2d_metrics.py` & `mmpose-1.0.0rc1/mmpose/evaluation/metrics/keypoint_2d_metrics.py`

 * *Files 13% similar despite different names*

```diff
@@ -33,16 +33,43 @@
         collect_device (str): Device name used for collecting results from
             different ranks during distributed training. Must be ``'cpu'`` or
             ``'gpu'``. Default: ``'cpu'``.
         prefix (str, optional): The prefix that will be added in the metric
             names to disambiguate homonymous metrics of different evaluators.
             If prefix is not provided in the argument, ``self.default_prefix``
             will be used instead. Default: ``None``.
+
+    Examples:
+
+        >>> from mmpose.evaluation.metrics import PCKAccuracy
+        >>> import numpy as np
+        >>> from mmengine.structures import InstanceData
+        >>> num_keypoints = 15
+        >>> keypoints = np.random.random((1, num_keypoints, 2)) * 10
+        >>> gt_instances = InstanceData()
+        >>> gt_instances.keypoints = keypoints
+        >>> gt_instances.keypoints_visible = np.ones(
+        ...     (1, num_keypoints, 1)).astype(bool)
+        >>> gt_instances.bboxes = np.random.random((1, 4)) * 20
+        >>> pred_instances = InstanceData()
+        >>> pred_instances.keypoints = keypoints
+        >>> data_sample = {
+        ...     'gt_instances': gt_instances.to_dict(),
+        ...     'pred_instances': pred_instances.to_dict(),
+        ... }
+        >>> data_samples = [data_sample]
+        >>> data_batch = [{'inputs': None}]
+        >>> pck_metric = PCKAccuracy(thr=0.5, norm_item='bbox')
+        ...: UserWarning: The prefix is not set in metric class PCKAccuracy.
+        >>> pck_metric.process(data_batch, data_samples)
+        >>> pck_metric.evaluate(1)
+        10/26 15:37:57 - mmengine - INFO - Evaluating PCKAccuracy (normalized by ``"bbox_size"``)...  # noqa
+        {'PCK': 1.0}
+
     """
-    default_prefix: Optional[str] = 'pck'
 
     def __init__(self,
                  thr: float = 0.05,
                  norm_item: Union[str, Sequence[str]] = 'bbox',
                  collect_device: str = 'cpu',
                  prefix: Optional[str] = None) -> None:
         super().__init__(collect_device=collect_device, prefix=prefix)
@@ -122,14 +149,18 @@
         """Compute the metrics from processed results.
 
         Args:
             results (list): The processed results of each batch.
         Returns:
             Dict[str, float]: The computed metrics. The keys are the names of
             the metrics, and the values are corresponding results.
+            The returned result dict may have the following keys:
+                - 'PCK': The pck accuracy normalized by `bbox_size`.
+                - 'PCKh': The pck accuracy normalized by `head_size`.
+                - 'tPCK': The pck accuracy normalized by `torso_size`.
         """
         logger: MMLogger = MMLogger.get_current_instance()
 
         # pred_coords: [N, K, D]
         pred_coords = np.concatenate(
             [result['pred_coords'] for result in results])
         # gt_coords: [N, K, D]
@@ -143,37 +174,37 @@
                 [result['bbox_size'] for result in results])
 
             logger.info(f'Evaluating {self.__class__.__name__} '
                         f'(normalized by ``"bbox_size"``)...')
 
             _, pck, _ = keypoint_pck_accuracy(pred_coords, gt_coords, mask,
                                               self.thr, norm_size_bbox)
-            metrics[f'PCK@{self.thr}'] = pck
+            metrics['PCK'] = pck
 
         if 'head' in self.norm_item:
             norm_size_head = np.concatenate(
                 [result['head_size'] for result in results])
 
             logger.info(f'Evaluating {self.__class__.__name__} '
                         f'(normalized by ``"head_size"``)...')
 
             _, pckh, _ = keypoint_pck_accuracy(pred_coords, gt_coords, mask,
                                                self.thr, norm_size_head)
-            metrics[f'PCKh@{self.thr}'] = pckh
+            metrics['PCKh'] = pckh
 
         if 'torso' in self.norm_item:
             norm_size_torso = np.concatenate(
                 [result['torso_size'] for result in results])
 
             logger.info(f'Evaluating {self.__class__.__name__} '
                         f'(normalized by ``"torso_size"``)...')
 
             _, tpck, _ = keypoint_pck_accuracy(pred_coords, gt_coords, mask,
                                                self.thr, norm_size_torso)
-            metrics[f'tPCK@{self.thr}'] = tpck
+            metrics['tPCK'] = tpck
 
         return metrics
 
 
 @METRICS.register_module()
 class MpiiPCKAccuracy(PCKAccuracy):
     """PCKh accuracy evaluation metric for MPII dataset.
@@ -191,24 +222,52 @@
         - num_keypoints: K
         - number of keypoint dimensions: D (typically D = 2)
 
     Args:
         thr(float): Threshold of PCK calculation. Default: 0.05.
         norm_item (str | Sequence[str]): The item used for normalization.
             Valid items include 'bbox', 'head', 'torso', which correspond
-            to 'PCK', 'PCKh' and 'tPCK' respectively. Default: ``'bbox'``.
+            to 'PCK', 'PCKh' and 'tPCK' respectively. Default: ``'head'``.
         collect_device (str): Device name used for collecting results from
             different ranks during distributed training. Must be ``'cpu'`` or
             ``'gpu'``. Default: ``'cpu'``.
         prefix (str, optional): The prefix that will be added in the metric
             names to disambiguate homonymous metrics of different evaluators.
             If prefix is not provided in the argument, ``self.default_prefix``
             will be used instead. Default: ``None``.
+
+    Examples:
+
+        >>> from mmpose.evaluation.metrics import MpiiPCKAccuracy
+        >>> import numpy as np
+        >>> from mmengine.structures import InstanceData
+        >>> num_keypoints = 16
+        >>> keypoints = np.random.random((1, num_keypoints, 2)) * 10
+        >>> gt_instances = InstanceData()
+        >>> gt_instances.keypoints = keypoints + 1.0
+        >>> gt_instances.keypoints_visible = np.ones(
+        ...     (1, num_keypoints, 1)).astype(bool)
+        >>> gt_instances.head_size = np.random.random((1, 1)) * 10
+        >>> pred_instances = InstanceData()
+        >>> pred_instances.keypoints = keypoints
+        >>> data_sample = {
+        ...     'gt_instances': gt_instances.to_dict(),
+        ...     'pred_instances': pred_instances.to_dict(),
+        ... }
+        >>> data_samples = [data_sample]
+        >>> data_batch = [{'inputs': None}]
+        >>> mpii_pck_metric = MpiiPCKAccuracy(thr=0.3, norm_item='head')
+        ... UserWarning: The prefix is not set in metric class MpiiPCKAccuracy.
+        >>> mpii_pck_metric.process(data_batch, data_samples)
+        >>> mpii_pck_metric.evaluate(1)
+        10/26 17:43:39 - mmengine - INFO - Evaluating MpiiPCKAccuracy (normalized by ``"head_size"``)...  # noqa
+        {'Head PCK': 100.0, 'Shoulder PCK': 100.0, 'Elbow PCK': 100.0,
+        Wrist PCK': 100.0, 'Hip PCK': 100.0, 'Knee PCK': 100.0,
+        'Ankle PCK': 100.0, 'PCK': 100.0, 'PCK@0.1': 100.0}
     """
-    default_prefix: Optional[str] = 'pck'
 
     def __init__(self,
                  thr: float = 0.5,
                  norm_item: Union[str, Sequence[str]] = 'head',
                  collect_device: str = 'cpu',
                  prefix: Optional[str] = None) -> None:
         super().__init__(
@@ -222,14 +281,25 @@
 
         Args:
             results (list): The processed results of each batch.
 
         Returns:
             Dict[str, float]: The computed metrics. The keys are the names of
             the metrics, and the values are corresponding results.
+            If `'head'` in `self.norm_item`, the returned results are the pck
+            accuracy normalized by `head_size`, which have the following keys:
+                - 'Head PCK': The PCK of head
+                - 'Shoulder PCK': The PCK of shoulder
+                - 'Elbow PCK': The PCK of elbow
+                - 'Wrist PCK': The PCK of wrist
+                - 'Hip PCK': The PCK of hip
+                - 'Knee PCK': The PCK of knee
+                - 'Ankle PCK': The PCK of ankle
+                - 'PCK': The mean PCK over all keypoints
+                - 'PCK@0.1': The mean PCK at threshold 0.1
         """
         logger: MMLogger = MMLogger.get_current_instance()
 
         # pred_coords: [N, K, D]
         pred_coords = np.concatenate(
             [result['pred_coords'] for result in results])
         # gt_coords: [N, K, D]
@@ -237,16 +307,15 @@
         # mask: [N, K]
         mask = np.concatenate([result['mask'] for result in results])
 
         # MPII uses matlab format, gt index is 1-based,
         # convert 0-based index to 1-based index
         pred_coords = pred_coords + 1.0
 
-        metrics = super().compute_metrics(results)
-
+        metrics = {}
         if 'head' in self.norm_item:
             norm_size_head = np.concatenate(
                 [result['head_size'] for result in results])
 
             logger.info(f'Evaluating {self.__class__.__name__} '
                         f'(normalized by ``"head_size"``)...')
 
@@ -277,26 +346,25 @@
             #   lsho 13  rsho 12
             #   lelb 14  relb 11
             #   lwri 15  rwri 10
             #   lhip 3   rhip 2
             #   lkne 4   rkne 1
             #   lank 5   rank 0
             stats = {
-                'Head': PCKh[9],
-                'Shoulder': 0.5 * (PCKh[13] + PCKh[12]),
-                'Elbow': 0.5 * (PCKh[14] + PCKh[11]),
-                'Wrist': 0.5 * (PCKh[15] + PCKh[10]),
-                'Hip': 0.5 * (PCKh[3] + PCKh[2]),
-                'Knee': 0.5 * (PCKh[4] + PCKh[1]),
-                'Ankle': 0.5 * (PCKh[5] + PCKh[0]),
-                'PCKh': np.sum(PCKh * jnt_ratio),
-                'PCKh@0.1': np.sum(pckAll[10, :] * jnt_ratio)
+                'Head PCK': PCKh[9],
+                'Shoulder PCK': 0.5 * (PCKh[13] + PCKh[12]),
+                'Elbow PCK': 0.5 * (PCKh[14] + PCKh[11]),
+                'Wrist PCK': 0.5 * (PCKh[15] + PCKh[10]),
+                'Hip PCK': 0.5 * (PCKh[3] + PCKh[2]),
+                'Knee PCK': 0.5 * (PCKh[4] + PCKh[1]),
+                'Ankle PCK': 0.5 * (PCKh[5] + PCKh[0]),
+                'PCK': np.sum(PCKh * jnt_ratio),
+                'PCK@0.1': np.sum(pckAll[10, :] * jnt_ratio)
             }
 
-            del metrics[f'PCKh@{self.thr}']
             for stats_name, stat in stats.items():
                 metrics[stats_name] = stat
 
         return metrics
 
 
 @METRICS.register_module()
@@ -324,16 +392,47 @@
         collect_device (str): Device name used for collecting results from
             different ranks during distributed training. Must be ``'cpu'`` or
             ``'gpu'``. Default: ``'cpu'``.
         prefix (str, optional): The prefix that will be added in the metric
             names to disambiguate homonymous metrics of different evaluators.
             If prefix is not provided in the argument, ``self.default_prefix``
             will be used instead. Default: ``None``.
+
+    Examples:
+
+        >>> from mmpose.evaluation.metrics import JhmdbPCKAccuracy
+        >>> import numpy as np
+        >>> from mmengine.structures import InstanceData
+        >>> num_keypoints = 15
+        >>> keypoints = np.random.random((1, num_keypoints, 2)) * 10
+        >>> gt_instances = InstanceData()
+        >>> gt_instances.keypoints = keypoints
+        >>> gt_instances.keypoints_visible = np.ones(
+        ...     (1, num_keypoints, 1)).astype(bool)
+        >>> gt_instances.bboxes = np.random.random((1, 4)) * 20
+        >>> gt_instances.head_size = np.random.random((1, 1)) * 10
+        >>> pred_instances = InstanceData()
+        >>> pred_instances.keypoints = keypoints
+        >>> data_sample = {
+        ...     'gt_instances': gt_instances.to_dict(),
+        ...     'pred_instances': pred_instances.to_dict(),
+        ... }
+        >>> data_samples = [data_sample]
+        >>> data_batch = [{'inputs': None}]
+        >>> jhmdb_pck_metric = JhmdbPCKAccuracy(thr=0.2, norm_item=['bbox', 'torso'])
+        ... UserWarning: The prefix is not set in metric class JhmdbPCKAccuracy.
+        >>> jhmdb_pck_metric.process(data_batch, data_samples)
+        >>> jhmdb_pck_metric.evaluate(1)
+        10/26 17:48:09 - mmengine - INFO - Evaluating JhmdbPCKAccuracy (normalized by ``"bbox_size"``)...  # noqa
+        10/26 17:48:09 - mmengine - INFO - Evaluating JhmdbPCKAccuracy (normalized by ``"torso_size"``)...  # noqa
+        {'Head PCK': 1.0, 'Sho PCK': 1.0, 'Elb PCK': 1.0, 'Wri PCK': 1.0,
+        'Hip PCK': 1.0, 'Knee PCK': 1.0, 'Ank PCK': 1.0, 'PCK': 1.0,
+        'Head tPCK': 1.0, 'Sho tPCK': 1.0, 'Elb tPCK': 1.0, 'Wri tPCK': 1.0,
+        'Hip tPCK': 1.0, 'Knee tPCK': 1.0, 'Ank tPCK': 1.0, 'tPCK': 1.0}
     """
-    default_prefix: Optional[str] = 'pck'
 
     def __init__(self,
                  thr: float = 0.05,
                  norm_item: Union[str, Sequence[str]] = 'bbox',
                  collect_device: str = 'cpu',
                  prefix: Optional[str] = None) -> None:
         super().__init__(
@@ -347,77 +446,92 @@
 
         Args:
             results (list): The processed results of each batch.
 
         Returns:
             Dict[str, float]: The computed metrics. The keys are the names of
             the metrics, and the values are corresponding results.
+            If `'bbox'` in `self.norm_item`, the returned results are the pck
+            accuracy normalized by `bbox_size`, which have the following keys:
+                - 'Head PCK': The PCK of head
+                - 'Sho PCK': The PCK of shoulder
+                - 'Elb PCK': The PCK of elbow
+                - 'Wri PCK': The PCK of wrist
+                - 'Hip PCK': The PCK of hip
+                - 'Knee PCK': The PCK of knee
+                - 'Ank PCK': The PCK of ankle
+                - 'PCK': The mean PCK over all keypoints
+            If `'torso'` in `self.norm_item`, the returned results are the pck
+            accuracy normalized by `torso_size`, which have the following keys:
+                - 'Head tPCK': The PCK of head
+                - 'Sho tPCK': The PCK of shoulder
+                - 'Elb tPCK': The PCK of elbow
+                - 'Wri tPCK': The PCK of wrist
+                - 'Hip tPCK': The PCK of hip
+                - 'Knee tPCK': The PCK of knee
+                - 'Ank tPCK': The PCK of ankle
+                - 'tPCK': The mean PCK over all keypoints
         """
         logger: MMLogger = MMLogger.get_current_instance()
 
         # pred_coords: [N, K, D]
         pred_coords = np.concatenate(
             [result['pred_coords'] for result in results])
         # gt_coords: [N, K, D]
         gt_coords = np.concatenate([result['gt_coords'] for result in results])
         # mask: [N, K]
         mask = np.concatenate([result['mask'] for result in results])
 
-        metrics = super().compute_metrics(results)
-
+        metrics = dict()
         if 'bbox' in self.norm_item:
             norm_size_bbox = np.concatenate(
                 [result['bbox_size'] for result in results])
 
             logger.info(f'Evaluating {self.__class__.__name__} '
                         f'(normalized by ``"bbox_size"``)...')
 
             pck_p, pck, _ = keypoint_pck_accuracy(pred_coords, gt_coords, mask,
                                                   self.thr, norm_size_bbox)
-            metrics[f'@{self.thr}'] = pck
-
             stats = {
-                'Head': pck_p[2],
-                'Sho': 0.5 * pck_p[3] + 0.5 * pck_p[4],
-                'Elb': 0.5 * pck_p[7] + 0.5 * pck_p[8],
-                'Wri': 0.5 * pck_p[11] + 0.5 * pck_p[12],
-                'Hip': 0.5 * pck_p[5] + 0.5 * pck_p[6],
-                'Knee': 0.5 * pck_p[9] + 0.5 * pck_p[10],
-                'Ank': 0.5 * pck_p[13] + 0.5 * pck_p[14],
-                'Mean': pck
+                'Head PCK': pck_p[2],
+                'Sho PCK': 0.5 * pck_p[3] + 0.5 * pck_p[4],
+                'Elb PCK': 0.5 * pck_p[7] + 0.5 * pck_p[8],
+                'Wri PCK': 0.5 * pck_p[11] + 0.5 * pck_p[12],
+                'Hip PCK': 0.5 * pck_p[5] + 0.5 * pck_p[6],
+                'Knee PCK': 0.5 * pck_p[9] + 0.5 * pck_p[10],
+                'Ank PCK': 0.5 * pck_p[13] + 0.5 * pck_p[14],
+                'PCK': pck
             }
 
-            del metrics[f'PCK@{self.thr}']
             for stats_name, stat in stats.items():
-                metrics[f'{stats_name} PCK'] = stat
+                metrics[stats_name] = stat
 
         if 'torso' in self.norm_item:
             norm_size_torso = np.concatenate(
                 [result['torso_size'] for result in results])
 
             logger.info(f'Evaluating {self.__class__.__name__} '
                         f'(normalized by ``"torso_size"``)...')
 
             pck_p, pck, _ = keypoint_pck_accuracy(pred_coords, gt_coords, mask,
                                                   self.thr, norm_size_torso)
 
             stats = {
-                'Head': pck_p[2],
-                'Sho': 0.5 * pck_p[3] + 0.5 * pck_p[4],
-                'Elb': 0.5 * pck_p[7] + 0.5 * pck_p[8],
-                'Wri': 0.5 * pck_p[11] + 0.5 * pck_p[12],
-                'Hip': 0.5 * pck_p[5] + 0.5 * pck_p[6],
-                'Knee': 0.5 * pck_p[9] + 0.5 * pck_p[10],
-                'Ank': 0.5 * pck_p[13] + 0.5 * pck_p[14],
-                'Mean': pck
+                'Head tPCK': pck_p[2],
+                'Sho tPCK': 0.5 * pck_p[3] + 0.5 * pck_p[4],
+                'Elb tPCK': 0.5 * pck_p[7] + 0.5 * pck_p[8],
+                'Wri tPCK': 0.5 * pck_p[11] + 0.5 * pck_p[12],
+                'Hip tPCK': 0.5 * pck_p[5] + 0.5 * pck_p[6],
+                'Knee tPCK': 0.5 * pck_p[9] + 0.5 * pck_p[10],
+                'Ank tPCK': 0.5 * pck_p[13] + 0.5 * pck_p[14],
+                'tPCK': pck
             }
 
-            del metrics[f'tPCK@{self.thr}']
             for stats_name, stat in stats.items():
-                metrics[f'{stats_name} tPCK'] = stat
+                metrics[stats_name] = stat
 
         return metrics
 
 
 @METRICS.register_module()
 class AUC(BaseMetric):
     """AUC evaluation metric.
@@ -439,15 +553,14 @@
             different ranks during distributed training. Must be ``'cpu'`` or
             ``'gpu'``. Default: ``'cpu'``.
         prefix (str, optional): The prefix that will be added in the metric
             names to disambiguate homonymous metrics of different evaluators.
             If prefix is not provided in the argument, ``self.default_prefix``
             will be used instead. Default: ``None``.
     """
-    default_prefix: Optional[str] = 'auc'
 
     def __init__(self,
                  norm_factor: float = 30,
                  num_thrs: int = 20,
                  collect_device: str = 'cpu',
                  prefix: Optional[str] = None) -> None:
         super().__init__(collect_device=collect_device, prefix=prefix)
@@ -506,15 +619,15 @@
 
         logger.info(f'Evaluating {self.__class__.__name__}...')
 
         auc = keypoint_auc(pred_coords, gt_coords, mask, self.norm_factor,
                            self.num_thrs)
 
         metrics = dict()
-        metrics[f'@{self.num_thrs}thrs'] = auc
+        metrics['AUC'] = auc
 
         return metrics
 
 
 @METRICS.register_module()
 class EPE(BaseMetric):
     """EPE evaluation metric.
@@ -531,15 +644,14 @@
             different ranks during distributed training. Must be ``'cpu'`` or
             ``'gpu'``. Default: ``'cpu'``.
         prefix (str, optional): The prefix that will be added in the metric
             names to disambiguate homonymous metrics of different evaluators.
             If prefix is not provided in the argument, ``self.default_prefix``
             will be used instead. Default: ``None``.
     """
-    default_prefix: Optional[str] = 'epe'
 
     def process(self, data_batch: Sequence[dict],
                 data_samples: Sequence[dict]) -> None:
         """Process one batch of data samples and predictions. The processed
         results should be stored in ``self.results``, which will be used to
         compute the metrics when all batches have been processed.
 
@@ -588,15 +700,15 @@
         mask = np.concatenate([result['mask'] for result in results])
 
         logger.info(f'Evaluating {self.__class__.__name__}...')
 
         epe = keypoint_epe(pred_coords, gt_coords, mask)
 
         metrics = dict()
-        metrics['epe'] = epe
+        metrics['EPE'] = epe
 
         return metrics
 
 
 @METRICS.register_module()
 class NME(BaseMetric):
     """NME evaluation metric.
@@ -631,15 +743,14 @@
             different ranks during distributed training. Must be ``'cpu'`` or
             ``'gpu'``. Default: ``'cpu'``.
         prefix (str, optional): The prefix that will be added in the metric
             names to disambiguate homonymous metrics of different evaluators.
             If prefix is not provided in the argument, ``self.default_prefix``
             will be used instead. Default: ``None``.
     """
-    default_prefix: Optional[str] = 'nme'
 
     DEFAULT_KEYPOINT_INDICES = {
         # horse10: corresponding to `nose` and `eye` keypoints
         'horse10': [0, 1],
         # 300w: corresponding to `right-most` and `left-most` eye keypoints
         '300w': [36, 45],
         # coco_wholebody_face corresponding to `right-most` and `left-most`
@@ -744,15 +855,15 @@
 
         if self.norm_mode == 'use_norm_item':
             normalize_factor_ = np.concatenate(
                 [result[self.norm_item] for result in results])
             # normalize_factor: [N, 2]
             normalize_factor = np.tile(normalize_factor_, [1, 2])
             nme = keypoint_nme(pred_coords, gt_coords, mask, normalize_factor)
-            metrics[f'@{self.norm_item}'] = nme
+            metrics['NME'] = nme
 
         else:
             if self.keypoint_indices is None:
                 # use default keypoint_indices in some datasets
                 dataset_name = self.dataset_meta['dataset_name']
                 if dataset_name not in self.DEFAULT_KEYPOINT_INDICES:
                     raise KeyError(
@@ -770,15 +881,15 @@
                 for idx in self.keypoint_indices:
                     assert idx in keypoint_id2name, f'The {dataset_name} '\
                         f'dataset does not contain the required '\
                         f'{idx}-th keypoint.'
             # normalize_factor: [N, 2]
             normalize_factor = self._get_normalize_factor(gt_coords=gt_coords)
             nme = keypoint_nme(pred_coords, gt_coords, mask, normalize_factor)
-            metrics[f'@{self.keypoint_indices}'] = nme
+            metrics['NME'] = nme
 
         return metrics
 
     def _get_normalize_factor(self, gt_coords: np.ndarray) -> np.ndarray:
         """Get the normalize factor. generally inter-ocular distance measured
         as the Euclidean distance between the outer corners of the eyes is
         used.
```

### Comparing `mmpose-1.0.0rc0/mmpose/evaluation/metrics/posetrack18_metric.py` & `mmpose-1.0.0rc1/mmpose/evaluation/metrics/posetrack18_metric.py`

 * *Files 16% similar despite different names*

```diff
@@ -24,24 +24,26 @@
 
     Evaluate AP, and mAP for keypoint detection tasks.
     Support PoseTrack18 (video) dataset. Please refer to
     `<https://github.com/leonid-pishchulin/poseval>`__
     for more details.
 
     Args:
-        ann_file (str): Path to the annotation file.
+        ann_file (str, optional): Path to the coco format annotation file.
+            If not specified, ground truth annotations from the dataset will
+            be converted to coco format. Defaults to None
         score_mode (str): The mode to score the prediction results which
             should be one of the following options:
 
                 - ``'bbox'``: Take the score of bbox as the score of the
                     prediction results.
                 - ``'bbox_keypoint'``: Use keypoint score to rescore the
                     prediction results.
 
-            Defaults to ``'bbox'`
+            Defaults to ``'bbox_keypoint'`
         keypoint_score_thr (float): The threshold of keypoint score. The
             keypoints with score lower than it will not be included to
             rescore the prediction results. Valid only when ``score_mode`` is
             ``bbox_keypoint``. Defaults to ``0.2``
         nms_mode (str): The mode to perform Non-Maximum Suppression (NMS),
             which should be one of the following options:
 
@@ -57,76 +59,47 @@
             used in NMS when ``nms_mode`` is ``'oks_nms'`` or
             ``'soft_oks_nms'``. Will retain the prediction results with OKS
             lower than ``nms_thr``. Defaults to ``0.9``
         format_only (bool): Whether only format the output results without
             doing quantitative evaluation. This is designed for the need of
             test submission when the ground truth annotations are absent. If
             set to ``True``, ``outfile_prefix`` should specify the path to
-            store the output results. Default: ``False``.
+            store the output results. Defaults to ``False``
         outfile_prefix (str | None): The prefix of json files. It includes
             the file path and the prefix of filename, e.g., ``'a/b/prefix'``.
-            If not specified, a temp file will be created. Default: ``None``.
-        collect_device (str): Device name used for collecting results from
-            different ranks during distributed training. Must be ``'cpu'`` or
-            ``'gpu'``. Default: ``'cpu'``.
-        prefix (str, optional): The prefix that will be added in the metric
-            names to disambiguate homonymous metrics of different evaluators.
-            If prefix is not provided in the argument, ``self.default_prefix``
-            will be used instead. Default: ``None``.
+            If not specified, a temp file will be created. Defaults to ``None``
+        **kwargs: Keyword parameters passed to :class:`mmeval.BaseMetric`
     """
     default_prefix: Optional[str] = 'posetrack18'
 
     def __init__(self,
-                 ann_file: str,
+                 ann_file: Optional[str] = None,
                  score_mode: str = 'bbox_keypoint',
                  keypoint_score_thr: float = 0.2,
                  nms_mode: str = 'oks_nms',
                  nms_thr: float = 0.9,
                  format_only: bool = False,
                  outfile_prefix: Optional[str] = None,
                  collect_device: str = 'cpu',
                  prefix: Optional[str] = None) -> None:
         # raise an error to avoid long time running without getting results
         if not has_poseval:
             raise ImportError('Please install ``poseval`` package for '
                               'evaluation on PoseTrack dataset '
                               '(see `requirements/optional.txt`)')
-        super(CocoMetric, self).__init__(
-            collect_device=collect_device, prefix=prefix)
-        self.ann_file = ann_file
-
-        allowed_score_modes = ['bbox', 'bbox_keypoint']
-        if score_mode not in allowed_score_modes:
-            raise ValueError(
-                "`score_mode` should be one of 'bbox', 'bbox_keypoint', "
-                f"'bbox_rle', but got {score_mode}")
-        self.score_mode = score_mode
-        self.keypoint_score_thr = keypoint_score_thr
-
-        allowed_nms_modes = ['oks_nms', 'soft_oks_nms', 'none']
-        if nms_mode not in allowed_nms_modes:
-            raise ValueError(
-                "`nms_mode` should be one of 'oks_nms', 'soft_oks_nms', "
-                f"'none', but got {nms_mode}")
-        self.nms_mode = nms_mode
-        self.nms_thr = nms_thr
-
-        if format_only:
-            assert outfile_prefix is not None, '`outfile_prefix` can not be '\
-                'None when `format_only` is True, otherwise the result file '\
-                'will be saved to a temp directory which will be cleaned up '\
-                'in the end.'
-        else:
-            # do evaluation only if the ground truth annotations exist
-            assert 'annotations' in load(ann_file), \
-                'Ground truth annotations are required for evaluation '\
-                'when `format_only` is False.'
-        self.format_only = format_only
-
-        self.outfile_prefix = outfile_prefix
+        super().__init__(
+            ann_file=ann_file,
+            score_mode=score_mode,
+            keypoint_score_thr=keypoint_score_thr,
+            nms_mode=nms_mode,
+            nms_thr=nms_thr,
+            format_only=format_only,
+            outfile_prefix=outfile_prefix,
+            collect_device=collect_device,
+            prefix=prefix)
 
     def results2json(self, keypoints: Dict[int, list],
                      outfile_prefix: str) -> str:
         """Dump the keypoint detection results into a json file.
 
         Args:
             keypoints (Dict[int, list]): Keypoint detection results
@@ -235,13 +208,13 @@
         logger.info('Average Precision (AP) metric:')
         eval_helpers.printTable(apAll)
 
         stats = eval_helpers.getCum(apAll)
 
         stats_names = [
             'Head AP', 'Shou AP', 'Elb AP', 'Wri AP', 'Hip AP', 'Knee AP',
-            'Ankl AP', 'Total AP'
+            'Ankl AP', 'AP'
         ]
 
         info_str = list(zip(stats_names, stats))
 
         return info_str
```

### Comparing `mmpose-1.0.0rc0/mmpose/models/__init__.py` & `mmpose-1.0.0rc1/mmpose/models/__init__.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/__init__.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/__init__.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/alexnet.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/alexnet.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/base_backbone.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/base_backbone.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/cpm.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/cpm.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/hourglass.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/hourglass.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/hourglass_ae.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/hourglass_ae.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/hrformer.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/hrformer.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/hrnet.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/hrnet.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/litehrnet.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/litehrnet.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/mobilenet_v2.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/mobilenet_v2.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/mobilenet_v3.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/mobilenet_v3.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/mspn.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/mspn.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/pvt.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/pvt.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/regnet.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/regnet.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/resnest.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/resnest.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/resnet.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/resnet.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/resnext.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/resnext.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/rsn.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/rsn.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/scnet.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/scnet.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/seresnet.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/seresnet.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/seresnext.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/seresnext.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/shufflenet_v1.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/shufflenet_v1.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/shufflenet_v2.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/shufflenet_v2.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/swin.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/swin.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,28 +1,27 @@
 # Copyright (c) OpenMMLab. All rights reserved.
-from collections import OrderedDict
 from copy import deepcopy
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import torch.utils.checkpoint as cp
 from mmcv.cnn import build_norm_layer
 from mmcv.cnn.bricks.transformer import FFN, build_dropout
 from mmengine.model import BaseModule
 from mmengine.model.weight_init import trunc_normal_
 from mmengine.runner import load_state_dict
 from mmengine.utils import to_2tuple
 
 from mmpose.registry import MODELS
-from ...utils import get_root_logger
+from mmpose.utils import get_root_logger
+from ..utils.transformer import PatchEmbed, PatchMerging
 from .base_backbone import BaseBackbone
 from .utils import get_state_dict
 from .utils.ckpt_convert import swin_converter
-from .utils.transformer import PatchEmbed, PatchMerging
 
 
 class WindowMSA(BaseModule):
     """Window based multi-head self-attention (W-MSA) module with relative
     position bias.
 
     Args:
@@ -664,21 +663,19 @@
             pretrained (str, optional): Path to pre-trained weights.
                 Defaults to None.
         """
         if (isinstance(self.init_cfg, dict)
                 and self.init_cfg['type'] == 'Pretrained'):
             # Suppress zero_init_residual if use pretrained model.
             logger = get_root_logger()
-            _state_dict = get_state_dict(
+            state_dict = get_state_dict(
                 self.init_cfg['checkpoint'], map_location='cpu')
             if self.convert_weights:
-                # supported loading weight from original repo,
-                _state_dict = swin_converter(_state_dict)
-
-            state_dict = OrderedDict()
+                # supported loading weight from original repo
+                state_dict = swin_converter(state_dict)
 
             # strip prefix of state_dict
             if list(state_dict.keys())[0].startswith('module.'):
                 state_dict = {k[7:]: v for k, v in state_dict.items()}
 
             # reshape absolute position embedding
             if state_dict.get('absolute_pos_embed') is not None:
```

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/tcn.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/tcn.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/utils/channel_shuffle.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/utils/channel_shuffle.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/utils/ckpt_convert.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/utils/ckpt_convert.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/utils/inverted_residual.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/utils/inverted_residual.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/utils/make_divisible.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/utils/make_divisible.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/utils/se_layer.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/utils/se_layer.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/utils/utils.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/utils/utils.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/v2v_net.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/v2v_net.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/vgg.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/vgg.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/vipnas_mbv3.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/vipnas_mbv3.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/backbones/vipnas_resnet.py` & `mmpose-1.0.0rc1/mmpose/models/backbones/vipnas_resnet.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/builder.py` & `mmpose-1.0.0rc1/mmpose/models/builder.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/heads/base_head.py` & `mmpose-1.0.0rc1/mmpose/models/heads/base_head.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,17 +1,19 @@
 # Copyright (c) OpenMMLab. All rights reserved.
+import warnings
 from abc import ABCMeta, abstractmethod
-from typing import List, Tuple, Union
+from typing import List, Sequence, Tuple, Union
 
 import torch
 import torch.nn.functional as F
 from mmengine.model import BaseModule
 from mmengine.structures import InstanceData
 from torch import Tensor
 
+from mmpose.models.utils.ops import resize
 from mmpose.utils.tensor_utils import to_numpy
 from mmpose.utils.typing import (Features, InstanceList, OptConfigType,
                                  OptSampleList, Predictions)
 
 
 class BaseHead(BaseModule, metaclass=ABCMeta):
     """Base head. A subclass should override :meth:`predict` and :meth:`loss`.
@@ -54,35 +56,49 @@
                 in_channels = sum(feat_channels[i] for i in self.input_index)
         elif self.input_transform == 'select':
             if isinstance(self.input_index, int):
                 in_channels = feat_channels[self.input_index]
             else:
                 in_channels = [feat_channels[i] for i in self.input_index]
         else:
-            raise (ValueError,
-                   f'Invalid input transform mode "{self.input_transform}"')
+            raise ValueError(
+                f'Invalid input transform mode "{self.input_transform}"')
 
         return in_channels
 
-    def _transform_inputs(self, feats: Tuple[Tensor]
-                          ) -> Union[Tensor, Tuple[Tensor]]:
+    def _transform_inputs(
+        self,
+        feats: Union[Tensor, Sequence[Tensor]],
+    ) -> Union[Tensor, Tuple[Tensor]]:
         """Transform multi scale features into the network input."""
+        if not isinstance(feats, Sequence):
+            warnings.warn(f'the input of {self._get_name()} is a tensor '
+                          f'instead of a tuple or list. The argument '
+                          f'`input_transform` will be ignored.')
+            return feats
+
         if self.input_transform == 'resize_concat':
             inputs = [feats[i] for i in self.input_index]
             resized_inputs = [
                 F.interpolate(
                     x,
                     size=inputs[0].shape[2:],
                     mode='bilinear',
                     align_corners=self.align_corners) for x in inputs
             ]
             inputs = torch.cat(resized_inputs, dim=1)
         elif self.input_transform == 'select':
             if isinstance(self.input_index, int):
                 inputs = feats[self.input_index]
+                if hasattr(self, 'upsample') and self.upsample > 0:
+                    inputs = resize(
+                        input=F.relu(inputs),
+                        scale_factor=self.upsample,
+                        mode='bilinear',
+                        align_corners=self.align_corners)
             else:
                 inputs = tuple(feats[i] for i in self.input_index)
         else:
             raise (ValueError,
                    f'Invalid input transform mode "{self.input_transform}"')
 
         return inputs
@@ -96,30 +112,36 @@
                 a data batch
 
         Returns:
             List[InstanceData]: A list of InstanceData, each contains the
             decoded pose information of the instances of one data sample.
         """
 
+        def _pack_and_call(args, func):
+            if not isinstance(args, tuple):
+                args = (args, )
+            return func(*args)
+
         if self.decoder is None:
             raise RuntimeError(
                 f'The decoder has not been set in {self.__class__.__name__}. '
                 'Please set the decoder configs in the init parameters to '
                 'enable head methods `head.predict()` and `head.decode()`')
 
         if self.decoder.support_batch_decoding:
-            batch_keypoints, batch_scores = self.decoder.batch_decode(
-                batch_outputs)
+            batch_keypoints, batch_scores = _pack_and_call(
+                batch_outputs, self.decoder.batch_decode)
 
         else:
             batch_output_np = to_numpy(batch_outputs, unzip=True)
             batch_keypoints = []
             batch_scores = []
             for outputs in batch_output_np:
-                keypoints, scores = self.decoder.decode(outputs)
+                keypoints, scores = _pack_and_call(outputs,
+                                                   self.decoder.decode)
                 batch_keypoints.append(keypoints)
                 batch_scores.append(scores)
 
         preds = [
             InstanceData(keypoints=keypoints, keypoint_scores=scores)
             for keypoints, scores in zip(batch_keypoints, batch_scores)
         ]
```

### Comparing `mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/cpm_head.py` & `mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/cpm_head.py`

 * *Files 1% similar despite different names*

```diff
@@ -90,15 +90,15 @@
         self.multi_deconv_layers = nn.ModuleList([])
         if deconv_out_channels:
             if deconv_kernel_sizes is None or len(deconv_out_channels) != len(
                     deconv_kernel_sizes):
                 raise ValueError(
                     '"deconv_out_channels" and "deconv_kernel_sizes" should '
                     'be integer sequences with the same length. Got '
-                    f'unmatched values {deconv_out_channels} and '
+                    f'mismatched lengths {deconv_out_channels} and '
                     f'{deconv_kernel_sizes}')
 
             for _ in range(self.num_stages):
                 deconv_layers = self._make_deconv_layers(
                     in_channels=in_channels,
                     layer_out_channels=deconv_out_channels,
                     layer_kernel_sizes=deconv_kernel_sizes,
```

### Comparing `mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/heatmap_head.py` & `mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/heatmap_head.py`

 * *Files 4% similar despite different names*

```diff
@@ -60,14 +60,16 @@
             transformation. Defaults to ``False``
         loss (Config): Config of the keypoint loss. Defaults to use
             :class:`KeypointMSELoss`
         decoder (Config, optional): The decoder config that controls decoding
             keypoint coordinates from the network output. Defaults to ``None``
         init_cfg (Config, optional): Config to control the initialization. See
             :attr:`default_init_cfg` for default settings
+        extra (dict, optional): Extra configurations.
+            Defaults to ``None``
 
     .. _`Simple Baselines`: https://arxiv.org/abs/1804.06208
     """
 
     _version = 2
 
     def __init__(self,
@@ -80,15 +82,16 @@
                  has_final_layer: bool = True,
                  input_transform: str = 'select',
                  input_index: Union[int, Sequence[int]] = -1,
                  align_corners: bool = False,
                  loss: ConfigType = dict(
                      type='KeypointMSELoss', use_target_weight=True),
                  decoder: OptConfigType = None,
-                 init_cfg: OptConfigType = None):
+                 init_cfg: OptConfigType = None,
+                 extra=None):
 
         if init_cfg is None:
             init_cfg = self.default_init_cfg
 
         super().__init__(init_cfg)
 
         self.in_channels = in_channels
@@ -97,29 +100,44 @@
         self.input_transform = input_transform
         self.input_index = input_index
         self.loss_module = MODELS.build(loss)
         if decoder is not None:
             self.decoder = KEYPOINT_CODECS.build(decoder)
         else:
             self.decoder = None
+        self.upsample = 0
+
+        if extra is not None and not isinstance(extra, dict):
+            raise TypeError('extra should be dict or None.')
+
+        kernel_size = 1
+        padding = 0
+        if extra is not None:
+            if 'upsample' in extra:
+                self.upsample = extra['upsample']
+            if 'final_conv_kernel' in extra:
+                assert extra['final_conv_kernel'] in [1, 3]
+                if extra['final_conv_kernel'] == 3:
+                    padding = 1
+                kernel_size = extra['final_conv_kernel']
 
         # Get model input channels according to feature
         in_channels = self._get_in_channels()
         if isinstance(in_channels, list):
             raise ValueError(
                 f'{self.__class__.__name__} does not support selecting '
                 'multiple input features.')
 
         if deconv_out_channels:
             if deconv_kernel_sizes is None or len(deconv_out_channels) != len(
                     deconv_kernel_sizes):
                 raise ValueError(
                     '"deconv_out_channels" and "deconv_kernel_sizes" should '
                     'be integer sequences with the same length. Got '
-                    f'unmatched values {deconv_out_channels} and '
+                    f'mismatched lengths {deconv_out_channels} and '
                     f'{deconv_kernel_sizes}')
 
             self.deconv_layers = self._make_deconv_layers(
                 in_channels=in_channels,
                 layer_out_channels=deconv_out_channels,
                 layer_kernel_sizes=deconv_kernel_sizes,
             )
@@ -128,31 +146,33 @@
             self.deconv_layers = nn.Identity()
 
         if conv_out_channels:
             if conv_kernel_sizes is None or len(conv_out_channels) != len(
                     conv_kernel_sizes):
                 raise ValueError(
                     '"conv_out_channels" and "conv_kernel_sizes" should '
-                    'be integer sequences with the same length. Got unmatched'
-                    f' values {conv_out_channels} and {conv_kernel_sizes}')
+                    'be integer sequences with the same length. Got '
+                    f'mismatched lengths {conv_out_channels} and '
+                    f'{conv_kernel_sizes}')
 
             self.conv_layers = self._make_conv_layers(
                 in_channels=in_channels,
                 layer_out_channels=conv_out_channels,
                 layer_kernel_sizes=conv_kernel_sizes)
             in_channels = conv_out_channels[-1]
         else:
             self.conv_layers = nn.Identity()
 
         if has_final_layer:
             cfg = dict(
                 type='Conv2d',
                 in_channels=in_channels,
                 out_channels=out_channels,
-                kernel_size=1)
+                padding=padding,
+                kernel_size=kernel_size)
             self.final_layer = build_conv_layer(cfg)
         else:
             self.final_layer = nn.Identity()
 
         # Register the hook to automatically convert old version state dicts
         self._register_load_state_dict_pre_hook(self._load_state_dict_pre_hook)
```

### Comparing `mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/mix_head.py` & `mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/mix_head.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/mspn_head.py` & `mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/mspn_head.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/simcc_head.py` & `mmpose-1.0.0rc1/mmpose/models/heads/coord_cls_heads/simcc_head.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from typing import Optional, Sequence, Tuple, Union
 
 import torch
 from mmcv.cnn import build_conv_layer
+from mmengine.structures import PixelData
 from torch import Tensor, nn
 
 from mmpose.evaluation.functional import simcc_pck_accuracy
 from mmpose.models.utils.tta import flip_vectors
 from mmpose.registry import KEYPOINT_CODECS, MODELS
 from mmpose.utils.tensor_utils import to_numpy
 from mmpose.utils.typing import (ConfigType, InstanceList, OptConfigType,
@@ -200,14 +201,15 @@
                           deconv_num_groups: OptIntSeq = (16, 16, 16),
                           conv_out_channels: OptIntSeq = None,
                           conv_kernel_sizes: OptIntSeq = None,
                           has_final_layer: bool = True,
                           input_transform: str = 'select',
                           input_index: Union[int, Sequence[int]] = -1,
                           align_corners: bool = False) -> nn.Module:
+        """Create deconvolutional layers by given parameters."""
 
         if deconv_type == 'heatmap':
             deconv_head = MODELS.build(
                 dict(
                     type='HeatmapHead',
                     in_channels=self.in_channels,
                     out_channels=out_channels,
@@ -311,22 +313,35 @@
             batch_pred_y = (_batch_pred_y + _batch_pred_y_flip) * 0.5
         else:
             batch_pred_x, batch_pred_y = self.forward(feats)
 
         preds = self.decode((batch_pred_x, batch_pred_y))
 
         if test_cfg.get('output_heatmaps', False):
+            B, K, _ = batch_pred_x.shape
+            # B, K, Wx -> B, K, Wx, 1
+            x = batch_pred_x.reshape(B, K, 1, -1)
+            # B, K, Wy -> B, K, 1, Wy
+            y = batch_pred_y.reshape(B, K, -1, 1)
+            # B, K, Wx, Wy
+            batch_heatmaps = torch.matmul(y, x)
+            pred_fields = [
+                PixelData(heatmaps=hm) for hm in batch_heatmaps.detach()
+            ]
+
             for pred_instances, pred_x, pred_y in zip(preds,
                                                       to_numpy(batch_pred_x),
                                                       to_numpy(batch_pred_y)):
 
                 pred_instances.keypoint_x_labels = pred_x[None]
                 pred_instances.keypoint_y_labels = pred_y[None]
 
-        return preds
+            return preds, pred_fields
+        else:
+            return preds
 
     def loss(
         self,
         feats: Tuple[Tensor],
         batch_data_samples: OptSampleList,
         train_cfg: OptConfigType = {},
     ) -> dict:
```

### Comparing `mmpose-1.0.0rc0/mmpose/models/heads/heatmap_heads/vipnas_head.py` & `mmpose-1.0.0rc1/mmpose/models/heads/heatmap_heads/vipnas_head.py`

 * *Files 6% similar despite different names*

```diff
@@ -112,22 +112,22 @@
 
         if deconv_out_channels:
             if deconv_kernel_sizes is None or len(deconv_out_channels) != len(
                     deconv_kernel_sizes):
                 raise ValueError(
                     '"deconv_out_channels" and "deconv_kernel_sizes" should '
                     'be integer sequences with the same length. Got '
-                    f'unmatched values {deconv_out_channels} and '
+                    f'mismatched lengths {deconv_out_channels} and '
                     f'{deconv_kernel_sizes}')
             if deconv_num_groups is None or len(deconv_out_channels) != len(
                     deconv_num_groups):
                 raise ValueError(
                     '"deconv_out_channels" and "deconv_num_groups" should '
                     'be integer sequences with the same length. Got '
-                    f'unmatched values {deconv_out_channels} and '
+                    f'mismatched lengths {deconv_out_channels} and '
                     f'{deconv_num_groups}')
 
             self.deconv_layers = self._make_deconv_layers(
                 in_channels=in_channels,
                 layer_out_channels=deconv_out_channels,
                 layer_kernel_sizes=deconv_kernel_sizes,
                 layer_groups=deconv_num_groups,
@@ -137,16 +137,17 @@
             self.deconv_layers = nn.Identity()
 
         if conv_out_channels:
             if conv_kernel_sizes is None or len(conv_out_channels) != len(
                     conv_kernel_sizes):
                 raise ValueError(
                     '"conv_out_channels" and "conv_kernel_sizes" should '
-                    'be integer sequences with the same length. Got unmatched'
-                    f' values {conv_out_channels} and {conv_kernel_sizes}')
+                    'be integer sequences with the same length. Got '
+                    f'mismatched lengths {conv_out_channels} and '
+                    f'{conv_kernel_sizes}')
 
             self.conv_layers = self._make_conv_layers(
                 in_channels=in_channels,
                 layer_out_channels=conv_out_channels,
                 layer_kernel_sizes=conv_kernel_sizes)
             in_channels = conv_out_channels[-1]
         else:
```

### Comparing `mmpose-1.0.0rc0/mmpose/models/heads/regression_heads/dsnt_head.py` & `mmpose-1.0.0rc1/mmpose/models/heads/regression_heads/dsnt_head.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/heads/regression_heads/integral_regression_head.py` & `mmpose-1.0.0rc1/mmpose/models/heads/regression_heads/integral_regression_head.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/heads/regression_heads/regression_head.py` & `mmpose-1.0.0rc1/mmpose/models/heads/regression_heads/regression_head.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/heads/regression_heads/rle_head.py` & `mmpose-1.0.0rc1/mmpose/models/heads/regression_heads/rle_head.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/losses/__init__.py` & `mmpose-1.0.0rc1/mmpose/models/losses/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,18 +1,17 @@
 # Copyright (c) OpenMMLab. All rights reserved.
+from .ae_loss import AssociativeEmbeddingLoss
 from .classification_loss import BCELoss, JSDiscretLoss, KLDiscretLoss
-from .heatmap_loss import AdaptiveWingLoss
-from .loss_wrappers import MultipleLossWrapper
-from .mse_loss import (CombinedTargetMSELoss, KeypointMSELoss,
-                       KeypointOHKMMSELoss)
-from .multi_loss_factory import AELoss, HeatmapLoss, MultiLossFactory
+from .heatmap_loss import (AdaptiveWingLoss, KeypointMSELoss,
+                           KeypointOHKMMSELoss)
+from .loss_wrappers import CombinedLoss, MultipleLossWrapper
 from .regression_loss import (BoneLoss, L1Loss, MPJPELoss, MSELoss, RLELoss,
-                              SemiSupervisionLoss, SmoothL1Loss, SoftWingLoss,
-                              WingLoss)
+                              SemiSupervisionLoss, SmoothL1Loss,
+                              SoftWeightSmoothL1Loss, SoftWingLoss, WingLoss)
 
 __all__ = [
-    'KeypointMSELoss', 'KeypointOHKMMSELoss', 'CombinedTargetMSELoss',
-    'HeatmapLoss', 'AELoss', 'MultiLossFactory', 'SmoothL1Loss', 'WingLoss',
+    'KeypointMSELoss', 'KeypointOHKMMSELoss', 'SmoothL1Loss', 'WingLoss',
     'MPJPELoss', 'MSELoss', 'L1Loss', 'BCELoss', 'BoneLoss',
     'SemiSupervisionLoss', 'SoftWingLoss', 'AdaptiveWingLoss', 'RLELoss',
-    'KLDiscretLoss', 'MultipleLossWrapper', 'JSDiscretLoss'
+    'KLDiscretLoss', 'MultipleLossWrapper', 'JSDiscretLoss', 'CombinedLoss',
+    'AssociativeEmbeddingLoss', 'SoftWeightSmoothL1Loss'
 ]
```

### Comparing `mmpose-1.0.0rc0/mmpose/models/losses/mse_loss.py` & `mmpose-1.0.0rc1/mmpose/models/losses/classification_loss.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,220 +1,221 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 import torch
 import torch.nn as nn
-from torch import Tensor
+import torch.nn.functional as F
 
 from mmpose.registry import MODELS
 
 
 @MODELS.register_module()
-class KeypointMSELoss(nn.Module):
-    """MSE loss for heatmaps.
+class BCELoss(nn.Module):
+    """Binary Cross Entropy loss.
 
     Args:
-        use_target_weight (bool): Option to use weighted MSE loss.
+        use_target_weight (bool): Option to use weighted loss.
             Different joint types may have different target weights.
-            Defaults to ``False``
-        loss_weight (float): Weight of the loss. Defaults to 1.0
+        loss_weight (float): Weight of the loss. Default: 1.0.
     """
 
-    def __init__(self,
-                 use_target_weight: bool = False,
-                 loss_weight: float = 1.):
+    def __init__(self, use_target_weight=False, loss_weight=1.):
         super().__init__()
-        self.criterion = nn.MSELoss()
+        self.criterion = F.binary_cross_entropy
         self.use_target_weight = use_target_weight
         self.loss_weight = loss_weight
 
-    def forward(self, output: Tensor, target: Tensor,
-                target_weights: Tensor) -> Tensor:
-        """Forward function of loss.
+    def forward(self, output, target, target_weight=None):
+        """Forward function.
 
         Note:
-            - batch_size: B
-            - num_keypoints: K
-            - heatmaps height: H
-            - heatmaps weight: W
+            - batch_size: N
+            - num_labels: K
 
         Args:
-            output (Tensor): The output heatmaps with shape [B, K, H, W].
-            target (Tensor): The target heatmaps with shape [B, K, H, W].
-            target_weights (Tensor): The target weights of differet keypoints,
-                with shape [B, K].
-
-        Returns:
-            Tensor: The calculated loss.
+            output (torch.Tensor[N, K]): Output classification.
+            target (torch.Tensor[N, K]): Target classification.
+            target_weight (torch.Tensor[N, K] or torch.Tensor[N]):
+                Weights across different labels.
         """
-        if self.use_target_weight:
-            assert target_weights is not None
-            assert output.ndim >= target_weights.ndim
 
-            for i in range(output.ndim - target_weights.ndim):
-                target_weights = target_weights.unsqueeze(-1)
-
-            loss = self.criterion(output * target_weights,
-                                  target * target_weights)
+        if self.use_target_weight:
+            assert target_weight is not None
+            loss = self.criterion(output, target, reduction='none')
+            if target_weight.dim() == 1:
+                target_weight = target_weight[:, None]
+            loss = (loss * target_weight).mean()
         else:
             loss = self.criterion(output, target)
 
         return loss * self.loss_weight
 
 
 @MODELS.register_module()
-class CombinedTargetMSELoss(nn.Module):
-    """MSE loss for combined target.
+class JSDiscretLoss(nn.Module):
+    """Discrete JS Divergence loss for DSNT with Gaussian Heatmap.
 
-    CombinedTarget: The combination of classification target
-    (response map) and regression target (offset map).
-    Paper ref: Huang et al. The Devil is in the Details: Delving into
-    Unbiased Data Processing for Human Pose Estimation (CVPR 2020).
+    Modified from `the official implementation
+    <https://github.com/anibali/dsntnn/blob/master/dsntnn/__init__.py>`_.
 
     Args:
-        use_target_weight (bool): Option to use weighted MSE loss.
+        use_target_weight (bool): Option to use weighted loss.
             Different joint types may have different target weights.
-            Defaults to ``False``
-        loss_weight (float): Weight of the loss. Defaults to 1.0
+        size_average (bool): Option to average the loss by the batch_size.
     """
 
-    def __init__(self,
-                 use_target_weight: bool = False,
-                 loss_weight: float = 1.):
-        super().__init__()
-        self.criterion = nn.MSELoss(reduction='mean')
+    def __init__(
+        self,
+        use_target_weight=True,
+        size_average: bool = True,
+    ):
+        super(JSDiscretLoss, self).__init__()
         self.use_target_weight = use_target_weight
-        self.loss_weight = loss_weight
+        self.size_average = size_average
+        self.kl_loss = nn.KLDivLoss(reduction='none')
 
-    def forward(self, output: Tensor, target: Tensor,
-                target_weights: Tensor) -> Tensor:
-        """Forward function of loss.
+    def kl(self, p, q):
+        """Kullback-Leibler Divergence."""
 
-        Note:
-            - batch_size: B
-            - num_channels: C
-            - heatmaps height: H
-            - heatmaps weight: W
-            - num_keypoints: K
-            Here, C = 3 * K
+        eps = 1e-24
+        kl_values = self.kl_loss((q + eps).log(), p)
+        return kl_values
+
+    def js(self, pred_hm, gt_hm):
+        """Jensen-Shannon Divergence."""
+
+        m = 0.5 * (pred_hm + gt_hm)
+        js_values = 0.5 * (self.kl(pred_hm, m) + self.kl(gt_hm, m))
+        return js_values
+
+    def forward(self, pred_hm, gt_hm, target_weight=None):
+        """Forward function.
 
         Args:
-            output (Tensor): The output feature maps with shape [B, C, H, W].
-            target (Tensor): The target feature maps with shape [B, C, H, W].
-            target_weights (Tensor): The target weights of differet keypoints,
-                with shape [B, K].
+            pred_hm (torch.Tensor[N, K, H, W]): Predicted heatmaps.
+            gt_hm (torch.Tensor[N, K, H, W]): Target heatmaps.
+            target_weight (torch.Tensor[N, K] or torch.Tensor[N]):
+                Weights across different labels.
 
         Returns:
-            Tensor: The calculated loss.
+            torch.Tensor: Loss value.
         """
-        batch_size = output.size(0)
-        num_channels = output.size(1)
-        heatmaps_pred = output.reshape(
-            (batch_size, num_channels, -1)).split(1, 1)
-        heatmaps_gt = target.reshape(
-            (batch_size, num_channels, -1)).split(1, 1)
-        loss = 0.
-        num_joints = num_channels // 3
-        for idx in range(num_joints):
-            heatmap_pred = heatmaps_pred[idx * 3].squeeze()
-            heatmap_gt = heatmaps_gt[idx * 3].squeeze()
-            offset_x_pred = heatmaps_pred[idx * 3 + 1].squeeze()
-            offset_x_gt = heatmaps_gt[idx * 3 + 1].squeeze()
-            offset_y_pred = heatmaps_pred[idx * 3 + 2].squeeze()
-            offset_y_gt = heatmaps_gt[idx * 3 + 2].squeeze()
-            if self.use_target_weight:
-                target_weight = target_weights[:, idx, None]
-                heatmap_pred = heatmap_pred * target_weight
-                heatmap_gt = heatmap_gt * target_weight
-            # classification loss
-            loss += 0.5 * self.criterion(heatmap_pred, heatmap_gt)
-            # regression loss
-            loss += 0.5 * self.criterion(heatmap_gt * offset_x_pred,
-                                         heatmap_gt * offset_x_gt)
-            loss += 0.5 * self.criterion(heatmap_gt * offset_y_pred,
-                                         heatmap_gt * offset_y_gt)
-        return loss / num_joints * self.loss_weight
+
+        if self.use_target_weight:
+            assert target_weight is not None
+            assert pred_hm.ndim >= target_weight.ndim
+
+            for i in range(pred_hm.ndim - target_weight.ndim):
+                target_weight = target_weight.unsqueeze(-1)
+
+            loss = self.js(pred_hm * target_weight, gt_hm * target_weight)
+        else:
+            loss = self.js(pred_hm, gt_hm)
+
+        if self.size_average:
+            loss /= len(gt_hm)
+
+        return loss.sum()
 
 
 @MODELS.register_module()
-class KeypointOHKMMSELoss(nn.Module):
-    """MSE loss with online hard keypoint mining.
+class KLDiscretLoss(nn.Module):
+    """Discrete KL Divergence loss for SimCC with Gaussian Label Smoothing.
+    Modified from `the official implementation.
 
+    <https://github.com/leeyegy/SimCC>`_.
     Args:
-        use_target_weight (bool): Option to use weighted MSE loss.
+        beta (float): Temperature factor of Softmax.
+        label_softmax (bool): Whether to use Softmax on labels.
+        use_target_weight (bool): Option to use weighted loss.
             Different joint types may have different target weights.
-            Defaults to ``False``
-        topk (int): Only top k joint losses are kept. Defaults to 8
-        loss_weight (float): Weight of the loss. Defaults to 1.0
     """
 
-    def __init__(self,
-                 use_target_weight: bool = False,
-                 topk: int = 8,
-                 loss_weight: float = 1.):
-        super().__init__()
-        assert topk > 0
-        self.criterion = nn.MSELoss(reduction='none')
+    def __init__(self, beta=1.0, label_softmax=False, use_target_weight=True):
+        super(KLDiscretLoss, self).__init__()
+        self.beta = beta
+        self.label_softmax = label_softmax
         self.use_target_weight = use_target_weight
-        self.topk = topk
-        self.loss_weight = loss_weight
-
-    def _ohkm(self, losses: Tensor) -> Tensor:
-        """Online hard keypoint mining.
 
-        Note:
-            - batch_size: B
-            - num_keypoints: K
+        self.log_softmax = nn.LogSoftmax(dim=1)
+        self.kl_loss = nn.KLDivLoss(reduction='none')
 
-        Args:
-            loss (Tensor): The losses with shape [B, K]
+    def criterion(self, dec_outs, labels):
+        """Criterion function."""
 
-        Returns:
-            Tensor: The calculated loss.
-        """
-        ohkm_loss = 0.
-        B = losses.shape[0]
-        for i in range(B):
-            sub_loss = losses[i]
-            _, topk_idx = torch.topk(
-                sub_loss, k=self.topk, dim=0, sorted=False)
-            tmp_loss = torch.gather(sub_loss, 0, topk_idx)
-            ohkm_loss += torch.sum(tmp_loss) / self.topk
-        ohkm_loss /= B
-        return ohkm_loss
-
-    def forward(self, output: Tensor, target: Tensor,
-                target_weights: Tensor) -> Tensor:
-        """Forward function of loss.
+        scores = self.log_softmax(dec_outs * self.beta)
+        if self.label_softmax:
+            labels = F.softmax(labels * self.beta, dim=1)
+        loss = torch.mean(self.kl_loss(scores, labels), dim=1)
+        return loss
 
-        Note:
-            - batch_size: B
-            - num_keypoints: K
-            - heatmaps height: H
-            - heatmaps weight: W
+    def forward(self, pred_simcc, gt_simcc, target_weight):
+        """Forward function.
 
         Args:
-            output (Tensor): The output heatmaps with shape [B, K, H, W].
-            target (Tensor): The target heatmaps with shape [B, K, H, W].
-            target_weights (Tensor): The target weights of differet keypoints,
-                with shape [B, K].
-
-        Returns:
-            Tensor: The calculated loss.
+            pred_simcc (Tuple[Tensor, Tensor]): Predicted SimCC vectors of
+                x-axis and y-axis.
+            gt_simcc (Tuple[Tensor, Tensor]): Target representations.
+            target_weight (torch.Tensor[N, K] or torch.Tensor[N]):
+                Weights across different labels.
         """
-        num_keypoints = output.size(1)
-        if num_keypoints < self.topk:
-            raise ValueError(f'topk ({self.topk}) should not be '
-                             f'larger than num_keypoints ({num_keypoints}).')
+        output_x, output_y = pred_simcc
+        target_x, target_y = gt_simcc
+        num_joints = output_x.size(1)
+        loss = 0
+
+        for idx in range(num_joints):
+            coord_x_pred = output_x[:, idx].squeeze()
+            coord_y_pred = output_y[:, idx].squeeze()
+            coord_x_gt = target_x[:, idx].squeeze()
+            coord_y_gt = target_y[:, idx].squeeze()
 
-        losses = []
-        for idx in range(num_keypoints):
             if self.use_target_weight:
-                target_weight = target_weights[:, idx, None, None]
-                losses.append(
-                    self.criterion(output[:, idx] * target_weight,
-                                   target[:, idx] * target_weight))
+                weight = target_weight[:, idx].squeeze()
             else:
-                losses.append(self.criterion(output[:, idx], target[:, idx]))
+                weight = 1.
+
+            loss += (
+                self.criterion(coord_x_pred, coord_x_gt).mul(weight).sum())
+            loss += (
+                self.criterion(coord_y_pred, coord_y_gt).mul(weight).sum())
+
+        return loss / num_joints
+
+
+@MODELS.register_module()
+class InfoNCELoss(nn.Module):
+    """InfoNCE loss for training a discriminative representation space with a
+    contrastive manner.
+
+    `Representation Learning with Contrastive Predictive Coding
+    arXiv: <https://arxiv.org/abs/1611.05424>`_.
+
+    Args:
+        temperature (float, optional): The temperature to use in the softmax
+            function. Higher temperatures lead to softer probability
+            distributions. Defaults to 1.0.
+        loss_weight (float, optional): The weight to apply to the loss.
+            Defaults to 1.0.
+    """
+
+    def __init__(self, temperature: float = 1.0, loss_weight=1.0) -> None:
+        super(InfoNCELoss, self).__init__()
+        assert temperature > 0, f'the argument `temperature` must be ' \
+                                f'positive, but got {temperature}'
+        self.temp = temperature
+        self.loss_weight = loss_weight
+
+    def forward(self, features: torch.Tensor) -> torch.Tensor:
+        """Computes the InfoNCE loss.
 
-        losses = [loss.mean(dim=(1, 2)).unsqueeze(dim=1) for loss in losses]
-        losses = torch.cat(losses, dim=1)
+        Args:
+            features (Tensor): A tensor containing the feature
+                representations of different samples.
 
-        return self._ohkm(losses) * self.loss_weight
+        Returns:
+            Tensor: A tensor of shape (1,) containing the InfoNCE loss.
+        """
+        n = features.size(0)
+        features_norm = F.normalize(features, dim=1)
+        logits = features_norm.mm(features_norm.t()) / self.temp
+        targets = torch.arange(n, dtype=torch.long, device=features.device)
+        loss = F.cross_entropy(logits, targets, reduction='sum')
+        return loss * self.loss_weight
```

### Comparing `mmpose-1.0.0rc0/mmpose/models/losses/regression_loss.py` & `mmpose-1.0.0rc1/mmpose/models/losses/regression_loss.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 import math
+from functools import partial
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from mmpose.registry import MODELS
 from ..utils.realnvp import RealNVP
@@ -132,14 +133,95 @@
         else:
             loss = self.criterion(output, target)
 
         return loss * self.loss_weight
 
 
 @MODELS.register_module()
+class SoftWeightSmoothL1Loss(nn.Module):
+    """Smooth L1 loss with soft weight for regression.
+
+    Args:
+        use_target_weight (bool): Option to use weighted MSE loss.
+            Different joint types may have different target weights.
+        supervise_empty (bool): Whether to supervise the output with zero
+            weight.
+        beta (float):  Specifies the threshold at which to change between
+            L1 and L2 loss.
+        loss_weight (float): Weight of the loss. Default: 1.0.
+    """
+
+    def __init__(self,
+                 use_target_weight=False,
+                 supervise_empty=True,
+                 beta=1.0,
+                 loss_weight=1.):
+        super().__init__()
+
+        reduction = 'none' if use_target_weight else 'mean'
+        self.criterion = partial(
+            self.smooth_l1_loss, reduction=reduction, beta=beta)
+
+        self.supervise_empty = supervise_empty
+        self.use_target_weight = use_target_weight
+        self.loss_weight = loss_weight
+
+    @staticmethod
+    def smooth_l1_loss(input, target, reduction='none', beta=1.0):
+        """Re-implement torch.nn.functional.smooth_l1_loss with beta to support
+        pytorch <= 1.6."""
+        delta = input - target
+        mask = delta.abs() < beta
+        delta[mask] = (delta[mask]).pow(2) / (2 * beta)
+        delta[~mask] = delta[~mask].abs() - beta / 2
+
+        if reduction == 'mean':
+            return delta.mean()
+        elif reduction == 'sum':
+            return delta.sum()
+        elif reduction == 'none':
+            return delta
+        else:
+            raise ValueError(f'reduction must be \'mean\', \'sum\' or '
+                             f'\'none\', but got \'{reduction}\'')
+
+    def forward(self, output, target, target_weight=None):
+        """Forward function.
+
+        Note:
+            - batch_size: N
+            - num_keypoints: K
+            - dimension of keypoints: D (D=2 or D=3)
+
+        Args:
+            output (torch.Tensor[N, K, D]): Output regression.
+            target (torch.Tensor[N, K, D]): Target regression.
+            target_weight (torch.Tensor[N, K, D]):
+                Weights across different joint types.
+        """
+        if self.use_target_weight:
+            assert target_weight is not None
+            assert output.ndim >= target_weight.ndim
+
+            for i in range(output.ndim - target_weight.ndim):
+                target_weight = target_weight.unsqueeze(-1)
+
+            loss = self.criterion(output, target) * target_weight
+            if self.supervise_empty:
+                loss = loss.mean()
+            else:
+                num_elements = torch.nonzero(target_weight > 0).size()[0]
+                loss = loss.sum() / max(num_elements, 1.0)
+        else:
+            loss = self.criterion(output, target)
+
+        return loss * self.loss_weight
+
+
+@MODELS.register_module()
 class WingLoss(nn.Module):
     """Wing Loss. paper ref: 'Wing Loss for Robust Facial Landmark Localisation
     with Convolutional Neural Networks' Feng et al. CVPR'2018.
 
     Args:
         omega (float): Also referred to as width.
         epsilon (float): Also referred to as curvature.
```

### Comparing `mmpose-1.0.0rc0/mmpose/models/necks/fpn.py` & `mmpose-1.0.0rc1/mmpose/models/necks/fpn.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/necks/gap_neck.py` & `mmpose-1.0.0rc1/mmpose/models/necks/gap_neck.py`

 * *Files 4% similar despite different names*

```diff
@@ -18,14 +18,16 @@
         super().__init__()
         self.gap = nn.AdaptiveAvgPool2d((1, 1))
 
     def init_weights(self):
         pass
 
     def forward(self, inputs):
+        """Forward function."""
+
         if isinstance(inputs, tuple):
             outs = tuple([self.gap(x) for x in inputs])
             outs = tuple(
                 [out.view(x.size(0), -1) for out, x in zip(outs, inputs)])
         elif isinstance(inputs, list):
             outs = [self.gap(x) for x in inputs]
             outs = [out.view(x.size(0), -1) for out, x in zip(outs, inputs)]
```

### Comparing `mmpose-1.0.0rc0/mmpose/models/necks/posewarper_neck.py` & `mmpose-1.0.0rc1/mmpose/models/necks/posewarper_neck.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/pose_estimators/topdown.py` & `mmpose-1.0.0rc1/mmpose/models/pose_estimators/topdown.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from itertools import zip_longest
-from typing import Optional, Tuple
+from typing import Optional
 
 from torch import Tensor
 
 from mmpose.registry import MODELS
 from mmpose.utils.typing import (ConfigType, InstanceList, OptConfigType,
                                  OptMultiConfig, PixelDataList, SampleList)
 from .base import BasePoseEstimator
@@ -20,78 +20,43 @@
         head (dict, optional): The head config. Defaults to ``None``
         train_cfg (dict, optional): The runtime config for training process.
             Defaults to ``None``
         test_cfg (dict, optional): The runtime config for testing process.
             Defaults to ``None``
         data_preprocessor (dict, optional): The data preprocessing config to
             build the instance of :class:`BaseDataPreprocessor`. Defaults to
-            ``None``.
+            ``None``
         init_cfg (dict, optional): The config to control the initialization.
             Defaults to ``None``
+        metainfo (dict): Meta information for dataset, such as keypoints
+            definition and properties. If set, the metainfo of the input data
+            batch will be overridden. For more details, please refer to
+            https://mmpose.readthedocs.io/en/1.x/user_guides/
+            prepare_datasets.html#create-a-custom-dataset-info-
+            config-file-for-the-dataset. Defaults to ``None``
     """
 
-    _version = 2
-
     def __init__(self,
                  backbone: ConfigType,
                  neck: OptConfigType = None,
                  head: OptConfigType = None,
                  train_cfg: OptConfigType = None,
                  test_cfg: OptConfigType = None,
                  data_preprocessor: OptConfigType = None,
-                 init_cfg: OptMultiConfig = None):
-        super().__init__(data_preprocessor, init_cfg)
-
-        self.backbone = MODELS.build(backbone)
-
-        if neck is not None:
-            self.neck = MODELS.build(neck)
-
-        if head is not None:
-            self.head = MODELS.build(head)
-
-        self.train_cfg = train_cfg if train_cfg else {}
-        self.test_cfg = test_cfg if test_cfg else {}
-
-        # Register the hook to automatically convert old version state dicts
-        self._register_load_state_dict_pre_hook(self._load_state_dict_pre_hook)
-
-    def extract_feat(self, inputs: Tensor) -> Tuple[Tensor]:
-        """Extract features.
-
-        Args:
-            inputs (Tensor): Image tensor with shape (N, C, H ,W).
-
-        Returns:
-            tuple[Tensor]: Multi-level features that may have various
-            resolutions.
-        """
-        x = self.backbone(inputs)
-        if self.with_neck:
-            x = self.neck(x)
-
-        return x
-
-    def _forward(self, inputs: Tensor):
-        """Network forward process. Usually includes backbone, neck and head
-        forward without any post-processing.
-
-        Args:
-            inputs (Tensor): Inputs with shape (N, C, H, W).
-
-        Returns:
-            tuple: A tuple of features from ``rpn_head`` and ``roi_head``
-            forward.
-        """
-
-        x = self.extract_feat(inputs)
-        if self.with_head:
-            x = self.head.forward(x)
-
-        return x
+                 init_cfg: OptMultiConfig = None,
+                 metainfo: Optional[dict] = None):
+        super().__init__(
+            backbone=backbone,
+            neck=neck,
+            head=head,
+            train_cfg=train_cfg,
+            test_cfg=test_cfg,
+            data_preprocessor=data_preprocessor,
+            init_cfg=init_cfg,
+            metainfo=metainfo)
 
     def loss(self, inputs: Tensor, data_samples: SampleList) -> dict:
         """Calculate losses from a batch of inputs and data samples.
 
         Args:
             inputs (Tensor): Inputs with shape (N, C, H, W).
             data_samples (List[:obj:`PoseDataSample`]): The batch
@@ -139,15 +104,15 @@
             _feats_flip = self.extract_feat(inputs.flip(-1))
             feats = [_feats, _feats_flip]
         else:
             feats = self.extract_feat(inputs)
 
         preds = self.head.predict(feats, data_samples, test_cfg=self.test_cfg)
 
-        if isinstance(preds, Tuple):
+        if isinstance(preds, tuple):
             batch_pred_instances, batch_pred_fields = preds
         else:
             batch_pred_instances = preds
             batch_pred_fields = None
 
         results = self.add_pred_to_datasample(batch_pred_instances,
                                               batch_pred_fields, data_samples)
@@ -161,64 +126,57 @@
 
         Args:
             batch_pred_instances (List[InstanceData]): The predicted instances
                 of the input data batch
             batch_pred_fields (List[PixelData], optional): The predicted
                 fields (e.g. heatmaps) of the input batch
             batch_data_samples (List[PoseDataSample]): The input data batch
-            merge (bool): Whether merge all predictions into a single
-                `PoseDataSample`. This is useful when the input batch is
-                instances (bboxes) from the same image. Defaults to ``False``
 
         Returns:
             List[PoseDataSample]: A list of data samples where the predictions
             are stored in the ``pred_instances`` field of each data sample.
-            The length of the list is the batch size when ``merge==False``, or
-            1 when ``merge==True``.
         """
         assert len(batch_pred_instances) == len(batch_data_samples)
         if batch_pred_fields is None:
             batch_pred_fields = []
+        output_keypoint_indices = self.test_cfg.get('output_keypoint_indices',
+                                                    None)
 
         for pred_instances, pred_fields, data_sample in zip_longest(
                 batch_pred_instances, batch_pred_fields, batch_data_samples):
 
             gt_instances = data_sample.gt_instances
 
             # convert keypoint coordinates from input space to image space
             bbox_centers = gt_instances.bbox_centers
             bbox_scales = gt_instances.bbox_scales
             input_size = data_sample.metainfo['input_size']
 
             pred_instances.keypoints = pred_instances.keypoints / input_size \
                 * bbox_scales + bbox_centers - 0.5 * bbox_scales
 
+            if output_keypoint_indices is not None:
+                # select output keypoints with given indices
+                num_keypoints = pred_instances.keypoints.shape[1]
+                for key, value in pred_instances.all_items():
+                    if key.startswith('keypoint'):
+                        pred_instances.set_field(
+                            value[:, output_keypoint_indices], key)
+
             # add bbox information into pred_instances
             pred_instances.bboxes = gt_instances.bboxes
             pred_instances.bbox_scores = gt_instances.bbox_scores
 
             data_sample.pred_instances = pred_instances
 
             if pred_fields is not None:
+                if output_keypoint_indices is not None:
+                    # select output heatmap channels with keypoint indices
+                    # when the number of heatmap channel matches num_keypoints
+                    for key, value in pred_fields.all_items():
+                        if value.shape[0] != num_keypoints:
+                            continue
+                        pred_fields.set_field(value[output_keypoint_indices],
+                                              key)
                 data_sample.pred_fields = pred_fields
 
         return batch_data_samples
-
-    def _load_state_dict_pre_hook(self, state_dict, prefix, local_meta, *args,
-                                  **kwargs):
-        """A hook function to convert old-version state dict of
-        :class:`TopdownHeatmapSimpleHead` (before MMPose v1.0.0) to a
-        compatible format of :class:`HeatmapHead`.
-
-        The hook will be automatically registered during initialization.
-        """
-        version = local_meta.get('version', None)
-        if version and version >= self._version:
-            return
-
-        # convert old-version state dict
-        keys = list(state_dict.keys())
-        for k in keys:
-            if 'keypoint_head' in k:
-                v = state_dict.pop(k)
-                k = k.replace('keypoint_head', 'head')
-                state_dict[k] = v
```

### Comparing `mmpose-1.0.0rc0/mmpose/models/utils/ckpt_convert.py` & `mmpose-1.0.0rc1/mmpose/models/utils/ckpt_convert.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/utils/geometry.py` & `mmpose-1.0.0rc1/mmpose/models/utils/geometry.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/utils/ops.py` & `mmpose-1.0.0rc1/mmpose/models/utils/ops.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/utils/realnvp.py` & `mmpose-1.0.0rc1/mmpose/models/utils/realnvp.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/models/utils/regularizations.py` & `mmpose-1.0.0rc1/mmpose/models/utils/regularizations.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/structures/__init__.py` & `mmpose-1.0.0rc1/mmpose/structures/__init__.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from .bbox import (bbox_cs2xywh, bbox_cs2xyxy, bbox_xywh2cs, bbox_xywh2xyxy,
                    bbox_xyxy2cs, bbox_xyxy2xywh, flip_bbox,
                    get_udp_warp_matrix, get_warp_matrix)
 from .keypoint import flip_keypoints
 from .multilevel_pixel_data import MultilevelPixelData
 from .pose_data_sample import PoseDataSample
-from .utils import merge_data_samples, revert_heatmap
+from .utils import merge_data_samples, revert_heatmap, split_instances
 
 __all__ = [
     'PoseDataSample', 'MultilevelPixelData', 'bbox_cs2xywh', 'bbox_cs2xyxy',
     'bbox_xywh2cs', 'bbox_xywh2xyxy', 'bbox_xyxy2cs', 'bbox_xyxy2xywh',
     'flip_bbox', 'get_udp_warp_matrix', 'get_warp_matrix', 'flip_keypoints',
-    'merge_data_samples', 'revert_heatmap'
+    'merge_data_samples', 'revert_heatmap', 'split_instances'
 ]
```

### Comparing `mmpose-1.0.0rc0/mmpose/structures/bbox/transforms.py` & `mmpose-1.0.0rc1/mmpose/structures/bbox/transforms.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/structures/keypoint/transforms.py` & `mmpose-1.0.0rc1/mmpose/structures/keypoint/transforms.py`

 * *Files 2% similar despite different names*

```diff
@@ -34,15 +34,15 @@
             (..., K, D)
         - keypoints_visible_flipped (np.ndarray, optional): Flipped keypoints'
             visibility in shape (..., K, 1). Return ``None`` if the input
             ``keypoints_visible`` is ``None``
     """
 
     assert keypoints.shape[:-1] == keypoints_visible.shape, (
-        f'Unmatched shapes of keypoints {keypoints.shape} and '
+        f'Mismatched shapes of keypoints {keypoints.shape} and '
         f'keypoints_visible {keypoints_visible.shape}')
 
     direction_options = {'horizontal', 'vertical', 'diagonal'}
     assert direction in direction_options, (
         f'Invalid flipping direction "{direction}". '
         f'Options are {direction_options}')
```

### Comparing `mmpose-1.0.0rc0/mmpose/structures/multilevel_pixel_data.py` & `mmpose-1.0.0rc1/mmpose/structures/multilevel_pixel_data.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/structures/pose_data_sample.py` & `mmpose-1.0.0rc1/mmpose/structures/pose_data_sample.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/structures/utils.py` & `mmpose-1.0.0rc1/mmpose/structures/utils.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,8 +1,9 @@
 # Copyright (c) OpenMMLab. All rights reserved.
+import warnings
 from typing import List
 
 import cv2
 import numpy as np
 import torch
 from mmengine.structures import InstanceData, PixelData
 from mmengine.utils import is_list_of
@@ -27,15 +28,17 @@
         PoseDataSample: The merged data sample.
     """
 
     if not is_list_of(data_samples, PoseDataSample):
         raise ValueError('Invalid input type, should be a list of '
                          ':obj:`PoseDataSample`')
 
-    assert len(data_samples) > 0
+    if len(data_samples) == 0:
+        warnings.warn('Try to merge an empty list of data samples.')
+        return PoseDataSample()
 
     merged = PoseDataSample(metainfo=data_samples[0].metainfo)
 
     if 'gt_instances' in data_samples[0]:
         merged.gt_instances = InstanceData.cat(
             [d.gt_instances for d in data_samples])
 
@@ -106,7 +109,30 @@
         heatmap, warp_mat, (img_w, img_h), flags=cv2.INTER_LINEAR)
 
     # [H, W, K] -> [K, H, W]
     if ndim == 3:
         heatmap = heatmap.transpose(2, 0, 1)
 
     return heatmap
+
+
+def split_instances(instances: InstanceData) -> List[InstanceData]:
+    """Convert instances into a list where each element is a dict that contains
+    information about one instance."""
+    results = []
+
+    # return an empty list if there is no instance detected by the model
+    if instances is None:
+        return results
+
+    for i in range(len(instances.keypoints)):
+        result = dict(
+            keypoints=instances.keypoints[i].tolist(),
+            keypoint_scores=instances.keypoint_scores[i].tolist(),
+        )
+        if 'bboxes' in instances:
+            result['bbox'] = instances.bboxes[i].tolist(),
+            if 'bbox_scores' in instances:
+                result['bbox_score'] = instances.bbox_scores[i]
+        results.append(result)
+
+    return results
```

### Comparing `mmpose-1.0.0rc0/mmpose/testing/_utils.py` & `mmpose-1.0.0rc1/mmpose/testing/_utils.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,12 +1,16 @@
 # Copyright (c) OpenMMLab. All rights reserved.
+import os.path as osp
+from copy import deepcopy
 from typing import Optional
 
 import numpy as np
 import torch
+from mmengine.config import Config
+from mmengine.dataset import pseudo_collate
 from mmengine.structures import InstanceData, PixelData
 
 from mmpose.structures import MultilevelPixelData, PoseDataSample
 from mmpose.structures.bbox import bbox_xyxy2cs
 
 
 def get_coco_sample(
@@ -49,14 +53,15 @@
         1., 1., 1., 1., 1., 1., 1., 1.2, 1.2, 1.5, 1.5, 1., 1., 1.2, 1.2, 1.5,
         1.5
     ]).astype(np.float32)
 
     data = {
         'img': img,
         'img_shape': img_shape,
+        'ori_shape': img_shape,
         'bbox': bbox,
         'keypoints': keypoints,
         'keypoints_visible': keypoints_visible,
         'upper_body_ids': upper_body_ids,
         'lower_body_ids': lower_body_ids,
         'flip_pairs': flip_pairs,
         'flip_indices': flip_indices,
@@ -73,25 +78,25 @@
     return data
 
 
 def get_packed_inputs(batch_size=2,
                       num_instances=1,
                       num_keypoints=17,
                       num_levels=1,
-                      img_shape=(128, 128),
+                      img_shape=(256, 192),
                       input_size=(192, 256),
                       heatmap_size=(48, 64),
                       simcc_split_ratio=2.0,
                       with_heatmap=True,
                       with_reg_label=True,
                       with_simcc_label=True):
     """Create a dummy batch of model inputs and data samples."""
     rng = np.random.RandomState(0)
 
-    packed_inputs = []
+    inputs_list = []
     for idx in range(batch_size):
         inputs = dict()
 
         # input
         h, w = img_shape
         image = rng.randint(0, 255, size=(3, h, w), dtype=np.uint8)
         inputs['inputs'] = torch.from_numpy(image)
@@ -110,15 +115,14 @@
 
         np.random.shuffle(img_meta['flip_indices'])
         data_sample = PoseDataSample(metainfo=img_meta)
 
         # gt_instance
         gt_instances = InstanceData()
         gt_instance_labels = InstanceData()
-
         bboxes = _rand_bboxes(rng, num_instances, w, h)
         bbox_centers, bbox_scales = bbox_xyxy2cs(bboxes)
 
         keypoints = _rand_keypoints(rng, bboxes, num_keypoints)
         keypoints_visible = np.ones((num_instances, num_keypoints),
                                     dtype=np.float32)
 
@@ -171,17 +175,18 @@
                 gt_fields = MultilevelPixelData()
                 gt_fields.heatmaps = heatmaps
             data_sample.gt_fields = gt_fields
 
         data_sample.gt_instances = gt_instances
         data_sample.gt_instance_labels = gt_instance_labels
 
-        inputs['data_sample'] = data_sample
-        packed_inputs.append(inputs)
+        inputs['data_samples'] = data_sample
+        inputs_list.append(inputs)
 
+    packed_inputs = pseudo_collate(inputs_list)
     return packed_inputs
 
 
 def _rand_keypoints(rng, bboxes, num_keypoints):
     n = bboxes.shape[0]
     relative_pos = rng.rand(n, num_keypoints, 2)
     keypoints = relative_pos * bboxes[:, None, :2] + (
@@ -192,16 +197,52 @@
 
 def _rand_simcc_label(rng, num_instances, num_keypoints, len_feats):
     simcc_label = rng.rand(num_instances, num_keypoints, int(len_feats))
     return simcc_label
 
 
 def _rand_bboxes(rng, num_instances, img_w, img_h):
-    cx, cy, bw, bh = rng.rand(num_instances, 4).T
+    cx, cy = rng.rand(num_instances, 2).T
+    bw, bh = 0.2 + 0.8 * rng.rand(num_instances, 2).T
 
     tl_x = ((cx * img_w) - (img_w * bw / 2)).clip(0, img_w)
     tl_y = ((cy * img_h) - (img_h * bh / 2)).clip(0, img_h)
     br_x = ((cx * img_w) + (img_w * bw / 2)).clip(0, img_w)
     br_y = ((cy * img_h) + (img_h * bh / 2)).clip(0, img_h)
 
     bboxes = np.vstack([tl_x, tl_y, br_x, br_y]).T
     return bboxes
+
+
+def get_repo_dir():
+    """Return the path of the MMPose repo directory."""
+    try:
+        # Assume the function in invoked is the source mmpose repo
+        repo_dir = osp.dirname(osp.dirname(osp.dirname(__file__)))
+    except NameError:
+        # For IPython development when __file__ is not defined
+        import mmpose
+        repo_dir = osp.dirname(osp.dirname(mmpose.__file__))
+
+    return repo_dir
+
+
+def get_config_file(fn: str):
+    """Return full path of a config file from the given relative path."""
+    repo_dir = get_repo_dir()
+    if fn.startswith('configs'):
+        fn_config = osp.join(repo_dir, fn)
+    else:
+        fn_config = osp.join(repo_dir, 'configs', fn)
+
+    if not osp.isfile(fn_config):
+        raise FileNotFoundError(f'Cannot find config file {fn_config}')
+
+    return fn_config
+
+
+def get_pose_estimator_cfg(fn: str):
+    """Load model config from a config file."""
+
+    fn_config = get_config_file(fn)
+    config = Config.fromfile(fn_config)
+    return deepcopy(config.model)
```

### Comparing `mmpose-1.0.0rc0/mmpose/utils/camera.py` & `mmpose-1.0.0rc1/mmpose/utils/camera.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/utils/hooks.py` & `mmpose-1.0.0rc1/mmpose/utils/hooks.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/utils/logger.py` & `mmpose-1.0.0rc1/mmpose/utils/logger.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/utils/setup_env.py` & `mmpose-1.0.0rc1/mmpose/utils/setup_env.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/utils/tensor_utils.py` & `mmpose-1.0.0rc1/mmpose/utils/tensor_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,15 +14,15 @@
     """Convert torch tensor to numpy.ndarray.
 
     Args:
         x (Tensor | Sequence[Tensor]): A single tensor or a sequence of
             tensors
         return_device (bool): Whether return the tensor device. Defaults to
             ``False``
-        unzip (bool): Whether unzip the input sequence. Ddfaults to ``False``
+        unzip (bool): Whether unzip the input sequence. Defaults to ``False``
 
     Returns:
         np.ndarray | tuple: If ``return_device`` is ``True``, return a tuple
         of converted numpy array(s) and the device indicator; otherwise only
         return the numpy array(s)
     """
```

### Comparing `mmpose-1.0.0rc0/mmpose/utils/timer.py` & `mmpose-1.0.0rc1/mmpose/utils/timer.py`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/mmpose/utils/typing.py` & `mmpose-1.0.0rc1/mmpose/utils/typing.py`

 * *Files 8% similar despite different names*

```diff
@@ -21,8 +21,9 @@
 Predictions = Union[InstanceList, Tuple[InstanceList, PixelDataList]]
 # Type hint of model outputs
 ForwardResults = Union[Dict[str, Tensor], List[PoseDataSample], Tuple[Tensor],
                        Tensor]
 # Type hint of features
 #   - Tuple[Tensor]: multi-level features extracted by the network
 #   - List[Tuple[Tensor]]: multiple feature pyramids for TTA
-Features = Union[Tuple[Tensor], List[Tuple[Tensor]]]
+#   - List[List[Tuple[Tensor]]]: multi-scale feature pyramids
+Features = Union[Tuple[Tensor], List[Tuple[Tensor]], List[List[Tuple[Tensor]]]]
```

### Comparing `mmpose-1.0.0rc0/mmpose/version.py` & `mmpose-1.0.0rc1/mmpose/version.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Copyright (c) Open-MMLab. All rights reserved.
 
-__version__ = '1.0.0rc0'
+__version__ = '1.0.0rc1'
 short_version = __version__
 
 
 def parse_version_info(version_str):
     """Parse a version string into a tuple.
 
     Args:
```

### Comparing `mmpose-1.0.0rc0/mmpose/visualization/local_visualizer.py` & `mmpose-1.0.0rc1/mmpose/visualization/local_visualizer.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 import torch
 from mmengine.dist import master_only
 from mmengine.structures import InstanceData, PixelData
 from mmengine.visualization import Visualizer
 
 from mmpose.registry import VISUALIZERS
 from mmpose.structures import PoseDataSample
+from .simcc_vis import SimCCVisualizer
 
 
 def _get_adaptive_scales(areas: np.ndarray,
                          min_area: int = 800,
                          max_area: int = 30000) -> np.ndarray:
     """Get adaptive scales according to areas.
 
@@ -170,15 +171,15 @@
                 edge_colors=self.bbox_color,
                 alpha=self.alpha,
                 line_widths=self.line_width)
         else:
             return self.get_image()
 
         if 'labels' in instances and self.text_color is not None:
-            classes = self.dataset_meta.get('CLASSES', None)
+            classes = self.dataset_meta.get('classes', None)
             labels = instances.labels
 
             positions = bboxes[:, :2]
             areas = (bboxes[:, 3] - bboxes[:, 1]) * (
                 bboxes[:, 2] - bboxes[:, 0])
             scales = _get_adaptive_scales(areas)
 
@@ -206,15 +207,16 @@
                     }])
 
         return self.get_image()
 
     def _draw_instances_kpts(self,
                              image: np.ndarray,
                              instances: InstanceData,
-                             kpt_score_thr: float = 0.3):
+                             kpt_score_thr: float = 0.3,
+                             show_kpt_idx: bool = False):
         """Draw keypoints and skeletons (optional) of GT or prediction.
 
         Args:
             image (np.ndarray): The image to draw.
             instances (:obj:`InstanceData`): Data structure for
                 instance-level annotations or predictions.
             kpt_score_thr (float, optional): Minimum score of keypoints
@@ -271,14 +273,22 @@
                     self.draw_circles(
                         kpt,
                         radius=np.array([self.radius]),
                         face_colors=color,
                         edge_colors=color,
                         alpha=transparency,
                         line_widths=self.radius)
+                    if show_kpt_idx:
+                        self.draw_texts(
+                            str(kid),
+                            kpt,
+                            colors=color,
+                            font_sizes=self.radius * 3,
+                            vertical_alignments='bottom',
+                            horizontal_alignments='center')
 
                 # draw links
                 if self.skeleton is not None and self.link_color is not None:
                     if self.link_color is None or isinstance(
                             self.link_color, str):
                         link_color = [self.link_color] * len(self.skeleton)
                     elif len(self.link_color) == len(self.skeleton):
@@ -358,23 +368,52 @@
             heatmaps = torch.from_numpy(heatmaps)
         if heatmaps.dim() == 3:
             heatmaps, _ = heatmaps.max(dim=0)
         heatmaps = heatmaps.unsqueeze(0)
         out_image = self.draw_featmap(heatmaps, overlaid_image)
         return out_image
 
+    def _draw_instance_xy_heatmap(
+        self,
+        fields: PixelData,
+        overlaid_image: Optional[np.ndarray] = None,
+        n: int = 20,
+    ):
+        """Draw heatmaps of GT or prediction.
+
+        Args:
+            fields (:obj:`PixelData`): Data structure for
+            pixel-level annotations or predictions.
+            overlaid_image (np.ndarray): The image to draw.
+            n (int): Number of keypoint, up to 20.
+
+        Returns:
+            np.ndarray: the drawn image which channel is RGB.
+        """
+        if 'heatmaps' not in fields:
+            return None
+        heatmaps = fields.heatmaps
+        _, h, w = heatmaps.shape
+        if isinstance(heatmaps, np.ndarray):
+            heatmaps = torch.from_numpy(heatmaps)
+        out_image = SimCCVisualizer().draw_instance_xy_heatmap(
+            heatmaps, overlaid_image, n)
+        out_image = cv2.resize(out_image[:, :, ::-1], (w, h))
+        return out_image
+
     @master_only
     def add_datasample(self,
                        name: str,
                        image: np.ndarray,
                        data_sample: PoseDataSample,
                        draw_gt: bool = True,
                        draw_pred: bool = True,
                        draw_heatmap: bool = False,
                        draw_bbox: bool = False,
+                       show_kpt_idx: bool = False,
                        show: bool = False,
                        wait_time: float = 0,
                        out_file: Optional[str] = None,
                        kpt_score_thr: float = 0.3,
                        step: int = 0) -> None:
         """Draw datasample and save to all backends.
 
@@ -415,15 +454,16 @@
         if draw_gt:
             gt_img_data = image.copy()
             gt_img_heatmap = None
 
             # draw bboxes & keypoints
             if 'gt_instances' in data_sample:
                 gt_img_data = self._draw_instances_kpts(
-                    gt_img_data, data_sample.gt_instances, kpt_score_thr)
+                    gt_img_data, data_sample.gt_instances, kpt_score_thr,
+                    show_kpt_idx)
                 if draw_bbox:
                     gt_img_data = self._draw_instances_bbox(
                         gt_img_data, data_sample.gt_instances)
 
             # draw heatmaps
             if 'gt_fields' in data_sample and draw_heatmap:
                 gt_img_heatmap = self._draw_instance_heatmap(
@@ -435,23 +475,28 @@
         if draw_pred:
             pred_img_data = image.copy()
             pred_img_heatmap = None
 
             # draw bboxes & keypoints
             if 'pred_instances' in data_sample:
                 pred_img_data = self._draw_instances_kpts(
-                    pred_img_data, data_sample.pred_instances, kpt_score_thr)
+                    pred_img_data, data_sample.pred_instances, kpt_score_thr,
+                    show_kpt_idx)
                 if draw_bbox:
                     pred_img_data = self._draw_instances_bbox(
                         pred_img_data, data_sample.pred_instances)
 
             # draw heatmaps
             if 'pred_fields' in data_sample and draw_heatmap:
-                pred_img_heatmap = self._draw_instance_heatmap(
-                    data_sample.pred_fields, image)
+                if 'keypoint_x_labels' in data_sample.pred_instances:
+                    pred_img_heatmap = self._draw_instance_xy_heatmap(
+                        data_sample.pred_fields, image)
+                else:
+                    pred_img_heatmap = self._draw_instance_heatmap(
+                        data_sample.pred_fields, image)
                 if pred_img_heatmap is not None:
                     pred_img_data = np.concatenate(
                         (pred_img_data, pred_img_heatmap), axis=0)
 
         # merge visualization results
         if gt_img_data is not None and pred_img_data is not None:
             if gt_img_heatmap is None and pred_img_heatmap is not None:
@@ -475,7 +520,9 @@
             self.show(drawn_img, win_name=name, wait_time=wait_time)
 
         if out_file is not None:
             mmcv.imwrite(drawn_img[..., ::-1], out_file)
         else:
             # save drawn_img to backends
             self.add_image(name, drawn_img, step)
+
+        return self.get_image()
```

### Comparing `mmpose-1.0.0rc0/mmpose.egg-info/PKG-INFO` & `mmpose-1.0.0rc1/mmpose.egg-info/PKG-INFO`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mmpose
-Version: 1.0.0rc0
+Version: 1.0.0rc1
 Summary: OpenMMLab Pose Estimation Toolbox and Benchmark.
 Home-page: https://github.com/open-mmlab/mmpose
 Author: MMPose Contributors
 Author-email: openmmlab@gmail.com
 License: Apache License 2.0
 Description: <div align="center">
           <img src="resources/mmpose-logo.png" width="450"/>
@@ -35,30 +35,47 @@
         [![Percentage of issues still open](https://isitmaintained.com/badge/open/open-mmlab/mmpose.svg)](https://github.com/open-mmlab/mmpose/issues)
         
         [Documentation](https://mmpose.readthedocs.io/en/1.x/) |
         [Installation](https://mmpose.readthedocs.io/en/1.x/installation.html) |
         [Model Zoo](https://mmpose.readthedocs.io/en/1.x/model_zoo.html) |
         [Papers](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/algorithms.html) |
         [Update News](https://mmpose.readthedocs.io/en/1.x/notes/changelog.html) |
-        [Reporting Issues](https://github.com/open-mmlab/mmpose/issues/new/choose)
+        [Reporting Issues](https://github.com/open-mmlab/mmpose/issues/new/choose) |
+        [RTMPose](/projects/rtmpose/)
         
         </div>
         
+        <div align="center">
+          <a href="https://openmmlab.medium.com/" style="text-decoration:none;">
+            <img src="https://user-images.githubusercontent.com/25839884/218352562-cdded397-b0f3-4ca1-b8dd-a60df8dca75b.png" width="3%" alt="" /></a>
+          <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
+          <a href="https://discord.com/channels/1037617289144569886/1046608014234370059" style="text-decoration:none;">
+            <img src="https://user-images.githubusercontent.com/25839884/218347213-c080267f-cbb6-443e-8532-8e1ed9a58ea9.png" width="3%" alt="" /></a>
+          <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
+          <a href="https://twitter.com/OpenMMLab" style="text-decoration:none;">
+            <img src="https://user-images.githubusercontent.com/25839884/218346637-d30c8a0f-3eba-4699-8131-512fb06d46db.png" width="3%" alt="" /></a>
+          <img src="https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png" width="3%" alt="" />
+          <a href="https://www.youtube.com/openmmlab" style="text-decoration:none;">
+            <img src="https://user-images.githubusercontent.com/25839884/218346691-ceb2116a-465a-40af-8424-9f30d2348ca9.png" width="3%" alt="" /></a>
+        </div>
+        
         ## Introduction
         
         English | [](README_CN.md)
         
         MMPose is an open-source toolbox for pose estimation based on PyTorch.
         It is a part of the [OpenMMLab project](https://github.com/open-mmlab).
         
         The master branch works with **PyTorch 1.6+**.
         
         https://user-images.githubusercontent.com/15977946/124654387-0fd3c500-ded1-11eb-84f6-24eeddbf4d91.mp4
         
-        <details open>
+        <br/>
+        
+        <details close>
         <summary><b>Major Features</b></summary>
         
         - **Support diverse tasks**
         
           We support a wide spectrum of mainstream pose analysis tasks in current research community, including 2d multi-person human pose estimation, 2d hand pose estimation, 2d face landmark detection, 133 keypoint whole-body human pose estimation, 3d human mesh recovery, fashion landmark detection and animal pose estimation.
           See [Demo](demo/docs/) for more information.
         
@@ -78,29 +95,45 @@
           pose estimation framework by combining different modules.
           We provide detailed documentation and API reference, as well as unittests.
         
         </details>
         
         ## What's New
         
-        - 2022-10-14: MMPose [v1.0.0rc0](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0rc0) is released. Major updates include:
+        - We are excited to release **RTMPose**, a real-time pose estimation framework including:
+        
+          - A family of lightweight pose estimation models with state-of-the-art performance
+          - Inference APIs for Python, C++, C#, Java, etc. Easy to integrate into your applications and empower real-time stable pose estimation
+          - Cross-platform deployment with various backends
+          - A step-by-step guide to training and deploying your own models
+        
+          Checkout our [project page](/projects/rtmpose/) and [technical report](https://arxiv.org/abs/2303.07399) for more information!
+        
+        ![rtmpose_intro](https://user-images.githubusercontent.com/13503330/219269619-935499e5-bdd9-49ea-8104-3c7796dbd862.png)
+        
+        - Welcome to [*projects of MMPose*](/projects/README.md), where you can access to the latest features of MMPose, and share your ideas and codes with the community at once. Contribution to MMPose will be simple and smooth:
+        
+          - Provide an easy and agile way to integrate algorithms, features and applications into MMPose
+          - Allow flexible code structure and style; only need a short code review process
+          - Build individual projects with full power of MMPose but not bound up with heavy frameworks
+          - Checkout new projects:
+            - [RTMPose](/projects/rtmpose/)
+            - [YOLOX-Pose (coming soon)](<>)
+            - [MMPose4AIGC (coming soon)](<>)
+          - Become a contributors and make MMPose greater. Start your journey from the [example project](/projects/example_project/)
+        
+        <br/>
+        
+        - 2022-03-15: MMPose [v1.0.0rc1](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0rc1) is released. Major updates include:
+        
+          - Release [RTMPose](/projects/rtmpose/), a high-performance real-time pose estimation framework based on MMPose
+          - Support [ViTPose](/configs/body_2d_keypoint/topdown_heatmap/coco/vitpose_coco.md) (NeurIPS'22), [CID](/configs/body_2d_keypoint/cid/coco/hrnet_coco.md) (CVPR'22) and [DEKR](/configs/body_2d_keypoint/dekr/) (CVPR'21)
+          - Add [*Inferencer*](/docs/en/user_guides/inference.md#out-of-the-box-inferencer), a convenient interface for inference and visualization
         
-          - Support 4 light-weight pose estimation algorithms
-            - SimCC (ECCV'22): [paper](https://doi.org/10.48550/arxiv.2107.03332) | [models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/simcc/README.md)
-            - Debias-IPR (ICCV'21): [paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Gu_Removing_the_Bias_of_Integral_Pose_Regression_ICCV_2021_paper.pdf) | [models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/integral_regression/README.md)
-            - IPR (ECCV'18): [paper](https://arxiv.org/abs/1711.08229) | [models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/integral_regression/README.md)
-            - DSNT (ArXiv'18): [paper](https://arxiv.org/abs/1801.07372v2) | [models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/integral_regression/README.md)
-          - Add [Colab tutorial](https://github.com/open-mmlab/mmpose/blob/1.x/demo/MMPose_Tutorial.ipynb) for MMPose v1.0
-        
-        - 2022-09-01: MMPose [v1.0.0b0](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0b0) is released!
-        
-          - This release introduced major refactoring to MMPose towards better performance, extensibility and user-friendliness.
-          - Built upon a brand new and flexible training & test engine, which is still in progress. Welcome to try according to [the documentation](https://mmpose.readthedocs.io/en/1.x/).
-          - There are BC-breaking changes. Please check [the migration tutorial](https://mmpose.readthedocs.io/en/1.x/migration.html).
-          - The beta and release candidate versions will last until the end of 2022, and during the release candidate, we will develop on the `1.x` branch. And we will still maintain 0.x version still at least the end of 2023.
+          See the full [release note](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0rc1) for more exciting updates brought by MMPose v1.0.0rc1!
         
         ## Installation
         
         Below are quick steps for installation:
         
         ```shell
         conda create -n open-mmlab python=3.8 pytorch==1.10.1 torchvision==0.11.2 cudatoolkit=11.3 -c pytorch -y
@@ -285,17 +318,16 @@
         
 Keywords: computer vision,pose estimation
 Platform: UNKNOWN
 Classifier: Development Status :: 4 - Beta
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.5
-Classifier: Programming Language :: Python :: 3.6
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
+Requires-Python: >=3.7
 Description-Content-Type: text/markdown
 Provides-Extra: all
 Provides-Extra: tests
 Provides-Extra: optional
 Provides-Extra: mim
```

#### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: mmpose Version: 1.0.0rc0 Summary: OpenMMLab Pose
+Metadata-Version: 2.1 Name: mmpose Version: 1.0.0rc1 Summary: OpenMMLab Pose
 Estimation Toolbox and Benchmark. Home-page: https://github.com/open-mmlab/
 mmpose Author: MMPose Contributors Author-email: openmmlab@gmail.com License:
 Apache License 2.0 Description:
                           [resources/mmpose-logo.png]
                                        
            OpenMMLab website HOT  OpenMMLab platform TRY_IT_OUT
                                        
@@ -20,83 +20,90 @@
        mmlab/mmpose.svg)](https://github.com/open-mmlab/mmpose/issues)
          [Documentation](https://mmpose.readthedocs.io/en/1.x/) |
 [Installation](https://mmpose.readthedocs.io/en/1.x/installation.html) |
     [Model Zoo](https://mmpose.readthedocs.io/en/1.x/model_zoo.html) |
       [Papers](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
   algorithms.html) | [Update News](https://mmpose.readthedocs.io/en/1.x/
  notes/changelog.html) | [Reporting Issues](https://github.com/open-mmlab/
-                           mmpose/issues/new/choose)
+         mmpose/issues/new/choose) | [RTMPose](/projects/rtmpose/)
+
 ## Introduction English | [](README_CN.md) MMPose is an open-source
 toolbox for pose estimation based on PyTorch. It is a part of the [OpenMMLab
 project](https://github.com/open-mmlab). The master branch works with **PyTorch
 1.6+**. https://user-images.githubusercontent.com/15977946/124654387-0fd3c500-
-ded1-11eb-84f6-24eeddbf4d91.mp4  Major Features - **Support diverse tasks** We
-support a wide spectrum of mainstream pose analysis tasks in current research
-community, including 2d multi-person human pose estimation, 2d hand pose
-estimation, 2d face landmark detection, 133 keypoint whole-body human pose
-estimation, 3d human mesh recovery, fashion landmark detection and animal pose
-estimation. See [Demo](demo/docs/) for more information. - **Higher efficiency
-and higher accuracy** MMPose implements multiple state-of-the-art (SOTA) deep
-learning models, including both top-down & bottom-up approaches. We achieve
-faster training speed and higher accuracy than other popular codebases, such as
-[HRNet](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch). See
-[benchmark.md](docs/en/notes/benchmark.md) for more information. - **Support
-for various datasets** The toolbox directly supports multiple popular and
-representative datasets, COCO, AIC, MPII, MPII-TRB, OCHuman etc. See
-[dataset_zoo](docs/en/dataset_zoo) for more information. - **Well designed,
-tested and documented** We decompose MMPose into different components and one
-can easily construct a customized pose estimation framework by combining
-different modules. We provide detailed documentation and API reference, as well
-as unittests.  ## What's New - 2022-10-14: MMPose [v1.0.0rc0](https://
-github.com/open-mmlab/mmpose/releases/tag/v1.0.0rc0) is released. Major updates
-include: - Support 4 light-weight pose estimation algorithms - SimCC (ECCV'22):
-[paper](https://doi.org/10.48550/arxiv.2107.03332) | [models](https://
-github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/simcc/README.md)
-- Debias-IPR (ICCV'21): [paper](https://openaccess.thecvf.com/content/ICCV2021/
-papers/Gu_Removing_the_Bias_of_Integral_Pose_Regression_ICCV_2021_paper.pdf) |
-[models](https://github.com/open-mmlab/mmpose/blob/1.x/configs/
-body_2d_keypoint/integral_regression/README.md) - IPR (ECCV'18): [paper](https:
-//arxiv.org/abs/1711.08229) | [models](https://github.com/open-mmlab/mmpose/
-blob/1.x/configs/body_2d_keypoint/integral_regression/README.md) - DSNT
-(ArXiv'18): [paper](https://arxiv.org/abs/1801.07372v2) | [models](https://
-github.com/open-mmlab/mmpose/blob/1.x/configs/body_2d_keypoint/
-integral_regression/README.md) - Add [Colab tutorial](https://github.com/open-
-mmlab/mmpose/blob/1.x/demo/MMPose_Tutorial.ipynb) for MMPose v1.0 - 2022-09-01:
-MMPose [v1.0.0b0](https://github.com/open-mmlab/mmpose/releases/tag/v1.0.0b0)
-is released! - This release introduced major refactoring to MMPose towards
-better performance, extensibility and user-friendliness. - Built upon a brand
-new and flexible training & test engine, which is still in progress. Welcome to
-try according to [the documentation](https://mmpose.readthedocs.io/en/1.x/). -
-There are BC-breaking changes. Please check [the migration tutorial](https://
-mmpose.readthedocs.io/en/1.x/migration.html). - The beta and release candidate
-versions will last until the end of 2022, and during the release candidate, we
-will develop on the `1.x` branch. And we will still maintain 0.x version still
-at least the end of 2023. ## Installation Below are quick steps for
-installation: ```shell conda create -n open-mmlab python=3.8 pytorch==1.10.1
-torchvision==0.11.2 cudatoolkit=11.3 -c pytorch -y conda activate open-mmlab
-pip install openmim git clone -b 1.x https://github.com/open-mmlab/mmpose.git
-cd mmpose mim install -e . ``` Please refer to [installation.md](https://
-mmpose.readthedocs.io/en/1.x/installation.html) for more detailed installation
-and dataset preparation. ## Getting Started We provided a series of tutorials
-about the basic usage of MMPose for new users: - [About Configs](https://
-mmpose.readthedocs.io/en/1.x/user_guides/configs.html) - [Add New Dataset]
-(https://mmpose.readthedocs.io/en/1.x/user_guides/prepare_datasets.html) -
-[Keypoint Encoding & Decoding](https://mmpose.readthedocs.io/en/1.x/
-user_guides/codecs.html) - [Inference with Existing Models](https://
-mmpose.readthedocs.io/en/1.x/user_guides/inference.html) - [Train and Test]
-(https://mmpose.readthedocs.io/en/1.x/user_guides/train_and_test.html) -
-[Visualization Tools](https://mmpose.readthedocs.io/en/1.x/user_guides/
-visualization.html) - [Other Useful Tools](https://mmpose.readthedocs.io/en/
-1.x/user_guides/useful_tools.html) ## Model Zoo Results and models are
-available in the **README.md** of each method's config directory. A summary can
-be found in the [Model Zoo](https://mmpose.readthedocs.io/en/1.x/modelzoo.html)
-page.  Supported algorithms: - [x] [DeepPose](https://mmpose.readthedocs.io/en/
-1.x/model_zoo_papers/algorithms.html#deeppose-cvpr-2014) (CVPR'2014) - [x]
-[CPM](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/backbones.html#cpm-
-cvpr-2016) (CVPR'2016) - [x] [Hourglass](https://mmpose.readthedocs.io/en/1.x/
+ded1-11eb-84f6-24eeddbf4d91.mp4
+ Major Features - **Support diverse tasks** We support a wide spectrum of
+mainstream pose analysis tasks in current research community, including 2d
+multi-person human pose estimation, 2d hand pose estimation, 2d face landmark
+detection, 133 keypoint whole-body human pose estimation, 3d human mesh
+recovery, fashion landmark detection and animal pose estimation. See [Demo]
+(demo/docs/) for more information. - **Higher efficiency and higher accuracy**
+MMPose implements multiple state-of-the-art (SOTA) deep learning models,
+including both top-down & bottom-up approaches. We achieve faster training
+speed and higher accuracy than other popular codebases, such as [HRNet](https:/
+/github.com/leoxiaobin/deep-high-resolution-net.pytorch). See [benchmark.md]
+(docs/en/notes/benchmark.md) for more information. - **Support for various
+datasets** The toolbox directly supports multiple popular and representative
+datasets, COCO, AIC, MPII, MPII-TRB, OCHuman etc. See [dataset_zoo](docs/en/
+dataset_zoo) for more information. - **Well designed, tested and documented**
+We decompose MMPose into different components and one can easily construct a
+customized pose estimation framework by combining different modules. We provide
+detailed documentation and API reference, as well as unittests.  ## What's New
+- We are excited to release **RTMPose**, a real-time pose estimation framework
+including: - A family of lightweight pose estimation models with state-of-the-
+art performance - Inference APIs for Python, C++, C#, Java, etc. Easy to
+integrate into your applications and empower real-time stable pose estimation -
+Cross-platform deployment with various backends - A step-by-step guide to
+training and deploying your own models Checkout our [project page](/projects/
+rtmpose/) and [technical report](https://arxiv.org/abs/2303.07399) for more
+information! ![rtmpose_intro](https://user-images.githubusercontent.com/
+13503330/219269619-935499e5-bdd9-49ea-8104-3c7796dbd862.png) - Welcome to
+[*projects of MMPose*](/projects/README.md), where you can access to the latest
+features of MMPose, and share your ideas and codes with the community at once.
+Contribution to MMPose will be simple and smooth: - Provide an easy and agile
+way to integrate algorithms, features and applications into MMPose - Allow
+flexible code structure and style; only need a short code review process -
+Build individual projects with full power of MMPose but not bound up with heavy
+frameworks - Checkout new projects: - [RTMPose](/projects/rtmpose/) - [YOLOX-
+Pose (coming soon)](<>) - [MMPose4AIGC (coming soon)](<>) - Become a
+contributors and make MMPose greater. Start your journey from the [example
+project](/projects/example_project/)
+- 2022-03-15: MMPose [v1.0.0rc1](https://github.com/open-mmlab/mmpose/releases/
+tag/v1.0.0rc1) is released. Major updates include: - Release [RTMPose](/
+projects/rtmpose/), a high-performance real-time pose estimation framework
+based on MMPose - Support [ViTPose](/configs/body_2d_keypoint/topdown_heatmap/
+coco/vitpose_coco.md) (NeurIPS'22), [CID](/configs/body_2d_keypoint/cid/coco/
+hrnet_coco.md) (CVPR'22) and [DEKR](/configs/body_2d_keypoint/dekr/) (CVPR'21)
+- Add [*Inferencer*](/docs/en/user_guides/inference.md#out-of-the-box-
+inferencer), a convenient interface for inference and visualization See the
+full [release note](https://github.com/open-mmlab/mmpose/releases/tag/
+v1.0.0rc1) for more exciting updates brought by MMPose v1.0.0rc1! ##
+Installation Below are quick steps for installation: ```shell conda create -
+n open-mmlab python=3.8 pytorch==1.10.1 torchvision==0.11.2 cudatoolkit=11.3 -
+c pytorch -y conda activate open-mmlab pip install openmim git clone -b 1.x
+https://github.com/open-mmlab/mmpose.git cd mmpose mim install -e . ``` Please
+refer to [installation.md](https://mmpose.readthedocs.io/en/1.x/
+installation.html) for more detailed installation and dataset preparation. ##
+Getting Started We provided a series of tutorials about the basic usage of
+MMPose for new users: - [About Configs](https://mmpose.readthedocs.io/en/1.x/
+user_guides/configs.html) - [Add New Dataset](https://mmpose.readthedocs.io/en/
+1.x/user_guides/prepare_datasets.html) - [Keypoint Encoding & Decoding](https:/
+/mmpose.readthedocs.io/en/1.x/user_guides/codecs.html) - [Inference with
+Existing Models](https://mmpose.readthedocs.io/en/1.x/user_guides/
+inference.html) - [Train and Test](https://mmpose.readthedocs.io/en/1.x/
+user_guides/train_and_test.html) - [Visualization Tools](https://
+mmpose.readthedocs.io/en/1.x/user_guides/visualization.html) - [Other Useful
+Tools](https://mmpose.readthedocs.io/en/1.x/user_guides/useful_tools.html) ##
+Model Zoo Results and models are available in the **README.md** of each
+method's config directory. A summary can be found in the [Model Zoo](https://
+mmpose.readthedocs.io/en/1.x/modelzoo.html) page.  Supported algorithms: - [x]
+[DeepPose](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
+algorithms.html#deeppose-cvpr-2014) (CVPR'2014) - [x] [CPM](https://
+mmpose.readthedocs.io/en/1.x/model_zoo_papers/backbones.html#cpm-cvpr-2016)
+(CVPR'2016) - [x] [Hourglass](https://mmpose.readthedocs.io/en/1.x/
 model_zoo_papers/backbones.html#hourglass-eccv-2016) (ECCV'2016) - [ ]
 [SimpleBaseline3D](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
 algorithms.html#simplebaseline3d-iccv-2017) (ICCV'2017) - [ ] [Associative
 Embedding](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
 algorithms.html#associative-embedding-nips-2017) (NeurIPS'2017) - [x]
 [SimpleBaseline2D](https://mmpose.readthedocs.io/en/1.x/model_zoo_papers/
 algorithms.html#simplebaseline2d-eccv-2018) (ECCV'2018) - [x] [DSNT](https://
@@ -285,12 +292,11 @@
 toolbox. - [MMGeneration](https://github.com/open-mmlab/mmgeneration):
 OpenMMLab image and video generative models toolbox. - [MMDeploy](https://
 github.com/open-mmlab/mmdeploy): OpenMMLab Model Deployment Framework.
 Keywords: computer vision,pose estimation Platform: UNKNOWN Classifier:
 Development Status :: 4 - Beta Classifier: License :: OSI Approved :: Apache
 Software License Classifier: Operating System :: OS Independent Classifier:
 Programming Language :: Python :: 3 Classifier: Programming Language :: Python
-:: 3.5 Classifier: Programming Language :: Python :: 3.6 Classifier:
-Programming Language :: Python :: 3.7 Classifier: Programming Language ::
-Python :: 3.8 Classifier: Programming Language :: Python :: 3.9 Description-
+:: 3.7 Classifier: Programming Language :: Python :: 3.8 Classifier:
+Programming Language :: Python :: 3.9 Requires-Python: >=3.7 Description-
 Content-Type: text/markdown Provides-Extra: all Provides-Extra: tests Provides-
 Extra: optional Provides-Extra: mim
```

### Comparing `mmpose-1.0.0rc0/mmpose.egg-info/SOURCES.txt` & `mmpose-1.0.0rc1/mmpose.egg-info/SOURCES.txt`

 * *Files 8% similar despite different names*

```diff
@@ -17,14 +17,15 @@
 mmpose/.mim/configs/_base_/datasets/aflw.py
 mmpose/.mim/configs/_base_/datasets/aic.py
 mmpose/.mim/configs/_base_/datasets/animalpose.py
 mmpose/.mim/configs/_base_/datasets/ap10k.py
 mmpose/.mim/configs/_base_/datasets/atrw.py
 mmpose/.mim/configs/_base_/datasets/campus.py
 mmpose/.mim/configs/_base_/datasets/coco.py
+mmpose/.mim/configs/_base_/datasets/coco_aic.py
 mmpose/.mim/configs/_base_/datasets/coco_wholebody.py
 mmpose/.mim/configs/_base_/datasets/coco_wholebody_face.py
 mmpose/.mim/configs/_base_/datasets/coco_wholebody_hand.py
 mmpose/.mim/configs/_base_/datasets/cofw.py
 mmpose/.mim/configs/_base_/datasets/crowdpose.py
 mmpose/.mim/configs/_base_/datasets/deepfashion_full.py
 mmpose/.mim/configs/_base_/datasets/deepfashion_lower.py
@@ -48,58 +49,102 @@
 mmpose/.mim/configs/_base_/datasets/panoptic_body3d.py
 mmpose/.mim/configs/_base_/datasets/panoptic_hand2d.py
 mmpose/.mim/configs/_base_/datasets/posetrack18.py
 mmpose/.mim/configs/_base_/datasets/rhd2d.py
 mmpose/.mim/configs/_base_/datasets/shelf.py
 mmpose/.mim/configs/_base_/datasets/wflw.py
 mmpose/.mim/configs/_base_/datasets/zebra.py
+mmpose/.mim/configs/animal_2d_keypoint/rtmpose/ap10k/rtmpose-m_8xb64-210e_ap10k-256x256.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_hrnet-w32_8xb64-210e_animalpose-256x256.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_hrnet-w48_8xb64-210e_animalpose-256x256.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res101_8xb64-210e_animalpose-256x256.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res152_8xb32-210e_animalpose-256x256.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/animalpose/td-hm_res50_8xb64-210e_animalpose-256x256.py
+mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/cspnext-m_udp_8xb64-210e_ap10k-256x256.py
+mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/resnet_ap10k.yml
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_hrnet-w32_8xb64-210e_ap10k-256x256.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_hrnet-w48_8xb64-210e_ap10k-256x256.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_res101_8xb64-210e_ap10k-256x256.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_res50_8xb64-210e_ap10k-256x256.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res101_8xb64-210e_locust-160x160.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res152_8xb32-210e_locust-160x160.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/locust/td-hm_res50_8xb64-210e_locust-160x160.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res101_8xb64-210e_zebra-160x160.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res152_8xb32-210e_zebra-160x160.py
 mmpose/.mim/configs/animal_2d_keypoint/topdown_heatmap/zebra/td-hm_res50_8xb64-210e_zebra-160x160.py
+mmpose/.mim/configs/body_2d_keypoint/associative_embedding/coco/ae_hrnet-w32_8xb24-300e_coco-512x512.py
+mmpose/.mim/configs/body_2d_keypoint/cid/coco/cid_hrnet-w32_8xb20-140e_coco-512x512.py
+mmpose/.mim/configs/body_2d_keypoint/cid/coco/cid_hrnet-w48_8xb20-140e_coco-512x512.py
+mmpose/.mim/configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_8xb10-140e_coco-512x512.py
+mmpose/.mim/configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w48_8xb10-140e_coco-640x640.py
+mmpose/.mim/configs/body_2d_keypoint/dekr/crowdpose/dekr_hrnet-w32_8xb10-300e_crowdpose-512x512.py
+mmpose/.mim/configs/body_2d_keypoint/dekr/crowdpose/dekr_hrnet-w48_8xb5-300e_crowdpose-640x640.py
 mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_8xb64-210e_coco-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_debias-8xb64-210e_coco-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/integral_regression/coco/ipr_res50_dsnt-8xb64-210e_coco-256x256.py
+mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-l_8xb256-420e_aic-coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-l_8xb256-420e_aic-coco-384x288.py
+mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-l_8xb256-420e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-m_8xb256-420e_aic-coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-m_8xb256-420e_aic-coco-384x288.py
+mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-m_8xb256-420e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-s_8xb256-420e_aic-coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-s_8xb256-420e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-t_8xb256-420e_aic-coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/rtmpose/coco/rtmpose-t_8xb256-420e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/rtmpose/crowdpose/rtmpose-m_8xb64-210e_crowdpose-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/rtmpose/mpii/rtmpose-m_8xb64-210e_mpii-256x256.py
+mmpose/.mim/configs/body_2d_keypoint/simcc/coco/mobilenetv2_coco.yml
+mmpose/.mim/configs/body_2d_keypoint/simcc/coco/resnet_coco.yml
 mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_mobilenetv2_wo-deconv-8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_res50_8xb32-140e_coco-384x288.py
 mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_res50_8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/simcc/coco/simcc_vipnas-mbv3_8xb64-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/simcc/coco/vipnas_coco.yml
 mmpose/.mim/configs/body_2d_keypoint/simcc/mpii/simcc_res50_wo-deconv-8xb64-210e_mpii-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/aic/td-hm_hrnet-w32_8xb64-210e_aic-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/aic/td-hm_res101_8xb64-210e_aic-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-l_udp_8xb256-210e_aic-coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-l_udp_8xb256-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-m_udp_8xb256-210e_aic-coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-m_udp_8xb256-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-s_udp_8xb256-210e_aic-coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-s_udp_8xb256-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-tiny_udp_8xb256-210e_aic-coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/cspnext-tiny_udp_8xb256-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/hourglass_coco.yml
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/hrnet_coco.yml
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/litehrnet_coco.yml
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/mspn_coco.yml
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_2xmspn50_8xb32-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_2xrsn50_8xb32-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_3xmspn50_8xb32-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_3xrsn50_8xb32-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_4xmspn50_8xb32-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-base-simple_8xb64-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-base_8xb64-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge-simple_8xb64-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-large-simple_8xb64-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-large_8xb64-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-small-simple_8xb64-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-small_8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_alexnet_8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_cpm_8xb32-210e_coco-384x288.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_cpm_8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hourglass52_8xb32-210e_coco-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hourglass52_8xb32-210e_coco-384x384.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-base_8xb32-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-base_8xb32-210e_coco-384x288.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-small_8xb32-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrformer-small_8xb32-210e_coco-384x288.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-384x288.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-aic-256x192-combine.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_8xb64-210e_coco-aic-256x192-merge.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_coarsedropout-8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_dark-8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_dark-8xb64-210e_coco-384x288.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_fp16-8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_gridmask-8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_photometric-8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w32_udp-8xb64-210e_coco-256x192.py
@@ -173,28 +218,31 @@
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-b-p4-w7_8xb32-210e_coco-384x288.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-l-p4-w7_8xb32-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-l-p4-w7_8xb32-210e_coco-384x288.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_swin-t-p4-w7_8xb32-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vgg16-bn_8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vipnas-mbv3_8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vipnas-res50_8xb64-210e_coco-256x192.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/coco/vitpose_coco.yml
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/cspnext-m_udp_8xb64-210e_crowpose-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_hrnet-w32_8xb64-210e_crowdpose-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res101_8xb64-210e_crowdpose-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res101_8xb64-210e_crowdpose-320x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res152_8xb64-210e_crowdpose-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/crowdpose/td-hm_res50_8xb64-210e_crowdpose-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub1-368x368.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub2-368x368.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_cpm_8xb32-40e_jhmdb-sub3-368x368.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub1-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub2-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50-2deconv_8xb64-40e_jhmdb-sub3-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub1-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub2-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/jhmdb/td-hm_res50_8xb64-20e_jhmdb-sub3-256x256.py
+mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/cspnext-m_udp_8xb64-210e_mpii-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_cpm_8xb64-210e_mpii-368x368.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hourglass52_8xb32-210e_mpii-384x384.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hourglass52_8xb64-210e_mpii-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w32_8xb64-210e_mpii-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w32_dark-8xb64-210e_mpii-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w48_8xb64-210e_mpii-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_heatmap/mpii/td-hm_hrnet-w48_dark-8xb64-210e_mpii-256x256.py
@@ -229,47 +277,57 @@
 mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_rle-8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_regression/coco/td-reg_res50_rle-pretrained-8xb64-210e_coco-256x192.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res101_8xb64-210e_mpii-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res152_8xb64-210e_mpii-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res50_8xb64-210e_mpii-256x256.py
 mmpose/.mim/configs/body_2d_keypoint/topdown_regression/mpii/td-reg_res50_rle-8xb64-210e_mpii-256x256.py
+mmpose/.mim/configs/face_2d_keypoint/rtmpose/coco_wholebody_face/rtmpose-m_8xb32-60e_coco-wholebody-face-256x256.py
+mmpose/.mim/configs/face_2d_keypoint/rtmpose/wflw/rtmpose-m_8xb64-60e_wflw-256x256.py
 mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/300w/td-hm_hrnetv2-w18_8xb64-60e_300w-256x256.py
 mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/aflw/td-hm_hrnetv2-w18_8xb64-60e_aflw-256x256.py
 mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/aflw/td-hm_hrnetv2-w18_dark-8xb64-60e_aflw-256x256.py
 mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hourglass52_8xb32-60e_coco-wholebody-face-256x256.py
 mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hrnetv2-w18_8xb32-60e_coco-wholebody-face-256x256.py
 mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_hrnetv2-w18_dark-8xb32-60e_coco-wholebody-face-256x256.py
 mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_mobilenetv2_8xb32-60e_coco-wholebody-face-256x256.py
 mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_res50_8xb32-60e_coco-wholebody-face-256x256.py
 mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/coco_wholebody_face/td-hm_scnet50_8xb32-60e_coco-wholebody-face-256x256.py
 mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/cofw/td-hm_hrnetv2-w18_8xb64-60e_cofw-256x256.py
+mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/hrnetv2_wflw.yml
 mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_8xb64-60e_wflw-256x256.py
 mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_awing-8xb64-60e_wflw-256x256.py
 mmpose/.mim/configs/face_2d_keypoint/topdown_heatmap/wflw/td-hm_hrnetv2-w18_dark-8xb64-60e_wflw-256x256.py
+mmpose/.mim/configs/hand_2d_keypoint/rtmpose/coco_wholebody_hand/rtmpose-m_8xb32-210e_coco-wholebody-hand-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hourglass52_8xb32-210e_coco-wholebody-hand-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hrnetv2-w18_8xb32-210e_coco-wholebody-hand-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_hrnetv2-w18_dark-8xb32-210e_coco-wholebody-hand-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_litehrnet-w18_8xb32-210e_coco-wholebody-hand-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_mobilenetv2_8xb32-210e_coco-wholebody-hand-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_res50_8xb32-210e_coco-wholebody-hand-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/coco_wholebody_hand/td-hm_scnet50_8xb32-210e_coco-wholebody-hand-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/freihand2d/td-hm_res50_8xb64-100e_freihand2d-224x224.py
+mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/resnet_onehand10k.yml
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_8xb64-210e_onehand10k-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_dark-8xb64-210e_onehand10k-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_hrnetv2-w18_udp-8xb64-210e_onehand10k-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_mobilenetv2_8xb64-210e_onehand10k-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/onehand10k/td-hm_res50_8xb32-210e_onehand10k-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_8xb64-210e_rhd2d-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_dark-8xb64-210e_rhd2d-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_hrnetv2-w18_udp-8xb64-210e_rhd2d-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_mobilenetv2_8xb64-210e_rhd2d-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_heatmap/rhd2d/td-hm_res50_8xb64-210e_rhd2d-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/onehand10k/td-reg_res50_8xb64-210e_onehand10k-256x256.py
 mmpose/.mim/configs/hand_2d_keypoint/topdown_regression/rhd2d/td-reg_res50_8xb64-210e_rhd2d-256x256.py
+mmpose/.mim/configs/wholebody_2d_keypoint/rtmpose/coco-wholebody/rtmpose-l_8xb32-270e_coco-wholebody-384x288.py
+mmpose/.mim/configs/wholebody_2d_keypoint/rtmpose/coco-wholebody/rtmpose-l_8xb64-270e_coco-wholebody-256x192.py
+mmpose/.mim/configs/wholebody_2d_keypoint/rtmpose/coco-wholebody/rtmpose-m_8xb64-270e_coco-wholebody-256x192.py
+mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/cspnext-l_udp_8xb64-210e_coco-wholebody-256x192.py
+mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/cspnext-m_udp_8xb64-210e_coco-wholebody-256x192.py
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_8xb64-210e_coco-wholebody-256x192.py
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_8xb64-210e_coco-wholebody-384x288.py
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w32_dark-8xb64-210e_coco-wholebody-256x192.py
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_8xb32-210e_coco-wholebody-256x192.py
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_8xb32-210e_coco-wholebody-384x288.py
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_dark-8xb32-210e_coco-wholebody-384x288.py
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res101_8xb32-210e_coco-wholebody-256x192.py
@@ -278,25 +336,27 @@
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res152_8xb32-210e_coco-wholebody-384x288.py
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res50_8xb64-210e_coco-wholebody-256x192.py
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_res50_8xb64-210e_coco-wholebody-384x288.py
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-mbv3_8xb64-210e_coco-wholebody-256x192.py
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-mbv3_dark-8xb64-210e_coco-wholebody-256x192.py
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-res50_8xb64-210e_coco-wholebody-256x192.py
 mmpose/.mim/configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_vipnas-res50_dark-8xb64-210e_coco-wholebody-256x192.py
+mmpose/.mim/demo/bottomup_demo.py
 mmpose/.mim/demo/image_demo.py
+mmpose/.mim/demo/inferencer_demo.py
 mmpose/.mim/demo/topdown_demo_with_mmdet.py
-mmpose/.mim/demo/topdown_face_demo.py
 mmpose/.mim/demo/webcam_demo.py
 mmpose/.mim/demo/mmdetection_cfg/cascade_rcnn_x101_64x4d_fpn_1class.py
 mmpose/.mim/demo/mmdetection_cfg/cascade_rcnn_x101_64x4d_fpn_coco.py
 mmpose/.mim/demo/mmdetection_cfg/faster_rcnn_r50_fpn_1class.py
 mmpose/.mim/demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py
 mmpose/.mim/demo/mmdetection_cfg/mask_rcnn_r50_fpn_2x_coco.py
 mmpose/.mim/demo/mmdetection_cfg/ssdlite_mobilenetv2-scratch_8xb24-600e_coco.py
 mmpose/.mim/demo/mmdetection_cfg/yolov3_d53_320_273e_coco.py
+mmpose/.mim/demo/mmdetection_cfg/yolox-s_8xb8-300e_coco-face.py
 mmpose/.mim/demo/mmtracking_cfg/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py
 mmpose/.mim/demo/mmtracking_cfg/tracktor_faster-rcnn_r50_fpn_4e_mot17-private.py
 mmpose/.mim/demo/webcam_cfg/pose_estimation.py
 mmpose/.mim/demo/webcam_cfg/test_camera.py
 mmpose/.mim/tools/dist_test.sh
 mmpose/.mim/tools/dist_train.sh
 mmpose/.mim/tools/slurm_test.sh
@@ -310,23 +370,28 @@
 mmpose/.mim/tools/dataset_converters/mat2json.py
 mmpose/.mim/tools/dataset_converters/parse_animalpose_dataset.py
 mmpose/.mim/tools/dataset_converters/parse_cofw_dataset.py
 mmpose/.mim/tools/dataset_converters/parse_deepposekit_dataset.py
 mmpose/.mim/tools/dataset_converters/parse_macaquepose_dataset.py
 mmpose/.mim/tools/dataset_converters/preprocess_h36m.py
 mmpose/.mim/tools/dataset_converters/preprocess_mpi_inf_3dhp.py
-mmpose/.mim/tools/deployment/mmpose2torchserve.py
-mmpose/.mim/tools/deployment/mmpose_handler.py
-mmpose/.mim/tools/deployment/pytorch2onnx.py
-mmpose/.mim/tools/deployment/test_torchserver.py
 mmpose/.mim/tools/misc/browse_dataset.py
 mmpose/.mim/tools/misc/keypoints2coco_without_mmdet.py
 mmpose/.mim/tools/misc/publish_model.py
+mmpose/.mim/tools/torchserve/mmpose2torchserve.py
+mmpose/.mim/tools/torchserve/mmpose_handler.py
+mmpose/.mim/tools/torchserve/test_torchserver.py
 mmpose/apis/__init__.py
 mmpose/apis/inference.py
+mmpose/apis/inferencers/__init__.py
+mmpose/apis/inferencers/base_mmpose_inferencer.py
+mmpose/apis/inferencers/mmpose_inferencer.py
+mmpose/apis/inferencers/pose2d_inferencer.py
+mmpose/apis/inferencers/utils/__init__.py
+mmpose/apis/inferencers/utils/default_det_models.py
 mmpose/apis/webcam/__init__.py
 mmpose/apis/webcam/webcam_executor.py
 mmpose/apis/webcam/nodes/__init__.py
 mmpose/apis/webcam/nodes/base_visualizer_node.py
 mmpose/apis/webcam/nodes/node.py
 mmpose/apis/webcam/nodes/registry.py
 mmpose/apis/webcam/nodes/helper_nodes/__init__.py
@@ -347,28 +412,32 @@
 mmpose/apis/webcam/utils/image_capture.py
 mmpose/apis/webcam/utils/message.py
 mmpose/apis/webcam/utils/misc.py
 mmpose/apis/webcam/utils/pose.py
 mmpose/codecs/__init__.py
 mmpose/codecs/associative_embedding.py
 mmpose/codecs/base.py
+mmpose/codecs/decoupled_heatmap.py
 mmpose/codecs/integral_regression_label.py
 mmpose/codecs/megvii_heatmap.py
 mmpose/codecs/msra_heatmap.py
 mmpose/codecs/regression_label.py
 mmpose/codecs/simcc_label.py
+mmpose/codecs/spr.py
 mmpose/codecs/udp_heatmap.py
 mmpose/codecs/utils/__init__.py
 mmpose/codecs/utils/gaussian_heatmap.py
+mmpose/codecs/utils/instance_property.py
 mmpose/codecs/utils/offset_heatmap.py
 mmpose/codecs/utils/post_processing.py
 mmpose/codecs/utils/refinement.py
 mmpose/datasets/__init__.py
 mmpose/datasets/builder.py
 mmpose/datasets/dataset_wrappers.py
+mmpose/datasets/samplers.py
 mmpose/datasets/datasets/__init__.py
 mmpose/datasets/datasets/utils.py
 mmpose/datasets/datasets/animal/__init__.py
 mmpose/datasets/datasets/animal/animalpose_dataset.py
 mmpose/datasets/datasets/animal/ap10k_dataset.py
 mmpose/datasets/datasets/animal/atrw_dataset.py
 mmpose/datasets/datasets/animal/fly_dataset.py
@@ -405,28 +474,33 @@
 mmpose/datasets/datasets/hand/rhd2d_dataset.py
 mmpose/datasets/datasets/wholebody/__init__.py
 mmpose/datasets/datasets/wholebody/coco_wholebody_dataset.py
 mmpose/datasets/datasets/wholebody/halpe_dataset.py
 mmpose/datasets/transforms/__init__.py
 mmpose/datasets/transforms/bottomup_transforms.py
 mmpose/datasets/transforms/common_transforms.py
+mmpose/datasets/transforms/converting.py
 mmpose/datasets/transforms/formatting.py
 mmpose/datasets/transforms/loading.py
 mmpose/datasets/transforms/topdown_transforms.py
 mmpose/engine/__init__.py
 mmpose/engine/hooks/__init__.py
+mmpose/engine/hooks/ema_hook.py
 mmpose/engine/hooks/visualization_hook.py
+mmpose/engine/optim_wrappers/__init__.py
+mmpose/engine/optim_wrappers/layer_decay_optim_wrapper.py
 mmpose/evaluation/__init__.py
 mmpose/evaluation/functional/__init__.py
 mmpose/evaluation/functional/keypoint_eval.py
 mmpose/evaluation/functional/nms.py
 mmpose/evaluation/metrics/__init__.py
 mmpose/evaluation/metrics/coco_metric.py
 mmpose/evaluation/metrics/coco_wholebody_metric.py
 mmpose/evaluation/metrics/keypoint_2d_metrics.py
+mmpose/evaluation/metrics/keypoint_partition_metric.py
 mmpose/evaluation/metrics/posetrack18_metric.py
 mmpose/models/__init__.py
 mmpose/models/builder.py
 mmpose/models/backbones/__init__.py
 mmpose/models/backbones/alexnet.py
 mmpose/models/backbones/base_backbone.py
 mmpose/models/backbones/cpm.py
@@ -457,52 +531,58 @@
 mmpose/models/backbones/vipnas_resnet.py
 mmpose/models/backbones/utils/__init__.py
 mmpose/models/backbones/utils/channel_shuffle.py
 mmpose/models/backbones/utils/ckpt_convert.py
 mmpose/models/backbones/utils/inverted_residual.py
 mmpose/models/backbones/utils/make_divisible.py
 mmpose/models/backbones/utils/se_layer.py
-mmpose/models/backbones/utils/transformer.py
 mmpose/models/backbones/utils/utils.py
 mmpose/models/data_preprocessors/__init__.py
 mmpose/models/data_preprocessors/data_preprocessor.py
 mmpose/models/heads/__init__.py
 mmpose/models/heads/base_head.py
+mmpose/models/heads/coord_cls_heads/__init__.py
+mmpose/models/heads/coord_cls_heads/rtmcc_head.py
+mmpose/models/heads/coord_cls_heads/simcc_head.py
 mmpose/models/heads/heatmap_heads/__init__.py
+mmpose/models/heads/heatmap_heads/ae_head.py
+mmpose/models/heads/heatmap_heads/cid_head.py
 mmpose/models/heads/heatmap_heads/cpm_head.py
 mmpose/models/heads/heatmap_heads/heatmap_head.py
 mmpose/models/heads/heatmap_heads/mix_head.py
 mmpose/models/heads/heatmap_heads/mspn_head.py
-mmpose/models/heads/heatmap_heads/simcc_head.py
 mmpose/models/heads/heatmap_heads/vipnas_head.py
+mmpose/models/heads/hybrid_heads/__init__.py
+mmpose/models/heads/hybrid_heads/dekr_head.py
 mmpose/models/heads/regression_heads/__init__.py
 mmpose/models/heads/regression_heads/dsnt_head.py
 mmpose/models/heads/regression_heads/integral_regression_head.py
 mmpose/models/heads/regression_heads/regression_head.py
 mmpose/models/heads/regression_heads/rle_head.py
 mmpose/models/losses/__init__.py
+mmpose/models/losses/ae_loss.py
 mmpose/models/losses/classification_loss.py
 mmpose/models/losses/heatmap_loss.py
 mmpose/models/losses/loss_wrappers.py
-mmpose/models/losses/mse_loss.py
-mmpose/models/losses/multi_loss_factory.py
 mmpose/models/losses/regression_loss.py
 mmpose/models/necks/__init__.py
 mmpose/models/necks/fpn.py
 mmpose/models/necks/gap_neck.py
 mmpose/models/necks/posewarper_neck.py
 mmpose/models/pose_estimators/__init__.py
 mmpose/models/pose_estimators/base.py
+mmpose/models/pose_estimators/bottomup.py
 mmpose/models/pose_estimators/topdown.py
 mmpose/models/utils/__init__.py
 mmpose/models/utils/ckpt_convert.py
 mmpose/models/utils/geometry.py
 mmpose/models/utils/ops.py
 mmpose/models/utils/realnvp.py
 mmpose/models/utils/regularizations.py
+mmpose/models/utils/rtmcc_block.py
 mmpose/models/utils/transformer.py
 mmpose/models/utils/tta.py
 mmpose/structures/__init__.py
 mmpose/structures/multilevel_pixel_data.py
 mmpose/structures/pose_data_sample.py
 mmpose/structures/utils.py
 mmpose/structures/bbox/__init__.py
@@ -510,22 +590,24 @@
 mmpose/structures/keypoint/__init__.py
 mmpose/structures/keypoint/transforms.py
 mmpose/testing/__init__.py
 mmpose/testing/_utils.py
 mmpose/utils/__init__.py
 mmpose/utils/camera.py
 mmpose/utils/collect_env.py
+mmpose/utils/config_utils.py
 mmpose/utils/hooks.py
 mmpose/utils/logger.py
 mmpose/utils/setup_env.py
 mmpose/utils/tensor_utils.py
 mmpose/utils/timer.py
 mmpose/utils/typing.py
 mmpose/visualization/__init__.py
 mmpose/visualization/local_visualizer.py
+mmpose/visualization/simcc_vis.py
 requirements/albu.txt
 requirements/build.txt
 requirements/docs.txt
 requirements/mminstall.txt
 requirements/optional.txt
 requirements/poseval.txt
 requirements/readthedocs.txt
```

### Comparing `mmpose-1.0.0rc0/setup.cfg` & `mmpose-1.0.0rc1/setup.cfg`

 * *Files identical despite different names*

### Comparing `mmpose-1.0.0rc0/setup.py` & `mmpose-1.0.0rc1/setup.py`

 * *Files 8% similar despite different names*

```diff
@@ -172,22 +172,21 @@
         include_package_data=True,
         package_data={'mmpose.ops': ['*/*.so']},
         classifiers=[
             'Development Status :: 4 - Beta',
             'License :: OSI Approved :: Apache Software License',
             'Operating System :: OS Independent',
             'Programming Language :: Python :: 3',
-            'Programming Language :: Python :: 3.5',
-            'Programming Language :: Python :: 3.6',
             'Programming Language :: Python :: 3.7',
             'Programming Language :: Python :: 3.8',
             'Programming Language :: Python :: 3.9',
         ],
         url='https://github.com/open-mmlab/mmpose',
         license='Apache License 2.0',
+        python_requires='>=3.7',
         install_requires=parse_requirements('requirements/runtime.txt'),
         extras_require={
             'all': parse_requirements('requirements.txt'),
             'tests': parse_requirements('requirements/tests.txt'),
             'optional': parse_requirements('requirements/optional.txt'),
             'mim': parse_requirements('requirements/mminstall.txt'),
         },
```

