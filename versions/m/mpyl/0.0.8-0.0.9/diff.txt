--- tmp/mpyl-0.0.8-py3-none-any.whl.zip
+++ tmp/mpyl-0.0.9-py3-none-any.whl.zip
â”œâ”€â”€ zipinfo {}
â”‚ @@ -1,70 +1,72 @@
â”‚ -Zip file size: 70700 bytes, number of entries: 68
â”‚ --rw-r--r--  2.0 unx     1952 b- defN 23-Mar-13 15:41 mpyl/__init__.py
â”‚ --rw-r--r--  2.0 unx      215 b- defN 23-Mar-13 15:41 mpyl/__main__.py
â”‚ --rw-r--r--  2.0 unx    11406 b- defN 23-Mar-13 15:41 mpyl/project.py
â”‚ --rw-r--r--  2.0 unx     1069 b- defN 23-Mar-13 15:41 mpyl/validation.py
â”‚ --rw-r--r--  2.0 unx       38 b- defN 23-Mar-13 15:41 mpyl/cli/__init__.py
â”‚ --rw-r--r--  2.0 unx       51 b- defN 23-Mar-13 15:41 mpyl/cli/build/__init__.py
â”‚ --rw-r--r--  2.0 unx     2212 b- defN 23-Mar-13 15:41 mpyl/cli/build/jenkins.py
â”‚ --rw-r--r--  2.0 unx     4353 b- defN 23-Mar-13 15:41 mpyl/cli/build/mpyl.py
â”‚ --rw-r--r--  2.0 unx       19 b- defN 23-Mar-13 15:41 mpyl/cli/commands/__init__.py
â”‚ --rw-r--r--  2.0 unx     3210 b- defN 23-Mar-13 15:41 mpyl/cli/commands/build.py
â”‚ --rw-r--r--  2.0 unx     2178 b- defN 23-Mar-13 15:41 mpyl/cli/commands/meta_info.py
â”‚ --rw-r--r--  2.0 unx     1457 b- defN 23-Mar-13 15:41 mpyl/cli/commands/projects.py
â”‚ --rw-r--r--  2.0 unx        0 b- defN 23-Mar-13 15:41 mpyl/projects/__init__.py
â”‚ --rw-r--r--  2.0 unx      265 b- defN 23-Mar-13 15:41 mpyl/projects/find.py
â”‚ --rw-r--r--  2.0 unx       92 b- defN 23-Mar-13 15:41 mpyl/reporting/__init__.py
â”‚ --rw-r--r--  2.0 unx       76 b- defN 23-Mar-13 15:41 mpyl/reporting/formatting/__init__.py
â”‚ --rw-r--r--  2.0 unx     2564 b- defN 23-Mar-13 15:41 mpyl/reporting/formatting/markdown.py
â”‚ --rw-r--r--  2.0 unx     1148 b- defN 23-Mar-13 15:41 mpyl/reporting/formatting/text.py
â”‚ --rw-r--r--  2.0 unx      488 b- defN 23-Mar-13 15:41 mpyl/reporting/targets/__init__.py
â”‚ --rw-r--r--  2.0 unx     5538 b- defN 23-Mar-13 15:41 mpyl/reporting/targets/github.py
â”‚ --rw-r--r--  2.0 unx     4264 b- defN 23-Mar-13 15:41 mpyl/reporting/targets/jira.py
â”‚ --rw-r--r--  2.0 unx     5755 b- defN 23-Mar-13 15:41 mpyl/reporting/targets/slack.py
â”‚ --rw-r--r--  2.0 unx     5688 b- defN 23-Mar-13 15:41 mpyl/schema/mpyl_config.schema.yml
â”‚ --rw-r--r--  2.0 unx    26691 b- defN 23-Mar-13 15:41 mpyl/schema/project.schema.yml
â”‚ --rw-r--r--  2.0 unx        0 b- defN 23-Mar-13 15:41 mpyl/stages/__init__.py
â”‚ --rw-r--r--  2.0 unx     2408 b- defN 23-Mar-13 15:41 mpyl/stages/discovery.py
â”‚ --rw-r--r--  2.0 unx     6135 b- defN 23-Mar-13 15:41 mpyl/steps/__init__.py
â”‚ --rw-r--r--  2.0 unx     4536 b- defN 23-Mar-13 15:41 mpyl/steps/models.py
â”‚ --rw-r--r--  2.0 unx     1589 b- defN 23-Mar-13 15:41 mpyl/steps/run.py
â”‚ --rw-r--r--  2.0 unx     5715 b- defN 23-Mar-13 15:41 mpyl/steps/steps.py
â”‚ --rw-r--r--  2.0 unx       59 b- defN 23-Mar-13 15:41 mpyl/steps/build/__init__.py
â”‚ --rw-r--r--  2.0 unx     2255 b- defN 23-Mar-13 15:41 mpyl/steps/build/docker_after_build.py
â”‚ --rw-r--r--  2.0 unx     2032 b- defN 23-Mar-13 15:41 mpyl/steps/build/dockerbuild.py
â”‚ --rw-r--r--  2.0 unx      765 b- defN 23-Mar-13 15:41 mpyl/steps/build/echo.py
â”‚ --rw-r--r--  2.0 unx     2388 b- defN 23-Mar-13 15:41 mpyl/steps/build/sbt.py
â”‚ --rw-r--r--  2.0 unx       60 b- defN 23-Mar-13 15:41 mpyl/steps/deploy/__init__.py
â”‚ --rw-r--r--  2.0 unx     1001 b- defN 23-Mar-13 15:41 mpyl/steps/deploy/echo.py
â”‚ --rw-r--r--  2.0 unx     1960 b- defN 23-Mar-13 15:41 mpyl/steps/deploy/kubernetes.py
â”‚ --rw-r--r--  2.0 unx        0 b- defN 23-Mar-13 15:41 mpyl/steps/deploy/k8s/__init__.py
â”‚ --rw-r--r--  2.0 unx     2195 b- defN 23-Mar-13 15:41 mpyl/steps/deploy/k8s/helm.py
â”‚ --rw-r--r--  2.0 unx     1431 b- defN 23-Mar-13 15:41 mpyl/steps/deploy/k8s/rancher.py
â”‚ --rw-r--r--  2.0 unx    11097 b- defN 23-Mar-13 15:41 mpyl/steps/deploy/k8s/service.py
â”‚ --rw-r--r--  2.0 unx        0 b- defN 23-Mar-13 15:41 mpyl/steps/deploy/k8s/resources/__init__.py
â”‚ --rw-r--r--  2.0 unx     4418 b- defN 23-Mar-13 15:41 mpyl/steps/deploy/k8s/resources/crd.py
â”‚ --rw-r--r--  2.0 unx     1330 b- defN 23-Mar-13 15:41 mpyl/steps/deploy/k8s/resources/customresources.py
â”‚ --rw-r--r--  2.0 unx    11697 b- defN 23-Mar-13 15:41 mpyl/steps/deploy/k8s/resources/schema/traeffik.schema.yml
â”‚ --rw-r--r--  2.0 unx       58 b- defN 23-Mar-13 15:41 mpyl/steps/test/__init__.py
â”‚ --rw-r--r--  2.0 unx     1428 b- defN 23-Mar-13 15:41 mpyl/steps/test/after_test.py
â”‚ --rw-r--r--  2.0 unx     2453 b- defN 23-Mar-13 15:41 mpyl/steps/test/before_test.py
â”‚ --rw-r--r--  2.0 unx     2830 b- defN 23-Mar-13 15:41 mpyl/steps/test/dockertest.py
â”‚ --rw-r--r--  2.0 unx      724 b- defN 23-Mar-13 15:41 mpyl/steps/test/echo.py
â”‚ --rw-r--r--  2.0 unx     4706 b- defN 23-Mar-13 15:41 mpyl/steps/test/sbt.py
â”‚ --rw-r--r--  2.0 unx        0 b- defN 23-Mar-13 15:41 mpyl/utilities/__init__.py
â”‚ --rw-r--r--  2.0 unx     3315 b- defN 23-Mar-13 15:41 mpyl/utilities/docker/__init__.py
â”‚ --rw-r--r--  2.0 unx     1547 b- defN 23-Mar-13 15:41 mpyl/utilities/github/__init__.py
â”‚ --rw-r--r--  2.0 unx     1542 b- defN 23-Mar-13 15:41 mpyl/utilities/jenkins/__init__.py
â”‚ --rw-r--r--  2.0 unx     5016 b- defN 23-Mar-13 15:41 mpyl/utilities/jenkins/runner.py
â”‚ --rw-r--r--  2.0 unx     1280 b- defN 23-Mar-13 15:41 mpyl/utilities/junit/__init__.py
â”‚ --rw-r--r--  2.0 unx      754 b- defN 23-Mar-13 15:41 mpyl/utilities/pyaml_env/__init__.py
â”‚ --rw-r--r--  2.0 unx     2558 b- defN 23-Mar-13 15:41 mpyl/utilities/repo/__init__.py
â”‚ --rw-r--r--  2.0 unx     1087 b- defN 23-Mar-13 15:41 mpyl/utilities/sbt/__init__.py
â”‚ --rw-r--r--  2.0 unx     1338 b- defN 23-Mar-13 15:41 mpyl/utilities/subprocess/__init__.py
â”‚ --rw-r--r--  2.0 unx    11357 b- defN 23-Mar-13 15:42 mpyl-0.0.8.dist-info/LICENSE
â”‚ --rw-r--r--  2.0 unx     2914 b- defN 23-Mar-13 15:42 mpyl-0.0.8.dist-info/METADATA
â”‚ --rw-r--r--  2.0 unx       92 b- defN 23-Mar-13 15:42 mpyl-0.0.8.dist-info/WHEEL
â”‚ --rw-r--r--  2.0 unx       35 b- defN 23-Mar-13 15:42 mpyl-0.0.8.dist-info/entry_points.txt
â”‚ --rw-r--r--  2.0 unx        5 b- defN 23-Mar-13 15:42 mpyl-0.0.8.dist-info/top_level.txt
â”‚ -?rw-rw-r--  2.0 unx     5759 b- defN 23-Mar-13 15:42 mpyl-0.0.8.dist-info/RECORD
â”‚ -68 files, 194598 bytes uncompressed, 61558 bytes compressed:  68.4%
â”‚ +Zip file size: 74388 bytes, number of entries: 70
â”‚ +-rw-r--r--  2.0 unx     1927 b- defN 23-Mar-16 09:26 mpyl/__init__.py
â”‚ +-rw-r--r--  2.0 unx      215 b- defN 23-Mar-16 09:26 mpyl/__main__.py
â”‚ +-rw-r--r--  2.0 unx    11538 b- defN 23-Mar-16 09:26 mpyl/project.py
â”‚ +-rw-r--r--  2.0 unx     1069 b- defN 23-Mar-16 09:26 mpyl/validation.py
â”‚ +-rw-r--r--  2.0 unx      568 b- defN 23-Mar-16 09:26 mpyl/cli/__init__.py
â”‚ +-rw-r--r--  2.0 unx       51 b- defN 23-Mar-16 09:26 mpyl/cli/build/__init__.py
â”‚ +-rw-r--r--  2.0 unx     2250 b- defN 23-Mar-16 09:26 mpyl/cli/build/jenkins.py
â”‚ +-rw-r--r--  2.0 unx     4542 b- defN 23-Mar-16 09:26 mpyl/cli/build/mpyl.py
â”‚ +-rw-r--r--  2.0 unx      471 b- defN 23-Mar-16 09:26 mpyl/cli/commands/__init__.py
â”‚ +-rw-r--r--  2.0 unx     4539 b- defN 23-Mar-16 09:26 mpyl/cli/commands/build.py
â”‚ +-rw-r--r--  2.0 unx     2170 b- defN 23-Mar-16 09:26 mpyl/cli/commands/meta_info.py
â”‚ +-rw-r--r--  2.0 unx     1756 b- defN 23-Mar-16 09:26 mpyl/cli/commands/projects.py
â”‚ +-rw-r--r--  2.0 unx       39 b- defN 23-Mar-16 09:26 mpyl/cli/projects/__init__.py
â”‚ +-rw-r--r--  2.0 unx        0 b- defN 23-Mar-16 09:26 mpyl/projects/__init__.py
â”‚ +-rw-r--r--  2.0 unx      265 b- defN 23-Mar-16 09:26 mpyl/projects/find.py
â”‚ +-rw-r--r--  2.0 unx       92 b- defN 23-Mar-16 09:26 mpyl/reporting/__init__.py
â”‚ +-rw-r--r--  2.0 unx       76 b- defN 23-Mar-16 09:26 mpyl/reporting/formatting/__init__.py
â”‚ +-rw-r--r--  2.0 unx     2622 b- defN 23-Mar-16 09:26 mpyl/reporting/formatting/markdown.py
â”‚ +-rw-r--r--  2.0 unx     1148 b- defN 23-Mar-16 09:26 mpyl/reporting/formatting/text.py
â”‚ +-rw-r--r--  2.0 unx      488 b- defN 23-Mar-16 09:26 mpyl/reporting/targets/__init__.py
â”‚ +-rw-r--r--  2.0 unx     5538 b- defN 23-Mar-16 09:26 mpyl/reporting/targets/github.py
â”‚ +-rw-r--r--  2.0 unx     4656 b- defN 23-Mar-16 09:26 mpyl/reporting/targets/jira.py
â”‚ +-rw-r--r--  2.0 unx     5755 b- defN 23-Mar-16 09:26 mpyl/reporting/targets/slack.py
â”‚ +-rw-r--r--  2.0 unx     5920 b- defN 23-Mar-16 09:26 mpyl/schema/mpyl_config.schema.yml
â”‚ +-rw-r--r--  2.0 unx    24999 b- defN 23-Mar-16 09:26 mpyl/schema/project.schema.yml
â”‚ +-rw-r--r--  2.0 unx        0 b- defN 23-Mar-16 09:26 mpyl/stages/__init__.py
â”‚ +-rw-r--r--  2.0 unx     2408 b- defN 23-Mar-16 09:26 mpyl/stages/discovery.py
â”‚ +-rw-r--r--  2.0 unx     6135 b- defN 23-Mar-16 09:26 mpyl/steps/__init__.py
â”‚ +-rw-r--r--  2.0 unx     4839 b- defN 23-Mar-16 09:26 mpyl/steps/models.py
â”‚ +-rw-r--r--  2.0 unx     2166 b- defN 23-Mar-16 09:26 mpyl/steps/run.py
â”‚ +-rw-r--r--  2.0 unx     5815 b- defN 23-Mar-16 09:26 mpyl/steps/steps.py
â”‚ +-rw-r--r--  2.0 unx       59 b- defN 23-Mar-16 09:26 mpyl/steps/build/__init__.py
â”‚ +-rw-r--r--  2.0 unx     2255 b- defN 23-Mar-16 09:26 mpyl/steps/build/docker_after_build.py
â”‚ +-rw-r--r--  2.0 unx     2032 b- defN 23-Mar-16 09:26 mpyl/steps/build/dockerbuild.py
â”‚ +-rw-r--r--  2.0 unx      765 b- defN 23-Mar-16 09:26 mpyl/steps/build/echo.py
â”‚ +-rw-r--r--  2.0 unx     2402 b- defN 23-Mar-16 09:26 mpyl/steps/build/sbt.py
â”‚ +-rw-r--r--  2.0 unx       60 b- defN 23-Mar-16 09:26 mpyl/steps/deploy/__init__.py
â”‚ +-rw-r--r--  2.0 unx     1001 b- defN 23-Mar-16 09:26 mpyl/steps/deploy/echo.py
â”‚ +-rw-r--r--  2.0 unx      876 b- defN 23-Mar-16 09:26 mpyl/steps/deploy/kubernetes.py
â”‚ +-rw-r--r--  2.0 unx     1008 b- defN 23-Mar-16 09:26 mpyl/steps/deploy/kubernetes_job.py
â”‚ +-rw-r--r--  2.0 unx     1491 b- defN 23-Mar-16 09:26 mpyl/steps/deploy/k8s/__init__.py
â”‚ +-rw-r--r--  2.0 unx    13565 b- defN 23-Mar-16 09:26 mpyl/steps/deploy/k8s/chart.py
â”‚ +-rw-r--r--  2.0 unx     2097 b- defN 23-Mar-16 09:26 mpyl/steps/deploy/k8s/helm.py
â”‚ +-rw-r--r--  2.0 unx     1431 b- defN 23-Mar-16 09:26 mpyl/steps/deploy/k8s/rancher.py
â”‚ +-rw-r--r--  2.0 unx        0 b- defN 23-Mar-16 09:26 mpyl/steps/deploy/k8s/resources/__init__.py
â”‚ +-rw-r--r--  2.0 unx     4418 b- defN 23-Mar-16 09:26 mpyl/steps/deploy/k8s/resources/crd.py
â”‚ +-rw-r--r--  2.0 unx     1330 b- defN 23-Mar-16 09:26 mpyl/steps/deploy/k8s/resources/customresources.py
â”‚ +-rw-r--r--  2.0 unx    11697 b- defN 23-Mar-16 09:26 mpyl/steps/deploy/k8s/resources/schema/traeffik.schema.yml
â”‚ +-rw-r--r--  2.0 unx       58 b- defN 23-Mar-16 09:26 mpyl/steps/test/__init__.py
â”‚ +-rw-r--r--  2.0 unx     1428 b- defN 23-Mar-16 09:26 mpyl/steps/test/after_test.py
â”‚ +-rw-r--r--  2.0 unx     2453 b- defN 23-Mar-16 09:26 mpyl/steps/test/before_test.py
â”‚ +-rw-r--r--  2.0 unx     2830 b- defN 23-Mar-16 09:26 mpyl/steps/test/dockertest.py
â”‚ +-rw-r--r--  2.0 unx      724 b- defN 23-Mar-16 09:26 mpyl/steps/test/echo.py
â”‚ +-rw-r--r--  2.0 unx     4669 b- defN 23-Mar-16 09:26 mpyl/steps/test/sbt.py
â”‚ +-rw-r--r--  2.0 unx        0 b- defN 23-Mar-16 09:26 mpyl/utilities/__init__.py
â”‚ +-rw-r--r--  2.0 unx     3315 b- defN 23-Mar-16 09:26 mpyl/utilities/docker/__init__.py
â”‚ +-rw-r--r--  2.0 unx     1547 b- defN 23-Mar-16 09:26 mpyl/utilities/github/__init__.py
â”‚ +-rw-r--r--  2.0 unx     1542 b- defN 23-Mar-16 09:26 mpyl/utilities/jenkins/__init__.py
â”‚ +-rw-r--r--  2.0 unx     5016 b- defN 23-Mar-16 09:26 mpyl/utilities/jenkins/runner.py
â”‚ +-rw-r--r--  2.0 unx     1280 b- defN 23-Mar-16 09:26 mpyl/utilities/junit/__init__.py
â”‚ +-rw-r--r--  2.0 unx      754 b- defN 23-Mar-16 09:26 mpyl/utilities/pyaml_env/__init__.py
â”‚ +-rw-r--r--  2.0 unx     2708 b- defN 23-Mar-16 09:26 mpyl/utilities/repo/__init__.py
â”‚ +-rw-r--r--  2.0 unx     1520 b- defN 23-Mar-16 09:26 mpyl/utilities/sbt/__init__.py
â”‚ +-rw-r--r--  2.0 unx     1338 b- defN 23-Mar-16 09:26 mpyl/utilities/subprocess/__init__.py
â”‚ +-rw-r--r--  2.0 unx    11357 b- defN 23-Mar-16 09:27 mpyl-0.0.9.dist-info/LICENSE
â”‚ +-rw-r--r--  2.0 unx     2914 b- defN 23-Mar-16 09:27 mpyl-0.0.9.dist-info/METADATA
â”‚ +-rw-r--r--  2.0 unx       92 b- defN 23-Mar-16 09:27 mpyl-0.0.9.dist-info/WHEEL
â”‚ +-rw-r--r--  2.0 unx       35 b- defN 23-Mar-16 09:27 mpyl-0.0.9.dist-info/entry_points.txt
â”‚ +-rw-r--r--  2.0 unx        5 b- defN 23-Mar-16 09:27 mpyl-0.0.9.dist-info/top_level.txt
â”‚ +?rw-rw-r--  2.0 unx     5937 b- defN 23-Mar-16 09:27 mpyl-0.0.9.dist-info/RECORD
â”‚ +70 files, 202066 bytes uncompressed, 64970 bytes compressed:  67.8%
â”œâ”€â”€ zipnote {}
â”‚ @@ -30,14 +30,17 @@
â”‚  
â”‚  Filename: mpyl/cli/commands/meta_info.py
â”‚  Comment: 
â”‚  
â”‚  Filename: mpyl/cli/commands/projects.py
â”‚  Comment: 
â”‚  
â”‚ +Filename: mpyl/cli/projects/__init__.py
â”‚ +Comment: 
â”‚ +
â”‚  Filename: mpyl/projects/__init__.py
â”‚  Comment: 
â”‚  
â”‚  Filename: mpyl/projects/find.py
â”‚  Comment: 
â”‚  
â”‚  Filename: mpyl/reporting/__init__.py
â”‚ @@ -108,24 +111,27 @@
â”‚  
â”‚  Filename: mpyl/steps/deploy/echo.py
â”‚  Comment: 
â”‚  
â”‚  Filename: mpyl/steps/deploy/kubernetes.py
â”‚  Comment: 
â”‚  
â”‚ +Filename: mpyl/steps/deploy/kubernetes_job.py
â”‚ +Comment: 
â”‚ +
â”‚  Filename: mpyl/steps/deploy/k8s/__init__.py
â”‚  Comment: 
â”‚  
â”‚ -Filename: mpyl/steps/deploy/k8s/helm.py
â”‚ +Filename: mpyl/steps/deploy/k8s/chart.py
â”‚  Comment: 
â”‚  
â”‚ -Filename: mpyl/steps/deploy/k8s/rancher.py
â”‚ +Filename: mpyl/steps/deploy/k8s/helm.py
â”‚  Comment: 
â”‚  
â”‚ -Filename: mpyl/steps/deploy/k8s/service.py
â”‚ +Filename: mpyl/steps/deploy/k8s/rancher.py
â”‚  Comment: 
â”‚  
â”‚  Filename: mpyl/steps/deploy/k8s/resources/__init__.py
â”‚  Comment: 
â”‚  
â”‚  Filename: mpyl/steps/deploy/k8s/resources/crd.py
â”‚  Comment: 
â”‚ @@ -180,26 +186,26 @@
â”‚  
â”‚  Filename: mpyl/utilities/sbt/__init__.py
â”‚  Comment: 
â”‚  
â”‚  Filename: mpyl/utilities/subprocess/__init__.py
â”‚  Comment: 
â”‚  
â”‚ -Filename: mpyl-0.0.8.dist-info/LICENSE
â”‚ +Filename: mpyl-0.0.9.dist-info/LICENSE
â”‚  Comment: 
â”‚  
â”‚ -Filename: mpyl-0.0.8.dist-info/METADATA
â”‚ +Filename: mpyl-0.0.9.dist-info/METADATA
â”‚  Comment: 
â”‚  
â”‚ -Filename: mpyl-0.0.8.dist-info/WHEEL
â”‚ +Filename: mpyl-0.0.9.dist-info/WHEEL
â”‚  Comment: 
â”‚  
â”‚ -Filename: mpyl-0.0.8.dist-info/entry_points.txt
â”‚ +Filename: mpyl-0.0.9.dist-info/entry_points.txt
â”‚  Comment: 
â”‚  
â”‚ -Filename: mpyl-0.0.8.dist-info/top_level.txt
â”‚ +Filename: mpyl-0.0.9.dist-info/top_level.txt
â”‚  Comment: 
â”‚  
â”‚ -Filename: mpyl-0.0.8.dist-info/RECORD
â”‚ +Filename: mpyl-0.0.9.dist-info/RECORD
â”‚  Comment: 
â”‚  
â”‚  Zip file comment:
â”œâ”€â”€ mpyl/__init__.py
â”‚ @@ -34,29 +34,28 @@
â”‚   - [Slack](https://slack.com/) `mpyl.reporting.targets.slack`
â”‚  
â”‚  .. include:: ../../README-usage.md
â”‚  
â”‚  .. include:: ../../README-dev.md
â”‚  """
â”‚  
â”‚ -from importlib.metadata import version as version_meta
â”‚ -
â”‚  import click
â”‚  
â”‚ +from .cli.commands import get_version
â”‚  from .cli.commands.build import build
â”‚  from .cli.commands.meta_info import version
â”‚  from .cli.commands.projects import projects
â”‚  from .utilities.pyaml_env import parse_config
â”‚  from .utilities.repo import RepoConfig, Repository
â”‚  
â”‚  
â”‚  @click.group(name='mpyl')
â”‚  def main_group():
â”‚      """Command Line Interface for MPyL"""
â”‚  
â”‚  
â”‚  def main():
â”‚ -    main_group.help = f"Command Line Interface for MPyL {version_meta('mpyl')}"
â”‚ +    main_group.help = f"Command Line Interface for MPyL {get_version()}"
â”‚      main_group.add_command(projects)
â”‚      main_group.add_command(build)
â”‚      main_group.add_command(version)
â”‚      main_group()  # pylint: disable = no-value-for-parameter
â”œâ”€â”€ mpyl/project.py
â”‚ @@ -11,14 +11,15 @@
â”‚  </details>
â”‚  
â”‚  .. include:: ../../README-dev.md
â”‚  """
â”‚  
â”‚  import logging
â”‚  import pkgutil
â”‚ +import time
â”‚  import traceback
â”‚  from dataclasses import dataclass
â”‚  from enum import Enum
â”‚  from pathlib import Path
â”‚  from typing import Optional, TypeVar, Dict, Any, TextIO
â”‚  
â”‚  import jsonschema
â”‚ @@ -192,27 +193,31 @@
â”‚  @dataclass(frozen=True)
â”‚  class Kubernetes:
â”‚      port_mappings: dict[int, int]
â”‚      liveness_probe: Optional[Probe]
â”‚      startup_probe: Optional[Probe]
â”‚      metrics: Optional[Metrics]
â”‚      resources: Resources
â”‚ +    cron: dict
â”‚  
â”‚      @staticmethod
â”‚      def from_config(values: dict):
â”‚          mappings = values.get('portMappings')
â”‚          liveness_probe = values.get('livenessProbe')
â”‚          startup_probe = values.get('startupProbe')
â”‚ -        metrics = values.get('metrics')
â”‚ +        metrics = values.get('metrics', None)
â”‚          resources = values.get('resources')
â”‚ -        return Kubernetes(port_mappings=mappings if mappings else {},
â”‚ -                          liveness_probe=Probe.from_config(liveness_probe) if liveness_probe else None,
â”‚ -                          startup_probe=Probe.from_config(startup_probe) if startup_probe else None,
â”‚ -                          metrics=Metrics.from_config(metrics) if metrics else None,
â”‚ -                          resources=Resources.from_config(resources) if resources else None)
â”‚ +        return Kubernetes(
â”‚ +            port_mappings=mappings if mappings else {},
â”‚ +            liveness_probe=Probe.from_config(liveness_probe) if liveness_probe else None,
â”‚ +            startup_probe=Probe.from_config(startup_probe) if startup_probe else None,
â”‚ +            metrics=Metrics.from_config(metrics) if metrics else None,
â”‚ +            resources=Resources.from_config(resources) if resources else None,
â”‚ +            cron=values.get('cron', {})
â”‚ +        )
â”‚  
â”‚  
â”‚  @dataclass(frozen=True)
â”‚  class Host:
â”‚      host: TargetProperty[str]
â”‚      tls: TargetProperty[str]
â”‚      whitelists: TargetProperty[list[str]]
â”‚ @@ -316,15 +321,15 @@
â”‚  
â”‚  def validate_project(file: TextIO) -> dict:
â”‚      """
â”‚      :file the file to validate
â”‚      :return: the validated schema
â”‚      :raises `jsonschema.exceptions.ValidationError` when validation fails
â”‚      """
â”‚ -    yaml_values = YAML().load(file)
â”‚ +    yaml_values = YAML(typ='unsafe').load(file)
â”‚      template = pkgutil.get_data(__name__, "schema/project.schema.yml")
â”‚      if not template:
â”‚          raise ValueError('Schema project.schema.yml not found in package')
â”‚      validate(yaml_values, template.decode('utf-8'))
â”‚  
â”‚      return yaml_values
â”‚  
â”‚ @@ -335,18 +340,18 @@
â”‚      :param root_dir: root source directory
â”‚      :param project_path: relative path from `root_dir` to the `project.yml`
â”‚      :param strict: indicates whether the schema should be validated
â”‚      :return: `Project` data class
â”‚      """
â”‚      with open(root_dir / project_path, encoding='utf-8') as file:
â”‚          try:
â”‚ -            yaml_values = validate_project(file) if strict else YAML().load(file)
â”‚ -
â”‚ +            start = time.time()
â”‚ +            yaml_values = validate_project(file) if strict else YAML(typ='unsafe').load(file)
â”‚              project = Project.from_config(yaml_values, project_path)
â”‚ -            logging.debug(f'Loaded project {project.path}')
â”‚ +            logging.debug(f'Loaded project {project.path} in {(time.time() - start) * 1000} ms')
â”‚              return project
â”‚          except jsonschema.exceptions.ValidationError as exc:
â”‚              logging.warning(f'{project_path} does not comply with schema: {exc.message}')
â”‚              raise
â”‚          except TypeError:
â”‚              traceback.print_exc()
â”‚              logging.warning('Type error', exc_info=True)
â”œâ”€â”€ mpyl/cli/__init__.py
â”‚ @@ -1 +1,17 @@
â”‚  """Command Line Interface for MPyL"""
â”‚ +import logging
â”‚ +
â”‚ +from rich.console import Console
â”‚ +from rich.logging import RichHandler
â”‚ +
â”‚ +FORMAT = "%(message)s"
â”‚ +
â”‚ +
â”‚ +def create_console_logger(local: bool, verbose: bool) -> Console:
â”‚ +    console = Console(markup=True, width=None if local else 135, no_color=False, log_path=False, color_system='256')
â”‚ +    logging.basicConfig(
â”‚ +        level="DEBUG" if verbose else "INFO", format=FORMAT, datefmt="[%X]",
â”‚ +        handlers=[RichHandler(markup=True,
â”‚ +                              console=console, show_path=local)]
â”‚ +    )
â”‚ +    return console
â”œâ”€â”€ mpyl/cli/build/jenkins.py
â”‚ @@ -42,12 +42,13 @@
â”‚                  status.update(f'Fetching Jenkins info for {pipeline_info.human_readable()} ...')
â”‚  
â”‚                  runner = JenkinsRunner(pipeline=pipeline_info,
â”‚                                         jenkins=Jenkins(jenkins_config.url, username=run_config.jenkins_user,
â”‚                                                         password=run_config.jenkins_password), status=status)
â”‚                  runner.run()
â”‚              except requests.ConnectionError:
â”‚ +                status.console.bell()
â”‚                  status.console.log('âš ï¸ Could not connect. Are you on VPN?')
â”‚              except Exception as exc:
â”‚                  status.console.log(f'Unexpected exception: {exc}')
â”‚                  status.console.print_exception()
â”‚                  raise exc
â”œâ”€â”€ mpyl/cli/build/mpyl.py
â”‚ @@ -1,32 +1,32 @@
â”‚  """Simple MPyL build runner"""
â”‚  
â”‚  import logging
â”‚ -import sys
â”‚  from dataclasses import dataclass
â”‚  from pathlib import Path
â”‚  from typing import Optional
â”‚  
â”‚  from rich.console import Console
â”‚  from rich.logging import RichHandler
â”‚ +from rich.markdown import Markdown
â”‚  
â”‚  from ...project import load_project, Stage, Project
â”‚  from ...reporting.formatting.markdown import run_result_to_markdown
â”‚  from ...reporting.targets import Reporter
â”‚  from ...stages.discovery import for_stage, find_invalidated_projects_per_stage
â”‚  from ...steps.models import RunProperties
â”‚  from ...steps.run import RunResult
â”‚  from ...steps.steps import Steps
â”‚  from ...utilities.repo import Repository, RepoConfig
â”‚  
â”‚  
â”‚  @dataclass(frozen=True)
â”‚  class MpylRunConfig:
â”‚      config: dict
â”‚ -    run_properties: dict
â”‚ +    run_properties: RunProperties
â”‚  
â”‚  
â”‚  @dataclass(frozen=True)
â”‚  class MpylCliParameters:
â”‚      local: bool
â”‚      verbose: bool = False
â”‚      all: bool = False
â”‚ @@ -37,68 +37,73 @@
â”‚      run_config: MpylRunConfig
â”‚      parameters: MpylCliParameters
â”‚  
â”‚  
â”‚  FORMAT = "%(name)s  %(message)s"
â”‚  
â”‚  
â”‚ +def get_build_plan(logger: logging.Logger, repo: Repository, mpyl_run_parameters: MpylRunParameters) -> RunResult:
â”‚ +    params = mpyl_run_parameters.parameters
â”‚ +    logger.info(f"Running with {params}")
â”‚ +    if not params.local:
â”‚ +        pull_result = repo.pull_main_branch()
â”‚ +        logger.info(f'Pulled `{pull_result[0].remote_ref_path.strip()}` to local')
â”‚ +
â”‚ +    changes_in_branch = repo.changes_in_branch_including_local() if params.local else repo.changes_in_branch()
â”‚ +    logger.debug(f'Changes: {changes_in_branch}')
â”‚ +
â”‚ +    projects_per_stage: dict[Stage, set[Project]] = find_build_set(repo, changes_in_branch, params.all)
â”‚ +    return RunResult(run_properties=mpyl_run_parameters.run_config.run_properties, run_plan=projects_per_stage)
â”‚ +
â”‚ +
â”‚  def run_mpyl(mpyl_run_parameters: MpylRunParameters, reporter: Optional[Reporter]) -> RunResult:
â”‚      params = mpyl_run_parameters.parameters
â”‚      console = Console(markup=True, width=None if params.local else 135, no_color=False, log_path=False,
â”‚                        color_system='256')
â”‚      logging.basicConfig(
â”‚          level="DEBUG" if params.verbose else "INFO", format=FORMAT, datefmt="[%X]",
â”‚          handlers=[RichHandler(markup=True,
â”‚                                console=console, show_path=params.local)]
â”‚      )
â”‚      logger = logging.getLogger('mpyl')
â”‚      try:
â”‚          with Repository(RepoConfig(mpyl_run_parameters.run_config.config)) as repo:
â”‚  
â”‚ -            logger.info(f"Running with {params}")
â”‚ -            if not params.local:
â”‚ -                pull_result = repo.pull_main_branch()
â”‚ -                logger.info(f'Pulled `{pull_result[0].remote_ref_path.strip()}` to local')
â”‚ -
â”‚ -            changes_in_branch = repo.changes_in_branch_including_local() if params.local else repo.changes_in_branch()
â”‚ -            logger.debug(f'Changes: {changes_in_branch}')
â”‚ +            run_plan = get_build_plan(logger, repo, mpyl_run_parameters)
â”‚  
â”‚ -            project_paths = repo.find_projects()
â”‚ -
â”‚ -            all_projects = set(map(lambda p: load_project(Path("."), Path(p), False), project_paths))
â”‚ -
â”‚ -            projects_per_stage: dict[Stage, set[Project]] = find_build_set(all_projects, changes_in_branch, params.all)
â”‚ -
â”‚ -            if params.local:
â”‚ -                mpyl_run_parameters.run_config.run_properties['build']['versioning']['revision'] = repo.get_sha
â”‚ -                mpyl_run_parameters.run_config.run_properties['build']['versioning']['pr_number'] = '123'
â”‚ -
â”‚ -            run_properties = RunProperties.from_configuration(
â”‚ -                run_properties=mpyl_run_parameters.run_config.run_properties,
â”‚ -                config=mpyl_run_parameters.run_config.config)
â”‚ -            if not projects_per_stage.items():
â”‚ +            if not run_plan.run_plan.items():
â”‚                  logger.info("Nothing to do. Exiting..")
â”‚ -                sys.exit()
â”‚ +                return run_plan
â”‚  
â”‚              logger.info("Building plan:")
â”‚ -            run_plan = RunResult(run_properties=run_properties, run_plan=projects_per_stage)
â”‚ -            logger.info(f"\n\n{run_result_to_markdown(run_plan)}")
â”‚ +            console.print(Markdown(f"\n\n{run_result_to_markdown(run_plan)}"))
â”‚  
â”‚ -            run_result = run_build(run_plan, Steps(logger=logger, properties=run_properties), reporter)
â”‚ +            run_result: RunResult = run_plan
â”‚ +            try:
â”‚ +                steps = Steps(logger=logger, properties=mpyl_run_parameters.run_config.run_properties)
â”‚ +                run_result = run_build(run_plan, steps, reporter)
â”‚ +            except Exception as exc:  # pylint: disable=broad-except
â”‚ +                console.log(f'Exception during build execution: {exc}')
â”‚ +                console.print_exception()
â”‚ +                run_result.exception = exc
â”‚  
â”‚ -            logger.info(run_result_to_markdown(run_result))
â”‚ +            console.print(run_result.status_line)
â”‚ +            console.print(Markdown(run_result_to_markdown(run_result)))
â”‚              return run_result
â”‚  
â”‚      except Exception as exc:
â”‚          console.log(f'Unexpected exception: {exc}')
â”‚          console.print_exception()
â”‚          raise exc
â”‚  
â”‚  
â”‚ -def find_build_set(all_projects, changes_in_branch, build_all: bool) -> dict[Stage, set[Project]]:
â”‚ +def find_build_set(repo: Repository, changes_in_branch, build_all: bool) -> dict[Stage, set[Project]]:
â”‚ +    project_paths = repo.find_projects()
â”‚ +    all_projects = set(map(lambda p: load_project(Path("."), Path(p), False), project_paths))
â”‚ +
â”‚      if build_all:
â”‚          return {Stage.BUILD: for_stage(all_projects, Stage.BUILD),
â”‚                  Stage.TEST: for_stage(all_projects, Stage.TEST),
â”‚                  Stage.DEPLOY: for_stage(all_projects, Stage.DEPLOY)}
â”‚  
â”‚      return find_invalidated_projects_per_stage(all_projects, changes_in_branch)
â”œâ”€â”€ mpyl/cli/commands/__init__.py
â”‚ @@ -1 +1,23 @@
â”‚  """CLI commands"""
â”‚ +import importlib
â”‚ +from dataclasses import dataclass
â”‚ +from importlib.metadata import version as version_meta
â”‚ +
â”‚ +from rich.console import Console
â”‚ +
â”‚ +from ...utilities.repo import Repository
â”‚ +
â”‚ +
â”‚ +@dataclass(frozen=True)
â”‚ +class CliContext:
â”‚ +    config: dict
â”‚ +    repo: Repository
â”‚ +    console: Console
â”‚ +    verbose: bool
â”‚ +
â”‚ +
â”‚ +def get_version():
â”‚ +    try:
â”‚ +        return f"v{version_meta('mpyl')}"
â”‚ +    except importlib.metadata.PackageNotFoundError:
â”‚ +        return '(local)'
â”œâ”€â”€ mpyl/cli/commands/build.py
â”‚ @@ -1,67 +1,85 @@
â”‚  """Commands related to build"""
â”‚  from typing import Any, Optional
â”‚  
â”‚  import click
â”‚  from click import Parameter, Context
â”‚ +from rich.markdown import Markdown
â”‚  
â”‚ +from . import CliContext
â”‚ +from .. import create_console_logger
â”‚  from ..build.jenkins import JenkinsRunParameters, run_jenkins
â”‚ -from ..build.mpyl import MpylRunParameters, run_mpyl, MpylCliParameters, MpylRunConfig
â”‚ +from ..build.mpyl import MpylRunParameters, run_mpyl, MpylCliParameters, MpylRunConfig, find_build_set
â”‚ +from ...reporting.formatting.markdown import run_result_to_markdown
â”‚ +from ...steps.models import RunProperties
â”‚ +from ...steps.run import RunResult
â”‚  from ...utilities.pyaml_env import parse_config
â”‚ +from ...utilities.repo import Repository, RepoConfig
â”‚  
â”‚  
â”‚  @click.group('build')
â”‚  @click.option('--config', '-c', required=True, type=click.Path(exists=True), help='Path to config.yml',
â”‚ -              default='config.yml')
â”‚ +              envvar="MPYL_CONFIG_PATH", default='config.yml')
â”‚ +@click.option('--verbose', '-v', is_flag=True, default=False)
â”‚  @click.pass_context
â”‚ -def build(ctx, config):
â”‚ +def build(ctx, config, verbose):
â”‚      """Pipeline build commands"""
â”‚ -    if ctx.obj is None:
â”‚ -        ctx.obj = {}
â”‚ -    ctx.obj["config"] = parse_config(config)
â”‚ +    console = create_console_logger(local=False, verbose=verbose)
â”‚ +    parsed_config = parse_config(config)
â”‚ +    repo = ctx.with_resource(Repository(config=RepoConfig(parsed_config)))
â”‚ +    ctx.obj = CliContext(parsed_config, repo, console, verbose)
â”‚  
â”‚  
â”‚  @build.command(help='Run an MPyL build')
â”‚ -@click.option('--properties', '-p', required=True, type=click.Path(exists=True), help='Path to run properties',
â”‚ -              default='run_properties.yml')
â”‚ +@click.option('--properties', '-p', required=False, type=click.Path(exists=False), help='Path to run properties',
â”‚ +              envvar="MPYL_RUN_PROPERTIES_PATH", default='run_properties.yml')
â”‚  @click.option('--local', '-l', is_flag=True, default=True, help='Local vs CI build')
â”‚  @click.option('--all', 'all_', is_flag=True, default=False, help='Build all projects, regardless of changes on branch')
â”‚ -@click.option('--verbose', '-v', is_flag=True, default=False)
â”‚  @click.pass_obj
â”‚  def run(obj, properties, local, all_, verbose):
â”‚ +    run_properties = RunProperties.for_local_run(obj.config, obj.repo.get_sha, obj.repo.get_branch) if local \
â”‚ +        else RunProperties.from_configuration(parse_config(properties), obj.config)
â”‚ +
â”‚      run_parameters = MpylRunParameters(
â”‚ -        run_config=MpylRunConfig(config=obj['config'], run_properties=parse_config(properties)),
â”‚ +        run_config=MpylRunConfig(config=obj.config, run_properties=run_properties),
â”‚          parameters=MpylCliParameters(local=local, all=all_, verbose=verbose)
â”‚      )
â”‚      run_mpyl(run_parameters, None)
â”‚  
â”‚  
â”‚ -@build.command()
â”‚ -def status():
â”‚ -    click.echo('build status')
â”‚ +@build.command(help="The status of the current local branch from MPyL's perspective")
â”‚ +@click.pass_obj
â”‚ +def status(obj: CliContext):
â”‚ +    changes_in_branch = obj.repo.changes_in_branch_including_local()
â”‚ +    build_set = find_build_set(obj.repo, changes_in_branch, False)
â”‚ +    run_properties = RunProperties.for_local_run(obj.config, obj.repo.get_short_sha, obj.repo.get_branch)
â”‚ +    result = RunResult(run_properties=run_properties, run_plan=build_set)
â”‚ +    version = run_properties.versioning
â”‚ +    header: str = f"**Revision:** `{version.branch}` at `{version.revision}`  \n"
â”‚ +    obj.console.print(Markdown(markup=header + "**Execution plan:**  \n" + run_result_to_markdown(result)))
â”‚  
â”‚  
â”‚  def get_default(ctx):
â”‚      if not ctx:
â”‚          return 'config.jenkins.defaultPipeline'
â”‚  
â”‚ -    return ctx.obj['config']['jenkins']['defaultPipeline']
â”‚ +    return ctx.obj.config['jenkins']['defaultPipeline']
â”‚  
â”‚  
â”‚  class DynamicChoice(click.Choice):
â”‚      def __init__(self):
â”‚          super().__init__([])
â”‚  
â”‚      def convert(
â”‚              self, value: Any, param: Optional[Parameter], ctx: Optional[Context]
â”‚      ) -> Any:
â”‚          if ctx is None:
â”‚              raise KeyError("Context needs to be set. Did you use @click.pass_context in the parent group?")
â”‚  
â”‚ -        config = ctx.obj['config']
â”‚ +        config = ctx.obj.config
â”‚          if value is None:
â”‚              value = config['jenkins']['defaultPipeline']
â”‚          self.choices = config['jenkins']['pipelines'].keys()
â”‚          return super().convert(value, param, ctx)
â”‚  
â”‚  
â”‚  @build.command(help='Run a multi branch pipeline build on Jenkins')
â”‚ @@ -85,13 +103,13 @@
â”‚           'Default value is `jenkins.defaultPipeline',
â”‚      type=DynamicChoice(),
â”‚      required=True,
â”‚      default=lambda: get_default(click.get_current_context(silent=True))
â”‚  )
â”‚  @click.pass_obj
â”‚  def jenkins(obj, user, password, pipeline):
â”‚ -    run_argument = JenkinsRunParameters(user, password, obj['config'], pipeline)
â”‚ +    run_argument = JenkinsRunParameters(user, password, obj.config, pipeline)
â”‚      run_jenkins(run_argument)
â”‚  
â”‚  
â”‚  if __name__ == '__main__':
â”‚      build()  # pylint: disable=no-value-for-parameter
â”œâ”€â”€ mpyl/cli/commands/meta_info.py
â”‚ @@ -1,14 +1,16 @@
â”‚  """Extractors for package meta information"""
â”‚  
â”‚  import os
â”‚ -from importlib.metadata import version as version_meta, distribution
â”‚ +from importlib.metadata import distribution
â”‚  
â”‚  import click
â”‚  
â”‚ +from . import get_version
â”‚ +
â”‚  VDB_LOGO = """
â”‚                                           .::.               
â”‚                                           :~~~^:.            
â”‚                                           ^~~~~~~^:.         
â”‚                 .........................:~~~~~~~~~^^.       
â”‚               .^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^:.    
â”‚               .^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^:. 
â”‚ @@ -32,15 +34,15 @@
â”‚    .^~~~~~~~~~~~~~~~~^:........................              
â”‚      .:^~~~~~~~~~~^^.                                        
â”‚         .:::^^:::.
â”‚  """
â”‚  
â”‚  
â”‚  def simple_version():
â”‚ -    return f"Version {version_meta('mpyl')}"
â”‚ +    return f"MPyL {get_version()}"
â”‚  
â”‚  
â”‚  def about():
â”‚      dist = distribution('mpyl')
â”‚      details = os.linesep.join(str(dist.metadata).split(os.linesep)[1:16])
â”‚      return f'{details}{VDB_LOGO}'
â”œâ”€â”€ mpyl/cli/commands/projects.py
â”‚ @@ -1,46 +1,50 @@
â”‚  """Commands related to projects and how they relate"""
â”‚  from pathlib import Path
â”‚  
â”‚  import click
â”‚  import jsonschema
â”‚  
â”‚ +from . import CliContext
â”‚ +from .. import create_console_logger
â”‚  from ...project import validate_project
â”‚  from ...utilities.pyaml_env import parse_config
â”‚  from ...utilities.repo import Repository, RepoConfig
â”‚  
â”‚  
â”‚  @click.group('projects')
â”‚ -@click.option('--config', '-c', required=True, type=click.Path(exists=True), help='Path to config.yml',
â”‚ -              default='config.yml')
â”‚ +@click.option('--config', '-c', required=True, type=click.Path(exists=True), help='Path to the config.yml',
â”‚ +              envvar="MPYL_CONFIG_PATH", default='config.yml')
â”‚ +@click.option('--verbose', '-v', is_flag=True, default=False)
â”‚  @click.pass_context
â”‚ -def projects(ctx, config):
â”‚ +def projects(ctx, config, verbose):
â”‚      """Commands related to projects"""
â”‚ +    console = create_console_logger(local=False, verbose=verbose)
â”‚      parsed_config = parse_config(config)
â”‚ -    ctx.obj = ctx.with_resource(Repository(config=RepoConfig(parsed_config)))
â”‚ +    ctx.obj = CliContext(parsed_config, ctx.with_resource(Repository(config=RepoConfig(parsed_config))), console,
â”‚ +                         verbose)
â”‚  
â”‚  
â”‚  @projects.command(name='list', help='List found projects')
â”‚  @click.pass_obj
â”‚ -def list_projects(repo):
â”‚ -    found_projects = repo.find_projects()
â”‚ +def list_projects(obj: CliContext):
â”‚ +    found_projects = obj.repo.find_projects()
â”‚      for proj in found_projects:
â”‚ -        click.echo(proj)
â”‚ +        obj.console.log(proj)
â”‚  
â”‚  
â”‚  @projects.command(help='Validate the yaml of found projects against their schema')
â”‚  @click.pass_obj
â”‚ -def lint(repo):
â”‚ -    found_projects: set[str] = repo.find_projects()
â”‚ -    for project in found_projects:
â”‚ +def lint(obj: CliContext):
â”‚ +    for project in obj.repo.find_projects():
â”‚          try:
â”‚              project_path = Path('.') / Path(project)
â”‚              with open(project_path, encoding='utf-8') as file:
â”‚                  validate_project(file)
â”‚          except jsonschema.exceptions.ValidationError as exc:
â”‚ -            click.echo(f'âŒ {project}: {exc.message}')
â”‚ +            obj.console.log(f'âŒ {project}: {exc.message}')
â”‚          else:
â”‚ -            click.echo(f'âœ… {project}')
â”‚ +            obj.console.log(f'âœ… {project}')
â”‚  
â”‚  
â”‚  if __name__ == '__main__':
â”‚      projects()  # pylint: disable=no-value-for-parameter
â”œâ”€â”€ mpyl/reporting/formatting/markdown.py
â”‚ @@ -40,30 +40,30 @@
â”‚      suites: list[list[TestSuite]] = list(map(to_test_suites, test_artifacts))
â”‚      flattened = list(itertools.chain(*suites))
â”‚      return flattened
â”‚  
â”‚  
â”‚  def stage_to_icon(stage: Stage):
â”‚      if stage == Stage.BUILD:
â”‚ -        return 'building_construction'
â”‚ +        return 'ðŸ—ï¸ '
â”‚      if stage == Stage.TEST:
â”‚ -        return 'test_tube'
â”‚ +        return 'ðŸ§ª'
â”‚      if stage == Stage.DEPLOY:
â”‚ -        return 'rocket'
â”‚ -    return 'arrow_right'
â”‚ +        return 'ðŸš€'
â”‚ +    return 'âž¡ï¸'
â”‚  
â”‚  
â”‚  def run_result_to_markdown(run_result: RunResult) -> str:
â”‚ -    result: str = ""
â”‚ +    result: str = f'â—Exception: \n```\n{run_result.exception}\n```\n' if run_result.exception else ""
â”‚  
â”‚      for stage in Stage:
â”‚          step_results: list[StepResult] = run_result.results_for_stage(stage)
â”‚          plan: set[Project] = run_result.plan_for_stage(stage)
â”‚          if step_results or plan:
â”‚ -            result += f":{stage_to_icon(stage)}: {__to_oneliner(step_results, plan)} \n"
â”‚ +            result += f"{stage_to_icon(stage)}  {__to_oneliner(step_results, plan)}  \n"
â”‚              test_results = __collect_test_results(step_results)
â”‚              if test_results:
â”‚                  result += to_markdown_test_report(
â”‚                      test_results) + f' [link]({run_result.run_properties.details.tests_url}) \n'
â”‚  
â”‚      return result
â”‚ â”œâ”€â”€ encoding
â”‚ â”‚ @@ -1 +1 @@
â”‚ â”‚ -us-ascii
â”‚ â”‚ +utf-8
â”œâ”€â”€ mpyl/reporting/targets/jira.py
â”‚ @@ -61,32 +61,37 @@
â”‚  
â”‚  
â”‚  @dataclass(frozen=True)
â”‚  class JiraConfig:
â”‚      site: str
â”‚      user_name: str
â”‚      password: str
â”‚ +    token: Optional[str]
â”‚  
â”‚      @staticmethod
â”‚      def from_config(config: dict):
â”‚ -        return JiraConfig(site=config['site'], user_name=config['userName'], password=config['password'])
â”‚ +        return JiraConfig(site=config['site'], user_name=config['userName'], password=config['password'],
â”‚ +                          token=config.get('token'))
â”‚  
â”‚  
â”‚  class JiraReporter(Reporter):
â”‚  
â”‚      def __init__(self, config: dict, branch: str, logger: Logger):
â”‚          jira_config = config.get('jira')
â”‚          if not jira_config:
â”‚              raise ValueError('jira section needs to be defined in config.yml')
â”‚          self._ticket = extract_ticket_from_branch(branch)
â”‚  
â”‚          jira_config = JiraConfig.from_config(jira_config)
â”‚          self._config = jira_config
â”‚ -        self._jira = Jira(url=jira_config.site, username=jira_config.user_name, password=jira_config.password,
â”‚ -                          api_version='3', cloud=True)
â”‚ +        self._jira = Jira(url=jira_config.site, token=jira_config.token, api_version='3',
â”‚ +                          cloud=True) if jira_config.token else Jira(url=jira_config.site,
â”‚ +                                                                     username=jira_config.user_name,
â”‚ +                                                                     password=jira_config.password,
â”‚ +                                                                     api_version='3', cloud=True)
â”‚          self._logger = logger
â”‚  
â”‚      def send_report(self, results: RunResult) -> None:
â”‚          if not self._ticket:
â”‚              return None
â”‚  
â”‚          issue_response = self._jira.get_issue(self._ticket)
â”œâ”€â”€ mpyl/schema/mpyl_config.schema.yml
â”‚ @@ -170,14 +170,24 @@
â”‚          type: boolean
â”‚        testWithCoverage:
â”‚          type: string
â”‚        javaOpts:
â”‚          type: string
â”‚        sbtOpts:
â”‚          type: string
â”‚ +      clientMode:
â”‚ +        type: object
â”‚ +        additionalProperties: false
â”‚ +        properties:
â”‚ +          build:
â”‚ +            type: boolean
â”‚ +            default: true
â”‚ +          test:
â”‚ +            type: boolean
â”‚ +            default: true
â”‚      required:
â”‚        - command
â”‚        - javaOpts
â”‚        - sbtOpts
â”‚      title: Sbt
â”‚    Project:
â”‚      type: object
â”‚ @@ -226,11 +236,11 @@
â”‚          description: "Only works with the cloud version of Jira"
â”‚          type: string
â”‚          format: uri
â”‚        userName:
â”‚          type: string
â”‚        password:
â”‚          type: string
â”‚ +      token:
â”‚ +        type: string
â”‚      required:
â”‚        - site
â”‚ -      - userName
â”‚ -      - password
â”œâ”€â”€ mpyl/schema/project.schema.yml
â”‚ @@ -83,14 +83,15 @@
â”‚            - Ephemeral Docker Deploy
â”‚            - Echo Deploy
â”‚            - NUC Deploy
â”‚            - Kubernetes Deploy
â”‚            - Echo Kubernetes Deploy
â”‚            - Kubernetes Job Deploy
â”‚            - Kubernetes Job Template Deploy
â”‚ +          - Kubernetes Spark Job Deploy
â”‚            - CloudFront Kubernetes Deploy
â”‚            - Renew Lets Encrypt Deploy
â”‚            - Helm Deploy
â”‚            - Dagster Deploy
â”‚        postdeploy:
â”‚          description: Additional steps that can be done after the project has been deployed.
â”‚          examples:
â”‚ @@ -217,57 +218,17 @@
â”‚        s3:
â”‚          additionalProperties: false
â”‚          type: object
â”‚          required:
â”‚            - bucket
â”‚          properties:
â”‚            bucket:
â”‚ -            type: object
â”‚ -            additionalProperties: false
â”‚ -            oneOf:
â”‚ -              - required:
â”‚ -                  - pr
â”‚ -                  - test
â”‚ -                  - acceptance
â”‚ -                  - production
â”‚ -              - required:
â”‚ -                  - all
â”‚ -            properties:
â”‚ -              pr:
â”‚ -                type: string
â”‚ -              test:
â”‚ -                type: string
â”‚ -              acceptance:
â”‚ -                type: string
â”‚ -              production:
â”‚ -                type: string
â”‚ -              all:
â”‚ -                type: string
â”‚ +            $ref: '#/definitions/dtapValue'
â”‚            path:
â”‚ -            type: object
â”‚ -            additionalProperties: false
â”‚ -            oneOf:
â”‚ -              - required:
â”‚ -                  - pr
â”‚ -                  - test
â”‚ -                  - acceptance
â”‚ -                  - production
â”‚ -              - required:
â”‚ -                  - all
â”‚ -            properties:
â”‚ -              pr:
â”‚ -                type: string
â”‚ -              test:
â”‚ -                type: string
â”‚ -              acceptance:
â”‚ -                type: string
â”‚ -              production:
â”‚ -                type: string
â”‚ -              all:
â”‚ -                type: string
â”‚ +            $ref: '#/definitions/dtapValue'
â”‚        kubernetes:
â”‚          $ref: '#/definitions/kubernetes'
â”‚        traefik:
â”‚          additionalProperties: false
â”‚          type: object
â”‚          properties:
â”‚            enabled:
â”‚ @@ -368,14 +329,36 @@
â”‚          type: string
â”‚        acceptance:
â”‚          type: string
â”‚        production:
â”‚          type: string
â”‚        all:
â”‚          type: string
â”‚ +  dtapNumberValue:
â”‚ +    type: object
â”‚ +    additionalProperties: false
â”‚ +    oneOf:
â”‚ +      - required:
â”‚ +          - pr
â”‚ +          - test
â”‚ +          - acceptance
â”‚ +          - production
â”‚ +      - required:
â”‚ +          - all
â”‚ +    properties:
â”‚ +      pr:
â”‚ +        type: number
â”‚ +      test:
â”‚ +        type: number
â”‚ +      acceptance:
â”‚ +        type: number
â”‚ +      production:
â”‚ +        type: number
â”‚ +      all:
â”‚ +        type: number
â”‚    traefikHost:
â”‚      type: object
â”‚      additionalProperties: false
â”‚      required:
â”‚        - host
â”‚      properties:
â”‚        host:
â”‚ @@ -678,39 +661,19 @@
â”‚            production:
â”‚              default: '512'
â”‚              type: integer
â”‚            all:
â”‚              default: '512'
â”‚              type: integer
â”‚        disk:
â”‚ -        type: object
â”‚ -        additionalProperties: false
â”‚ +        $ref: '#/definitions/dtapValue'
â”‚          description: >-
â”‚            Sets the amount of swap space a pod can use. Note: this is not
â”‚            persistent storage.
â”‚            https://kubernetes.io/docs/concepts/storage/ephemeral-volumes/
â”‚ -        oneOf:
â”‚ -          - required:
â”‚ -              - pr
â”‚ -              - test
â”‚ -              - acceptance
â”‚ -              - production
â”‚ -          - required:
â”‚ -              - all
â”‚ -        properties:
â”‚ -          pr:
â”‚ -            type: number
â”‚ -          test:
â”‚ -            type: number
â”‚ -          acceptance:
â”‚ -            type: number
â”‚ -          production:
â”‚ -            type: number
â”‚ -          all:
â”‚ -            type: number
â”‚    limitResources:
â”‚      type: object
â”‚      additionalProperties: false
â”‚      description: >-
â”‚        Sets the upper limit for resource consumption. Any consumption more than
â”‚        this will be curtailed.
â”‚        https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits
â”‚ @@ -768,39 +731,19 @@
â”‚              type: integer
â”‚            production:
â”‚              default: '2048'
â”‚              type: integer
â”‚            all:
â”‚              type: integer
â”‚        disk:
â”‚ -        type: object
â”‚ -        additionalProperties: false
â”‚ +        $ref: '#/definitions/dtapNumberValue'
â”‚          description: >-
â”‚            Sets the amount of swap space a pod can use. Note: this is not
â”‚            persistent storage.
â”‚            https://kubernetes.io/docs/concepts/storage/ephemeral-volumes/
â”‚ -        oneOf:
â”‚ -          - required:
â”‚ -              - pr
â”‚ -              - test
â”‚ -              - acceptance
â”‚ -              - production
â”‚ -          - required:
â”‚ -              - all
â”‚ -        properties:
â”‚ -          pr:
â”‚ -            type: number
â”‚ -          test:
â”‚ -            type: number
â”‚ -          acceptance:
â”‚ -            type: number
â”‚ -          production:
â”‚ -            type: number
â”‚ -          all:
â”‚ -            type: number
â”‚    alert:
â”‚      type: object
â”‚      required:
â”‚        - name
â”‚        - expr
â”‚        - forDuration
â”‚        - severity
â”‚ @@ -825,36 +768,53 @@
â”‚          additionalItems: false
â”‚          required:
â”‚            - name
â”‚          properties:
â”‚            name:
â”‚              type: string
â”‚        cron:
â”‚ +        description: 'CronJobSpec describes how the job execution will look like and when it
â”‚ +          will actually run. Identical to See https://kubernetesjsonschema.dev/v1.14.0/_definitions.json#/definitions/io.k8s.api.batch.v1beta1.CronJobSpec
â”‚ +          but without jobTemplate'
â”‚          additionalProperties: false
â”‚ -        type: object
â”‚ -        required:
â”‚ -          - schedule
â”‚          properties:
â”‚ -          schedule:
â”‚ -            type: string
â”‚ -          successfulJobHistory:
â”‚ -            type: integer
â”‚ -            description: number of jobs to keep in history that succeeded
â”‚ -          failedJobHistory:
â”‚ -            type: integer
â”‚ -            description: number of jobs to keep in history that failed
â”‚            concurrencyPolicy:
â”‚ +            description: 'Specifies how to treat concurrent executions of a Job. Valid values
â”‚ +              are: - "Allow" (default): allows CronJobs to run concurrently; - "Forbid": forbids
â”‚ +              concurrent runs, skipping next run if previous run hasn''t finished yet; - "Replace":
â”‚ +              cancels currently running job and replaces it with a new one
â”‚ +              See https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/#concurrency-policy
â”‚ +              '
â”‚              type: string
â”‚              enum:
â”‚                - Allow
â”‚                - Forbid
â”‚                - Replace
â”‚ -            description: >-
â”‚ -              treatment of concurrent job executions. See
â”‚ -              https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/#concurrency-policy
â”‚ +          failedJobsHistoryLimit:
â”‚ +            description: The number of failed finished jobs to retain. This is a pointer to
â”‚ +              distinguish between explicit zero and not specified. Defaults to 1.
â”‚ +            format: int32
â”‚ +            type: integer
â”‚ +          schedule:
â”‚ +            description: The schedule in Cron format, see https://en.wikipedia.org/wiki/Cron.
â”‚ +            type: string
â”‚ +          startingDeadlineSeconds:
â”‚ +            description: Optional deadline in seconds for starting the job if it misses scheduled
â”‚ +              time for any reason.  Missed jobs executions will be counted as failed ones.
â”‚ +            format: int64
â”‚ +            type: integer
â”‚ +          successfulJobsHistoryLimit:
â”‚ +            description: The number of successful finished jobs to retain. This is a pointer
â”‚ +              to distinguish between explicit zero and not specified. Defaults to 3.
â”‚ +            format: int32
â”‚ +            type: integer
â”‚ +          suspend:
â”‚ +            description: This flag tells the controller to suspend subsequent executions,
â”‚ +              it does not apply to already started executions.  Defaults to false.
â”‚ +            type: boolean
â”‚        policies:
â”‚          type: array
â”‚          minItems: 1
â”‚        labels:
â”‚          type: array
â”‚          items:
â”‚            $ref: '#/definitions/label'
â”‚ @@ -868,57 +828,18 @@
â”‚        livenessProbe:
â”‚          description: >-
â”‚            Detects whether a pod is healthy by running a command or making a
â”‚            network request inside the container. Containers that fail the
â”‚            check are restarted.
â”‚          $ref: '#/definitions/livenessProbe'
â”‚        cmd:
â”‚ -        type: object
â”‚ -        additionalProperties: false
â”‚ -        oneOf:
â”‚ -          - required:
â”‚ -              - pr
â”‚ -              - test
â”‚ -              - acceptance
â”‚ -              - production
â”‚ -          - required:
â”‚ -              - all
â”‚ -        properties:
â”‚ -          pr:
â”‚ -            type: string
â”‚ -          test:
â”‚ -            type: string
â”‚ -          acceptance:
â”‚ -            type: string
â”‚ -          production:
â”‚ -            type: string
â”‚ -          all:
â”‚ -            type: string
â”‚ +        $ref: '#/definitions/dtapValue'
â”‚        args:
â”‚          type: object
â”‚ -        additionalProperties: false
â”‚ -        oneOf:
â”‚ -          - required:
â”‚ -              - pr
â”‚ -              - test
â”‚ -              - acceptance
â”‚ -              - production
â”‚ -          - required:
â”‚ -              - all
â”‚ -        properties:
â”‚ -          pr:
â”‚ -            type: string
â”‚ -          test:
â”‚ -            type: string
â”‚ -          acceptance:
â”‚ -            type: string
â”‚ -          production:
â”‚ -            type: string
â”‚ -          all:
â”‚ -            type: string
â”‚ +        $ref: '#/definitions/dtapValue'
â”‚        resources:
â”‚          type: object
â”‚          properties:
â”‚            instances:
â”‚              description: Sets the number of replicas to be started
â”‚              type: object
â”‚              additionalProperties: false
â”‚ @@ -950,57 +871,17 @@
â”‚              $ref: '#/definitions/limitResources'
â”‚            request:
â”‚              $ref: '#/definitions/requestResources'
â”‚          additionalProperties: false
â”‚        portMappings:
â”‚          type: object
â”‚        ttlSecondsAfterFinished:
â”‚ -        type: object
â”‚ -        additionalProperties: false
â”‚ -        oneOf:
â”‚ -          - required:
â”‚ -              - pr
â”‚ -              - test
â”‚ -              - acceptance
â”‚ -              - production
â”‚ -          - required:
â”‚ -              - all
â”‚ -        properties:
â”‚ -          pr:
â”‚ -            type: number
â”‚ -          test:
â”‚ -            type: number
â”‚ -          acceptance:
â”‚ -            type: number
â”‚ -          production:
â”‚ -            type: number
â”‚ -          all:
â”‚ -            type: number
â”‚ +        $ref: '#/definitions/dtapNumberValue'
â”‚        activeDeadlineSeconds:
â”‚ -        type: object
â”‚ -        additionalProperties: false
â”‚ -        oneOf:
â”‚ -          - required:
â”‚ -              - pr
â”‚ -              - test
â”‚ -              - acceptance
â”‚ -              - production
â”‚ -          - required:
â”‚ -              - all
â”‚ -        properties:
â”‚ -          pr:
â”‚ -            type: number
â”‚ -          test:
â”‚ -            type: number
â”‚ -          acceptance:
â”‚ -            type: number
â”‚ -          production:
â”‚ -            type: number
â”‚ -          all:
â”‚ -            type: number
â”‚ +        $ref: '#/definitions/dtapNumberValue'
â”‚        role:
â”‚          type: object
â”‚          additionalProperties: false
â”‚          required:
â”‚            - resources
â”‚            - verbs
â”‚          properties:
â”œâ”€â”€ mpyl/steps/models.py
â”‚ @@ -61,14 +61,19 @@
â”‚      versioning: VersioningProperties
â”‚      config: dict
â”‚      """Globally specified configuration, to be used by specific steps. Complies with the schema as
â”‚      specified in `mpyl_config.schema.yml`
â”‚       """
â”‚  
â”‚      @staticmethod
â”‚ +    def for_local_run(config: Dict, revision: str, branch: Optional[str]):
â”‚ +        return RunProperties(details=RunContext("", "", "", "", "", None), target=Target.PULL_REQUEST,
â”‚ +                             versioning=VersioningProperties(revision, branch, 123, None), config=config)
â”‚ +
â”‚ +    @staticmethod
â”‚      def from_configuration(run_properties: Dict, config: Dict):
â”‚          build = run_properties['build']
â”‚          versioning = build['versioning']
â”‚          versioning = VersioningProperties(revision=versioning['revision'], branch=versioning['branch'],
â”‚                                            pr_number=int(versioning.get('pr_number')), tag=versioning.get('tag'))
â”‚  
â”‚          return RunProperties(details=RunContext.from_configuration(build['run']),
â”œâ”€â”€ mpyl/steps/run.py
â”‚ @@ -17,14 +17,31 @@
â”‚      _exception: Optional[Exception]
â”‚  
â”‚      def __init__(self, run_properties: RunProperties, run_plan=None):
â”‚          if run_plan is None:
â”‚              run_plan = {}
â”‚          self._run_properties = run_properties
â”‚          self._run_plan = run_plan
â”‚ +        self._exception = None
â”‚ +
â”‚ +    @property
â”‚ +    def status_line(self) -> str:
â”‚ +        if self._exception:
â”‚ +            return 'â—Failed with exception'
â”‚ +        if self._results_success():
â”‚ +            return 'âœ…Successful'
â”‚ +        return 'âŒFailed'
â”‚ +
â”‚ +    @property
â”‚ +    def exception(self) -> Optional[Exception]:
â”‚ +        return self._exception
â”‚ +
â”‚ +    @exception.setter
â”‚ +    def exception(self, exception: Exception):
â”‚ +        self._exception = exception
â”‚  
â”‚      @property
â”‚      def run_properties(self) -> RunProperties:
â”‚          return self._run_properties
â”‚  
â”‚      @property
â”‚      def run_plan(self) -> dict[Stage, set[Project]]:
â”‚ @@ -34,14 +51,19 @@
â”‚          self._results.append(result)
â”‚  
â”‚      def extend(self, results: list[StepResult]):
â”‚          self._results.extend(results)
â”‚  
â”‚      @property
â”‚      def is_success(self):
â”‚ +        if self._exception:
â”‚ +            return False
â”‚ +        return self._results_success()
â”‚ +
â”‚ +    def _results_success(self):
â”‚          return all(r.output.success for r in self._results)
â”‚  
â”‚      @staticmethod
â”‚      def sort_chronologically(results: list[StepResult]) -> list[StepResult]:
â”‚          return sorted(results, key=operator.attrgetter('timestamp'))
â”‚  
â”‚      def results_for_stage(self, stage: Stage) -> list[StepResult]:
â”‚ â”œâ”€â”€ encoding
â”‚ â”‚ @@ -1 +1 @@
â”‚ â”‚ -us-ascii
â”‚ â”‚ +utf-8
â”œâ”€â”€ mpyl/steps/steps.py
â”‚ @@ -12,14 +12,15 @@
â”‚  
â”‚  from . import Step
â”‚  from .build.dockerbuild import BuildDocker
â”‚  from .build.echo import BuildEcho
â”‚  from .build.sbt import BuildSbt
â”‚  from .deploy.echo import DeployEcho
â”‚  from .deploy.kubernetes import DeployKubernetes
â”‚ +from .deploy.kubernetes_job import DeployKubernetesJob
â”‚  from .models import Output, Input, RunProperties, ArtifactType, Artifact
â”‚  from .test.dockertest import TestDocker
â”‚  from .test.echo import TestEcho
â”‚  from .test.sbt import TestSbt
â”‚  from ..project import Project
â”‚  from ..project import Stage
â”‚  from ..validation import validate
â”‚ @@ -58,15 +59,16 @@
â”‚              Stage.TEST: {
â”‚                  TestEcho(logger),
â”‚                  TestSbt(logger),
â”‚                  TestDocker(logger)
â”‚              },
â”‚              Stage.DEPLOY: {
â”‚                  DeployEcho(logger),
â”‚ -                DeployKubernetes(logger)
â”‚ +                DeployKubernetes(logger),
â”‚ +                DeployKubernetesJob(logger)
â”‚              }
â”‚          }
â”‚  
â”‚          self._properties = properties
â”‚          for stage, steps in self._step_executors.items():
â”‚              self._logger.debug(f"Registered executors for stage {stage.name}: "
â”‚                                 f"{[step.meta.name for step in steps]}")
â”œâ”€â”€ mpyl/steps/build/sbt.py
â”‚ @@ -50,10 +50,10 @@
â”‚              command for command in [
â”‚                  f'project {step_input.project.name}',
â”‚                  f'set docker / imageNames := Seq(ImageName("{image_name}"))',
â”‚                  check_fmt,
â”‚                  'docker'
â”‚              ] if command is not None
â”‚          ]
â”‚ -        command = SbtConfig.from_config(config=step_input.run_properties.config).to_command()
â”‚ -        command.append("; ".join(commands))
â”‚ +        config = SbtConfig.from_config(config=step_input.run_properties.config)
â”‚ +        command = config.to_command(config.build_with_client, commands)
â”‚          return command
â”œâ”€â”€ mpyl/steps/deploy/kubernetes.py
â”‚ @@ -1,15 +1,13 @@
â”‚  """ Step that deploys the docker image produced in the build stage to Kubernetes, using HELM. """
â”‚  
â”‚  from logging import Logger
â”‚  
â”‚ -from kubernetes import config, client
â”‚ -
â”‚ -from .k8s import helm
â”‚ -from .k8s.rancher import rancher_namespace_metadata, cluster_config
â”‚ +from .k8s import deploy_helm_chart
â”‚ +from .k8s.chart import ChartBuilder, to_service_chart
â”‚  from .. import Step, Meta
â”‚  from ..models import Input, Output, ArtifactType
â”‚  from ...project import Stage
â”‚  
â”‚  
â”‚  class DeployKubernetes(Step):
â”‚  
â”‚ @@ -18,31 +16,9 @@
â”‚              name='Kubernetes Deploy',
â”‚              description='Deploy to k8s',
â”‚              version='0.0.1',
â”‚              stage=Stage.DEPLOY
â”‚          ), produced_artifact=ArtifactType.NONE, required_artifact=ArtifactType.DOCKER_IMAGE)
â”‚  
â”‚      def execute(self, step_input: Input) -> Output:
â”‚ -        self._logger.info(f"Deploying project {step_input.project.name} with dry run: {step_input.dry_run}")
â”‚ -        if not step_input.required_artifact:
â”‚ -            return Output(success=False, message=f"Step requires artifact of type {self.required_artifact}")
â”‚ -
â”‚ -        properties = step_input.run_properties
â”‚ -        context = cluster_config(properties.target).context
â”‚ -
â”‚ -        config.load_kube_config(context=context)
â”‚ -        self._logger.info(f"Deploying target {properties.target} and k8s context {context}")
â”‚ -        api = client.CoreV1Api()
â”‚ -
â”‚ -        namespace = f'pr-{properties.versioning.pr_number}'
â”‚ -        meta_data = rancher_namespace_metadata(namespace, properties.target)
â”‚ -
â”‚ -        namespaces = api.list_namespace(field_selector=f'metadata.name={namespace}')
â”‚ -        if len(namespaces.items) == 0 and not step_input.dry_run:
â”‚ -            api.create_namespace(
â”‚ -                client.V1Namespace(api_version='v1', kind='Namespace', metadata=meta_data))
â”‚ -        else:
â”‚ -            self._logger.info(f"Found namespace {namespace}")
â”‚ -
â”‚ -        helm_result = helm.install(self._logger, step_input, namespace, context)
â”‚ -        self._logger.info(helm_result.message)
â”‚ -        return helm_result
â”‚ +        builder = ChartBuilder(step_input)
â”‚ +        return deploy_helm_chart(self._logger, to_service_chart(builder), step_input, builder.release_name)
â”œâ”€â”€ mpyl/steps/deploy/k8s/__init__.py
â”‚ @@ -0,0 +1,94 @@
â”‚ +00000000: 2222 224b 7562 6572 6e65 7465 7320 6465  """Kubernetes de
â”‚ +00000010: 706c 6f79 6d65 6e74 2072 656c 6174 6564  ployment related
â”‚ +00000020: 2068 656c 7065 7220 6d65 7468 6f64 7322   helper methods"
â”‚ +00000030: 2222 0a66 726f 6d20 6c6f 6767 696e 6720  "".from logging 
â”‚ +00000040: 696d 706f 7274 204c 6f67 6765 720a 0a66  import Logger..f
â”‚ +00000050: 726f 6d20 6b75 6265 726e 6574 6573 2069  rom kubernetes i
â”‚ +00000060: 6d70 6f72 7420 636f 6e66 6967 2c20 636c  mport config, cl
â”‚ +00000070: 6965 6e74 0a0a 6672 6f6d 202e 2e2e 6465  ient..from ...de
â”‚ +00000080: 706c 6f79 2e6b 3873 2e72 6573 6f75 7263  ploy.k8s.resourc
â”‚ +00000090: 6573 2e63 7264 2069 6d70 6f72 7420 4375  es.crd import Cu
â”‚ +000000a0: 7374 6f6d 5265 736f 7572 6365 4465 6669  stomResourceDefi
â”‚ +000000b0: 6e69 7469 6f6e 0a66 726f 6d20 2e2e 2e2e  nition.from ....
â”‚ +000000c0: 7374 6570 7320 696d 706f 7274 2049 6e70  steps import Inp
â”‚ +000000d0: 7574 2c20 4f75 7470 7574 0a66 726f 6d20  ut, Output.from 
â”‚ +000000e0: 2e2e 2e2e 7374 6570 732e 6465 706c 6f79  ....steps.deploy
â”‚ +000000f0: 2e6b 3873 2069 6d70 6f72 7420 6865 6c6d  .k8s import helm
â”‚ +00000100: 0a66 726f 6d20 2e2e 2e2e 7374 6570 732e  .from ....steps.
â”‚ +00000110: 6465 706c 6f79 2e6b 3873 2e72 616e 6368  deploy.k8s.ranch
â”‚ +00000120: 6572 2069 6d70 6f72 7420 636c 7573 7465  er import cluste
â”‚ +00000130: 725f 636f 6e66 6967 2c20 7261 6e63 6865  r_config, ranche
â”‚ +00000140: 725f 6e61 6d65 7370 6163 655f 6d65 7461  r_namespace_meta
â”‚ +00000150: 6461 7461 0a0a 0a64 6566 2075 7073 6572  data...def upser
â”‚ +00000160: 745f 6e61 6d65 7370 6163 6528 6c6f 6767  t_namespace(logg
â”‚ +00000170: 6572 3a20 4c6f 6767 6572 2c20 7374 6570  er: Logger, step
â”‚ +00000180: 5f69 6e70 7574 3a20 496e 7075 742c 2063  _input: Input, c
â”‚ +00000190: 6f6e 7465 7874 3a20 7374 7229 3a0a 2020  ontext: str):.  
â”‚ +000001a0: 2020 7072 6f70 6572 7469 6573 203d 2073    properties = s
â”‚ +000001b0: 7465 705f 696e 7075 742e 7275 6e5f 7072  tep_input.run_pr
â”‚ +000001c0: 6f70 6572 7469 6573 0a0a 2020 2020 636f  operties..    co
â”‚ +000001d0: 6e66 6967 2e6c 6f61 645f 6b75 6265 5f63  nfig.load_kube_c
â”‚ +000001e0: 6f6e 6669 6728 636f 6e74 6578 743d 636f  onfig(context=co
â”‚ +000001f0: 6e74 6578 7429 0a20 2020 206c 6f67 6765  ntext).    logge
â”‚ +00000200: 722e 696e 666f 2866 2244 6570 6c6f 7969  r.info(f"Deployi
â”‚ +00000210: 6e67 2074 6172 6765 7420 7b70 726f 7065  ng target {prope
â”‚ +00000220: 7274 6965 732e 7461 7267 6574 7d20 616e  rties.target} an
â”‚ +00000230: 6420 6b38 7320 636f 6e74 6578 7420 7b63  d k8s context {c
â”‚ +00000240: 6f6e 7465 7874 7d22 290a 2020 2020 6170  ontext}").    ap
â”‚ +00000250: 6920 3d20 636c 6965 6e74 2e43 6f72 6556  i = client.CoreV
â”‚ +00000260: 3141 7069 2829 0a0a 2020 2020 6e61 6d65  1Api()..    name
â”‚ +00000270: 7370 6163 6520 3d20 6627 7072 2d7b 7072  space = f'pr-{pr
â”‚ +00000280: 6f70 6572 7469 6573 2e76 6572 7369 6f6e  operties.version
â”‚ +00000290: 696e 672e 7072 5f6e 756d 6265 727d 270a  ing.pr_number}'.
â”‚ +000002a0: 2020 2020 6d65 7461 5f64 6174 6120 3d20      meta_data = 
â”‚ +000002b0: 7261 6e63 6865 725f 6e61 6d65 7370 6163  rancher_namespac
â”‚ +000002c0: 655f 6d65 7461 6461 7461 286e 616d 6573  e_metadata(names
â”‚ +000002d0: 7061 6365 2c20 7072 6f70 6572 7469 6573  pace, properties
â”‚ +000002e0: 2e74 6172 6765 7429 0a0a 2020 2020 6e61  .target)..    na
â”‚ +000002f0: 6d65 7370 6163 6573 203d 2061 7069 2e6c  mespaces = api.l
â”‚ +00000300: 6973 745f 6e61 6d65 7370 6163 6528 6669  ist_namespace(fi
â”‚ +00000310: 656c 645f 7365 6c65 6374 6f72 3d66 276d  eld_selector=f'm
â”‚ +00000320: 6574 6164 6174 612e 6e61 6d65 3d7b 6e61  etadata.name={na
â”‚ +00000330: 6d65 7370 6163 657d 2729 0a20 2020 2069  mespace}').    i
â”‚ +00000340: 6620 6c65 6e28 6e61 6d65 7370 6163 6573  f len(namespaces
â”‚ +00000350: 2e69 7465 6d73 2920 3d3d 2030 2061 6e64  .items) == 0 and
â”‚ +00000360: 206e 6f74 2073 7465 705f 696e 7075 742e   not step_input.
â”‚ +00000370: 6472 795f 7275 6e3a 0a20 2020 2020 2020  dry_run:.       
â”‚ +00000380: 2061 7069 2e63 7265 6174 655f 6e61 6d65   api.create_name
â”‚ +00000390: 7370 6163 6528 0a20 2020 2020 2020 2020  space(.         
â”‚ +000003a0: 2020 2063 6c69 656e 742e 5631 4e61 6d65     client.V1Name
â”‚ +000003b0: 7370 6163 6528 6170 695f 7665 7273 696f  space(api_versio
â”‚ +000003c0: 6e3d 2776 3127 2c20 6b69 6e64 3d27 4e61  n='v1', kind='Na
â”‚ +000003d0: 6d65 7370 6163 6527 2c20 6d65 7461 6461  mespace', metada
â”‚ +000003e0: 7461 3d6d 6574 615f 6461 7461 2929 0a20  ta=meta_data)). 
â”‚ +000003f0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
â”‚ +00000400: 206c 6f67 6765 722e 696e 666f 2866 2246   logger.info(f"F
â”‚ +00000410: 6f75 6e64 206e 616d 6573 7061 6365 207b  ound namespace {
â”‚ +00000420: 6e61 6d65 7370 6163 657d 2229 0a20 2020  namespace}").   
â”‚ +00000430: 2072 6574 7572 6e20 6e61 6d65 7370 6163   return namespac
â”‚ +00000440: 650a 0a0a 6465 6620 6465 706c 6f79 5f68  e...def deploy_h
â”‚ +00000450: 656c 6d5f 6368 6172 7428 6c6f 6767 6572  elm_chart(logger
â”‚ +00000460: 3a20 4c6f 6767 6572 2c20 6368 6172 743a  : Logger, chart:
â”‚ +00000470: 2064 6963 745b 7374 722c 2043 7573 746f   dict[str, Custo
â”‚ +00000480: 6d52 6573 6f75 7263 6544 6566 696e 6974  mResourceDefinit
â”‚ +00000490: 696f 6e5d 2c20 7374 6570 5f69 6e70 7574  ion], step_input
â”‚ +000004a0: 3a20 496e 7075 742c 0a20 2020 2020 2020  : Input,.       
â”‚ +000004b0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
â”‚ +000004c0: 656c 6561 7365 5f6e 616d 653a 2073 7472  elease_name: str
â”‚ +000004d0: 2920 2d3e 204f 7574 7075 743a 0a20 2020  ) -> Output:.   
â”‚ +000004e0: 2070 726f 7065 7274 6965 7320 3d20 7374   properties = st
â”‚ +000004f0: 6570 5f69 6e70 7574 2e72 756e 5f70 726f  ep_input.run_pro
â”‚ +00000500: 7065 7274 6965 730a 2020 2020 636f 6e74  perties.    cont
â”‚ +00000510: 6578 7420 3d20 636c 7573 7465 725f 636f  ext = cluster_co
â”‚ +00000520: 6e66 6967 2870 726f 7065 7274 6965 732e  nfig(properties.
â”‚ +00000530: 7461 7267 6574 292e 636f 6e74 6578 740a  target).context.
â”‚ +00000540: 2020 2020 6e61 6d65 7370 6163 6520 3d20      namespace = 
â”‚ +00000550: 7570 7365 7274 5f6e 616d 6573 7061 6365  upsert_namespace
â”‚ +00000560: 286c 6f67 6765 722c 2073 7465 705f 696e  (logger, step_in
â”‚ +00000570: 7075 742c 2063 6f6e 7465 7874 290a 2020  put, context).  
â”‚ +00000580: 2020 7265 7475 726e 2068 656c 6d2e 696e    return helm.in
â”‚ +00000590: 7374 616c 6c28 6c6f 6767 6572 2c20 6368  stall(logger, ch
â”‚ +000005a0: 6172 742c 2073 7465 705f 696e 7075 742c  art, step_input,
â”‚ +000005b0: 2072 656c 6561 7365 5f6e 616d 652c 206e   release_name, n
â”‚ +000005c0: 616d 6573 7061 6365 2c20 636f 6e74 6578  amespace, contex
â”‚ +000005d0: 7429 0a                                  t).
â”œâ”€â”€ mpyl/steps/deploy/k8s/helm.py
â”‚ @@ -2,55 +2,49 @@
â”‚  step.
â”‚  """
â”‚  
â”‚  import shutil
â”‚  from logging import Logger
â”‚  from pathlib import Path
â”‚  
â”‚ -from .service import ServiceChart
â”‚ -from ...models import RunProperties, Input, Output
â”‚ +from .resources.crd import to_yaml, CustomResourceDefinition
â”‚ +from ...models import RunProperties, Output, Input
â”‚  from ....utilities.subprocess import custom_check_output
â”‚  
â”‚  
â”‚  def to_chart_metadata(chart_name: str, run_properties: RunProperties):
â”‚      return f"""apiVersion: v3
â”‚  name: {chart_name}
â”‚ -description: A helm chart used by the MPL pipeline
â”‚ +description: A helm chart used by the MPyL pipeline
â”‚  type: application
â”‚  version: 0.1.0
â”‚  appVersion: "{run_properties.versioning.identifier}"
â”‚  """
â”‚  
â”‚  
â”‚ -def write_chart(step_input: Input, chart_path: Path, chart_metadata: str) -> None:
â”‚ -    if step_input.required_artifact:
â”‚ -        image_name = step_input.required_artifact.spec['image']
â”‚ -    else:
â”‚ -        raise ValueError('Required artifact must be defined')
â”‚ -
â”‚ -    service_chart = ServiceChart(step_input, image_name)
â”‚ -
â”‚ +def write_chart(chart: dict[str, CustomResourceDefinition], chart_path: Path, chart_metadata: str) -> None:
â”‚      shutil.rmtree(chart_path, ignore_errors=True)
â”‚      template_path = chart_path / Path("templates")
â”‚      template_path.mkdir(parents=True, exist_ok=True)
â”‚  
â”‚      with open(chart_path / Path("Chart.yaml"), mode='w+', encoding='utf-8') as file:
â”‚          file.write(chart_metadata)
â”‚      with open(chart_path / Path("values.yaml"), mode='w+', encoding='utf-8') as file:
â”‚          file.write("# This file is intentionally left empty. All values in /templates have been pre-interpolated")
â”‚  
â”‚ -    templates = service_chart.to_chart()
â”‚ -    for name, template in templates.items():
â”‚ -        with open(template_path / str(name), mode='w+', encoding='utf-8') as file:
â”‚ +    my_dictionary: dict[str, str] = dict(map(lambda item: (item[0], to_yaml(item[1])), chart.items()))
â”‚ +
â”‚ +    for name, template in my_dictionary.items():
â”‚ +        with open(template_path / name, mode='w+', encoding='utf-8') as file:
â”‚              file.write(template)
â”‚  
â”‚  
â”‚ -def install(logger: Logger, step_input: Input, name_space: str, kube_context: str) -> Output:
â”‚ -    chart_name = step_input.project.name.lower()
â”‚ +def install(logger: Logger, chart: dict[str, CustomResourceDefinition], step_input: Input, chart_name: str,
â”‚ +            name_space: str, kube_context: str) -> Output:
â”‚      chart_path = Path(step_input.project.target_path) / "chart"
â”‚ -    write_chart(step_input, chart_path, to_chart_metadata(chart_name, step_input.run_properties))
â”‚ +    write_chart(chart, chart_path, to_chart_metadata(chart_name, step_input.run_properties))
â”‚  
â”‚      cmd = f"helm upgrade -i {chart_name} -n {name_space} --kube-context {kube_context} {chart_path}"
â”‚      if step_input.dry_run:
â”‚          cmd = f"helm upgrade -i {chart_name} -n namespace --kube-context {kube_context} {chart_path} --debug --dry-run"
â”‚  
â”‚      return custom_check_output(logger, cmd)
â”œâ”€â”€ mpyl/steps/test/sbt.py
â”‚ @@ -88,15 +88,13 @@
â”‚  
â”‚      @staticmethod
â”‚      def _construct_sbt_command_test_without_coverage(step_input: Input):
â”‚          return [f'{step_input.project.name}/test']
â”‚  
â”‚      @staticmethod
â”‚      def _construct_sbt_command(step_input: Input, config: SbtConfig, commands_fn: Callable[[Input], list[str]]):
â”‚ -        command = config.to_command()
â”‚ -        command.append("; ".join(commands_fn(step_input)))
â”‚ -        return command
â”‚ +        return config.to_command(config.test_with_client, commands_fn(step_input))
â”‚  
â”‚      @staticmethod
â”‚      def _extract_test_report(project: Project, step_input: Input) -> Artifact:
â”‚          return input_to_artifact(artifact_type=ArtifactType.JUNIT_TESTS, step_input=step_input,
â”‚                                   spec={TEST_OUTPUT_PATH_KEY: f'{project.test_report_path}'})
â”œâ”€â”€ mpyl/utilities/repo/__init__.py
â”‚ @@ -44,14 +44,18 @@
â”‚          return self
â”‚  
â”‚      @property
â”‚      def get_sha(self):
â”‚          return self._repo.head.commit.hexsha
â”‚  
â”‚      @property
â”‚ +    def get_short_sha(self):
â”‚ +        return self._repo.git.rev_parse(self._repo.head, short=True)
â”‚ +
â”‚ +    @property
â”‚      def get_branch(self):
â”‚          return self._repo.active_branch.name
â”‚  
â”‚      def root_dir(self) -> Path:
â”‚          return Path(self._root_dir)
â”‚  
â”‚      def changes_in_branch(self) -> list[Revision]:
â”‚ @@ -70,10 +74,11 @@
â”‚          main = self._config.main_branch
â”‚          return remote.fetch(f"+refs/heads/{main}:refs/heads/{main}")
â”‚  
â”‚      def changes_in_commit(self) -> set[str]:
â”‚          changed: set[str] = set(self._repo.git.diff(None, name_only=True).splitlines())
â”‚          return changed.union(self._repo.untracked_files)
â”‚  
â”‚ -    def find_projects(self) -> set[str]:
â”‚ +    def find_projects(self) -> list[str]:
â”‚          """ returns a set of all project.yml files """
â”‚ -        return set(self._repo.git.ls_files(f'**/{Project.project_yaml_path()}').splitlines())
â”‚ +        projects = set(self._repo.git.ls_files(f'**/{Project.project_yaml_path()}').splitlines())
â”‚ +        return sorted(projects)
â”œâ”€â”€ mpyl/utilities/sbt/__init__.py
â”‚ @@ -7,27 +7,37 @@
â”‚  @dataclass(frozen=True)
â”‚  class SbtConfig:
â”‚      java_opts: str
â”‚      sbt_opts: str
â”‚      sbt_command: str
â”‚      test_with_coverage: bool
â”‚      verbose: bool
â”‚ +    build_with_client: bool
â”‚ +    test_with_client: bool
â”‚  
â”‚      @staticmethod
â”‚      def from_config(config: Dict):
â”‚          sbt_config = config.get('sbt', None)
â”‚          if not sbt_config:
â”‚              raise KeyError(f"'sbt' could not be loaded from {config}")
â”‚ -        return SbtConfig(sbt_command=sbt_config['command'],
â”‚ -                         java_opts=sbt_config['javaOpts'],
â”‚ -                         sbt_opts=sbt_config['sbtOpts'],
â”‚ -                         test_with_coverage=(str(sbt_config['testWithCoverage']).lower() == 'true'),
â”‚ -                         verbose=(str(sbt_config['verbose']).lower() == 'true')
â”‚ -                         )
â”‚ +        return SbtConfig(
â”‚ +            sbt_command=sbt_config['command'],
â”‚ +            java_opts=sbt_config['javaOpts'],
â”‚ +            sbt_opts=sbt_config['sbtOpts'],
â”‚ +            test_with_coverage=(str(sbt_config['testWithCoverage']).lower() == 'true'),
â”‚ +            verbose=(str(sbt_config['verbose']).lower() == 'true'),
â”‚ +            build_with_client=(str(sbt_config.get('clientMode', {}).get('build')).lower() == 'true'),
â”‚ +            test_with_client=(str(sbt_config.get('clientMode', {}).get('test')).lower() == 'true')
â”‚ +        )
â”‚  
â”‚ -    def to_command(self):
â”‚ +    def to_command(self, client_mode: bool, sbt_commands: list[str]):
â”‚          cmd = [self.sbt_command]
â”‚          if self.verbose:
â”‚              cmd.append('-v')
â”‚ +        if client_mode:
â”‚ +            cmd.append('--client')
â”‚          cmd.extend([f'-J{opt}' for opt in self.java_opts.split(' ')])
â”‚          cmd.extend([f'-D{opt}' for opt in self.sbt_opts.split(' ')])
â”‚ +
â”‚ +        joined_commands = "; ".join(sbt_commands)
â”‚ +        cmd.append(f"'{joined_commands}" if client_mode else joined_commands)
â”‚          return cmd
â”‚   --- mpyl/steps/deploy/k8s/service.py
â”œâ”€â”€ +++ mpyl/steps/deploy/k8s/chart.py
â”‚â”„ Files 17% similar despite different names
â”‚ @@ -1,25 +1,25 @@
â”‚  """
â”‚  Data classes for the composition of Custom Resource Definitions.
â”‚  More info: https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/
â”‚  """
â”‚  
â”‚  from dataclasses import dataclass
â”‚ -from typing import Dict, Optional
â”‚ +from typing import Dict
â”‚  
â”‚  from kubernetes.client import V1Deployment, V1Container, V1DeploymentSpec, V1ObjectMeta, V1PodSpec, \
â”‚      V1RollingUpdateDeployment, V1LabelSelector, V1ContainerPort, V1EnvVar, V1Service, \
â”‚      V1ServiceSpec, V1ServicePort, V1ServiceAccount, V1LocalObjectReference, \
â”‚      V1EnvVarSource, V1SecretKeySelector, V1Probe, ApiClient, V1HTTPGetAction, V1ResourceRequirements, \
â”‚ -    V1PodTemplateSpec, V1DeploymentStrategy
â”‚ +    V1PodTemplateSpec, V1DeploymentStrategy, V1Job, V1JobSpec, V1CronJob, V1CronJobSpec, V1JobTemplateSpec
â”‚  from ruamel.yaml import YAML
â”‚  
â”‚ -from .resources.crd import to_yaml  # pylint: disable = no-name-in-module
â”‚ +from .resources.crd import CustomResourceDefinition, to_dict  # pylint: disable = no-name-in-module
â”‚  from .resources.customresources import V1AlphaIngressRoute, V1SealedSecret  # pylint: disable = no-name-in-module
â”‚ -from ...models import Input
â”‚ +from ...models import Input, ArtifactType
â”‚  from ....project import Project, KeyValueProperty, Probe, Deployment, TargetProperty, Resources, Target
â”‚  
â”‚  yaml = YAML()
â”‚  
â”‚  # Determined (unscientifically) to be sensible factors.
â”‚  # Based on actual CPU usage, pods rarely use more than 10% of the allocated CPU. 60% usage is healthy, so we
â”‚  # scale down to 20% in order to keep some slack.
â”‚ @@ -51,47 +51,45 @@
â”‚      @staticmethod
â”‚      def from_config(values: dict):
â”‚          return KubernetesConfig(resources_defaults=ResourceDefaults.from_config(values['resources']),
â”‚                                  liveness_probe_defaults=values['livenessProbe'],
â”‚                                  startup_probe_defaults=values['startupProbe'])
â”‚  
â”‚  
â”‚ -class ServiceChart:
â”‚ +class ChartBuilder:
â”‚      step_input: Input
â”‚      project: Project
â”‚      mappings: dict[int, int]
â”‚      env: list[KeyValueProperty]
â”‚      sealed_secrets: list[KeyValueProperty]
â”‚      deployment: Deployment
â”‚      target: Target
â”‚      release_name: str
â”‚ -    image_name: str
â”‚      kubernetes_config: KubernetesConfig
â”‚  
â”‚ -    def __init__(self, step_input: Input, image_name: str):
â”‚ +    def __init__(self, step_input: Input):
â”‚          self.step_input = step_input
â”‚          project = self.step_input.project
â”‚          self.project = project
â”‚          if project.deployment is None:
â”‚              raise AttributeError("deployment field should be set")
â”‚          kubernetes_config_dict = step_input.run_properties.config.get('project', {}).get('deployment', {}).get(
â”‚              'kubernetes', {})
â”‚          if kubernetes_config_dict is None:
â”‚              raise KeyError("Configuration should have project.deployment.kubernetes section")
â”‚  
â”‚          self.kubernetes_config = KubernetesConfig.from_config(kubernetes_config_dict)
â”‚  
â”‚          self.deployment = project.deployment
â”‚          properties = self.deployment.properties
â”‚ -        self.env = properties.env if properties.env else []
â”‚ -        self.sealed_secrets = properties.sealed_secret if properties.sealed_secret else []
â”‚ +        self.env = properties.env if properties and properties.env else []
â”‚ +        self.sealed_secrets = properties.sealed_secret if properties and properties.sealed_secret else []
â”‚          self.mappings = self.project.kubernetes.port_mappings
â”‚          self.target = step_input.run_properties.target
â”‚          self.release_name = self.project.name.lower()
â”‚ -        self.image_name = image_name
â”‚  
â”‚      def _to_labels(self) -> Dict:
â”‚          run_properties = self.step_input.run_properties
â”‚          app_labels = {'name': self.project.name, 'app.kubernetes.io/version': run_properties.versioning.identifier,
â”‚                        'app.kubernetes.io/managed-by': 'Helm', 'app.kubernetes.io/name': self.release_name,
â”‚                        'app.kubernetes.io/instance': self.release_name}
â”‚  
â”‚ @@ -120,107 +118,134 @@
â”‚      def _to_k8s_model(values: dict, model_type):
â”‚          return ApiClient()._ApiClient__deserialize(values, model_type)  # pylint: disable=protected-access
â”‚  
â”‚      @staticmethod
â”‚      def _to_probe(probe: Probe, defaults: dict, target: Target) -> V1Probe:
â”‚          values = defaults.copy()
â”‚          values.update(probe.values)
â”‚ -        v1_probe: V1Probe = ServiceChart._to_k8s_model(values, V1Probe)
â”‚ +        v1_probe: V1Probe = ChartBuilder._to_k8s_model(values, V1Probe)
â”‚          path = probe.path.get_value(target)
â”‚          v1_probe.http_get = V1HTTPGetAction(path='/health' if path is None else path, port='port-0')
â”‚          return v1_probe
â”‚  
â”‚      def to_service(self) -> V1Service:
â”‚          service_ports = list(map(lambda key: V1ServicePort(port=key, target_port=self.mappings[key], protocol="TCP",
â”‚                                                             name=f"{key}-webservice-port"), self.mappings.keys()))
â”‚  
â”‚          return V1Service(api_version='v1', kind='Service', metadata=self._to_object_meta(),
â”‚                           spec=V1ServiceSpec(type="ClusterIP", ports=service_ports,
â”‚                                              selector=self._to_selector().match_labels))
â”‚  
â”‚ -    def to_ingress_routes(self) -> Optional[V1AlphaIngressRoute]:
â”‚ -        if not self.deployment.traefik:
â”‚ -            return None
â”‚ +    def to_job(self) -> V1Job:
â”‚ +        job_container = V1Container(
â”‚ +            name=self.project.name, image=self._get_image(), env=self._get_env_vars(), image_pull_policy="Always",
â”‚ +            resources=self._get_resources()
â”‚ +        )
â”‚ +        pod_template = V1PodTemplateSpec(
â”‚ +            metadata=self._to_object_meta(),
â”‚ +            spec=V1PodSpec(containers=[job_container], service_account=self.release_name,
â”‚ +                           service_account_name=self.release_name),
â”‚ +        )
â”‚ +        return V1Job(api_version='batch/v1', kind='Job', metadata=self._to_object_meta(),
â”‚ +                     spec=V1JobSpec(ttl_seconds_after_finished=3600, template=pod_template))
â”‚ +
â”‚ +    def to_cron_job(self) -> V1CronJob:
â”‚ +        values = self._get_kubernetes().cron
â”‚ +        job_template = V1JobTemplateSpec(spec=self.to_job().spec)
â”‚ +        template_dict = to_dict(job_template)
â”‚ +        values['jobTemplate'] = template_dict
â”‚ +        v1_cron_job_spec: V1CronJobSpec = ChartBuilder._to_k8s_model(values, V1CronJobSpec)
â”‚ +        return V1CronJob(api_version='batch/v1', kind='CronJob', metadata=self._to_object_meta(), spec=v1_cron_job_spec)
â”‚ +
â”‚ +    def to_ingress_routes(self) -> V1AlphaIngressRoute:
â”‚ +        if self.deployment.traefik is None:
â”‚ +            raise AttributeError("deployment.traefik field should be set")
â”‚ +
â”‚          return V1AlphaIngressRoute(metadata=self._to_object_meta(), hosts=self.deployment.traefik.hosts,
â”‚                                     service_port=123, name=self.release_name, target=self.target)
â”‚  
â”‚      def to_service_account(self) -> V1ServiceAccount:
â”‚          return V1ServiceAccount(api_version="v1", kind="ServiceAccount", metadata=self._to_object_meta(),
â”‚                                  image_pull_secrets=[V1LocalObjectReference("bigdataregistry")])
â”‚  
â”‚ -    def to_chart(self) -> dict[str, str]:
â”‚ -        chart = {'deployment': to_yaml(self.to_deployment()), 'serviceaccount': to_yaml(self.to_service_account()),
â”‚ -                 'service': to_yaml(self.to_service())}
â”‚ -        if self.sealed_secrets:
â”‚ -            chart['sealedsecrets'] = to_yaml(self.to_sealed_secrets())
â”‚ -
â”‚ -        if self.deployment.traefik:
â”‚ -            chart['ingress-https-route'] = to_yaml(self.to_ingress_routes())
â”‚ -
â”‚ -        return chart
â”‚ -
â”‚ -    def to_sealed_secrets(self) -> Optional[V1SealedSecret]:
â”‚ -        if self.sealed_secrets is None:
â”‚ -            return None
â”‚ -
â”‚ +    def to_sealed_secrets(self) -> V1SealedSecret:
â”‚          secrets: dict[str, str] = {}
â”‚          for secret in self.sealed_secrets:
â”‚              secrets[secret.key] = secret.get_value(self.target)
â”‚  
â”‚          return V1SealedSecret(name=self.release_name, secrets=secrets)
â”‚  
â”‚      @staticmethod
â”‚      def _to_resources(resources: Resources, defaults: ResourceDefaults, target: Target):
â”‚ -        cpus = resources.cpus if resources.cpus else defaults.cpus
â”‚ +        cpus = resources.cpus if resources and resources.cpus else defaults.cpus
â”‚          cpus_limit = cpus.get_value(target=target) * 1000.0
â”‚          cpus_request = cpus_limit * CPU_REQUEST_SCALE_FACTOR
â”‚  
â”‚ -        mem = resources.mem if resources.mem else defaults.mem
â”‚ +        mem = resources.mem if resources and resources.mem else defaults.mem
â”‚          mem_limit = mem.get_value(target=target)
â”‚          mem_request = mem_limit * MEM_REQUEST_SCALE_FACTOR
â”‚          return V1ResourceRequirements(limits={'cpu': f'{int(cpus_limit)}m', 'memory': f'{int(mem_limit)}Mi'},
â”‚                                        requests={'cpu': f'{int(cpus_request)}m', 'memory': f'{int(mem_request)}Mi'})
â”‚  
â”‚ -    def to_deployment(self) -> V1Deployment:
â”‚ +    def _get_image(self):
â”‚ +        docker_image = self.step_input.required_artifact
â”‚ +        if not docker_image or docker_image.artifact_type != ArtifactType.DOCKER_IMAGE:
â”‚ +            raise ValueError(f'Required artifact of type {ArtifactType.DOCKER_IMAGE.name} must be defined')
â”‚ +        return docker_image.spec['image']
â”‚ +
â”‚ +    def _get_kubernetes(self):
â”‚          kubernetes = self.deployment.kubernetes
â”‚          if kubernetes is None:
â”‚              raise AttributeError("deployment.kubernetes field should be set")
â”‚ +        return kubernetes
â”‚  
â”‚ -        ports = [
â”‚ -            V1ContainerPort(container_port=key, host_port=self.mappings[key], protocol="TCP", name=f'port-{idx}')
â”‚ -            for idx, key in enumerate(self.mappings.keys())
â”‚ -        ]
â”‚ +    def _get_resources(self):
â”‚ +        kubernetes = self._get_kubernetes()
â”‚ +        resources = kubernetes.resources
â”‚ +        defaults = self.kubernetes_config.resources_defaults
â”‚ +        return ChartBuilder._to_resources(resources, defaults, self.target)
â”‚ +
â”‚ +    def _get_env_vars(self):
â”‚          env_vars = list(
â”‚              filter(lambda v: v.value, map(lambda e: V1EnvVar(name=e.key, value=e.get_value(self.target)), self.env)))
â”‚ -
â”‚          sealed_for_target = list(
â”‚ -            filter(lambda v: v.get_value(self.target) is not None, self.deployment.properties.sealed_secret))
â”‚ +            filter(lambda v: v.get_value(self.target) is not None, self.sealed_secrets))
â”‚          sealed_secrets = list(map(lambda e: V1EnvVar(name=e.key, value_from=V1EnvVarSource(
â”‚              secret_key_ref=V1SecretKeySelector(key=e.key, name=self.release_name, optional=False))),
â”‚                                    sealed_for_target))
â”‚ +        return env_vars + sealed_secrets
â”‚  
â”‚ +    def to_deployment(self) -> V1Deployment:
â”‚ +
â”‚ +        ports = [
â”‚ +            V1ContainerPort(container_port=key, host_port=self.mappings[key], protocol="TCP", name=f'port-{idx}')
â”‚ +            for idx, key in enumerate(self.mappings.keys())
â”‚ +        ]
â”‚ +
â”‚ +        kubernetes = self._get_kubernetes()
â”‚          resources = kubernetes.resources
â”‚          defaults = self.kubernetes_config.resources_defaults
â”‚ -        instances = resources.instances if resources.instances else defaults.instances
â”‚  
â”‚          container = V1Container(
â”‚              name=self.project.name,
â”‚ -            image=self.image_name,
â”‚ -            env=env_vars + sealed_secrets,
â”‚ +            image=self._get_image(),
â”‚ +            env=self._get_env_vars(),
â”‚              ports=ports,
â”‚              image_pull_policy="Always",
â”‚ -            resources=ServiceChart._to_resources(resources, defaults, self.target),
â”‚ -            liveness_probe=ServiceChart._to_probe(kubernetes.liveness_probe,
â”‚ +            resources=ChartBuilder._to_resources(resources, defaults, self.target),
â”‚ +            liveness_probe=ChartBuilder._to_probe(kubernetes.liveness_probe,
â”‚                                                    self.kubernetes_config.liveness_probe_defaults,
â”‚                                                    self.target) if kubernetes.liveness_probe else None,
â”‚ -            startup_probe=ServiceChart._to_probe(kubernetes.startup_probe,
â”‚ +            startup_probe=ChartBuilder._to_probe(kubernetes.startup_probe,
â”‚                                                   self.kubernetes_config.startup_probe_defaults,
â”‚                                                   self.target) if kubernetes.startup_probe else None
â”‚          )
â”‚  
â”‚ +        instances = resources.instances if resources.instances else defaults.instances
â”‚ +
â”‚          return V1Deployment(
â”‚              api_version="apps/v1",
â”‚              kind="Deployment",
â”‚              metadata=V1ObjectMeta(annotations=self._to_annotations(), name=self.release_name,
â”‚                                    labels=self._to_labels()),
â”‚              spec=V1DeploymentSpec(
â”‚                  replicas=instances.get_value(target=self.target),
â”‚ @@ -231,7 +256,37 @@
â”‚                  ),
â”‚                  strategy=V1DeploymentStrategy(
â”‚                      rolling_update=V1RollingUpdateDeployment(max_surge="25%", max_unavailable="25%"),
â”‚                      type="RollingUpdate"),
â”‚                  selector=self._to_selector(),
â”‚              ),
â”‚          )
â”‚ +
â”‚ +
â”‚ +def to_service_chart(builder: ChartBuilder) -> dict[str, CustomResourceDefinition]:
â”‚ +    chart = {'deployment': builder.to_deployment(), 'serviceaccount': builder.to_service_account(),
â”‚ +             'service': builder.to_service()}
â”‚ +    if builder.sealed_secrets:
â”‚ +        chart['sealedsecrets'] = builder.to_sealed_secrets()
â”‚ +
â”‚ +    if builder.deployment.traefik:
â”‚ +        chart['ingress-https-route'] = builder.to_ingress_routes()
â”‚ +
â”‚ +    return chart
â”‚ +
â”‚ +
â”‚ +def to_job_chart(builder: ChartBuilder) -> dict[str, CustomResourceDefinition]:
â”‚ +    chart = {'job': builder.to_job(), 'serviceaccount': builder.to_service_account()}
â”‚ +
â”‚ +    if builder.sealed_secrets:
â”‚ +        chart['sealedsecrets'] = builder.to_sealed_secrets()
â”‚ +
â”‚ +    return chart
â”‚ +
â”‚ +
â”‚ +def to_cron_job_chart(builder: ChartBuilder) -> dict[str, CustomResourceDefinition]:
â”‚ +    chart = {'cronjob': builder.to_cron_job(), 'serviceaccount': builder.to_service_account()}
â”‚ +
â”‚ +    if builder.sealed_secrets:
â”‚ +        chart['sealedsecrets'] = builder.to_sealed_secrets()
â”‚ +
â”‚ +    return chart
â”‚   --- mpyl-0.0.8.dist-info/LICENSE
â”œâ”€â”€ +++ mpyl-0.0.9.dist-info/LICENSE
â”‚â”„ Files identical despite different names
â”‚   --- mpyl-0.0.8.dist-info/METADATA
â”œâ”€â”€ +++ mpyl-0.0.9.dist-info/METADATA
â”‚â”„ Files 0% similar despite different names
â”‚ @@ -1,10 +1,10 @@
â”‚  Metadata-Version: 2.1
â”‚  Name: mpyl
â”‚ -Version: 0.0.8
â”‚ +Version: 0.0.9
â”‚  Summary: Modular Pipeline Library
â”‚  Home-page: https://vandebron.github.io/mpyl
â”‚  Author: Vandebron Energie BV
â”‚  Project-URL: Documentation, https://vandebron.github.io/mpyl
â”‚  Project-URL: Source, https://github.com/Vandebron/mpyl
â”‚  Project-URL: Tracker, https://github.com/Vandebron/mpyl/issues
â”‚  Classifier: Topic :: Software Development :: Build Tools
â”‚   --- mpyl-0.0.8.dist-info/RECORD
â”œâ”€â”€ +++ mpyl-0.0.9.dist-info/RECORD
â”‚â”„ Files 8% similar despite different names
â”‚ @@ -1,68 +1,70 @@
â”‚ -mpyl/__init__.py,sha256=yHcp2JWhf43KQ1wkTXrMxLqVbQsBSoWFj_4w8KeLzCo,1952
â”‚ +mpyl/__init__.py,sha256=P3C0ql70EyN6Mk3zitknkQd1YLiWrQ7p4kKjr1f2EHE,1927
â”‚  mpyl/__main__.py,sha256=S7WS_61OT3kRc5RJq3vz4AI6N4YRU5h2KG1kBeQKK6I,215
â”‚ -mpyl/project.py,sha256=_5NaYDYh5hA3xSM0KMDKv6TqgXtiECa2_ZQWcegHfN4,11406
â”‚ +mpyl/project.py,sha256=eOoOq3q0GwAO98d6kKT9rt-3b8BLszmBKyhjrsoyzBA,11538
â”‚  mpyl/validation.py,sha256=aSyfAetAlnmFlj5QZittgCdU_P_FVjWnArRQ_Wzk2Xc,1069
â”‚ -mpyl/cli/__init__.py,sha256=9TBRwB04WDyQfGoF9vc1P9p7sgb79_mfGulRiGnvttQ,38
â”‚ +mpyl/cli/__init__.py,sha256=ylIL8Wh6ZFB_8ilrV8sh9DLRXngwz9xdyL6ECgIL7Wo,568
â”‚  mpyl/cli/build/__init__.py,sha256=HYego6gfL5ffgwUi7XLuUkQZiApwlxMIRns8ABcONdo,51
â”‚ -mpyl/cli/build/jenkins.py,sha256=uLeSCt9f7PjLSVOR4mW5rqKb4_ySbJ4DmW_Pzu67k7A,2212
â”‚ -mpyl/cli/build/mpyl.py,sha256=MlLd4xAIfCqj6cQZIW5oUbPptgl0KZ65s5qizxOTiN4,4353
â”‚ -mpyl/cli/commands/__init__.py,sha256=UH7MdYduBG_YoulgdiWkUCtcgGLzuYRGFzxaqoa0pyg,19
â”‚ -mpyl/cli/commands/build.py,sha256=rVvPDavHIQvIZtnUY1OHiJ7IplbXeCjyxWmShs1i1IQ,3210
â”‚ -mpyl/cli/commands/meta_info.py,sha256=L2Mj5CS-KDL2DVoC9zFG2Mf1A1lXYJ0JSYBwfpBHahQ,2178
â”‚ -mpyl/cli/commands/projects.py,sha256=yt35d0iinH8wOQM3pDA13yHoWKmc9SvOKZif9VyLRCM,1457
â”‚ +mpyl/cli/build/jenkins.py,sha256=-zYAuGIT_G2bkSKYCXJIpMA0JsVELffwRqKwvhbnRFE,2250
â”‚ +mpyl/cli/build/mpyl.py,sha256=gnfhZiUYoVNLJmZ5SAQ5V2hcdYQJhIdFidxVFf0UuPM,4542
â”‚ +mpyl/cli/commands/__init__.py,sha256=WCIqCDghvbs1k1Yi5Z77uWADYr5mMGIULQqbSljrBnw,471
â”‚ +mpyl/cli/commands/build.py,sha256=C1J9wdhJ7GOer0qfCdgQmjsth66kWuIu5ClMB_S40zk,4539
â”‚ +mpyl/cli/commands/meta_info.py,sha256=MJhWR8GxSL1Anx7Cs_6c0QU6_tYP_pNxaazGV8JoO60,2170
â”‚ +mpyl/cli/commands/projects.py,sha256=gzVGCwYq8kuIT1kgXmc23gzAR5ouN9cHbng4Z6_Iq2o,1756
â”‚ +mpyl/cli/projects/__init__.py,sha256=BNpkKojzNeQBtvivF3nsTV8HBvGMTClFckKtpvIuyaY,39
â”‚  mpyl/projects/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚  mpyl/projects/find.py,sha256=Rck2cuTXiGNJuEcnHBGDQvAlDlQL-MiK1b8i2WNJ1js,265
â”‚  mpyl/reporting/__init__.py,sha256=vRvt_67opWXCfe_zYZChT-YhjoPOahAjLagoaVzOcFM,92
â”‚  mpyl/reporting/formatting/__init__.py,sha256=GAvYJpHT2SMQxjiLCSqFy57PNWsGI_Ow2bFnA8cX08k,76
â”‚ -mpyl/reporting/formatting/markdown.py,sha256=cZb6o1gAiWA1BJvXdRPHDBO-uFNtxe-UDVOnmLE2yCg,2564
â”‚ +mpyl/reporting/formatting/markdown.py,sha256=RuTFSlK3D6O3ojry_465bf6G9J3fVUxZY5s8hKp3YBc,2622
â”‚  mpyl/reporting/formatting/text.py,sha256=YAQGBHfb8XktvGIqeKAyjaJeppEmVrMWQu8Oszm1TN8,1148
â”‚  mpyl/reporting/targets/__init__.py,sha256=OEj6eAiU_j6C3fcyMV9MgTTKdEMco2dYUVAf9OzpRYc,488
â”‚  mpyl/reporting/targets/github.py,sha256=dARo6Q1zarulI_b6-i02S4R74heVTlNFwZK4rWhKAJU,5538
â”‚ -mpyl/reporting/targets/jira.py,sha256=xCuZSqELi2id9zK18YwjDrqngHWpWYOSIjZx6Y0UWVw,4264
â”‚ +mpyl/reporting/targets/jira.py,sha256=KgHJcNy-Xa504lHT8aULNC18HKXn8x0fzTUw9YBmeB8,4656
â”‚  mpyl/reporting/targets/slack.py,sha256=T8gbKgJUzSZdl7ZkgXZdc-MGdmsIn3kzzf0QQuGFx88,5755
â”‚ -mpyl/schema/mpyl_config.schema.yml,sha256=IWLUJpcYJbmE66us9z7bZgxKl0UPGA_Wh3z0QNQnKg8,5688
â”‚ -mpyl/schema/project.schema.yml,sha256=xY-g-b89bMS985uHTM5F2oZKEVYMWr3JzBgG-Pl97sQ,26691
â”‚ +mpyl/schema/mpyl_config.schema.yml,sha256=7pek7Qty3gxr6TjVFyb-VxHtrrDSWRePehwsKt2Ttz0,5920
â”‚ +mpyl/schema/project.schema.yml,sha256=vd-LnJRgG1uCLJ3VhO785gufXuvb1N4toZUy7X1hnwQ,24999
â”‚  mpyl/stages/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚  mpyl/stages/discovery.py,sha256=iIizkXgT3-F5nAJe1UZFAwyTJN0iLQa-Bh1wPRC1yxE,2408
â”‚  mpyl/steps/__init__.py,sha256=jpcKUPNLQm_8LngC7mbwYUzaoiisgyJy4R8u0qOkmAU,6135
â”‚ -mpyl/steps/models.py,sha256=Q5ZQ5ROUNxdym104cpOpyaLSiVub-U2VjZURTxNUFFM,4536
â”‚ -mpyl/steps/run.py,sha256=nuE59ax48YR1SGH9NHdFXa1uhNbqWRRQTYfRrJBCayo,1589
â”‚ -mpyl/steps/steps.py,sha256=soXKwFCHlbNiUVCrmrtDVRqOawIbWH3Map6TRY6pRQk,5715
â”‚ +mpyl/steps/models.py,sha256=WzLkdCvszRODvgxX1nF0OXUoBxol7hyPX0jn8jQl9Bw,4839
â”‚ +mpyl/steps/run.py,sha256=h26b4qbL_2CIh4-KU8Tn8DHsGDz2-eFqpsZz4tLGe3M,2166
â”‚ +mpyl/steps/steps.py,sha256=QC8LvfWyOQ9ceO-g-xqmglTc0r6sAjM07RhcvVQ6L_s,5815
â”‚  mpyl/steps/build/__init__.py,sha256=EyPUNNDMQfJK-RVjYM9WvPhEDITbu2n4fx9mxhGLlDs,59
â”‚  mpyl/steps/build/docker_after_build.py,sha256=IAs69oDgdaoyjTOY3NGCUUPGP9hK4Wjx-MG2ii_hQ8s,2255
â”‚  mpyl/steps/build/dockerbuild.py,sha256=LMayPPf4ckOwwJAvOe6H9eAM7OMMAw67gGMqS0_P5U0,2032
â”‚  mpyl/steps/build/echo.py,sha256=on6n-zYs55z6_CouMrSTRIV_JDSTVdQ53raTt3im1qU,765
â”‚ -mpyl/steps/build/sbt.py,sha256=gxf7M2GOlXO5l_SlorHAyRBHlGeJdTTqO8B-PNEo3hM,2388
â”‚ +mpyl/steps/build/sbt.py,sha256=rvJzIVgsx6KrX5HW_jqEhu6yV2QAttEXQRJ3A7XJJ-k,2402
â”‚  mpyl/steps/deploy/__init__.py,sha256=14PYgOvt7YEO2Zw4kEeZxWUNBR7Lz91nSoJZpvJHqzE,60
â”‚  mpyl/steps/deploy/echo.py,sha256=f43TQmiY96Da_OLZcjkQx-RjCvlo09Dclpezv9RoMlo,1001
â”‚ -mpyl/steps/deploy/kubernetes.py,sha256=px32sHTnYY_pSkcKnAXsLLrl4a9life31cW-f-SdTp8,1960
â”‚ -mpyl/steps/deploy/k8s/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚ -mpyl/steps/deploy/k8s/helm.py,sha256=AWGMnVY47FGq2K0pwHI_BJVw___pd_0XERFjeS5NyS4,2195
â”‚ +mpyl/steps/deploy/kubernetes.py,sha256=60FnJ0nba3T87Pef_BAoxOcQxsNcr95LiOc_NgX-fM0,876
â”‚ +mpyl/steps/deploy/kubernetes_job.py,sha256=2365tZnTuoumEFqgNoqUX6ectXrXFc_YVyysbLcip0E,1008
â”‚ +mpyl/steps/deploy/k8s/__init__.py,sha256=v1Rev8KnpCg3FSx4BrxBLDeeUioDr_UHu9Qu2cFE8sQ,1491
â”‚ +mpyl/steps/deploy/k8s/chart.py,sha256=fl3u-8ZD4JN51a5VWr8NUquO3EBb3mWJjytumXlxs_0,13565
â”‚ +mpyl/steps/deploy/k8s/helm.py,sha256=r0OoYfvvzAe2IAJ4qPMG_zIB78w-idkL0_9IV2eKXWs,2097
â”‚  mpyl/steps/deploy/k8s/rancher.py,sha256=7P5nc6Jir3O3z2oE2Vd0HBlQxDesMwkQ86Omchh1-Es,1431
â”‚ -mpyl/steps/deploy/k8s/service.py,sha256=Vj0UVsQICO8MyhLMpQuk3uQFq-q7cu9zRLlEyC8irM4,11097
â”‚  mpyl/steps/deploy/k8s/resources/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚  mpyl/steps/deploy/k8s/resources/crd.py,sha256=ShjvwOK9648yM0-US4m6OS5824hfgMEnUU8uwIe91fI,4418
â”‚  mpyl/steps/deploy/k8s/resources/customresources.py,sha256=qoIy0Xso1B4ftM5i00pcsgSOZkv6frAGsT9k3p9JxoA,1330
â”‚  mpyl/steps/deploy/k8s/resources/schema/traeffik.schema.yml,sha256=TJAs7dC-xSajyQfQFFFc9AAa2_VyHDFpRMh7I17W2MY,11697
â”‚  mpyl/steps/test/__init__.py,sha256=XL1gSbIMJYSFcy4Vf8YRbZM9yAs3Fzvq2tfX9xTDZX8,58
â”‚  mpyl/steps/test/after_test.py,sha256=bKTBVFm88s4Kzr6JypxLAbKTlbRsha7gff3RjSr3ip0,1428
â”‚  mpyl/steps/test/before_test.py,sha256=IOUvAa3lKox8IKS28aGmmWJMNWcQWv9yGnTydVBvM14,2453
â”‚  mpyl/steps/test/dockertest.py,sha256=2IOKdT2FqcDGtWqOJGmSZWOjktH9d9sZPOqODJH55Qk,2830
â”‚  mpyl/steps/test/echo.py,sha256=Ca-kMWw4V9uFl3wSiOoJRbVTdbnI_MHnWx6y5e-LeNk,724
â”‚ -mpyl/steps/test/sbt.py,sha256=a1_zqi8eK1M9ODE3_IPVZz2Dakue53LyaGnjwCSDC1c,4706
â”‚ +mpyl/steps/test/sbt.py,sha256=vemH1UWKw4jolwQeeVdhrLpQeDostkLG_WbHce-ewbM,4669
â”‚  mpyl/utilities/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
â”‚  mpyl/utilities/docker/__init__.py,sha256=vOS-pgSfCdYw7fFtIZkPDVCJDYiYSLNh_PHEe15DlY8,3315
â”‚  mpyl/utilities/github/__init__.py,sha256=VumtjLWl2QAeQvPWGDGQ51EGmvGA1rm1xOLsivW3s5E,1547
â”‚  mpyl/utilities/jenkins/__init__.py,sha256=hUtF0yi5TeiE_wBhT1-mhkkohKSnyZffMkPY1wAC8Uo,1542
â”‚  mpyl/utilities/jenkins/runner.py,sha256=pv8N4jZy0r8cVzyrzanA2dVEXW9AeEkhtuxoZNULDWY,5016
â”‚  mpyl/utilities/junit/__init__.py,sha256=ZnIs3muoUPTpb9DlcrjWl4G8HC8Xb3PIcL7AHGdzb1Q,1280
â”‚  mpyl/utilities/pyaml_env/__init__.py,sha256=mJaO3uKnt5QUBvqKAIer3uvv1aD4qOX4djvNc27P71g,754
â”‚ -mpyl/utilities/repo/__init__.py,sha256=8xJlCr80SMhgvwjXxAihCpLQIkgCU9j0LvQ0P8gc58k,2558
â”‚ -mpyl/utilities/sbt/__init__.py,sha256=67sQE8z_v5kvSMoTRu83uGe-2jjdMPQTaOazAsQbNMA,1087
â”‚ +mpyl/utilities/repo/__init__.py,sha256=qRCDDtXRqSY7rR4I88nsbzyZucRa1wboOMoazmxW7X0,2708
â”‚ +mpyl/utilities/sbt/__init__.py,sha256=zriEJFx9s-mg2qNrHxZeygEqztGDhP9Kk54pKVwFIS0,1520
â”‚  mpyl/utilities/subprocess/__init__.py,sha256=eIE5t57AVwuRUC1QFYzKSviE8tVa4QjF3s9KQWi_eyU,1338
â”‚ -mpyl-0.0.8.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
â”‚ -mpyl-0.0.8.dist-info/METADATA,sha256=hzjTaqveO9Aa9fwNEy9K_e2w-bmG0wvv4Xv8VgBH7Wk,2914
â”‚ -mpyl-0.0.8.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
â”‚ -mpyl-0.0.8.dist-info/entry_points.txt,sha256=Jf4zjGLsiokFbaQ2dfX9AC5Bu3kp7zxrBOAzErmAYs8,35
â”‚ -mpyl-0.0.8.dist-info/top_level.txt,sha256=xVSrrk0ECDxKYaW8mAyGy02yY8KhKlUSyzHaq9UDVNs,5
â”‚ -mpyl-0.0.8.dist-info/RECORD,,
â”‚ +mpyl-0.0.9.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
â”‚ +mpyl-0.0.9.dist-info/METADATA,sha256=EQ7arkX8CO7VvsIhiQo-kqy6RThIxo71z4H24ZjvU-c,2914
â”‚ +mpyl-0.0.9.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
â”‚ +mpyl-0.0.9.dist-info/entry_points.txt,sha256=Jf4zjGLsiokFbaQ2dfX9AC5Bu3kp7zxrBOAzErmAYs8,35
â”‚ +mpyl-0.0.9.dist-info/top_level.txt,sha256=xVSrrk0ECDxKYaW8mAyGy02yY8KhKlUSyzHaq9UDVNs,5
â”‚ +mpyl-0.0.9.dist-info/RECORD,,
